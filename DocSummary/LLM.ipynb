{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd2a135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e4f5c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =  r'D:\\Spyder_files\\NoteBooks\\Projects\\DocSummary\\train.csv'\n",
    "df = pd.read_csv(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36293a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Summarize the first paper\n",
    "summary = summarizer(df['clean_text'][0], max_length=150, min_length=40, do_sample=False)\n",
    "print(summary[0]['summary_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f70921f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "paper_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "summary",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "clean_text",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "4f102ba8-f947-4a74-a2a6-d25de959f18a",
       "rows": [
        [
         "0",
         "0",
         "## FROM SOVEREIGNTY TO EXTRATERRITORIAL CONSCIOUSNESS\n\n\nSince 1997, the concept of extraterritoriality has been configured in the political tension between Hong Kong and Beijing. From the perspective of the Central Government, it is fundamental for the people of China to shijian zhuquan instantiate its sovereignty over Hong Kong. But while most Hong / Kong residents insist on interpreting this concept in terms of the Euro-American notion of selfdetermination  (zizhu / making decisions  for  oneself),  the  Beijing  government  believes  that  the Hong Kong legislature must make decisions in conformation to the larger will of the people, which the Party represents, a concept taken from the writings of Lenin and Stalin (Gao 2010: 26-30). This tension is crystalised in the long debate about Article 23 of the Hong Kong Basic Law, which requires  the  SAR  to  'enact  laws  on  its  own  to  prohibit  any  act  of  treason,  secession,  sedition, subversion  against  the  Central  People's  Government'  (China  1995  [1991]:  8-9;  Hong  Kong Human Rights Monitor 2004), and the Occupy Central movement demanding for the Hong Kong residents' right to nominate candidates for the Chief Executive election in 2017. From Beijing's perspective, the Hong Kong legislature is obliged to pass laws that will ascertain the larger political will that the Party represents, but for the residents in Hong Kong, such laws infringe their civil rights  and  violate the  SAR's  rights  to  make  its  own  legal  decisions.  In  the  eyes  of  many  Hong\n\nKongers, while Hong Kong is posited within the sovereign authority of the Chinese government, there is an extra juridical dimension in excess of the state power, instantiated in Hong Kong as a terrain free of any sovereign intervention.\n\nThis concept of extraterritoriality was developed out of a pluralistic juridical history. In Europe, the  idea  of  extraterritoriality  emerged  between  the  fifteenth  and  sixteenth  centuries  and  became matured,  together  with  the  idea  of  the  nation  states,  around  the  seventeenth  century.  At  first,  the Catholic Church defined Africa and the Americas as extraterritorial spaces, i.e. terra /land that lay beyond European jurisdiction and therefore could be freely acquired as colonies (Schmitt  2006 [1950]: 215-17). By the eighteenth century, the 'Orient' was seen as exercising an unsystematic notion of law, which was considered incompatible with the European conception of legality, thus justifying the right of European subjects to bring their laws and exercise them outside the sovereign terrains  of  their  nation  states  (Cassel  2012:  39-62).  During  the  1820s  and  1830s,  Portuguese, British, and  American merchants accepted with reluctance that they were legally bound by the codes of the Qing Empire (1644-1911). Yet in 1844, the Treaty of Wanghia (Wangxia), signed between the Qing Empire and the United States in Macau, stipulated that American citizens were to enjoy extraterritorial privileges, a clause that was then copied and provided for in all subsequent treaties between China and other European nation states (Fan 2015: 38; Ruskola 2013: 128-42).\n\nBetween 1844 and 1895, the European and Chinese understandings of extraterritoriality were somewhat different (Cassel 2012: 15-38). The Qing Empire was not a nation state as defined in  Euro-American  terms;  it  was  an  empire  governed  and  administered  with  a  linguistically, ethnically, culturally, and legally pluralistic system. The Qing code was a mixture of fazhi /rule by the law of the land and renzhi/judgment in accordance with the law of the political community to which a person belonged, and hence subjects had the right to be judged in accordance with the laws of their  respective  communities, which overrode the law of the  land where they  actually resided. In a legal case involving a dispute between subjects of two different ethnicities, a huishen /mixed court would be set up, presided by a Qing judge and accompanied by legal observers from the two respective communities. In this light, the Zongli Yamen/Foreign office at first understood extraterritoriality as a huishen quan/right of being judged in a mixed court, not a colonial privilege (Cassel 2012: 63-84). In 1863, the Qing government even established the famous Shanghai Mixed Court, which dealt with legal processes between Chinese and Euro-American subjects. In the SinoJapanese  Friendship  and  Trade  Treaty  (1871),  the  Japanese  delegates  called  the  huishen  quan enjoyed  by  the  Qing  subjects  in  Japan  sagaihōgen  (pronounced  zhiwai  faquan  in  Mandarin), borrowed in  1895  by  the  Qing  officials  to  redefine  the  extraterritorial  clause  in  the  Treaty  of Shimonoseki as a colonial privilege (Cassel 2012: 85-114).\n\nDuring the Republican period (1911-49), both Hong Kong and the foreign concessions of Shanghai were referred to as extraterritorial spaces, areas where the Chinese law formed only one component  of  a  complex  and  often  internally  inconsistent  pluralistic  system.  Based  on  the historical plurality of this concept, I propose to repurpose this term critically and redefine it in two ways: (1) these zones are geographically and juridically extraterritorial, that is, they are parts of the  larger  Chinese  territory;  they  somehow  stand  outside,  but  are  potentially  subject  to,  direct sovereign intervention from China; (2) because of its geographical and juridical extraterritoriality, its cultural, linguistic, and political spheres can be understood as pluralistic formations where both Chinese  and  Euro-American  discourses  unsystematically,  inconsistently,  or  even  conflictingly compete and negotiate with each other. The latter definition resonates with Shih Shu-mei's (2001: 34-35) definition of semicolonialism: a form of colonial consciousness based on unsystematic, mutually conflicting, and highly fragmented notions of Euro-American ideas and values that were reinvented and reconfigured through a complex discourse of translations.\n\nThe lack of direct sovereign intervention created an illusion, among those people who live in these zones, that their sense of cosmopolitanism, social mobility, political freedom, economic pleasure, and cultural fluidity are the results of such an extraterritorial privilege. However, I do not wish to reduce such political consciousness as a colonial privilege; rather, its affect, through Hong Kong's colonial experience, has been deeply ingrained in the Mainland-Hong Kong relationship under its specific historical conditions. In this sense, extraterritoriality, a colonial privilege that undercut Chinese sovereignty, has produced a sense of social, cultural, economic and political difference among  the  colonised  and  postcolonial  subjects.  As  Ackbar  Abbas  (2002  [1997]:  6-8)  argues, colonialism  in  Hong  Kong  was  characterised  by  a  'strange  dialectic  between  autonomy  and dependency that we see in Hong Kong's relation both to Britain and China' through a process of mutual misrecognition. As I argued in an article about the extraterritorial consciousness of  the Hong Kong Mandarin musical produced between 1945 and 1949 (Fan 2015: 39):\n\nas a Hong Konger, when I am being asked 'Are you Chinese?', I always feel compelled to answer  'No,  I'm  a  Hong  Konger.'  But  when  I  am  asked  the  reverse  'Are  you  a  Hong Konger?', I always find myself denying it by saying 'No, I am Chinese.' Thomas Elsaesser (2009: 47-62) calls this process 'double occupancy', that I am constantly doubly occupied by two mutually conflicting identities. Each time I choose one identity over the other, I am actively  putting  the  other  identity  'under  erasure',  i.e.  I  make  visible  the  structural difference and process of contestation between these two identities (Derrida 1976).\n\nSuch a difference is instantiated as an internally conflicting belief that one stands both inside and outside a larger national imagination and political consciousness. Ironically, the more eagerly the state  wishes  to  suture this  imaginary  gap,  the  more  adamantly  Hong  Kongers  feel  the  need  to redefine this  boundary as an attempt to reindividuate themselves from the Other. In this sense, extraterritoriality, despite its colonial history, has also been mobilised by Hong Kongers as a means of sociopolitical resistance.\n\n\n## FROM CEPA TO EXTRATERRITORIAL CINEMA\n\n\nIn cinema, through a series of legislations between 1998 and 2003, Hong Kong was reconfigured as an extraterritorial zone that occupies the threshold between the inside and outside of Chinese cinema. CEPA, signed in 2003, defines a Hong Kong production as a foreign-produced Chineselanguage film made by a Hong-Kong registered company that owns 75 per cent of its copyright. Yet if the company submits the screenplay to the China Film Bureau and passes its pre-censorship, it will be a granted domestic status and be distributed freely in the Mainland movie theatres. Once a Hong Kong production acquires its domestic status, it can persuade Mainland investors to finance the film. In 2006, of the 51 commercially released features produced in Hong Kong, 29 (56.86 per cent) of them were granted domestic status (Yang 2012: 20-21). In this sense, big-budget Hong Kong films financed by Mainland companies are best understood as extraterritorial productions that submit themselves to Mainland's legal regulation or a Mainland production that enjoys certain extraterritorial privileges.\n\nAccording to Lie Fu (2006: 615-18), Yang (2012: 46-51), and Zhao (2008: 216-19), CEPA was initially designed as a step towards national integration. Yet the China Film Bureau and the Mainland production companies soon realised that the spectators in Hong Kong, Shanghai and Beijing - the three major film markets - carry different qinggan  affectivities. Yang (2012: 51-/ 56) argues that the Film Bureau and the production companies encourage projects that can help\n\nachieve  yishi  fenghe  /ideological  suture.  What  it means  is  that  a  commercially  successful  film should reconnect the two mutually  incoherent ideological  formations together,  by suturing the subjectival inconsistencies not between the Hong Kong and Mainland audiences, but within the political  subjectivities  of  the  Hong  Kong  spectators  and  the  Mainland  spectators  respectively. Yang (2012: 56-57) argues that postsocialist Mainland Chinese subjectivity and postcolonial Hong Kong subjectivity are both characterised by their respective modes of schizophrenia. The former is split into a continuous belief in and resistance against classical socialism on the one hand, and state-directed capitalism on the other. The latter is split into a growing acceptance of and resistance against Hong Kong's position in the larger national imagination.\n\nFor  instance,  based  on  the  negative  reception  of  the  2009  Hong  Kong-Mainland  coproduction Shiyue  weicheng (Ct. Sapjyut  waising Bodyguards  and  Assassins / (Chan,  2009)  in Mainland China, a  film about a number of unknown working-class Hong  Kong  martial artists sacrificing  their  lives  in  order to  protect  Sun  Yat-sen  (1866-1925)  from  being  assassinated  by killers sent by the Qing (1644-1911) government, Yang observes that while the Hong Kong critics praised the film for its successful negotiation between its local Hong Kong sensibility and its role in the larger national history, the Mainland viewers found the film incapable of addressing their ideological split:\n\nAs viewing subjects, these young [Mainland] spectators [of Bodyguards and Assassins ] were in a state of schizophrenia. On the one hand, in the film's attempt to educate [the Mainland viewers classical socialist beliefs], its vacuous modality of consciousness [ideology] was seen as overtly didactic […] The rhetoric of the film fails to communicate a message without preaching it. As a result, these young viewers find [the film] untrustworthy or even disgusting. In other words, [the film's]  classical  socialist  rhetoric  and  the  [Mainland]  spectators'  'real'  sensations  or  daily experience [under state-directed capitalism] constitute a severed or contradictory condition. Such a schizophrenic subjectival condition is precisely the very subjectival position constructed at the cusp  between  the  1970s and  the  1980s;  it  is  a  form  of  inconsistency  within  the  subjectivity  of postsocialist China. (Yang 2012: 56-57).\n\nYang (2012: 54) cites the film Tou ming zhuang (Ct. Tau ming zong )/ The Warlords (Chan, 2007), as a failed attempt to satisfy the ideal of ideological suture. As she points out, The Warlords was exceptionally well received in Hong Kong. The film represents a story about the rise and fall of three  sworn  brothers  as  warlords  who  help  the  Qing  government  to  fight  against  the  Taiping Rebellion (1850-64); after their success, these brothers, in their respective ways, hope to retain their regional influence despite the Qing court's effort to limit their power. In so doing, the film promotes a form of multi-focal and pluralistic form of government alternative to the centralized system of the PRC. Likewise, John Woo's Chibi (Ct. Cekbik ) / Red Cliff (2008-09) is structured around the preservation of the three kingdoms as divided yet codependent political entities. Before the final battle, the character Zhu Geliang (Kaneshiro Takeshi) whispers to himself:  tianxia san fen, zhi zai tianyi/I entrust my hope to maintain our tripartite political divide to the will of heaven. His wish can be read as a metaphor of the tripartite relationship between the Mainland, Taiwan, and Hong Kong, and the Hong Kong director and audience's desire to maintain such a status quo with minimum Mainland intervention. In other words, these works are more interested in healing the subjectival conflict sensed and perceived by the Hong Kong viewers, than in renegotiating the subjectival inconsistencies of their Mainland counterparts.\n\nWhat is at stake in these films that are believed to have failed to suture the ideological divide  between  the  Mainland  and  Hong  Kong,  and  within  their  respective  schizophrenic\n\nsubjectivities is their instance on the idea of making palpable a sense of extraterritorial affectivity. By engaging the spectators in scenarios where heroes and warriors - often played by top-billing movie stars - fight for regional autonomy or alternative modes of political governance, these films validate the idea of national integrity and unity as an underlying political assumption, yet suggest that centralized governance may not be the best option for those who enjoy the political and economic privileges with their extraterritorial status.\n\n\n## Drug War\n\n\nThe  underlying  assumption  of  Yuan  Yanying's  argument,  and  the  political  intention  of  many coproductions made after CEPA, is that political schizophrenia requires suturing by reconstructing a unified political subjectivity. As William Brown argues, in Lacanian terms, ideological suture is less about the reconciliation of two seemingly incompatible ideological structures within one's subjectivity, than the 'sewing' of one's conflicting affects and sensibilities to a totalising imaginary Other. 2 Drug War, I  propose, opens  a  new  path  by  putting  the  spectators  in  a  position  where  all  attempts  to reconfigure a unified political subjectivity have already failed. As Elsaesser (2012: 225-36; Fan 2008: 454) argues, the failure to perform is also a performance of failure. He takes this clue from Freud's concept Fehlleistung/ parapraxis,  more  popularly  known  as  the  Freudian  slip.  When  one  fails  to perform a task or utterance, one indeed performs one's failure to perform such a task or utterance as a process of reconfiguring a traumatic memory that one has failed to acknowledge. For example, if I promise my guest a cup of tea, and I bring him whiskey instead, I failed to bring my promise to fruition. But  my  failure  to  do  so  performs  my  failure  to  acknowledge  a  personal  trauma  that  I  may  have repressed all along (e.g. I have always wished to have whiskey with my father since my childhood, but he always insisted that I have tea instead). In the context of Hong Kong's extraterritoriality, the failure to configure a unified political subjectivity performs the failure by the Beijing government to graft the concept of national identity onto the political subjectivity of Hong Kongers and to acknowledge Hong Kong's double occupancy and extraterritorial consciousness, and the failure of any attempt to construct a unified political subjectivity in the first place.\n\nThe narrative structure of Drug War is organised around two imaginary differences: law and lawlessness, humanity and animality. In the film, Hong Kong drug trafficker Timmy Choi (Louis Koo) is arrested by Mainland police officer Zhang Lei (Zhang Honglei), and Timmy decides to cooperate with the police in hopes of reducing his sentence. In the end, however, Timmy not only fights against the  Mainland  police,  but  also  kills  his  Hong  Kong  and  Mainland  compatriots.  Through  the collaboration  and  contestation  between  Timmy  and  Zhang  Lei,  the  narrative  offers  an  imaginary discourse and resolution to the real tension between Hong Kong and Mainland along the dual axes of legality and humanity.\n\nUnlike many post-CEPA films in which the protagonist mediates and reconciles the subjectival difference between the Hong Kong and Mainland viewers by making a moral decision that can bring these two imaginary poles to a meeting point, Timmy in Drug War is unfettered by any standard of morality  and  identity.  Being  a  character  from  Hong  Kong  and  the  one  who  consistently  speaks Cantonese (in the Hong Kong version), Timmy can be easily identified as a representative of Hong Kong. Yet the film does not clarify his identity in the beginning. Instead, Timmy is shown in the first fifteen minutes of the film as an animal body that has no subjectival coordination, sense of unity, and complete control over his sensorimotor system. The film begins with a long shot of a (meth) factory located in a rural area in the background of the frame. Yellow smoke rises from the factory, suggesting  that  an  explosion  has  occurred.  A  car  emerges  from  the  background,  and  runs diagonally from the background (right of frame) to the foreground (left of frame). . The film then cuts to a medium closeup of a man (Timmy) steering the car recklessly, and looking like he is about to vomit (intoxicated by the fumes from the explosion). This is followed by a long shot of\n\nthe car swirling down a road, away from the camera, and then by a reverse shot of the car on a different road. The film then cuts back to a medium close-up of Timmy, in which he vomits outside the window. A 'medium shot' of the car then follows, where it makes a sharp turn around a street corner, and the camera pans right as the car is driven down the road. After that, the film shows a low-angle long shot of a series of surveillance cameras, from the perspective of a moving car, followed by a repetition of Timmy's medium closeup, where Timmy begins to lose control of the steering wheel.\n\nThen, the film cuts to a high-angle long shot of a city street, where Timmy's car is driven across different lanes. The viewers then see a close-up of Timmy's arm and hear the ring tone of a mobile phone; as Timmy raises his arm, the phone is revealed, and the camera zooms into it a little. This is followed by a long shot of the car approaching a busy intersection, with the camera panning to the left and craning up to reveal a wider view of the street. The film then cuts to a highangle long shot of the car turning around the intersection towards the front door of a restaurant, followed by a low angle long shot of the vestibule area inside the restaurant, and then a straight on angle long shot of this area from the interior of the restaurant, as the car crashes through the door into the reception area.\n\nThis  fast-paced  montage  sequence  introduces  Timmy  as  an  irrational,  intoxicated,  and reckless being who is entirely governed by an animal instinct to survive without necessarily having any specific desire or want. The sequence begins with Timmy coming out of the meth factory (death), and  ends  with  his  car  smashing  into  the  restaurant  (rushing  to  death).  While  Timmy's  sense  of disorientation is instilled into the viewers' sensoria by means of its fast-paced editing, subtle and quick camera movements, and rapid alternation between long shots and close ups. Meanwhile, his animalistic determination to survive is emphasised by the spectators' overall sense that Timmy is driving his car to a certain destination, albeit the destination is his potential death. Yet embedded in this sequence is a long shot of a series of surveillance cameras. Although these cameras are seen from the perspective of a moving car, the shot itself is never sutured to a shot of Timmy looking, thus creating an effect that these cameras are actively looking back at the audience. In a similar manner, even though the phone call may have come from a friend of Timmy's, the mobile phone itself serves (as the film will later confirm) as a GPS device under the state's surveillance system. In short, the animality and lawlessness of Timmy is, from the beginning moment of this film, actively tracked, surveyed, and regulated by the law and the mode of humanity the law claims to protect and maintain.\n\nLater, after Timmy has woken up in his hospital bed, he is shown as a trapped animal that is alerted by his corporeal instinct to escape, but again without a specific destination or objective. In these two sequences, Timmy is therefore shown neither as a human being who can think, nor as a rational being who actively pursues a desire. Rather, every movement and decision he makes is simply driven by a physiological instinct to survive - first without any control of his body (in the car), and then with his body taking complete control over his cognitive functions (in the hospital). In Lacanian terms, Timmy can be understood as a drive creature, i.e. a creature that is already dead, driven not by any lack and governed not by any law (of the father or of the land), but as an embodiment of all those ethical values, pleasures, and displeasures that are precisely unsanctioned by the law. Yet the gaze of the Other constantly puts him under surveillance, restrains him, and pursues him.\n\n<!-- image -->\n\n<!-- image -->\n\n<!-- image -->\n\nThe dual axes between law and lawlessness, humanity and animality are further reiterated in  the  interrogation  scene,  where  they  are  clearly  mapped  onto  the  dichotomized  relationship between Hong Kong and the Mainland. During the initial interrogation, Timmy sits behind bars as though he were a caged animal. Officer Yang Xiaobei (Huang Yi) reads out Timmy's bio, and strategically  pauses  at  a  point  when  she  announces  that  he  is  a  Hong  Konger.  Here,  the  film deliberately cuts to a shot-reverse-shot, with a door slamming at the interval between the first two shots that haunts the soundtrack: (1) Xiaobei announces Timmy's identity over Timmy's close-up as the camera dollies in, followed by the sound of a metallic door slamming at the cut (see Figure 1); here, Timmy stares directly at the camera; (2) a three-quarter shot of Xiaobei and Zhang Lei, shot behind Timmy's shoulders - Xiaobei and Zhang Lei raise their eyes towards Timmy (see Figure 2); (3) a reverse shot of Timmy (three-quarter) looking at Xiaobei (see Figure 3).\n\nThis shot-reverse-shot structure sets up a peculiar tension between Timmy and the two Mainland police officers, where the accuser and the accused are intricately reversible. The key of this shot-reverse-shot structure is the first image, in which Timmy looks directly into the camera lens while hearing Xiaobei's announcement of his identity. This shot, together with the sound of the door slam, has the effect of turning Xiaobei's announcement into a legal accusation, as though being  a  Hong  Konger  is  the  criminal  charge  itself.  The  second  over-the-shoulder  shot  from Timmy's point of view accentuates Xiaobei's accusative gaze, which has the effect of turning what she said into a speech-act that instantiates her authority, one that subsumes Timmy under the law of  the  land,  but  at  the  same  time,  ostracizes  him  from  the  interior  of  the  imaginary  polis  (the Mainland). Curiously, such a speech act is conferred upon a creature that is 'already dead' under the gaze of the law, who is interrogated, with his presumed guilt, behind bars as though he had already  been  stripped  of  his  subjectivity,  citizenship  and  humanity.  Nevertheless,  the  first  two shots align the camera's gaze with Timmy's, which invite the spectators to identify with him and 'look back' at his accuser. Eventually, in the third over-the-shoulder shot, the spectators' eyes are drawn to Timmy's equally accusative gaze towards Xiaobei, thus making the power relationship between the accuser and the accused reversible. 3\n\nAs an  outlaw  and  a  figure  that  has  no  sense  of  morality,  Timmy  is  posited  from  the  very beginning of the film as what Giorgio Agamben (1998 [1995]: 1-2) would call a homo sacer. Agamben defines the homo sacer as a bare life that is neither human nor animal, and is ostracised by a political community as someone who can be executed without breaking the law. But by the same token, he is also there to manage, manipulate, and execute life at the liminal space between law and lawlessness. For Agamben, both the socially ostracised, and curiously, the sovereign, occupy this liminal position between life and death, human and animal. The former can be executed by the law, as it occupies this zone of exception from the law and humanity, whereas the latter makes law from a position where it is not answerable to any law. In this light, Zhang Lei and Timmy are both homines sacri: while Zhang Lei stands outside the law in order to instantiate Chinese sovereignty, Timmy, as a Hong Konger, is a priori ostracised by the Chinese sovereign authority in order to be managed, disciplined, and eventually, executed. Once understood as two homines sacri, Zhang Lei and Timmy are no longer standing on the two opposite sides of the dual axes between law and lawlessness, humanity and animality. Instead, they both occupy the positions of lawlessness and animality, and sovereignty is instantiated precisely by their mutual negotiation, collaboration, and reconfiguration.\n\nIf  one  reads  Timmy  as  a homo  sacer, the  film  neither  tries  to  humanise  him  nor  further animalise him; rather, it works through the various means by which a homo sacer can make use of his liminal space between law and lawlessness, humanity and animality to survive as abject. For example, Timmy's juridical liminality and dehumanised status allow him to manipulate his information in order to try getting himself out of his impasse, often without any scruples. Yet over and over again, Timmy ends up drawing himself into deeper and deeper trouble with the Mainland authority, which constantly tries to rein him in by breaking its own law (Fan 2014: 29). For example, in the first collaborative mission between Timmy and Zhang Lei, Zhang Lei masquerades himself as a midlevel drug trafficker Ha Ha, and is introduced by Timmy to a higher-level trafficker Chang. During their meeting, Chang offers Zhang Lei pure-grade cocaine, which Zhang Lei cannot refuse without exposing his identity as a  police  officer.  After  the  meeting,  Zhang  Lei's  body  reacts  violently  to  the  drug,  and  Timmy  is immediately handcuffed, pushed to the ground in an undignified squatting position. Despite all this, Timmy cries out instructions to teach the other police officers to help Zhang Lei cool down his body. After Zhang Lei has finally recovered, he walks up to Timmy and squats down in front of him. Instead of thanking Timmy, Zhang Lei accuses Timmy of sending a signal to Chang during their meeting. Upset by this accusation, Timmy gives Zhang Lei an angry tirade. After this, Zhang Lei calms down and orders his team to go to Erzhou, and the film cuts to a high angle close up of Timmy and Zhang\n\nLei facing each other in a graphically symmetrical composition (figure 4), thus suggesting that the two are in fact occupying the same liminal position between law and lawlessness, humanity and animality.\n\n<!-- image -->\n\nFor many spectators, in the film, there is one scene in which Timmy does seem to show some compassion, and therefore, hints of humanity. When Timmy, under arrest, returns to the warehouse where he adheres surveillance microphones and cameras around the facility, he is invited by his staff, a family of mutes, for dinner, and they thank Timmy for taking care of them. At dinner, Timmy pauses and cries, and he gesticulates to the family that his wife was killed in the explosion earlier that morning. Timmy then performs the rite of wine offering at the table. He then burns real money as sacrificial offering. In this scene, Timmy seems to show a hint of compassion for his wife, and Zhang Lei and his team also seem to be touched by Timmy's sense of Confucian lunchang   human order and relationship. / Yet what undermines Timmy's humanity is that he performs these rituals with full knowledge that he is being watched, thus rendering his action as a pure performance under surveillance. In addition, by burning real money, the offering is less intended for his wife, but for the still-living, i.e. for a drive creature like Timmy, who is already at the liminal space between life and death, and is simply waiting for the moment of his physical execution by the law.\n\nIn the final face-off between Timmy, the Mainland police, and the Hong Kong triad members, Timmy  manages  to  kill  everyone,  only  to  find  himself  fettered  by  the  law,  as  Zhang  Lei  cuffed Timmy's leg immediately before he died (figure 21). In one register, this denouement can be read as Timmy being reined in by the law of the land, but in another register, this image reinforces the idea that both Timmy and Zhang Lei are homines sacri who work together to instantiate sovereign authority. Johnnie To chooses to end the film with the sight of Timmy getting executed. The sight of his dying body,  I  argue,  serves  to  offer  a  critique  of  the  state  power.  This  image  opens  up  the  imaginary incommensurability between the Mainland and Hong Kong legal systems and values of life: in the former system, the death sentence has to be carried out, whereas in the latter, following the British protocol, it is automatically condoned by the Chief Executive. In the image, a Hong Konger, who is supposed to enjoy some level of extraterritorial privilege, is executed as a bare life under the state power of the PRC, thus criticising the biopolitical power of the Central Government -- that is, as Michel Foucault (2002 [1976]: 178) argues, 'to take life or let live.'\n\n\n## CONCLUSION\n\n\nDrug War offers a peculiar new model of film narrative for post-CEPA Hong Kong cinema. In one register, the film seems to try reining in the extraterritorial mentality and sensibility of the Hong Kong spectators by subsuming, and eventually, executing, a Hong Konger under the national criminal law (Fan 2014: 29-30). In another register, however, by inviting the viewers to identify and share the fear and anxiety with a protagonist who is effectively reduced as a homo sacer, the  film rehearses and reperforms the audience's sense of  failure, that  is, the  failure  to  claim  any  political  subjectivity  or\n\nafford any  sociopolitical morality and humanity  under  the  biopolitical power  of  the state. Extraterritoriality, in this sense, is no longer considered a postcolonial privilege or sense of superiority; rather,  it  is  both  a  legacy  of  colonial  biopolitics  and  a  gradual  erosion  of  concepts  of  political subjectivity and citizenship under the SAR government. But by the same token, the only way one can survive as a Hong Konger is, ironically, to retain this extraterritorial status as the basis of reconfiguring its sense of political community and ontological consistency. But perhaps more disturbingly, the film illustrates that extraterritoriality itself is in fact a myth. It is because this  liminal space between law and lawlessness, humanity and animality is deliberately set up, under state surveillance, in order that sovereign authority can be instantiated not as the law of the land, but as a land where the law can be freely reconfigured, reinterpreted, reinstated, annulled or dissolved as a means to manage, discipline, educate,  and  execute  those homines  sacri that  occupy  this  space.  Hong  Kong  is  therefore  best understood as a place that is doubly occupied of two modes of extraterritoriality: the version sanctioned by the state in order to manage and discipline, and the version promoted by those residents who resist any form of ideological suture. Hong Kong is, after all, always already occupied and always doubly occupied.\n\n",
         "In this article, Victor Fan argues that analysing contemporary Hong Kong cinema requires active rewriting of established postcolonial theories by taking into account the specific mode of colonisation of Hong Kong: extraterritoriality. This concept has been responsible for the construction of the cultural plurality, linguistic ambiguity, and political liminality of Hong Kong and its cinematographic experience, as well as the incongruence between the community’s political consciousness after 1997 and the larger national imagination promulgated by the Beijing government. The term ‘extraterritoriality’ was translated into Chinese after 1895 via Japanese as zhiwai faquan the right to exercise one’s law outside a nation state’s sovereign terrain, and colonialism in China between 1844 and 1949 was largely characterized by a continuous reformulation and systematisation of this concept. It in fact still informs the way former colonised regions in China are administered today, and the political unconscious of their residents. With Jonnie To’s 2012 film Duzhan (Dukzin) /Drug War as a case study, contemporary Hong Kong cinema, Fan argues, can be understood as a public sphere where an extraterritorial consciousness and the contesting political affects associated with it are actively negotiated.",
         ""
        ],
        [
         "1",
         "1",
         "## 1. Introduction\n\n\nAn Electronic Health Record (EHR) System is the digitized version of a patient's medical chart record  containing  medical  history,  diagnoses,  treatment  plans,  immunization  records,  and  test  results. 1 EHRs reduce diagnostic errors and patient safety concerns (Graber et al. 2017, Hydari et al. 2019). EHRs also improve coordination and integration of care by providing real-time data at the point of care, efficient transfer of information across settings, and physician decision-support (Rathert et al. 2019). As of 2021, 89% of office-based physicians in the US had adopted an EHR system (Office of the National Coordinator for Health Information Technology 2021). In a 2018 survey of 500 primary care physicians in the US, 63% of physicians agreed that EHRs had led to improved care. However, 71% of physicians also said EHRs significantly contribute to physician burnout (Stanford Medicine 2018).\n\nSinsky et al. (2016) found that outpatient clinicians spend two hours on EHR and desk work for every hour spent on direct clinical face time. Several recent studies have associated physician time spent on EHR systems with lower patient satisfaction (Marmor 2018), and for physicians, more work-after-work hours (Attipoe 2021), attrition (Melnick et al. 2021), and burnout (Arndt et al. 2017). In an article in The New  Yorker on  physician  EHR  workload,  Dr.  Atul  Gawande  states,  \" Something's  gone  terribly wrong. Doctors are among the most technology-avid people in society; computerization has simplified tasks in many industries. Yet somehow, we've reached a point where people in the medical profession actively, viscerally, volubly hate their computers.\" (Gawande 2018). In a 2019 statement, the American Medical Association called an overhaul of the design and use of EHR systems a \"national imperative\" due to the high correlation between EHR use and physician burnout (American Medical Association 2019).\n\nAlthough numerous studies have identified the detrimental impact of physician EHR workload, a key question remains - is it possible to reduce EHR workload through better operational practices, such as structuring the EHR work differently? Interviews conducted by Zhang (2016) and Attiope (2021) show that physicians take varying approaches to manage their EHR work before or after appointments, while in the examination room with the patient (multitasking), and finally, after the end of the workday. Figure 1 shows the same categories in our dataset, and we see large differences across physicians. In this paper, we seek to exploit the heterogeneity in physician actions across appointments to study how these differences impact total time spent using EHR and time spent after-work hours on EHR.\n\nIn particular, we investigate the trade-offs of working on EHR tasks in different idle times between appointments (i.e., before and after appointments). The time between appointments represents the idle time from the primary task (seeing a patient) but are times when secondary tasks may be completed. Doing EHR work before an appointment may help physicians conduct early task initiation (Batt and Terwiesch 2017), prepare for tasks during the appointment (Verbruggen et al. 2007, Altmann 2004), and efficiently capture key EHR details due to this effort. Alternatively, by doing work beforehand, it may take longer as task switching occurs (Staats and Gino 2012, KC, 2014, Gurvich et al., 2020), and the work may fill to expand the time available (Parkinson 1955, Hasija et al. 2010). When work is completed after an appointment, it may be more efficient as all (or most) information is available, and there is better recall after an appointment (KC 2014). However, it is also possible that time increases due to lower productivity from longer work hours (Caruso 2014) and task interruptions (Froehle and White 2014).\n\nWe focus on EHR tasks performed during idle time as the idle time between appointments is a decision variable for hospital management during appointment scheduling. So, idle time can potentially be used to influence physicians' practices around EHR usage. Additionally, the trade-offs associated with doing EHR tasks in idle time between appointments have been discussed qualitatively in prior studies (Zhang  et  al.  2016,  Attiope  2021).  In  these  surveys,  physicians  have  expressed  various  opinions  and\n\nintuitive  reasons  for  performing  EHR  in  different  time  intervals,  and  we  want  to  study  idle  time quantitatively.\n\nThis  topic  is  critical  to  improving  healthcare  operations,  but  it  is  also  part  of  a  more  general discussion on how work should be done (Narayanan et al. 2009, KC et al. 2020, Pendem et al. 2022). Although much emphasis is placed on the primary tasks to be completed, such as patient treatment or surgery (Bartel et al. 2020, Youn et al. 2022), assembling a car in a factory (Bernstein &amp; Kok 2009), or answering a call in a call center (Aksin et al. 2007), operations also include secondary tasks that support the primary work (Dai et al. 2015, Legros et al. 2020). These might consist of EHR use, hand hygiene (Dai et al. 2015) or lab tests in healthcare (Batt and Terwiesch 2017), supply positioning or tool preparation in manufacturing, or data entry in call centers. Secondary work is necessary to complete the primary work, and an open question is when (or, in some cases, if) it should be completed.\n\nIt  is  necessary  to  study  secondary  tasks  separately  as  service  operators  typically  have  greater discretion  on  when to  perform  them.  Secondly,  during  scheduling,  workload  due  to  secondary tasks is typically ignored,  even  though  these tasks are  often a  significant  burden  on  the  operator.  Lastly, these secondary tasks are usually performed outside of customer encounter time but may influence the workload and  outcome  of  the  service  experience.  Consequently,  it  may  be  possible  to  affect  performance  by identifying and implementing improved practices for managing secondary tasks.\n\nThis paper uses the critical context of EHR usage to shed light on this more general question. In particular, we focus on the following research questions:\n\n- 1. How does the total time spent on EHR depend on when the EHR tasks are performed?\n- 2. How does an increase in idle time between appointments affect the timing of EHR work?\n- Figure 1: Average EHR Use at Different Parts of the Day for Each Physician\n\n<!-- image -->\n\nThe first research question allows us to understand the operational impact of structuring secondary tasks. At least part of the answer addresses a classic question, is it better to prepare before or wait until after the primary task is completed to work on secondary tasks? The answer to the second research question\n\nprovides  insights  into  managing  appointment  schedules  to  influence  secondary  task  completion.  For balancing workload, prior studies have discussed trade-offs associated with early task initiation (Batt and Terwiesch 2017), multitasking (Tan and Netessine 2014), and task switching (Staats and Gino, Gurvich et al. 2019). However, the impact of structuring secondary tasks with scheduled appointments has not been studied.\n\nWe examine when EHR work should be completed using data from over 150,000 appointments across 74 physicians in the Family Medicine unit of a large Academic Medical Center in the US. Our dataset includes  detailed  information  on  appointments  and  physicians'  EHR  system  use,  including  activity  on individual patient records. This allows us to obtain time spent on EHR by a physician related to a particular patient. We perform our analysis at the appointment level as there is considerable heterogeneity in when EHR tasks are done even for the same physician. We focus our attention on two key outcome measures: total time spent on EHR systems and physicians' EHR time after regular work hours. We focus on these two measures for two reasons. First, total EHR workload and EHR time spent during after-work hours significantly contribute to physician burnout (Tran et al. 2019). Second, these two measures have been identified as important aspects of hospital operational performance (Sinsky et al. 2020).\n\nWe categorize when physicians complete the secondary task of EHR use. There are four times during a day when physicians might complete EHR work for an appointment: before the appointment (what we label prework), during the appointment (what we label multitasking), after the appointment, but before the end of the day (what we label postwork) or after the workday (what we label end-of-day work). Different trade-offs are associated with doing EHR tasks in each time period.\n\nOur paper demonstrates that work structure is important for EHR tasks, as when they are performed significantly impacts total and after-work EHR time. Specifically, we find prework is a dominant strategy because it can reduce total time spent on EHR and end-of-day EHR work, whereas postwork can reduce end-of-day EHR work but increase total time spent on EHR.\n\nWe estimate that performing an additional five minutes of prework (about a one standard deviation increase) reduces the sum of multitasking, postwork, and end-of-day EHR work by 6.9 minutes. In other words, a 5-minute increase in prework in an appointment leads to a net reduction in total EHR time of 1.9 minutes for that appointment, a decrease of 10.5%.  Approximately 0.9 minutes of this reduction is from the decrease in end-of-day EHR work, a decrease of 46%. In our setting, with 74 physicians who average 13 appointments per day, this translates into 31 fewer hours of total EHR work with 13 fewer hours in afterhour EHR work per day.\n\nIf  a  physician  spends  five  additional  minutes  on  postwork,  then  end-of-day  work  for  that appointment decreases by 1.4 minutes, a reduction of 72%. This translates to a total reduction of 21 hours in after-hour EHR work per day for our setting. However, the total EHR workload goes up by 3.6 minutes\n\nper appointment, or 58 hours per day, across all physicians in our setting. To summarize, our results indicate that  increasing  prework  helps  reduce  both  total  and  end-of-day  EHR  work.  Alternatively,  increasing postwork reduces end-of-day EHR hours but at the cost of increasing total EHR time.\n\nHospitals can encourage physicians to do more prework and postwork by increasing the idle time between appointments. We find that increases in idle time lead to significant increases in prework and postwork in our sample. The magnitude of the increase is significantly more for postwork than for prework. This suggests that during increases in idle times, physicians increase prework and postwork but focus more on postwork.\n\nOur solution approach and results contribute in the following principal ways. First, the appointment scheduling literature has typically focused on the trade-off between idle buffer time between appointments, patient delays, and physician makespan when scheduling customer encounters. Appointment scheduling literature  typically  defines  makespan  as  the  sum  of  idle  time  and  appointment  time.  According  to  this definition,  increasing  idle  time  between  appointments  reduces  patient  delay  at  the  cost  of  increasing physician makespan (Robinson and Chen 2003). However, if we incorporate time spent on secondary tasks, makespan would need to be defined as the sum of idle time, appointment time, and end-of-day time spent on secondary tasks. In the presence of secondary tasks, physicians can perform these tasks during the idle time  between appointments,  leading to  less  end-of-day  work  and  a  lower  makespan.  Therefore,  in  the presence of secondary tasks, increasing idle time may not always have a detrimental effect on makespan.\n\nSecond, we contribute to the literature on task selection and sequencing. We find that performing some secondary tasks before the primary task can be a dominant strategy leading to less time spent on secondary  work  and  less  time  spent  on  secondary  work  after  the  end  of  the  workday.  These  benefits potentially accrue due to task preparation and early-task initiation (Batt and Terwiesch 2017) by reducing the load from busier parts of the workday. We also find that performing secondary tasks after the primary task helps reduce work at the end of the workday but would increase the total time spent on secondary tasks due to increased interruptions. Prior findings in the literature related to task sequencing have not typically focused on the relative value of doing pre-appointment and post-appointment secondary tasks.\n\nFinally, our managerial insights help schedulers create appointment schedules that reduce burnout due to EHR workload. These varying effects of prework and postwork suggest that when clinicians create protected time for EHR tasks, the recommended use of that time would depend on the clinic's objective. If the objective is to reduce the total EHR workload, greater emphasis can be placed on doing prework. If the objective is to reduce after-work EHR time, then increasing postwork would give a greater marginal benefit, although at the cost of increasing total EHR time.\n\nThe paper is organized as follows. In Section 2, we discuss the related literature. Section 3 describes a  physician's  appointment  and  EHR  activities  in  detail  and  motivates  our  study's  relevant  hypotheses.\n\nSection 4 describes the data, the empirical strategy, and the results. In Section 5, we discuss the model and our empirical strategy. In Section 6, we present our findings and discuss possible alternative explanations. Finally, in Section 7, we discuss the implications of our findings and end with concluding remarks.\n\n\n## 2. Literature Review\n\n\nOur paper is related to four streams of literature. The first stream of literature is research on the impact of technology on healthcare professionals' workload and productivity. Introducing technology in healthcare delivery has many advantages, such as improving patient access through additional delivery channels  and  improved  physician  decision  support.  However,  recent  studies  have  found  that  these technologies' operational impact may sometimes be negative.\n\nTechnology-enabled channels of healthcare delivery, such as e-visits and telemedicine, increase physician workload (Bavafa et al. 2018, Bavafa and Terwiesch 2019), increase costs (Çakıcı and Mills 2021), and may worsen patient health disparities (Sunar and Staats 2022). Adopting IT technologies may also create legal vulnerabilities for physicians through increased information visibility (Kim et al. 2021) and may lead to lower physician productivity (Bhargava and Mishra 2014). Recent studies on EHR usage in  clinical services literature  have found an association between increasing EHR usage with increasing burnout and turnover (Sinsky et al. 2016, Melnick 2021) and lower patient satisfaction (Marmor et al. 2018). Lee  et  al.  (2021)  consider  EHR  documentation  work  from  a  queuing  modeling  perspective.  They computationally evaluate different workflow policies for managing EHR work. They conduct a numerical evaluation of these workflow management policies' impact on patient wait time and physician overtime. We contribute to this literature by investigating the effect of structuring EHR work in the idle time between appointments on the total and after-hours EHR workload.\n\nThe second research stream related to our work is multitasking. Empirical studies on multitasking analyze servers simultaneously handling multiple customers or various task types (Narayanan et al. 2009, Staats and Gino 2012, Tan and Netessine 2014, KC 2014, Freeman et al. 2017, Berry Jaeker et al. 2017, Gurvich et al. 2020). Gurvich et al. (2020) is a closely related paper to our context. They quantify the changeover  time  when  the  physicians  switch  between  documentation  and  collaboration  with  other physicians. Patient interactions are not scheduled and are at the physician's discretion in their setting. A key distinguishing feature in our paper is that physicians alternate between scheduled face-to-face time with patients and documentation tasks. Progression of scheduled appointments creates idle time during the day, and we focus on physicians' use of this idle time towards EHR tasks.\n\nA related set of papers on multitasking are queuing models with one server or group of servers balancing two work queues (Gans and Zhou 2003, Legros et al. 2020). Legros et al. (2020) discuss service operators' switching between customer interaction and back-office tasks. They derive optimal threshold policies  for  using  the  interlude  time  between  customer  interactions.  Further,  they  show  that  with  task-\n\nswitching costs and multiple interludes, back-office work should be concentrated on fewer, more extended, and later interludes. There are two primary differences in our context. First, in our context, physicians can also  perform  documentation  work  during  the  appointment  in  addition  to  the  time  between  customer encounters which is not the case for tasks in Legros et al. (2020). Second, with EHR documentation work, as we observe from our results, not all work done in the interludes between appointments may have the same effect. We find that pre-appointment and post-appointment EHR work affect the total EHR workload differently.\n\nThe third stream of literature is related to the operational impact of task selection and sequencing by service workers. The sequencing of tasks can be driven by a motivation to shift work upstream, as in Batt and Terwiesch (2017). They find that early initiation of lab tests during the triage process in Emergency Departments (EDs) reduces treatment time but may increase the total number of tests performed. Another motivation for task selection could be a preference to complete tasks. KC et al. (2020) find that a preference to complete easy tasks is related to lower throughput and learning in an ED. Ibanez et al. (2018) find that in addition to preferring to do easier tasks first, physicians also prefer to batch similar tasks together. They find this preference for easier and similar tasks negatively impacts productivity. In a related study, Feizi et al. (2022) found that ED physicians' preference for batching admissions leads to longer patient wait times. The preference to do easier tasks may be driven by task familiarity, as Niewoehner et al. (2022) find with physicians'  selection  of  patients  in  an  ED.  They  find  that  greater  familiarity  with  patients  increases physicians' patient pick-up rate, leading to shorter wait times with no negative impact on processing time or  length  of  stay.  We  contribute  to  this  stream  of  work  by  studying  how  physicians  use  the  interludes between appointments to complete secondary tasks such as EHR-related tasks.\n\nThe  fourth  stream  of  literature  related  to  our  work  is  appointment  scheduling.  Healthcare appointment scheduling has a long line of research (Gupta and Denton 2008, Ahmadi-Javid et al. 2017). The  principal  problem  in  scheduling  is  allocating  time  for  each  appointment  of  the  day  to  optimize performance measures such as idle time, physician overtime, and patient wait times. Recent literature in this field has incorporated factors such as no-shows, cancellations (Liu et al. 2010, Kong et al. 2020), walkin customers (Chen and Robinson 2014, Wang et al. 2019), patient preferences (Feldman et al., 2014), and multi-priority  patients  (Sauré  et  al.  2020).  To  the  best  of  our  knowledge,  recent  literature  has  not incorporated the impact of doing secondary tasks such as documentation work between appointments. In scheduling literature,  idle  time  between  appointments  has  a  detrimental  effect  on  physician  makespan. However,  when  EHR  workload  is  considered,  increased  idle  time  can  reduce  physician  makespan  by reducing  after-work  hours  doing  documentation  tasks.  Our  empirical  investigation  on  the  impact  of physicians utilizing the idle time between appointments for documentation work will help guide future research on appointment scheduling.\n\n\n## 3. Process Description and Hypothesis Development\n\n\n\n## 3.1 Process Description\n\n\nDetailed descriptions of physician actions related to a visit are available in Dobson et al. (2009), Wetterneck et al. (2012), and Holman et al. (2016). We summarize the salient points below.\n\nPatients typically book appointments a few days to a few months in advance. On the day of the appointment, the front desk staff collects basic information such as age and insurance information after the patient's  arrival.  Patients  who  fail  to  attend  an  appointment  without  prior  notice  are  called  no-shows. Literature estimates the prevalence of no-shows between 7-26% for Academic Medical Centers in the US (Dantas et al. 2018).\n\nAt the scheduled start time, when an examination room becomes available, the nurse receives and accompanies the patient to the room, where they perform a preliminary physical examination, including measuring  weight  and  blood  pressure.  Following  this,  the  physician,  after  they  have  concluded  their previous visit, enters the examination room. After entering the room, the physician performs the following principal tasks: gathers patient information through discussion and questions, reviews patient information by  reading  from  the  EHR,  documents  patient  information  in  the  EHR  system,  performs  a  physical examination of the patient, looks up treatment and drug information, recommends treatment options after discussion  with  the  patient,  orders  medication  and  tests,  gives/communicates  to  patient  prescription, information, or instructions, and finally concludes the appointment, sometimes by walking the patient to another location in the clinic.\n\nAs Holman et al. (2016) note, physicians do not perform these activities consistently in the same sequence,  and  task  sequencing  demonstrates  significant  variation  depending  on  the  patient's  clinical conditions, the progression of the visit, and physician characteristics. For example, the physician may cycle through activities such as gathering, reviewing, looking up information, and communicating with the patient multiple times  within the same  appointment.  Some EHR tasks,  such  as  reviewing  patient  information, interpreting laboratory reports, finding missing or pending information, arranging tests or consultations, and completing forms, may be done before the appointment (Gottschalk et al. 2005). Surveys (Attipoe 2021) indicate that physicians perform some EHR activities such as finishing their notes, closing outpatient charts, and following up on lab results and patients' responses or comments after the end of the workday. Gottschalk et al. (2005) estimate that physicians performed 14.5% of visit-specific activities either before or after the appointment.\n\n\n## 3.2 Hypothesis Development\n\n\nWe  develop  hypotheses  on  the  impact  of  performing  EHR  activity  in  idle  time  between appointments. We first consider the causal impact of prework on the total time spent on the EHR system.\n\nPrework  includes  reviewing  patient  demographic  information,  previous  laboratory  reports,  and  any previous communication from the patient or other caregivers (Wetterneck et al. 2012, Zhang et al. 2016).\n\nThere are three potential reasons prework may increase total EHR time. First, prework will increase task-switching from patient interactions to documentation. Switching time may increase physicians' EHR system time. Literature in operations management and psychology has identified the detrimental effects of task switching due to increased changeover time (Staats and Gino 2012, KC 2014, Gurvich et al. 2020). Second, idle time before an appointment may lead physicians to spend more time doing prework than usual, demonstrating Parkinson's law, the adage that \"work expands to fill the time available for its completion\" (Parkinson 1955). Parkinson's law has been studied in contexts such as project management (Gutierrez and Kouvelis 1991) and call centers (Hasija et al. 2010).\n\nLastly, some prework tasks may be unnecessary, and the physician may need to rework in the patient's presence. Holman et al. (2016) give the following example of a patient encounter:\n\nThe PCP suggests a medication for one of the patient's problems, and the patient recognizes that the  medication  was  tried  previously  and  affected  her  negatively.  The  PCP  again  searches  the patient's EHR, reviewing the patient's historical medications and laboratory values to confirm this and changes the patient's treatment recommendation.\n\nThe above example indicates that clinical appointments benefit from service co-production between physicians and patients due to high variability in patient needs. Roels (2014) shows that when a task is less standard,  it  is  optimal  to  increase  interaction  between  the  service  provider  and  customer.  Management literature has previously discussed the benefits of reduced rework with increasing customer engagement (Lengnick-Hall 1996).\n\nDespite  these  disadvantages,  surveys  of  physicians  indicate  that  they  prefer  to  perform  some prework on EHR before an appointment. Particularly,\n\n-  I find it useful to know the purpose of the visit and the scope of the patient's concerns and to review the data before the appointment. This allows me to formulate a tentative plan before I enter the exam room and makes it less likely that some aspect of care will fall through the cracks. Spending a few minutes reviewing the chart and patient questionnaire and discussing the patient with the nurse pays off with a more efficient, focused visit (Sinsky 2016).\n-  I feel that preparation ahead of the visit is the key (Zhang et al. 2016).\n\nWhile some EHR work would always be done with the patient in the room, prework may help reduce the total EHR workload. First, doing some prework would be an example of early initiation of tasks. Early task initiation shifts the workload from more congested parts of the workday to an earlier non-valueadded idle time and may reduce total processing time (Batt and Terwiesch 2017). Time with the patient in the examination room is a busy time for the physician. They must listen to the patient, review and type\n\npatient-supplied information into EHR, and recommend treatment options. Doing some EHR work, such as  reviewing  patient  history  and  preparing  notes  before  entering  the  room,  may  help  reduce  the  time physicians spend alternating between talking to the patient and interacting with the EHR system. This would help the physician perform the remaining EHR work with the patient in the room more efficiently.  This improvement in efficiency by moving tasks from busy server time is also related to the lean concept of changeover reduction by doing external setup tasks when the machine is stopped (Shingo 1989, Costa et al. 2013). EHR tasks such as reviewing patient records and selecting templates 2 in the EHR system can be thought of as setup tasks, and performing them before the appointment would help reduce the time spent on EHR during the appointment.\n\nSecondly, research in psychology has indicated that although switching costs are incurred when switching between tasks, the switching cost reduces (although it is not eliminated) when workers are given an opportunity to prepare for the switch (Verbruggen et al. 2007). Task preparation may be considered as the activation of mental structures in anticipation of their future use, such as collecting one's thoughts before a lecture or collecting tools before a manual task, making the process progress more efficiently (Altmann 2004). Therefore, doing some prework, such as reviewing patient records, would help the physician be mentally prepared and help them do the multitasking part of EHR work in a more efficient manner. Given that prework could potentially lead to an increase or decrease in total EHR work, we propose the following hypotheses:\n\nHypothesis 1a . An increase in pre-appointment EHR work leads to less total time spent on EHR. Hypothesis 1b . An increase in pre-appointment EHR work leads to more total time spent on EHR.\n\nPhysician  burnout  from  EHR  activities  is  related  to  total  EHR  workload  and  after-work  hours (Sinsky et al. 2016, Attipoe 2021). In our second hypothesis, we try to measure the effect of prework on EHR workload after the end of the day. As we remarked in the discussion above, prework may increase the total EHR workload due to Parkinson's law, task-switching, and rework due to low service co-production. Prior studies have found that knowledge workers often batch similar tasks, and this batching behavior is positively associated with increasing workload (Ibanez et al. 2018). Therefore, if prework increases the total EHR workload, it may also lead to increased after-work hours due to batching of EHR tasks to the end of the day. Also, with an increasing workload, physicians may prefer not to be rushed during clinic hours and do these additional tasks after the end of the workday (Attipoe 2021).\n\nOn the contrary, performing prework may reduce the end-of-day work since the physician is more prepared for the appointment. This may lead to reduced errors in EHR work during the appointment and, therefore, less EHR work during after-work hours. We hypothesize the following:\n\nHypothesis 2a. An increase in pre-appointment EHR work leads to less end-of-day EHR work.\n\nHypothesis 2b. An increase in pre-appointment EHR work leads to more end-of-day EHR work.\n\nWe next consider the effect of postwork on the total EHR workload. After the conclusion of the appointment, the physician performs several actions on the EHR system. These are typically tasks such as writing after-visit notes, ordering tests, sending medication orders to pharmacies, and communicating with the  patient  over  secure  communication  about  the  summary  of  the  visit  and  any  recommendations.  A physician may choose to complete this work as postwork in the idle time between appointments or wait until the end of the day.\n\nThere  are  three  reasons  postwork  would  lead  to  an  increase  in  total  EHR  time.  First,  if  the physicians stop doing the postwork of the focal appointment when the next patient is ready, then it would lead to an interruption in the EHR activity of the focal appointment. Froehle and White (2014) show that interruptions can induce forgetting in a worker leading to increased rework to complete the task. Second, similar to prework, introducing postwork may also lead to the detrimental effect of task switching from face-to-face  appointment  to  EHR  work,  introducing  changeover  time  when  starting  postwork  EHR. Postwork EHR introduces changeover time like prework EHR, however, without the advantages of task preparation. Lastly, physicians may prefer easier tasks when selecting EHR tasks to perform during the post-appointment time. Selecting easier tasks has been associated with lower productivity (KC et al. 2020, Ibanez et al. 2018). Therefore, the time taken to complete EHR work for the appointment may go up if the physician selects easier EHR tasks during the postwork period.\n\nThere are three advantages to performing EHR tasks during idle time after an appointment. First, shifting  EHR-related  activity  to  after  the  appointment  may  help  reduce  information  overload  (KarrWisniewski and Lu 2010) for the physician during the appointment. Doing dedicated EHR work during idle time without interference from patient interaction may lead to improved efficiency in doing EHR work. Second, when compared to end-of-day work, the physician may have better recall during regular work hours and thus  may  be  able  to  complete  EHR  tasks  faster.  Operations  management  literature  has  previously identified the productivity benefits of improved recall. Third, the physician may need to collaborate with the nurse or other care providers while filling in the information in EHR or may need technical assistance on the EHR system itself. In that case, it is preferable to complete tasks during regular work hours. Afterwork coordination and communication may need to be done asynchronously, as not everyone is available. Recent  studies  on  work  from  home  of  information  workers  have  shown  that  increased  asynchronous\n\ncommunication leads to slower information sharing (Yang et al. 2022). Considering the effect of postwork on total EHR usage, we have the following hypotheses:\n\nHypothesis 3a. An increase in post-appointment EHR work leads to less total EHR workload.\n\nHypothesis 3b. An increase in post-appointment EHR work leads to more total EHR workload.\n\nAs discussed above, postwork may increase the total EHR workload, and as discussed previously, workers tend to batch tasks with increasing workload, which may increase after-work hours. On the other hand, postwork helps shift work from after-work hours and may improve EHR productivity as longer work hours have been associated with lower productivity (Caruso 2014). Given these factors, we hypothesize:\n\nHypothesis 4a. An increase in post-appointment EHR leads to less end-of-day EHR workload.\n\nHypothesis 4b. An increase in post-appointment EHR leads to more end-of-day EHR workload.\n\nPhysicians have considerable discretion on how they choose to distribute EHR activity before, after, or during appointments or after the end of the workday (Zhang 2016, Attipoe 2021). In the following two hypotheses, we consider whether increasing the idle time between appointments would lead to changes in the amount of prework and postwork.\n\nWe first consider the effect of idle time on prework. Research in psychology has demonstrated that when presented with an opportunity to prepare for upcoming tasks to reduce task-switching costs, workers may fail  to  do  so.  This  may  happen  due  to  a  lack  of  motivation,  fatigue,  or  lack  of  feedback  on  the performance benefits of preparation (De Jong 2000). Short breaks can benefit productivity (Pendem et al. 2022), and physicians may wish to take benefit of these short breaks to rejuvenate themselves rather than work on EHR. Lastly, since there is a possibility that the upcoming appointment may be a no-show, the physician may not do prework to avoid wasted effort.\n\nOn the  other  hand,  increasing  the  idle  time  before  an  appointment  may  lead  to  the  physician spending more time on prework. The physician may be aware of the productivity benefits of prework and may do so when given an opportunity. The physician may prefer to spend more face time with the patient and perform more prework EHR work when the idle time before an appointment increases. In the context of  hand  hygiene,  Dai  et  al.  (2015)  show  that  when  there  is  time  off  between  shifts,  the  time  spent  on secondary tasks goes up.  Given these effects, we present the following hypotheses:\n\nHypothesis 5a. An increase in the average idle time between preceding appointments leads to more preappointment EHR time for the focal appointment.\n\nHypothesis 5b. An increase in the average idle time between preceding appointments leads to less preappointment EHR time for the focal appointment.\n\nIncreasing idle time after an appointment may not lead to any increase in postwork. Physicians may procrastinate any remaining EHR tasks for the appointment to the end of the day and utilize idle time for rejuvenation. Secondly, the physician may prefer to batch EHR tasks to the end of the day. Batching of\n\ntasks by healthcare professionals has been observed in other healthcare contexts, such as radiology and the emergency department (Ibanez et al. 2017, Meng et al. 2021, and Feizi et al. 2022). Physicians may also prefer the flexibility of working from home (Attipoe 2021) and may not utilize the idle time for postwork.\n\nOn  the  other  hand,  several  factors  may  lead  to  increasing  postwork  with  increasing  idle  time between appointments. First, an increase in idle time between appointments may increase the likelihood of completing  a  patient's  EHR-related  tasks  and  not  getting  interrupted  by  the  following  appointment.  If physicians are averse to interruptions and incomplete work, they may increase postwork activity if more time becomes available. Additionally, physicians may prefer to end the day early, spend more face time with  the  patients,  and  take  advantage  of  better  recall  immediately  after  the  appointment.  Thus,  with additional idle time after the appointment, physicians will utilize that to increase postwork. We present the following hypotheses:\n\nHypothesis 6a. An increase in average idle time after an appointment leads to more post-appointment work. Hypothesis 6b. An increase in average idle time after an appointment leads to less post-appointment work.\n\nWe tabulate the mechanisms through which prework and postwork may affect total and end-of-day time spent on EHR in Table 1.\n\nTable 1: Mechanisms of the effect of Prework and Postwork on Total and End-of-Day Time on EHR\n\n\n## 4. Data\n\n\n\n## 4.1 Data Description\n\n\nWe test our hypotheses using data from the Family Medicine unit of one of the largest Academic Medical  Centers  in  the  United  States.  The  Family  Medicine  unit  delivers  primary  care  services  in  an outpatient setting. All physicians are required to use the same EHR system provided by Epic Systems Inc. 3 Our data ranges from May 2017 through May 2019. We restrict our data to those days with at least five appointments  in  the  day,  as  days  with  less  than  five  appointments  are  not  representative  of  the  daily workload of the physicians. Our final data comprises 152,970 appointments from 74 physicians.\n\nEHR systems record time stamps of activities performed. This data is called audit log data or event log data. This data tracks who logged in to the EHR system, what task was performed, when they did the task, and the patient record on which it was performed. This audit data is recorded because of the HIPAA requirements to audit inappropriate access (Adler-Milstein et al. 2020). Several studies have validated the measurement of EHR use from audit log data through other means. Tai-Seale (2017) compared EHR audit log data by two means, in-person observation, and audio recording. Sinha et al. (2021) and Arndt et al. (2017) validated EHR time stamp data with observed data. These studies find the difference between EHR time stamp data and observed data of EHR usage to be small and recommend using audit log data to study clinic workflow and EHR use by physicians.\n\nWe have  two  separate  datasets  of  audit  log  data.  The  first  dataset  relates  to  the  appointment progression. This data consists of the following fields for each appointment: Patient ID,  Physician ID, Date of appointment, Age of patient, Gender of patient, Patient insurance provider, Scheduled start time of appointment, Start time of patient check-in at the front desk, Time patient enters an examination room, Time nurse leaves the examination room, Time physician enters the examination room, Diagnosis codes for visit and Time physician ends the appointment. The second dataset is EHR usage log data. This data has timestamps for each EHR action and the identifier for the patient whose records were being viewed or edited by the physician. This data consists of the following: Physician ID, Patient ID, EHR activity starting timestamp, and EHR activity name. Given Physician ID, Patient ID, appointment time stamps, and EHR activity time stamps, we can combine the two data sets to get the time spent on EHR activity for each patient between two given time limits. Next, we define the different time windows when physicians perform EHR tasks.\n\nPrework ( PRE ) is the amount of time a physician spends on a patient's EHR record from 12:01 AM on the day of the appointment until the start of the face-to-face appointment. We ignore work done on EHR before 12:01 AM, as we observe that less than 0.01% of EHR work for an appointment is done on the previous  day.  Multitasking  ( MULTI )  EHR  time  is  spent  on  EHR  tasks  while  the  physician  is  in  the examination room with the patient. Postwork ( POST ) EHR activity is done between the end of the face-to-\n\nface appointment and the end of the workday. End-of-day ( EOD ) EHR activity denotes time spent on EHR after the end of the workday. We define the end of the workday as 6 pm because it is the standard practice in our setting and several studies define regular work hours for physicians to be between 8 am and 6 pm (Arndt et al. 2017, Sinha et al. 2021). We repeat our analysis with the physician workday ending at 5 pm, as used by Bavafa and Terwiesch (2019), and also by computing the end of the workday to be the end of the last appointment. Our findings do not change for these alternate definitions for the end of the workday.\n\nIn Figure 2, we show the representative timing of these EHR activities. The blocks above the central horizontal line represent the time physicians spend with patients in the room. We show five appointments, the second appointment is a no-show, and the fourth appointment has a delayed start, starting after its scheduled start time. For simplicity, we only show EHR activities of appointment 4. We show the timing of EHR activity in the blocks below the horizontal line. As discussed above, we can observe that physicians divide their EHR activity into prework ( PRE ), postwork ( POST ), multitasking work with the patient in the room ( MULTI ), and EHR work at the end of the day ( EOD ). We next describe the procedure of computing the time spent on EHR activity between given time intervals.\n\nFigure 2: Representative diagram of timing of appointments and EHR work for a physician's day.\n\n<!-- image -->\n\n\n## 4.2 Data Transformation\n\n\nOur unit of analysis is an appointment, and we analyze the timing of EHR usage relative to the appropriate appointment. For this, we transform the data so that for each appointment, we have the EHR work done during the intervals for PRE, MULTI, POST, and EOD. Next, we describe the steps to compute the duration of EHR activity done by a physician within these time intervals.\n\nFirst, we select the subset of EHR usage log data for the given Physician ID and Patient ID. Then we find all EHR activities where the activity time stamp falls within the start and end times of the required time interval. We order all these activities in increasing time. Let these activities be ( 𝑎ଵ , 𝑎 ଶ , … , 𝑎 ே ) and the corresponding time stamps be ( 𝑡 ଵ , 𝑡 ଶ , … , 𝑡 ே ).\n\nNext, we compute the duration of the activity 𝑎௜ by computing 𝑡 ௜ାଵ -𝑡௜ . The timestamp for each activity is created by the EHR internal system when the physician interacts with the system. However, there is no direct way to ascertain how long the physician was active on the EHR system for a particular task. The physician may have the EHR open while engaging in other activities, such as talking to the patient or a colleague. To eliminate idle time where the system is open without any activity, we applied a cutoff of 90 seconds, i.e., for activity 𝑎௜ if 𝑡 ௜ାଵ -𝑡௜ exceeds 90 seconds, we set it to 90 seconds. We used a 90-second cutoff as Arndt et al. (2017) validated that applying a 90-second cutoff supported observed data of physician EHR usage. Tai-Seale (2017) and Sinha et al. (2021) used a cutoff of 60 seconds. Both studies also validate the measurement from EHR audit logs against data from actual observations of physicians. To demonstrate that  our results are not sensitive to this cutoff threshold, we repeat our analysis for cutoff values of 60 seconds, 90 seconds, and 120 seconds. We present these results in the Electronic Companion (EC.3.2), showing that our principal findings do not change. We compute PRE, MULTI, POST , and EOD using the above procedure. Next, we will describe the definition of each variable and present descriptive statistics.\n\n\n## 4.3 Variable Definitions and Descriptive Statistics\n\n\nIn Table 1, we present the summary statistics. We have two dependent variables for our analysis . The first is the total time spent on EHR on an appointment on the day of the appointment ( TOTAL . ) The second dependent variable of interest is the time physicians spend on EHR systems after the end of the work day ( EOD . )\n\nWe have four principal endogenous variables for our analysis: PRE, MULTI, POST, and EOD. Our last  variable  of  interest  is  the  average  idle  time  between  appointments  after  the  index  appointment ( MeanIdleAfter ). We compute the duration between the end time of the index appointment and the start time of the subsequent appointment as the idle time after the index appointment. To compute the average idle time after the index appointment, we compute the average of all such idle times after the end of the index appointment. This variable will measure the time available to do post-appointment EHR tasks after an  appointment.  As MULTI may influence MeanIdleAfter ,  we  model MeanIdleAfter as  an  endogenous variable. Finally, we include the following control variables:\n\nPatient controls: Patient characteristics such as clinical complexity may determine how much time physicians spend outside clinical hours and during appointments on EHR systems (Zhang et al. 2016, Arndt et al. 2017). Therefore, we control for several patient-level factors, such as gender, age, and whether the patient has Medicaid, Medicare, or private insurance. We control for patient continuity by including an indicator  variable  if  the  patient  has  last  visited  the  same  physician  previously.  We  control  for  patient complexity by including a variable for the Charlson Comorbidity Index (CCI), which is used frequently in the literature (Austin et al. 2015, KC and Tushe 2021). CCI measures the one-year mortality of patients by incorporating the acuity of several severe medical conditions and is expressed as an integer between 0 and\n\n13. We use the R package 'comorbidity'  to convert the diagnosis codes of a visit to CCI scores. 4 Workload and scheduling controls: The clinical workload of the physician may influence the choice to allocate EHR work during work hours or after the end of the day. Therefore, we include the total number of appointments scheduled and the total scheduled duration of all appointments on the day. Additionally, we control for the appointment sequence because physicians' choices for allocating EHR tasks may vary for earlier and later appointments for the day. We include a control for the scheduled duration of the index appointment, as that may influence the physician's choice to increase multitasking EHR activity during the appointment. We also control for the average  idle time between  appointments preceding the index appointment ( MeanIdleBefore). Other controls: We include fixed effects for physicians to control for time-invariant physician characteristics. We also include the day-of-week effect.\n\nTable 2: Descriptive Statistics at the Appointment Level\n\nNotes: N=152,970. Unit of analysis is an appointment. Other control variables not in the table: Physician FE, Patient Gender, Patient Age, Patient Insurance, Patient Continuity Indicator, and Day of Week\n\n\n## 5. Econometric Model\n\n\nOur observational dataset on physician EHR use is detailed and granular, allowing us to perform a process-level analysis. The patient ID labels EHR activity for a particular patient's record. This allows us to connect the appointment progression and patient characteristics with the EHR use giving us a view into when EHR tasks were performed for a particular appointment.\n\nThe central challenge in using observational data to identify causal effects in our analyses arises from physicians' endogenous choice of when and how much EHR tasks to perform during idle time. While we control for factors such as daily workload and patient complexity, other unobservable patient factors may affect the total time on EHR and the work done during idle time. For example, if a patient expresses a severe mental health condition during the appointment, the physician would be more likely to spend face time with the patient than do EHR work while the patient is in the room (Zhang et al. 2016). This would likely increase POST and EOD while reducing MULTI . A patient having a severe mental health condition is also correlated with increased EHR usage by the physician (Young et al. 2018). Young et al. (2018) find that patients and physicians having linguistic and cultural similarities correlate with more face-to-face time and total EHR time. These examples indicate that using observational data of EHR time stamps would be challenging for our analysis. We address this problem by setting up an identifiable system of simultaneous equations accounting for the simultaneity bias among our key variables of interest. Through this system of equations,  we  model  the  relationship  between PRE , MULTI , POST , EOD ,  and  the  idle  time  between appointments. Through this system of equations, we estimate the effect of PRE and POST on TOTAL and EOD .\n\n\n## 5.1 Model Formulation and Identification\n\n\n𝑳𝒐𝒈𝑷𝑹𝑬𝒊 = 𝜶𝑨𝑫,𝑷𝑹𝑬𝑳𝒐𝒈𝑨𝒓𝒓𝑫𝒆𝒍𝒂𝒚𝒊 + 𝜶𝑷𝑫,𝑷𝑹𝑬𝑳𝒐𝒈𝑷𝑪𝑷𝑫𝒆𝒍𝒂𝒚𝒊 + 𝜶𝑰𝑩,𝑷𝑹𝑬𝑳𝒐𝒈𝑰𝒅𝒍𝒆𝑩𝒆𝒇𝒐𝒓𝒆 + 𝜽𝑷𝑹𝑬𝑿𝒊 + 𝝐𝑷𝑹𝑬,𝒊 (𝟏) 𝑳𝒐𝒈𝑴𝑼𝑳𝑻𝑰𝒊 = 𝜷𝑷𝑹𝑬,𝑴𝑳𝒐𝒈𝑷𝑹𝑬𝒊 + 𝜶𝑨𝑫,𝑴𝑼𝑳𝑻𝑰𝑳𝒐𝒈𝑨𝒓𝒓𝑫𝒆𝒍𝒂𝒚𝒊 + 𝜶𝑷𝑫,𝑴𝑳𝒐𝒈𝑷𝑪𝑷𝑫𝒆𝒍𝒂𝒚𝒊 + 𝜶𝑴𝑳𝑨𝑮,𝑴𝑳𝒐𝒈𝑳𝒂𝒈𝑴𝒖𝒍𝒕𝒊𝒊 + 𝜽𝑴𝑿𝒊 + 𝝐𝑴𝑼𝑳𝑻𝑰,𝒊 (𝟐) 𝑳𝒐𝒈𝑰𝒅𝒍𝒆𝑨𝒇𝒕𝒆𝒓 = 𝜷𝑷𝑹𝑬,𝑰𝑨𝑳𝒐𝒈𝑷𝑹𝑬𝒊 + 𝜶𝑨𝑫,𝑰𝑨𝑳𝒐𝒈𝑨𝒓𝒓𝑫𝒆𝒍𝒂𝒚𝒊 + 𝜷𝑴,𝑰𝑨𝑳𝒐𝒈𝑴𝑼𝑳𝑻𝑰𝒊 + 𝜶𝑵𝑨,𝑰𝑨𝑵𝒐𝑺𝒉𝒐𝒘𝑨𝒇𝒕𝒆𝒓 + 𝜽𝑰𝑨𝑿𝒊 + 𝝐𝑰𝑨,𝒊 (𝟑) 𝑳𝒐𝒈𝑷𝑶𝑺𝑻𝒊 = 𝜷𝑷𝑹𝑬,𝑷𝑶𝑺𝑻𝑳𝒐𝒈𝑷𝑹𝑬𝒊 + 𝜷𝑴𝑼𝑳𝑻𝑰,𝑷𝑶𝑺𝑻𝑳𝒐𝒈𝑴𝑼𝑳𝑻𝑰𝒊 + 𝜷𝑰𝑨,𝑷𝑶𝑺𝑻𝑳𝒐𝒈𝑰𝒅𝒍𝒆𝑨𝒇𝒕𝒆𝒓𝒊 + 𝜶𝑳𝑷𝑳𝒂𝒈𝑳𝒐𝒈𝑷𝑶𝑺𝑻 + 𝜽𝑷𝑶𝑺𝑻𝑿𝒊 + 𝝐𝑷𝑶𝑺𝑻,𝒊 (𝟒) 𝑳𝒐𝒈𝑬𝑶𝑫𝒊 = 𝜷𝑷𝑹𝑬,𝑬𝑶𝑫𝑳𝒐𝒈𝑷𝑹𝑬𝒊 + 𝜷𝑴𝑼𝑳𝑻𝑰,𝑬𝑶𝑫𝑳𝒐𝒈𝑴𝑼𝑳𝑻𝑰𝒊 + 𝜷𝑰𝑨,𝑬𝑶𝑫𝑳𝒐𝒈𝑰𝒅𝒍𝒆𝑨𝒇𝒕𝒆𝒓𝒊 + 𝜷𝑷𝑶𝑺𝑻,𝑬𝑶𝑫𝑳𝒐𝒈𝑷𝑶𝑺𝑻𝒊 + 𝜽𝑬𝑶𝑫𝑿𝒊 + 𝝐𝑬𝑶𝑫,𝒊 (𝟓)\n\nThese equations model the relationship between PRE MULTI MeanIdleAfter , , , POST , and EOD . We perform a log transformation for all variables that are a duration of an activity or a time interval. We use log transformation because it has been used to model service time in healthcare (KC and Terwiesch 2009). Gurvich et al. (2020) show that documentation time by physicians follows a log-normal distribution. The estimates (𝛽௉ோா,ெ , 𝛽 ௉ோா,ூ஺ , 𝛽 ெ,ூ஺ , 𝛽 ௉ோா,௉ைௌ் , 𝛽 ெ௎௅்ூ,௉ைௌ்  , 𝛽 ூ஺,௉ைௌ் , 𝛽 ௉ோா,ாை஽ , 𝛽 ெ௎௅்ூ,ாை஽ , 𝛽 ூ஺,ாை஽ , 𝛽௉ைௌ்,ாை஽ ) give the relationship among the endogenous variables. The parameters (𝛼஺஽,௉ோா , 𝛼 ௉஽,௉ோா , 𝛼 ூ஻,௉ோா , 𝛼ெ௅஺ீ,ெ , 𝛼 ே஺,ூ஺ , 𝛼 ௅௉ ) are  the  coefficients  of  the  exogenous  variables.  All\n\nother controls, such as patient controls, workload, and scheduling controls, are collected together in 𝑿𝒊 and the coefficients corresponding to these controls are (𝜃௉ோா , 𝜃 ெ, 𝜃 ூ஺ , 𝜃 ௉ைௌ் , 𝜃 ாை஽ ) . Finally, ( 𝜖 ௉ோா,௜ , 𝜖 ெ௎௅்ூ,௜ , 𝜖 ூோ,௜ , 𝜖 ௉ைௌ்,௜ , 𝜖 ாை஽,௜ ) are the error terms for each equation. Figure 3 illustrates the block diagram for the system of equations.\n\n<!-- image -->\n\nWe first consider equation (1). With increasing idle time before an appointment, physicians would have more time to do prework. If this coefficient is positive, that would indicate that physicians utilize the idle time before an appointment to perform tasks on the EHR system before face-to-face time with the patient. If the physician is delayed for an appointment, the physician may reduce the time spent on prework. We note that physicians being delayed due to the previous appointment will be exogenous to physician EHR use for the index appointment. Next, in equation (2), we model the time spent on the EHR system while the patient is in the room to depend on prework and physician delay.\n\nThe  time  physicians  multitask  on  EHR  may  influence  the  idle  time  between  subsequent appointments. From this, we have equation (3). Depending on the effect of previous work done on EHR ( PRE , MULTI )  and  the  amount  of  idle  time  available  between  appointments  after  its  conclusion,  the physician may choose to perform some postwork. We model this by equation (4). Finally, depending on the effect of previous EHR tasks, the remaining EHR task is done after the end of the workday ( EOD) . We model this by equation (5).\n\nWe note that the system of equations above is recursive, where in each equation, only endogenous variables  from  the  previous  equations  appear  on  the right-hand  side  (Wooldridge  2010).  However,  the system of equation is not fully recursive because, as we discussed above, there may be unobserved patient characteristics that may influence both total EHR time spent on an appointment and the distribution of EHR tasks to PRE, MULTI,  POST , and EOD . Therefore, we cannot assume that the error terms ( 𝜖 ௉ோா,௜ , 𝜖 ெ௎௅்ூ,௜ , 𝜖 ூோ,௜ , 𝜖 ௉ைௌ்,௜ , 𝜖 ாை஽,௜ ) are  pairwise  uncorrelated.  Consequently,  for  the  system  to  be\n\nidentified, we include instrumental variables in addition to the variables discussed above. We define the instrumental variables below.\n\nPatient Arrival Delay ( ArrDelay ): This is the delay in patient arrival, computed by the time difference between the appointment's scheduled start time and the patient's check-in time.\n\nLagged Multitasking ( LagMULTI ): This is the time spent on EHR by the physician during an appointment ( MULTI ) on the previous day, which has the same sequence as the index appointment.\n\nNo Show After Appointment ( NoShowAfter ): Indicator variable if one of the scheduled appointments after the index appointment is a no-show.\n\nLagged Postwork ( LagPOST ): We compute this variable by taking the time spent on EHR by the physician after an appointment ( POST ) on the previous day, which has the same sequence as the index appointment.\n\nA valid instrument for a system of equations needs to satisfy specific requirements. First, it needs to be uncorrelated with all the error terms. Secondly, some of the exogenous variables must be excluded from some of the equations, i.e., not all exogenous variables can affect all of the endogenous variables directly. This requirement is called the exclusion requirement. For a system of equations to be identified, the exclusions must satisfy the order and rank conditions. The order condition for an equation states that the number of excluded exogenous variables from the equation must be greater than or equal to the number of  included  right-hand-side  endogenous  variables.  The  rank  condition  requires  that  the  matrix  of  all structural equations of the model have full rank. A detailed discussion of these requirements is available in Wooldridge (2010), Chapter 9. We discuss our choice of instrumental variables and their validity below.\n\nFirst, for equation (1), we include patient arrival delay. If a patient arrives late for an appointment, that will give time for the physician to do additional prework. Similar to physician arrival delay, patient arrival delay may impact MULTI and the IdleAfter but is unlikely to be correlated with the error terms for the equations for POST or EOD. For equation (2), we include the logged transformation of LagMULTI, which is MULTI for the appointment on the previous day of the physician, which had the same sequence as the index appointment. Using lagged variables as instrumental variables is a common practice (Kesavan et al. 2014, Tan and Netessine 2014). We also used an alternate construction of LagMULTI by computing the average  lagged  multitasking  EHR  for  the  physician's  appointments  on  the  previous  day.  Our  results remained the same.\n\nNext, in equation (3), we use the indicator variable NoShowAfter, which denotes the presence of a no-show appointment after the index appointment. The information that an appointment is a no-show is available only at the start of that appointment. Therefore, it is unlikely that the presence of a no-show following the index appointment would be correlated with unobservable patient characteristics of the index appointment. Lastly, we used LagLogPOST for equation (4). LagPOST is the lagged variable for POST and is computed similarly to LagMULTI.\n\nWe can  verify  through  observation  that  our  system  of  equations  satisfies  the  order  condition because, for all equations, the number of excluded exogenous variables from the equation is greater than the number of included right-hand-side endogenous variables. We use the Stata package 'checkreg3' (Baum 2007) to verify that all the equations satisfy the rank condition.  Our estimation procedure is based on the Two-Stage Least Squares (2SLS) estimation procedure for simultaneous equations described in Wooldridge (2010). We describe the estimation steps in the electronic companion (EC.1). We cluster robust standard error by Physician and Date of Appointment.\n\nAs a part of our robustness tests, we also show results from estimating our model using the threestage least squares (3SLS) estimator (Zellner and Theil 1992) (EC.3.4), and we observe that parameter estimates  show  only  minor  differences  from  the  2SLS  estimation.  We  also  present  results  on  tests  of endogeneity (EC.3.5) and show that the results support endogeneity in the system of equations. In the next section, we discuss our results and their managerial relevance.\n\n\n## 6. Results and Discussion\n\n\nIn  Table  3,  we  present  the  estimated  parameters  of  our  system  of  equations.  The  dependent variables label the columns, and the column numbers correspond to equations (1)-(5). The right-hand-side variables of the corresponding equations label the rows. We have rows for all endogenous variables and, for conciseness, include only a subset of the exogenous variables. From the estimates of equation (1), we observe that as the idle time before an appointment increases, the physicians increase PRE . A small but significant increase in PRE is also observed when patients check in after their scheduled appointment start time. This also suggests that when physicians have time available before an appointment, they are likely to increase PRE. When physicians are delayed, they reduce PRE . This suggests that a more congested schedule with less idle time for physicians would lead to physicians reducing PRE.\n\nFrom equation (2), we observe that an increase in PRE leads to a reduction in MULTI. As comments by Sinsky (2016), literature on task preparation and early-task initiation suggest, this could be due to the advantages of early-task initiation and task preparation . In column (3), we observe that a no-show after an appointment increases the idle time between appointments. However, if a physician arrives late to the index appointment, the effect of physician delay persists beyond the completion of the index appointment by reducing the idle time following the appointment. Finally, from estimates for LogEOD in column (5), we observe that increasing PRE, MULTI, and POST reduces EHR work from after-work hours.\n\nWhile the above-discussed effects are statistically significant, due to the logarithmic transformation of variables, the interpretation of these coefficients is not obvious. Furthermore, we want to estimate the marginal impact of PRE and POST on total EHR time spent, which is also not evident from these estimates. Therefore,  next,  we  compute  the  marginal  effects  corresponding  to  these  coefficients  and  the  overall marginal effect of PRE and POST on TOTAL .\n\nTable 3: Summary Regression Results for Simultaneous Equation Model Equations (1)-(5)\n\nStandard errors in parentheses Notes: N=152,970. The unit of analysis is an appointment. All models include Physician FE, Patient Controls, and Scheduling Controls, as described in Section 4. Robust standard errors, in parenthesis, are clustered by Physician and Date of Appointment. * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n## 6.1 Marginal Effects and Managerial Relevance\n\n\nFrom equation (5), we compute the marginal effect of PRE and POST on EOD . In the electronic companion, we show the computation of the overall marginal effect of PRE and POST on TOTAL from the coefficients of the system of equations. From equations (1) and (4), we compute the marginal effect of MeanIdleBefore and MeanIdleAfter on PRE and POST. We present these in Tables 4 and 5.\n\nTable 4: Marginal Effects at Mean of Prework and Postwork on End of Day Work and Total EHR work\n\nTable 5: Marginal Effects at Mean Idle Time on Prework and Postwork EHR Work\n\nWe observe that a unit increase in PRE decreases EOD by 0.167 units and TOTAL by 0.391 units. Therefore, we find support for Hypotheses 1a and 2a. The advantages of PRE , such as task preparation and early task initiation, outweigh the additional time spent doing PRE and any task changeover time introduced by doing more prework between appointments. The managerial relevance of these estimates is that if a physician increases PRE for an appointment by 5 minutes, then the sum of MULTI, POST, and EOD reduces by 6.9 minutes. In other words, a 5-minute increase in PRE reduces TOTAL by 1.9 minutes, a decrease of 10.4%. A 5-minute increase in PRE reduces EOD by 0.8 minutes, a decrease of 45%. In our setting, with 74 physicians who, on average, have 13 appointments per day, this translates into 21 fewer hours of endof-day EHR work.\n\nA unit  increase  in POST decreases EOD by  0.317  units,  which  leads  to  an  overall  increase  in TOTAL of 0.683 units. Therefore, we find support for hypotheses 4a and 3b. The disadvantages of POST include the interruption effects of subsequent appointments, meaning that the reduction in EOD does not outweigh the additional work done during POST. If a physician spends 5 additional minutes doing POST for  an  appointment, EOD will  decrease  by  1.3  minutes,  a  reduction  of  72%.  However,  the  total  EHR workload would go up by 3.6 minutes, an increase of 19.4%. We can observe that POST has a greater marginal effect on EOD as compared to the effect of PRE on EOD. This is possibly due to the fact that the physician has similar information regarding the patient visit when doing POST and EOD. Due to this, POST and EOD efforts are substitutable to a greater extent than PRE and EOD.\n\nFrom the above results, we estimate that increasing prework has the potential to significantly reduce both total and end-of-day EHR activity time for physicians. While postwork reduces end-of-day EHR time significantly  more  than  prework,  postwork  comes  at  the  cost  of  increased  overall  EHR  workload.  Our results are interesting as they demonstrate the differential impact of doing the secondary task as a pre or postwork. In fact, while prior literature on managing primary and secondary tasks, such as Legros et al. (2020) and EHR documentation tasks (Gurvich et al. 2020), has not differentiated prework and postwork, in our context we find that prework strictly dominates postwork.\n\nGiven  the  relative  advantages  of  prework  and  postwork,  hospital  administrators  may  consider providing protected time for EHR tasks depending on the outcomes required. If the objective is to reduce both total and end-of-day EHR workload, more focus can be placed on increasing prework. If the focus is on decreasing end-of-day time, a greater emphasis can be placed on postwork. After-hours EHR work has been identified as a significant contributor to physician fatigue (Adler-Milstein et al. 2020) and burnout (Robertson et al. 2017). Therefore, while postwork may increase total EHR work, its impact on reducing after-hours EHR work may still make postwork attractive.\n\nWhile considering increasing protected time for EHR tasks, an important consideration would be if  physicians would actually make use of the protected time to do EHR tasks. Due to the observational nature of our data, we can only provide insights into increases in unscheduled idle times. It is likely that physician  behavior  may  change  if  physicians  are  informed  of  an  increase  in  the  idle  time  between appointments ex-ante and are offered encouragement to use this time towards PRE and POST. Further research is required into the effect of scheduled idle time on pre and post-appointment EHR time.\n\nFrom our analysis of unscheduled idle time, we find that physicians show an increase in PRE and POST with increasing idle time before and after an appointment . We note that the overall marginal effect of MeanIdleBefore on PRE is smaller than that of MeanIdleAfter on POST .      An  increase of 5 minutes between the preceding appointment increases PRE by 7 seconds. On the other hand, an increase of 5 minutes between following appointments increases POST by 2 minutes. Our data suggest that physicians increase\n\nboth PRE and POST when presented with unscheduled increases in idle time. Therefore, we find support for Hypotheses 5a and 6a.  While we find that prework is a dominating strategy; however, with increasing idle time, physicians spend more time on postwork than prework.\n\n## 6.2 Alternative Explanation of Relationship between Prework and Total EHR Time\n\nIn our analysis, increasing prework reduces total EHR time. There are two possible explanations for this. The first explanation is that physicians are more productive with increasing prework due to task preparation and early task initiation advantages. An alternative explanation is that prework may be a loadbased response mechanism; therefore, the negative association between PRE and TOTAL may be due to task reduction. Previous literature has identified the relationship between increased load and eroding service standards (Olivia  and  Sterman 2001, KC and  Terwiesch 2012). To assess this question, we examine a different measure of EHR work - word count. Given the patient identifying information in the provider notes, we are not able to access them directly. However, we obtained precise word counts of the progress notes, patient instructions, and all other notes entered by the physician for each appointment. We use this word count as a proxy measure of EHR quality. If the decrease in TOTAL from increasing PRE is a result of task reduction, we should find a negative association between EHR word count and PRE. Controlling for all workload, physician, and patient characteristics described in Section 4.3, we find that an increase in PRE is associated with an increase in the total word count. Although careful qualitative analysis of all notes would be necessary to fully rule out the alternative explanation, this finding helps mitigate concerns that the negative relationship between PRE and TOTAL is from task reduction. We provide the result of this analysis in the Electronic Companion (EC.4)\n\n\n## 7. Discussion and Conclusion\n\n\n\n## 7.1 Discussion\n\n\nPhysician burnout is at an all-time high, with over 68% of physicians in the US reporting burnout in 2021.  In the U.S., the cost of physician turnover from burnout has been estimated to be between $2.8bn 5 to $6.3bn per year (Han et al. 2019). Several studies have identified the significant impact of EHR workload on physician burnout. However, operational suggestions for reducing this workload have been relatively unexplored. We investigate the impact of the structure of EHR work during a physician's day. We find that doing EHR work in preparation for the upcoming appointment is a dominating strategy and can reduce a physician's total and after-hours time on EHR. Doing EHR work after an appointment can significantly reduce after-hours EHR time, however, at the cost of increasing the total EHR workload. We find that idle time between appointments is an important driver of how physicians structure their daily EHR workload.\n\nIncreasing  idle  time  between  appointments  increases  both  pre-appointment  and  post-appointment  EHR workload. However, post-appointment EHR work increases to a greater degree.\n\nOur  findings  are  also  relevant  to  several  other  service  contexts.  Service  operators  often  must manage secondary tasks in addition to the primary task with customer interaction. Examples include data entry between calls for call center operators, working on insurance claim investigations between customer interactions  for  insurance  agents,  hand  washing  for  surgeons,  and  collaboration  with  other  physicians between inpatient rounds for hospitalists. These secondary tasks are related to the primary task; however, service  operators  have  greater  discretion  when  they  choose  to  do  them.  Our  results  show  when  these secondary tasks are done during the day determines the total and after-hours secondary task workload.\n\nWe make the following four principal contributions. First, we contribute to physician EHR use literature  by  quantifying  the  impact  of  pre  and  post-appointment  EHR  work  during  idle  time  between appointments. EHR use literature has focused on the overall impact of increasing EHR workload. We add to this literature by measuring the impact of the structure of EHR work during the day. We find that preappointment and post-appointment EHR tasks have different impacts on total and end-of-day EHR work. Pre-appointment  EHR  tasks  reduce  both  total  and  end-of-day  EHR  workload.  This  suggests  that  the advantages of pre-appointment EHR tasks, such as better preparation and early task initiation, outweigh the costs  of  increased  task  switching  from  documentation  to  face-to-face  activities.  While  interviews  with physicians have qualitatively indicated these factors, through our analysis, we are able to provide a rigorous quantitative  analysis  of  the  positive  impact  of  pre-appointment  EHR  work.  We  also  find  that  postappointment EHR tasks significantly reduce end-of-day EHR. The marginal reduction of end-of-day EHR time is greater from increasing post-appointment EHR tasks than from increasing pre-appointment EHR tasks. This is likely because the physician has similar information regarding the appointment when doing post-appointment and end-of-day EHR activities. Therefore, end-of-day EHR time can be easily substituted by post-appointment EHR. However, increasing post-appointment EHR tasks leads to an increase in total time  spent  on  EHR.  This  suggests  that  the  disadvantages  of  post-appointment  EHR  work,  such  as interruption due to following appointments and task switching, outweigh the advantages of reducing the end-of-day EHR workload.\n\nSecond, we contribute to task selection literature in operations management which has discussed the structure of work and the trade-offs involved in strategies such as multitasking, batching, and early-task initiation. Many of these studies have focused on the workload from the primary task. However, like the EHR workload for physicians, in many services, the workload due to secondary tasks is significant, and we study the operational impact of the structure of secondary tasks. Our findings show that the total time spent on secondary tasks depends on how service operators structure secondary work before, during, and after an appointment. Doing secondary tasks before an appointment may help reduce the time spent on secondary\n\ntasks by taking advantage of task preparation and early task initiation. Increasing secondary tasks after an appointment significantly reduces after-work hours; however, post-appointment secondary tasks may be interrupted  by  the  following  appointment  and  may  lead  to  an  overall  increase  in  total  time  spent  on secondary tasks due to interruption-driven inefficiencies.\n\nIn addition to contributing to theory, our findings have important implications for practice.  Service designers can use these insights to create workflows for service operators managing primary and secondary tasks to improve server productivity and reduce after-work hours. The impact of the structure of secondary tasks on operational performance, such as makespan and after-work hours, will have relevance in a wide variety of service contexts. For clinics, these insights will help healthcare administrators in primary care create EHR workflows and appointment schedules that reduce burnout due to EHR workload. The idle time between appointments can be increased to increase both pre-appointment and post-appointment EHR time. The varying effects of pre and post-appointment EHR work suggest that the recommended use of idle time would  depend  on  the  clinic's  objective.  If  the  objective  is  to  reduce  the  total  EHR  workload,  greater emphasis can be placed on doing pre-appointment EHR tasks. If the objective is to reduce end-of-day EHR time, then increasing post-appointment EHR work would give a greater marginal benefit, although at the cost of increasing total EHR time.\n\nOur results have significant implications for the theory and practice of appointment scheduling. Scheduling  literature  for  services  has  typically  focused  on  customer  interaction  time  and  has  not incorporated the workload from these secondary tasks. In the appointment scheduling literature, an increase in idle time is often associated with an increase in makespan. However, as we observe from our results, idle time between appointments may be used to perform pre and post-appointment secondary tasks. Given our findings that prework and postwork effects both total time spent on secondary tasks and after-hours time, an important question is how does idle time affect physician makespan in the presence of secondary tasks like EHR. Since makespan is a day-level measure for a physician, we perform the following analysis to answer this question.\n\n\n## 7.2 Impact of Increasing Idle Time Between Appointments on Physician Makespan\n\n\nOur results show that increasing idle time increases PRE and POST. We also observe PRE and POST reduce EOD and POST increases TOTAL . So, the overall effect of performing EHR tasks in idle time on TOTAL is not obvious.  To estimate the combined effect of increasing idle time, we conduct an analysis on the impact of increasing idle time between appointments on physician makespan, where makespan also includes the end-of-day time spent by the physician on EHR systems. Since makespan for a physician is a day-level measure, our unit of measure for this analysis is physician-day.\n\nThe  components  of  our  model  are  as  follows:  our  outcome  of  interest  is  the  makespan  for  a physician ( 𝑃ℎ𝑦𝑠𝑖𝑐𝑖𝑎𝑛𝑀𝑎𝑘𝑒𝑠𝑝𝑎𝑛) . We define makespan as the sum of face time with patients, idle time\n\nbetween appointments, and end-of-day EHR time. We compute this by calculating the time difference between the end of the last appointment of a physician's day and the start of the first appointment. Then we add the total end-of-day EHR work for the physician's appointments. Our primary independent variable is the amount of idle time between appointments ( 𝑇𝑜𝑡𝑎𝑙𝐷𝑎𝑖𝑙𝑦𝐼𝑑𝑙𝑒𝑇𝑖𝑚𝑒) . We compute the idle time between two consecutive appointments by the time difference between an appointment's end and the subsequent appointment's  start.  We  then  sum  these  idle  times  for  all  appointments  of  a  physician's  day  to  get 𝑇𝑜𝑡𝑎𝑙𝐷𝑎𝑖𝑙𝑦𝐼𝑑𝑙𝑒𝑇𝑖𝑚𝑒 . We define the variable PhysicianWorking as the difference between makespan and the idle time, i.e., ( 𝑃ℎ𝑦𝑠𝑖𝑐𝑖𝑎𝑛𝑊𝑜𝑟𝑘𝑖𝑛𝑔 = 𝑃ℎ𝑦𝑠𝑖𝑐𝑖𝑎𝑛𝑀𝑎𝑘𝑒𝑠𝑝𝑎𝑛 - 𝑇𝑜𝑡𝑎𝑙𝐷𝑎𝑖𝑙𝑦𝐼𝑑𝑙𝑒𝑇𝑖𝑒 ). We control for the number of appointments scheduled in the day, the total scheduled duration of appointments, the average age of patients on the day, average patient complexity (as measured by CCI) of the day, the average number of patients having Medicare insurance, day of the week, and physician fixed effects. The summary statistics of all variables are in the Electronic Companion (EC.5).\n\nOur  econometric  model  is  as  follows, 𝑝 indicates  physician, 𝑗 indicates  day.  The  vector 𝒀𝒑𝒋 represents the control variables and 𝛿௣௝ indicates the error term. The coefficient 𝛽ூ,ௐ signifies the effect of increasing a physician's total idle time in a day on the non-idle time of a physician's makespan.\n\n## 𝐿𝑜𝑔൫𝑃ℎ𝑦𝑠𝑖𝑐𝑖𝑎𝑛𝑊𝑜𝑟𝑘𝑖𝑛𝑔௣௝൯ = 𝛽ூ,ௐ 𝐿𝑜𝑔൫𝑇𝑜𝑡𝑎𝑙𝐷𝑎𝑖𝑙𝑦𝐼𝑑𝑙𝑒𝑇𝑖𝑚𝑒௣௝൯ + 𝜸𝒀𝒑𝒋 + 𝛿 ௣௝    (𝟔)\n\nThere may be unobserved patient and appointment characteristics that may influence both total idle time and physician makespan. For example, as discussed before, if a patient has a serious mental health condition and discusses that with the physician during the appointment, it may lead to more time spent with the patient in the room, consequently leading to less idle time following the appointment. Since mental health conditions correlate with higher EHR use, the end-of-day EHR time would be higher, leading to a longer  makespan.  We  use  the  instrumental  variables  approach  to  circumvent  the  possibility  that 𝑇𝑜𝑡𝑎𝑙𝐷𝑎𝑖𝑙𝑦𝐼𝑑𝑙𝑒𝑇𝑖𝑚𝑒 may be endogenous. We use the number of no-shows on the physician's day as our instrumental variable. We estimate our modeling using the 2SLS procedure. The first stage is given by:\n\n## 𝐿𝑜𝑔(𝑇𝑜𝑡𝑎𝑙𝐷𝑎𝑖𝑙𝑦𝐼𝑑𝑙𝑒𝑇𝑖𝑚𝑒௣௝ ) = 𝛽 ஻,஽௅ 𝑁𝑢𝑚𝑏𝑒𝑟𝑜𝑓𝑁𝑜𝑆ℎ𝑜𝑤𝑠௣௝ + 𝜸𝒀𝒑𝒋 + 𝜙௣௝      (𝟕)\n\nWe show the results of regression analysis and the computation of the marginal effect of total daily idle time on physician makespan in the Electronic Companion (EC.5). We find that if the total idle time increase by 5 minutes in a day, the physician makespan decreases by 0.55 minutes. Therefore, pre and postappointment  EHR  time  may  be  increased  through  increasing  idle  time  without  negatively  impacting makespan.\n\nIdle  time  between  appointments  allows  the  service  operator  to  perform    EHR  as  prework  and postwork. Our results in Section 6 show that prework and postwork can reduce after-hours work.  Therefore,\n\nfor at least small increases in idle time, the makespan for the physician reduces due to the reduction in afterhours work.\n\n\n## 7.3 Limitations\n\n\nOur study has some limitations. First, our analysis is from a primary care setting. Physicians in other settings, such as inpatients, Emergency Department (ED), and surgery, may behave differently from primary care physicians when managing EHR workload. Physicians in an inpatient and ED setting do not have scheduled appointments and often do not have the opportunity to perform prework. Therefore, our findings may not be valid in that context. Secondly, when physicians perform tasks after work, whether they are in the clinic performing these tasks or at home is not observable. Physicians use Virtual Private Networks (VPN) to connect to EHR systems when located outside the clinic. To demarcate after-hours work, we rely on the current practice in our setting and prior literature (Bavafa and Terwiesch, 2019) to set a standard time for the end of the day. We also repeat our analysis for alternative definitions of end-of-day. Lastly, since we utilize EHR audit logs to measure physician EHR use, it will be an approximate measure of time spent on the EHR system. We use a cut-off time of 90 seconds to remove the idle time between EHR tasks. This method has been validated through several other observational studies.\n\n\n## 7.4 Conclusion\n\n\nSeveral  recent  studies  in  healthcare  literature  have  determined  that  workload  due  to  EHR contributes significantly to physician burnout. However, the operational implications of physician EHR usage behavior have not been rigorously studied. We contribute to the literature on healthcare operations by  analyzing  detailed  data  on  physician  EHR  usage.  We  find  that  pre-appointment  EHR  work  is  a dominating  strategy  reducing  both  total  and  after-hours  EHR  time.  Post-appointment  EHR  work significantly reduces after-hours EHR work, however, at the cost of increasing total EHR time. We find that when the idle time between appointments increases, physicians increase pre and post-appointment EHR work. However, they focus more on post-appointment EHR work. To assess the overall impact of increasing idle time between appointments, we find that in the presence of secondary tasks like EHR, a physician's makespan may be reduced by increasing the idle time between appointments.\n\nOur  findings  also  contribute  broadly  to  operations  management  literature  by  studying  the implications of the structure of secondary work on workload and makespan. Our results have implications for the theory of task selection and appointment scheduling. Additionally, our results will provide insights to managers when creating schedules in the presence of a secondary task workload.\n\n",
         "Problem definition: Physicians spend more than 5 hours a day working on Electronic Health Record (EHR) systems and more than an hour doing EHR tasks after the end of the workday. Numerous studies have identified the detrimental effects of excessive EHR use and after-hours work, including physician burnout, physician attrition, and appointment delays. However, EHR time is not purely an exogenous factor as it depends on physician usage behavior that could have important operational consequences.\nInterestingly, prior literature has not considered this topic rigorously. In this paper, we investigate how\nphysicians' workflow decisions on when to perform EHR tasks affect: (1) total time on EHR and (2) time\nspent after work.\nMethodology/Results: Our data comprise around 150,000 appointments from 74 physicians from a large\nAcademic Medical Center Family Medicine unit. Our dataset contains detailed, process-level time stamps\nof appointment progression and EHR use. We find that the effect of working on EHR systems depends on\nwhether the work is done before or after an appointment. Pre-appointment EHR work reduces total EHR\nworkload and after-work hours spent on EHR. Post-appointment EHR work reduces after-work hours on\nEHR but increases total EHR time. We find that increasing idle time between appointments can encourage\nboth pre- and post-appointment EHR work.\nManagerial implications: Our results not only help us understand the timing and structure of work on\nsecondary tasks, more generally, but also will help healthcare administrators create EHR workflows and\nappointment schedules to reduce physician burnout associated with excessive EHR use.",
         ""
        ],
        [
         "2",
         "2",
         "## Introduction\n\n\nTranslation  plays  an  important  role  in  our  life.  Due  to  the  proliferation  of  technology, globalization and many other reasons, the need for translation has increased widely. There are many types of translation such as literary, religious and legal translation. One of the most inspiring types of translation is literary translation. Despite the difficulties and challenges it involves for translators, literary translation is  still  desired  as one  of the  most important  field  of translation. Based on this, I have decided to translate a literary work entitled 'The Saddler's Notebook '. It is a short story written by Professor Musa Al-Halool, a well-known Arabic author and translator, and was published in Beirut in 2020. Also, it will be published in London in 2021.\n\nThis story belongs to a short story collection called Merya'istan (Bellwetheristan). The story is narrated by a wise old man about a saddler who has acquired this nickname, not due to his profession, but due to a trifle because of which he lost his mother. His father had abandoned them while he was still young, thus he lived with his mother until she died because of him. He completed his parents' mission which was inciting against the people of his town. Thus, he lived alone on the margin of life.\n\nThe main idea of this story is presenting a perfect example of how unloyalty and revolution against one's homeland and family ends in loneliness and negative consequences. Also, the story presents real life events and poses many serious and heavy social questions and lessons using irony, and like many other literary works, the story is written for entertainment.\n\nAccording to the hypothetical translation brief submitted to the translator by the author, the story  was  translated  from  Arabic  into  English  by  taking  into  account  the  target  audience  who include  people  of  different  ages,  genders  and  levels  of  education  and  income.  Any  interested person can read this story and render its main purpose into the target readers.\n\nThe translated story is rich in cultural expression such as collocations and metaphors which make  its  translation  a  real  challenge.  However,  English  and  Arabic  belong  to  two  different language families. Arabic belongs to the Semitic language family while English belongs to the Indo-European  language  family.  The  great  linguistic  and  cultural  difference  between  the  two languages adds further difficulty to the translation process between them. Newmark (1981, p.7) stated that 'translation is a craft implying the attempt to replace a written message or a statement in  one  language by the same message or statement in another language.' In light of this, it is\n\nimportant to pay more attention when rendering these two cultural issues taking into account the cultural features of the two languages.\n\nAs this story consists of many examples of collocations and metaphors, these two cultural expressions will be discussed in terms of their difficulty and the effective strategies that were used to  overcome  them.  Chapter  one  includes  the  definition  of  collocations  and  their  types.  It  also tackles the issue of collocations in translation with some examples from the translated story along with the strategies used to translate these collocations. Chapter two sheds light on metaphor and its definition and types along with the issue of metaphors in translation with some examples from the translated story. It also discusses the strategies used to translate these metaphors. Finally, the conclusion  presents  other  aspects  of  interest  and  provides  an  outline  of  this  critical  analysis illustrating  the  areas  that  have  been  covered  in  this  research,  and  those  that  still  need  further research.\n\n\n## Chapter One Collocation\n\n\n\n## 1.1 Introduction\n\n\nEvery language has its cultural expressions. Collocations are one type of these expressions representing an actual interesting and important phenomenon in language. In order to translate these expressions correctly, translators need to have considerable knowledge of both the source and the target cultures. Nida (1964, p.130) states that 'the differences between cultures may cause more serious problems for the translator than the differences in language structure.' However, by using the proper strategies and techniques, collocation can be rendered into the target language in an understandable way. In the following sections, the definition and types of collocation will be discussed. The issue of collocation in translation will be illustrated by presenting some examples from the short story. I will also present an explanation of the strategies used to overcome the difficulties of translating these expressions.\n\n\n## 1.2 Collocation Definition\n\n\nThere  are  numerous  definitions  of  collocations.  Baker,  (2018,  p.54)  defined  them  as 'semantically arbitrary restrictions which do not follow logically from the propositional meaning of  a  word.'  Another  way  of  looking  at  collocation  would  be  to  think  of  them  in  terms  of  the tendency of certain words to co-occur regularly in a given language'. According to Sarikas (2006, p.36) 'collocations are important combinations of words that endow the language with natural sounding speech and writing. Cambridge Dictionary defined collocation as 'a word or phrase that is often used with another word or phrase in a way that sounds correct to people who have spoken the language all their lives but might not be expected from the meaning'.\n\nIt  is  noticeable that the three definitions share a common meaning of this term as they almost refer to it as two words or more who have different meanings when they appear together.\n\n\n## 1.3 Types of Collocation\n\n\nAccording to Sughair (2011, p. 6), collocations are divided into two sections, grammatical and lexical.\n\n- -Grammatical collocations consist of a noun, an adjective or a verb plus a particle (a preposition, an adverb or a grammatical structure such as an infinitive gerund or clause) (Bahns, 1993:57). Some examples of grammatical collocations include: at night, extend to, good at, fall for, to be afraid that .\n- -Lexical  collocations are  the  natural  combinations  of  content  words  (nouns,  verbs, adjectives, and adverbs) (Sughair, 2011: 6).\n\nCollocations in Arabic have not received a detailed treatment by Arab scholars. Although Arabic collocations were collected and documented by lexicographers such as Ibn Seedah, AlTha'aliby and Al-Yazijy, they were not studied in detail. (Sughair, 2011. P. 9)\n\n## 1. 4 Collocation and Translation\n\nCollocations  are  a  captivating  linguistic  phenomenon  in  language  in  general  and  in translation in particular. They are usually used impulsively in people's speech and they are used generously in literary texts.\n\nBaker (2018, p. 60) states that there are some problems and pitfalls in the translation of collocations such as the engrossing effect of source text patterning, misinterpreting of the meaning of the source-language collocation, the tension between accuracy and naturalness, cultural-specific collocations and marked collocations in the source text. In addition, she suggested some strategies to be used in translating idioms. Such strategies include using an idiom of similar meaning and form, using an idiom of similar meaning but with a dissimilar form, borrowing the source language idiom, translation by paraphrasing, translation by omission of a play on idiom, and translation by the  omission  of  the  entire  idiom.  These  strategies  are  also  effective  in  translating  collocations because both idioms and collocations are culturally oriented.\n\nOne of the strategies suggested in translation studies is dynamic equivalence. It appears to be an effective procedure of dealing with collocations in literary texts. Nida proposes two kinds of equivalence:  formal  equivalence  and  dynamic  equivalence.  Formal  equivalence  is  'sourceoriented; that is, it is designed to reveal as much as possible of the form and content of the original message.' (Nida, 1964, p. 134). This means that a formal equivalent depends more on the source text and message rather than the TT. On the other hand, dynamic equivalence depends on the TT and makes it more natural for the receptor.  According  to  Nida  (1964,  p.  136),  the  focus  of  a dynamic equivalence is directed to the receptor's response as 'the closest natural equivalent to the\n\nsource-language  message'.  Thus,  these  procedures  of  formal  and  dynamic  equivalences  help translators overcome the difficult task of translating collocations.\n\nA lot of models of translation strategies have been suggested by different scholars to deal with and examine the linguistic differences that a translator makes through the translation process. Newmark (1988) proposes sixteen  translation  procedures:  transference,  naturalization,  cultural equivalent, functional equivalent, descriptive equivalent, synonymy, through-translation, shift or transposition, modulation, recognized translation, compensation, componential analysis, reduction and  expansion,  paraphrase,  couplets,  and  notes.  Thus,  the  present  analysis  applies  the  same procedures model of translation proposed by Newmark since this model is an exhaustive model in regard to the translation of culture-specific items.\n\n\n## 1.5 Analysis and Discussion\n\n\nAs  Arabic  and  English  have  numerous  different  features  and  different  linguistic  and cultural  systems,  translators  have  to  apply  effective  translation  procedures  and  strategies  to overcome  the  differences  between  the  two  languages.  To  illustrate  these  differences,  some examples from the short story 'The Saddler's Notebook' and its translation will be presented and analyzed. In addition, the most frequently translation procedures that are applied in the translation of collocations will be illustrated in the analysis.\n\nSome Arabic  collocations  are  typically  compatible  with  English.  Thus,  translators  can utilize them without any loss of semantic or stylistic features. For example, the Arabic collocation 'حلقة مفقودة' was rendered to 'A missing link' which is semantically and stylistically acceptable in English.\n\nThree examples are illustrated in table 1 while other examples for the same strategy are included in appendix 1.\n\nSome other Arabic collocations are not totally compatible with English. However, one part of the Arabic collocation could be compatible with one part of the English collocation. An example of this is the Arabic collocation ' 'يصيبه المرض which was rendered into 'falls ill' by using the  strategy  of  the functional  equivalent  because  this  strategy  involves  neutralization  or generalization of the Arabic collocation.\n\nTo illustrate this, three examples are presented in table 2 while other examples for the same strategy are included in appendix 2.\n\nTable 2: Examples of collocations translated by using functional equivalent\n\nSome Arabic collocations that are not typically compatible with English include examples like the Arabic collocation ' 'متجهم الوجه which was translated as 'had a scowl on his face.' Thus, the  translator  tends  to  overcome  this  difficulty  by  using  the  procedure  of  explaining  and paraphrasing the Arabic collocation\n\nMoreover, three examples are illustrated in table 3 and other examples for the same strategy are included in appendix 3.\n\nTable 3: Examples of collocations translated by using Paraphrase\n\nSome Arabic collocations are compatible with culture-specific items in English such as the Arabic  collocation  ' 'هب  ودب which  was  replaced  by  'Tom,  Dick,  and  Harry',  whereas  the translator applied the cultural equivalent strategy which involves replacing a culture-specific item\n\nor expression with a target language item which does not have the same propositional meaning (Baker, 2018: 30).\n\nThree related examples are illustrated in table 4 and other examples for the same strategy are included in appendix 3.\n\nTable 4: Examples of collocations translated by using cultural equivalent\n\nIn  the  process  of  translating  an  Arabic  collocation  into  an  English  collocation,  most translators use the transposition strategy due to the differences between Arabic and English in many linguistic features. An example of this is the collocation ' 'حل لغز which was translated into 'demystify'. Transposition means 'replacing one word class with another without changing the meaning of the message' (Vinay &amp; Darbelnet, 1995:36). As it is illustrated in in table 5, three Arabic collocations consisting of two words are rendered into English through selecting one word only.\n\nThree  examples  are  illustrated  below  and  other  examples  for  the  same  strategy  are presented in appendix 3.\n\nTable 5: Examples of collocations translated by using transposition\n\nFigure 1 : A statistic of the number of strategies used in the translation of collocations\n\n<!-- image -->\n\nAs it is illustrated in figure 1, translators in general use many procedures in order to convey the ST meaning into the TT. In translating collocations in ' The Saddler Notebook ', the translator employed some strategies such as through- translation (calque), functional equivalent, paraphrase, cultural equivalent and transposition.\n\nThis  chapter  discusses  the  types  and  definitions  of  collocations  as  well  as  the  issue  of collocations  in  translation.  It  also  presents  some  examples  of  the  translation  of  collocations extracted  from  the  short  story  along  with  the  strategies  that  translators  used  to  overcome  the difficulties they face in translating collocations from Arabic into English.\n\n\n## Chapter Two Metaphor\n\n\n\n## 2.1 Introduction\n\n\nLakoff &amp; Johnson (1980) stated that native speakers of all languages utilize a great number of metaphors in their communication with the world. Moreover, according to Newmark (1988), foreign cultural expressions include many aspects and metaphor is one of them. In translation, both language and culture are interrelated. Due to the differences between cultures, translators face many obstacles when they try to translate metaphors properly. This chapter discusses the definition and types of metaphor as well as the issue of metaphor in translation. it also consists of some examples  that  are  extracted  from  the 'The  Saddler  Notebook' .  They  are  presented  with  an explanation of the strategies used to overcome the difficulties arising from translating metaphor.\n\n\n## 2.2 Metaphor Definition\n\n\nDefining metaphor is a complicated task because it implies different meanings to different people;  and  it  varies  according  to  the  perspective  of  various  schools  of  language.  However, according to Oxford English Dictionary (1996), metaphor is 'a figure of speech in which a name or descriptive word or phrase is transferred to an object or action different from, but analogous to, that to which it is literally applicable; an instance of this [is] a metaphorical expression'. Moreover, according to Steen (2008, p. 213). 'Metaphors in language invite people to understand one thing in  terms  of  another,  and  this  involves  various  forms  of analogy,  similarity,  and  comparison  in thought'.\n\n\n## 2.3 Types of Metaphor\n\n\nAlthough there are many types of metaphor, some linguists tried to restrict them to a certain number. According to Yaseen (2013), there are three types of metaphor; their definitions vary according to the school of language and rhetoric that each one belongs to. These types are as follows:\n\nThe first type divides metaphor according to the verb in which metaphor is used and subdivided into. The types are concretizing metaphors, animating metaphors, synesthetic metaphors and personifying metaphors.\n\nThe second type divides metaphor in terms of its circulation and usage which includes absolute metaphor, active metaphor, cliché metaphor complex metaphor, compound metaphor, dead  metaphor,  dormant  metaphor,  extended  metaphor,  implicit  metaphor,  mixed  metaphor, original  metaphor,  recent  metaphor,  root  metaphor,  simple  metaphor,  standard  metaphor,  and submerged metaphor.\n\nThe third type divides metaphor in terms of concepts depending on the speech of a personal experience or the experience of the society as whole. This type is called conceptual metaphor and it includes structural metaphor, orientational metaphor, and ontological metaphor.\n\nAccording to Newmark (1981, p. 83), the purpose of a metaphor is \"to describe an entity, event or quality more comprehensively and concisely and in a more complex way than is possible by using literal language.\" He classifies it into five different types:\n\n- -Dead  metaphors:  These  are  distinguished  from  others  only  in  degree.  They  are lexicalized metaphors like the arm of the chair .\n- -Cliché metaphors: These forms have already become automatic and not expressive at all because of the excessive use. Examples of them include leave no stone unturned .\n- -Stock metaphors: They are very common, but they are not yet fossilized like a ray of hope .\n- -Recent metaphors: They have not been used in the past like Irangate . Many similar metaphors  are  used  in  computer  language  like software,  hardware and a  word processor .\n- -Original metaphors: These are poetic metaphors invented for a specific expression or occasion like the valley was embroidered with flowers. (1981: 84)\n\n\n## 2.4 Metaphor and Translation\n\n\nCulture and language are connected in many ways and this interconnection poses many challenges for the translators of literary texts which are known to be rich in cultural expressions such as metaphor.\n\nDespite the scarcity of research on the subject of the translatability of metaphor, translation theorists have tackled this question. Kloepfer (1967) supported the simplistic approach saying that there is no problem in translating metaphor. Mason also stated that it is worthless to set a theory for  metaphor  translation:  \"there  can  only  be  a  theory  of  translation;  the  problems  involved  in translating a metaphor are a function of problems involved in translating in general\" (Mason 1982: 149).\n\nThe  modes  of  metaphor  translation  present  the  following  possibilities  according  to Newmark's preferences (1981: 88):\n\n- -Reproducing the same image in the TL\n- -Replacing the image in the SL with a standard TL image\n- -Translating the metaphor by a simile\n- -Transferring the metaphor by a simile plus sense\n- -Converting the metaphor into sense\n\nThus, the present analysis applies the same model of metaphor translation proposed by Newmark (1981).\n\n\n## 2.5 Analysis and Discussion\n\n\nAs  Arabic  and  English  belong  to  different  language  families  and  they  have  different linguistic and cultural systems, translators have to apply the appropriate translation procedures and strategies to overcome these linguistic and cultural differences. Furthermore, some examples from the  short  story 'The  Saddler's  Notebook' and  their  translation  are  illustrated  and  analyzed depending on Newmark (1981) translation procedures of metaphor.  The most frequently applied procedures are also illustrated.\n\n## -Reproducing the Same Image in the TL\n\nWhen the same metaphorical expression is available or accepted in English, the translator applies  this  strategy  almost  the  same  as  it  occurs  in  the  Arabic  metaphorical  expression.  For example, the expression \" 'طِرت إلى الشارع was reproduced in English as 'I flew into the street'.\n\nHowever, three examples are illustrated in table 6 and other examples for the same strategy are included in appendix 4.\n\nTable 6: Examples of metaphors translated by reproducing the same image in the TL\n\n## -Replacing the Image in the SL with a Standard TL Image\n\nSome Arabic metaphors are not typically compatible with English such as the Arabic metaphorical  expression  ' .'في  ظل  هذه  الحرب  الطاحنة The  translator  manages  to  overcome  this challenge by replacing the image in the SL with a standard TL image such as 'in light of this grinding war'.\n\nThree examples on this technique are illustrated in table 7:\n\nTable 7: Examples of metaphors translated by replacing the image in the SL, with a standard TL image\n\n## -Converting the Metaphor into Sense\n\nConverting the metaphor into mense means that if the SL metaphors are not accepted in TL, or if SL metaphors do not have an equivalent in TL, the translator can convert the metaphor into sense. An example of this is the Arabic metaphorical expression ' 'هو همزة الوصل which was converted into English sense as 'was the only link'.\n\nThree related examples are illustrated in table 8 and other examples for the same strategy are included in appendix 4.\n\nTable 8 : Examples of metaphors translated by converting the metaphor into sense)\n\n## -Translating the Metaphor by a Simile\n\nTranslating the metaphor by a simile means that if the SL metaphors are not accepted in TL or if SL metaphors do not have an equivalent in TL, the translator can replace the metaphor by a simile in order to maintain the flavor of figure of speech in literary texts. An example of this is the Arabic metaphorical expression ' 'كانت هي طفلة ً  أيض ًا which was translated by English simile as 'it was also as young as a child'. An example of this is shown in table 9:\n\nTable 9: Examples of metaphor translated by translating the metaphor by a simile)\n\nTo sum up, translators apply several procedures to convey the ST meaning into TT. In translating  metaphors  in  ' The  Saddler  Notebook '  short  story,  the  translator  utilized  some  of Newmark strategies such as reproducing the same image in the TL, replacing the image in the SL with a standard TL image, translating the metaphor by a simile and converting the metaphor into sense as shown in figure 2.\n\nFigure 2: A statistic of the number of strategies used in the translation of metaphors\n\n<!-- image -->\n\nMetaphor is prevalent in literary texts. When translating metaphors, a translator should consider the culture of the audience as well as the context in which the metaphor is used to decide what type of strategies should be applied. However, this chapter introduces the definition and types of metaphor as well as the issue of metaphor in translation. Also, it presents some examples of metaphor and their translations from the short story. It also reviews the strategies used to overcome some difficulties in translating metaphors from Arabic into English.\n\n\n## Conclusion\n\n\nFinally,  translators  usually  face  difficulties  in  translating  literary  texts.  One  of  these difficulties  is  translating  cultural  expressions.  Thus,  while  I  was  translating  ' The  Saddler Notebook ', I faced many obstacles in translating Arabic collocations and metaphorical expression into English.\n\nHowever,  to  overcome  these  difficulties,  I  applied  Newmark  strategies  which  present numerous options to deal with these cultural elements. Also, by applying these strategies, I achieve the purpose of translation brief and provide an adequate translation for ' The Saddler Notebook'.\n\nThis critical analysis has tackled several issues such as the definition of collocations and  metaphors  and  their  types,  collocations  and  the  issue  of  metaphors  in  translation,  Arabic examples and their translation extracted from the story 'The Saddler's Notebook' as well as the strategies used to translate these collocations and metaphors.\n\nOn  other  hand.  This  critical  analysis  has  not  accomplished  some  points  such  as  the definitions and examples of each type of collocation and metaphor. It does not investigate further previous  studies  in  translating  collocation  and  metaphor  and  does  not  identify  the  differences between Arabic and English collocation and metaphor.\n\n",
         "Literary translation is one of the most challenging fields of translation because literary texts are rich in figurative language such as collocations and metaphors. This critical analysis discusses the translation process and its reconstruction. It also focuses on collocations and metaphors that emerge in the original version and how they are dealt with during the translation process. The discussion includes the difficulties that collocations and metaphors pose to translators and the effective strategies that were used to overcome these difficulties. Chapter one includes the definition of collocations and their types. It also tackles the issue of collocations in translation with some examples from the translated story along with the strategies used to translate these collocations. Chapter two sheds light on metaphor and its definition and types along with the issue of metaphors in translation with some examples from the translated story. It also discusses the strategies used to translate these metaphors. Finally, the conclusion presents other aspects of interest and provides an outline of this critical analysis illustrating the areas that have been covered and those that still need further research.",
         ""
        ],
        [
         "3",
         "3",
         "## 1 Problem Setup\n\n\nRecent political science scholarship has questioned the ability to evaluate presidential election forecasts [1]. On its face, this argument is plausible: presidential elections are rare, and state-level outcomes within presidential elections are highly correlated. If we believe we need 10 or 20 or 100 presidential elections to evaluate whether a forecast provides useful information, we could be waiting a long time wondering if we are being lead astray by forecasts or not.\n\nDespite the seeming plausibility of the argument by Grimmer, Knox, and Westwood (henceforth GKW), I argue 1 that there are several ways we may evaluate election forecasts on shorter timescales than 'decades to millennia.'\n\nAs a heuristic, I argue that we can generally determine whether a forecast is better than random guessing using only publicly available data no more granular than the congressional district level on timescales of two-to-three election cycles (4-6 years in the U.S. counting both midterms and presidentials).\n\nThe basic intuition underlying my argument is that there are many ways to be wrong but few ways to be right. Forecasters that make assumptions which are robust across several election cycles likely have parametric models of the world in their heads which are better than random guessing and therefore provide information. By a process of selection, forecasts that are implausibly wrong die off or are modified, leading to a marketplace of major forecasts that are generally informative.\n\nI note that in GKW's article, they conflate the general usefulness of forecasts, comparing good forecasts to one another, and potential secondary harms of probabilistic forecasts such as depressing turnout. I will focus only on determining whether forecasts provide information, not how to pick the best forecast or secondary effects of forecasts. I also note that GKW takes the strong position that presidential elections are completely different from other elections, a point I strongly disagree with.\n\nQuoting from the conclusion of GKW:\n\nEven under the most optimistic assumptions, we are far from being able to rigorously assess probabilistic forecasters' claims of superiority to conventional punditry. Yet despite the lack of demonstrable benefits, forecasts induce known harms: producing vacuous, unverifiable horse-race coverage; potentially depressing votes for forecasted winners; and misleading the public and campaigns alike. Taken together, it is hard to justify the place of forecasts in the political discourse around elections without fundamentally recalibrating claims to match the available empirical evidence.\n\nFrom this, it is clear that the key argument in GKW is that forecasts provide little information relative to alternatives. Determining this fully is difficult, since it requires the information in a replacement-level pundit's subjective election forecast. I will focus on demonstrating that contemporary major election forecasts can be distinguished from random guessing. My argument is that if election forecasts are clearly better than random guessing,\n\nthey provide a key source of evidence about the state of politics that is different from punditry in that it is explicit about its assumptions and it has a process independent from events of incorporating new information. Forecasts help us resist being overwhelmed by hot and cold feelings in election cycles and therefore, to at least some people, provide value. They also can be presented in partisan spaces and help us combat contemporary epistemic closure in a way that hot takes (punditry) cannot.\n\nI do not engage with GKW's argument that forecasts have secondary harms such as depressing turnout. This may be true, and if it is true it should be a key consideration for how, when, and where we present election forecasts in the media. But that question is completely distinct from the key argument GKW make that forecasts provide essentially no information relative to vibes.\n\n\n## 2 Paper plan\n\n\nFirst, I will use only the topline result from the 2012, 2016, and 2020 presidential elections and the forecasted probability by two major forecasters to show we can distinguish good and bad forecasts using only these minimal data points. Contrary to the argument in GKW, using only six numbers (one probability from two different forecasters over three elections) and Bayes' theorem, we can convince ourselves that one of two election forecasters is much more likely to be right. I note that GKW did not consider this simple approach.\n\nSecond, I conduct a simulation which demonstrates that we can distinguish even moderately good (65-70% accuracy) forecasters from random guessing in 7 to 10 election cycles. This assumes that we look at only a single number per forecaster per election: the topline win probability.\n\nThen, I argue that we can increase the number of 'effective elections' in two different ways: we can relax the extremely strong GKW assumption that presidential elections and other elections are unrelated, and we can consider state-level outcomes (or for midterms, congressional-district level ones). I estimate that each presidential election when forecasted at the state level provides roughly 5 'elections' worth of information.\n\n\n## 3 'Just Use Bayes' Theorem'\n\n\nThe position taken by GKW is that single elections give little information. This is wrong. Let's use Bayes' theorem to show this using only six data points: the topline win probabilities from two prominent forecast models from the 2012, 2016, and 2020 presidential cycles. While this strategy will not give us classical statistical significance, it will give us a probability that each forecast is correct (given some assumptions). We will see that one forecast is much more likely to be correct than the other.\n\nThe quantity we're interested in is p (forecast correct election outcome), | which we will abbreviate p f e ( | ). Using Bayes' theorem, we can turn this in to a tractable problem.\n\n<!-- formula-not-decoded -->\n\nLet's go through each term on the right hand side:\n\n- · p e f ( | ): This is the probability of the election outcome given the forecast, or the win probability of the candidate that actually won.\n- · p f ( ): This is our subjective judgement of how likely we think the forecast is to be correct before seeing the election outcome, also called the prior.\n- · p e ( ): This is the probability of the election outcome, which is created from two components: the probability of the election outcome given the forecast is correct, and the probability of the election outcome given the forecast is not correct. This requires subjective judgment in the second part: we will assume elections are a coin flip, and say that both candidates have a 50% chance to win in the case that the forecast is wrong. The equation for this using the law of total probability is p e ( ) = p e f ( | ) p f ( ) + p e ( |¬ f ) p ( ¬ f ). We assume that p e ( |¬ f ) = 0 5, . meaning in the case where the forecast is wrong each candidate has a 50% chance of winning.\n\nNow, let's look at the probability that two competing forecasts assigned to the presidential winner in 2012, 2016, and 2020.\n\nThe large difference is the 2016 election, where Nate Silver gave Donald Trump a 29% chance to win, while Sam Wang gave Trump only a 1% chance.\n\nBy successively applying Bayes' theorem to these three elections, and putting an initial prior of 50% on each forecast being right, we obtain the following probabilities of each forecast being correct\n\nSo simply from observing the topline win probability across 3 elections, we assign roughly 9 times the probability that Nate Silver's forecast is correct relative to Sam Wang's and twice as likely as random guessing. This is clear evidence that Nate Silver's forecast is better than the alternatives, and to ignore this because it does not fit in a narrow null hypothesis significance testing framework (NHST) means throwing out good evidence that we should be incorporating.\n\n\n## 4 A tweaked simulation\n\n\nLet's move now to NHST simulations. The main simulation in GKW's paper (Figure 1, p. 9; details in Appendix A.1, p. 23) claims that it would take 24 years to determine if a 95% accurate forecaster is better than random guessing. This is only true in the narrow case where we insist on using an accuracy metric and focus on 'hard' predictions (win/lose) rather than probabilities. GKW's focus on binary predictions and accuracy is puzzling in the context of a paper about the dangers of probabilistic forecasts.\n\nIf we simply tweak the simulation so that forecasters produce probabilistic forecasts, we can plausibly distinguish 95% accurate (I only consider up to 90%) forecasters from chance in as little as 3 elections.\n\nI perform the following simulation: let's assume that a forecaster produces a noisy forecast that is on average right θ fraction of the time. The forecaster makes some assumptions, does some data analysis, and outputs a probability drawn from the following beta distribution: κ ∼ β cθ, c ( (1 -θ )). On average,\n\nκ = θ but there is noise around this mean. The shape parameter c controls how certain the forecaster is around this overall mean. Lower values of c will induce more spread while higher values of c will produce less spread around the mean of θ . I choose the values of c = 5 for a reasonable forecaster and c = 0 7 for an overconfident forecaster. . These choices are displayed in Figure 1 and are chosen heuristically (real forecasters likely choose more effectively).\n\nFigure 1: The two beta distribution concentrations we use, for a 0.7 correctness probability.\n\n<!-- image -->\n\nAfter drawing the correctness probability κ , we draw a random uniform draw υ ∼ Uniform(0 1) representing a TV pundit who just says stuff . Then, , 2 we compute the Brier score (the mean squared error but for probabilities) to judge correctness ( y -κ ) 2 and ( y -υ ) 2 . We average the Brier score over a number of elections N and examine whether we can use NHST and a simple t-test to determine if the forecaster is better than random guessing.\n\nWe present data in one of two ways: the expected significance value over 1000 simulations for a given ( θ, N ), and the percentage of simulations that reach the traditional 95% significance level in a one-way t-test (forecaster\n\nbetter than pundit).\n\nFigure 2 (left panel) shows that a forecaster can be distinguished from random chance in as little as 3 elections. For forecasters in the empirical accuracy range (70% to 80%), the number is about 10 elections on average. Moving to Figure 3, we see that for a 75% accurate forecaster over 10 elections, about 70% of simulations we conducted were significant at the 95% level. For highly accurate forecasters (90%) only 3 elections are needed before virtually every simulation was significant.\n\nFigure 2: Left: a decently good forecaster that does not get overconfident can be distinguished from random guessing. Right: an overconfident forecaster is much harder to distinguish from random chance.\n\n<!-- image -->\n\nThe lesson here is that random guessing produces terrible results, and even moderately accurate forecasters (in the 65% range) can be distinguished from random guessing in 20-40 election cycles. I note that these estimates are likely over-estimates of the amount of time needed to distinguish forecasts from random guessing, because real forecasts do not just draw numbers from a somewhat arbitrarily chosen beta distribution, but are highly tuned and refined over decades.\n\nAs a final note, the right plot in both Figures 2 and 3 shows an on-averagecorrect but overconfident forecast. Such a forecast is much less likely to be\n\nFigure 3: Left: a decently good forecaster is distinguishable from random guessing. Right: an overconfident forecaster is much harder to distinguish.\n\n<!-- image -->\n\ndistinighsed from random chance and therefore will likely be out-competed by better forecasts.\n\n\n## 5 Combining elections\n\n\nHaving established that there are scenarios where a relatively small number of elections can separate good forecasts from junk, I'm now going to argue that we can increase the number of 'elections' in two ways: first by combining presidential forecasts with other political forecasts, and second by examining plausibly uncorrelated microdata (such as demographic groups).\n\nGKW take the strong position that presidential elections are unicorns that cannot even be compared to other elections in the United States such as midterms. In Grimmer's words , they are 'distinctive.' 3\n\nI don't believe this, and I don't believe the available evidence supports this. Rather, I think that if someone is good at forecasting a presidential, they are probably good at forecasting a midterm and vice versa. If we simply\n\naccept that midterms and presidentials both go in the analysis, we've doubled the number of elections to consider. So now we're hitting 10 cycles in 20 years rather than 40, and so on.\n\nProfessional forecasters make detailed forecasts about primaries, off-year elections, midterms, and specials in addition to presidential elections. It is plausible that such less-prominent elections are more difficult to forecast than presidentials, meaning forecast skill at such elections may be actually more informative about presidential forecast skill than forecasting another presidential.\n\nIf we focus on a number of 10 elections to reliably distinguish decent forecasts from noise using NHST, and insist that each election held on a single day only counts for a single election, we should be able to tell signal from noise in about 10 years, since there is at least one election cycle (and often times more) each year.\n\n\n## 6 Microdata and effective elections\n\n\nThe final part of my argument relies on increasing the number of 'effective elections' via microdata. While it is true that state-level results in presidential elections are highly correlated with one another, they are not perfectly correlated. And this increases the number of 'effective elections'. Using the Economist's state level correlation matrix from the 2020 cycle, we can compute the number of effective observations in the 50 states. First, we get the eigenvalues of the correlation matrix λ i , and then we compute the effective sample size\n\n<!-- formula-not-decoded -->\n\nThis yields n eff = 5 12, meaning that each presidential election forecasted . at the state level contains the information of about 5 independent observations. So we can get to our heuristic 10 election threshold in two presidential elections by examining state-level forecasts.\n\nSuch analysis can also be done at the house district level, or using even finer grained microdata, going all the way down to the voterfile level. It is beyond the scope of this paper to determine exactly how many 'effective elections' are contained in a full voterfile-level analysis of a single presidential\n\nelection, but the microdata perspective is useful when thinking about how to evaluate forecasts.\n\n\n## 7 We can evaluate forecasts\n\n\nAs I have shown, we can evaluate forecasts in a few election cycles. This evaluation is not immediate, and there are obvious validation problems with a backtesting-only approach, but the situation is not as dire as GKW claim. Forecasters such as Nate Silver have produced forecasts over a period of almost two decades which can be easily shown to be informative compared to random guessing.\n\nWhile the harms of forecasts such as depressing turnout may be real (I take no position on this as its beyond the scope of this paper), the remedy for this potential problem is to insist that we present forecasts in responsible ways. Instead, GKW attempt to argue that forecasts themselves are uninformative, which is unlikely to be true if we simply consider all of the information available in each election and assume that forecasters of one type of election are likely to be good at other elections.\n\nI note that all of the major forecasts that have survived multiple election cycles are likely to be fairly good, as wrong forecasts are abandoned or changed in response to events. The collective body of political forecasting knowledge has continued to grow and I expect this indicates that our major forecasts are increasingly reliable.\n\n",
         "There is a long-running debate on evaluating forecasts of rare events such as presidential elections. Recent scholarship has argued that forecasts cannot be evaluated on practical timelines and therefore do not provide reliable information. I argue the opposite: that a variety of statistical methods indicate that election forecasts can be evaluated in a timely manner, and that key forecasts that have survived many election cycles are likely to be informative.",
         ""
        ],
        [
         "4",
         "4",
         "## INTRODUCTION\n\n\nThis  article  investigates  the  contemporary  Japanese  phenomenon  that  values  youth  over maturity, resulting in measures taken to postpone the latter. Throughout Japan, one can find many anti-aging products, as well as magazines, advertisements and television programmes related to this industry. Indeed, recent developments in beauty products, make-up techniques, hairstyles and hair dyes and fashion, together with a health-conscious lifestyle and diet, have allowed people to maintain the appearance of youth. Miller (2006) has conducted extensive research on the Japanese  beauty  industry and explored how such beauty practices relate to femininity and masculinity in Japan, as well as to the global image of beauty. As Bordo (2003) argues, the female body is culturally constructed in western societies; in truth, this is the same in Japan. Many Japanese women are unable to free themselves from comparing their bodies with the 'ideal  body'. This type of self-consciousness is very common among many young women, but it is also becoming more common among women who have reached middle age.\n\nThis article will look at how the Japanese discourse of a youthful appearance has become popular among women in their late thirties and above. In order to understand this trend, it is necessary  to  examine  how  Japanese  women  have  been  dealing  with  their  social  norms. According to the World Economic Forum, Japan is ranked 105 in the 2013 Global Gender Gap Index; it is not difficult to imagine the struggle that this presents to Japanese women (Wold Economic Forum 2013: 10). Certainly, they can consciously rebel against patriarchal society. However, the  author  has  observed  that  many  Japanese  women  are  unconsciously  avoiding social expectations and finding ways to make their lives more comfortable, an idea akin to de Certeau's notion of 'tactic' (de Certeau 1984). According to de Certeau, tactic, unlike strategy, is the art of the weak, a way common people operate in everyday life, and these unplanned tactics  can  mobilize  people's  ideas  and  actions  in  unexpected  directions.  This  article  will investigate how Japanese women have been tactically challenging the social expectations thrust upon them and how this has led to the postponement of maturity.\n\nKeeping  a  youthful  appearance  is  a  trend  found  among  Japanese  men  as  well.  Some research  conducted  on  young  Japanese  point  to  problems  among  young  men  (cf.  Miyadai Ishihara and Otsuka 1993; Miyadai, Tsuji and Okai 2009; Saito 1998; Yamada 1999). While it is worth discussing how this phenomena has affected Japanese men, due to matters of space, this article will focus solely on Japanese women.\n\nThe  author  has  contacted  48  Japanese  women  and  collected  data  via  an  ethnographic methodology, which consists of semi-structured and unstructured interviews and participant observations.  As  Kitamura  (2009)  argues,  the  ethnographic  method  is  able  to  pick  up information which otherwise could be ignored. Out of the 48 women, four women whom the author finds as prime examples will be introduced throughout this article. These four women, as well as several of the others, are part of a larger trend that Japanese society calls 'bimajyo' ( 美魔女 ). Bimajyo are women aged 35 and above but who look much younger (Yamamoto 2012). They use high-quality make-up, wear the latest hairstyles and fashion and they keep their  bodies  fit.  The  term  was  coined  by  the  Japanese  magazine Bi-STORY ( 美 STORY )  in 2009 1 and  became  widely  recognized  through  a TV  variety  show  where  these  ladies  were presented. In order to begin to understand the magnitude of this social phenomenon, let us first examine how what was considered as the normal course of the life of women has changed.\n\n\n## BLURRING THE BOUNDARIES OF THE STAGES OF LIFE AND THE DISAPPEARANCE OF THE MIDDLE-AGED WOMAN\n\n\nPraise for staying young is not new in Japan. During the Heian period (794-1185), the poet Ono no Komachi wrote a poem lamenting her aging looks, a work familiar to many Japanese people. The pursuit of youth occurs all over the world, but in order to understand the current connection between this and the devaluation of maturity in Japan, we must investigate what had become the dominant discourse on the stages of one's life after modernization.\n\nIn  pre-modern Japan, a boy celebrated his coming of age around  15  years of age  in a samurai family, while girls would be married off around the age of 15. The children of farmers and  townspeople  started  working  before  they  were  10  years  old.  Even  though  Japan modernized during the Meiji period (1868-1912), the distinction between being a daughter and being a mother still remained among women.\n\nIn Japan, the transition of life was quite distinctive in the post-war period. The typical life course  of  a  Japanese  person  is:  kodomo  (child),  shōgakusei  (primary  school  student), chūgakusei (junior high school student), kōkōsei (high school student), daigakusei (college student) and then a shakaijin (a member of society) (Skov and Moeran 1995). In the case of women, after finishing school, they were classified into several categories, which remained until the early 1990s. Unmarried young working women were called OL (office ladies) and women who were pursuing a career path were called kyariya ūman (career women). When they got married they were called okusan (wives), when they had a child they were called okāsan (mother) and when they had a grandchild they were called obāsan (grandmother) (Skov and Moeran 1995). At the end of the 1980s, women were still expected to marry early; in fact, a woman was called 'Kurisumasu kēki' or 'Christmas cake' if she had not married by the age of 25,  because  Christmas  cakes  are  difficult  to  sell  after  25 December.  There  were  clear classifications depending on the different stages in a Japanese person's life, and there were clear distinctions made between adult and non-adult. When a Japanese person finished school, they were considered to be an adult, and when a woman became a mother, society considered her to be a mature woman.\n\nHowever, things have changed in the past twenty years, and these boundaries have become blurred. Now, as it has become so common for women to continue their careers, the term 'career woman' refers not only to single women but also to married women and mothers. Furthermore, the social pressure on women to get married has decreased. Ten years ago, the term  'arasā' (meaning 'around 30') became popular, and women around 30 years old were considered to be at the twilight of marriageable age. Then a few years ago, the term 'arafō' (meaning 'around 40') came to the media's attention. These women around 40 look very young, and many of them are single. The media has portrayed women of that age as looking for a husband, meaning that now it is not unusual for a forty-something woman to get married.   The willingness of 2 marriage is not only among women but also among single men in their  forties. As Iwakami (2010) argues, this is partly because the rigid life course, as mentioned above, has weakened over the  past  decades,  and  diversity  in  life  choices  has  strengthened.  Iwakami  (2010)  also argues  that  when  the  modern  rigid  life  course  was  established,  the  division  between  otona (adult) and kodomo (child) was rather clear, with a transitory period called 'seinen'. According to Iwakami (2010) the seinen period falls between the mid-teens and early twenties. Miyadai (1994) also points out the division between adults and the youth; youthful rebellion against adults was prevalent in the late 1960s when the student movement was strong. These students were led mainly by young men, but it does not mean that young women conformed to society. Just as McRobbie (1994) has observed with regards to popular culture practices among young British girls, Japanese girls have also been creating their own cultures, although their cultures have not been recognized when compared to recognition of young men's cultures. 'Kawaii' or 'cute  culture'  is  one  of  the  cultures  that  Japanese  young  women  have  been  practising. According to Otsuka (1989), kawaii culture became exuberant in the early 1970s when 'fancy' products for young girls such as Hello Kitty came onto the market. Around the same time, girl comic magazines were launched, which became quite popular. Miyadai, Ishihara and Otsuka (1993) have observed that, when celibacy among young women relaxed in the 1970s, some young women hesitated to keep up this sexual revolution and instead cocooned themselves into the fancy world of kawaii. Somewhat similarly, Kinsella (1995) argues that the young girls who are into kawaii culture are reacting to social expectations for them to become adults.\n\nAs mentioned above, Japanese society expects a woman to marry and become a mother; it is only after she meets this responsibility that she is considered to be an adult. In addition, as Ohinata  (2003)  points  out,  Japanese  society  has  very  clear  notions  of  what  a  good  and appropriate (often described as  benevolent) mother is. Ohinata (2003) also  mentions that a woman is seen as a mother and not as a woman after she becomes a mother, observing how Japanese mothers are portrayed in the media. Against social expectations toward motherhood, some Japanese women have challenged this dominant discourse. Hamada (1997) describes the frustration  of  full-time  mothers  and  argues  that  her  informants  yearn  for  self-actualization beyond maternity; mothers in Japan nowadays are not necessarily women who devote their lives to their child (or children) but, rather, women who seek out their own personal satisfaction, often outside the household. Tokuhiro (2010) suggests that young women resist their typical gender roles as wives and mothers.\n\nWomen today find it extremely difficult to develop their own individual identities within marriage or rather that the institution of marriage works unfavourably for women trying to express their 'selves', their authentic individual identities. (Tokuhiro 2010: 52)\n\nSelf-actualization among Japanese young mothers is also noted by Sasagawa (2004); in her field research, she frequently heard the phrase 'jibun rashii' or 'to be oneself', in conversations with younger mothers.\n\nThis  expression  also  implies  emancipation  from  external  pressure  imposing  fixed social  roles,  such  as  that  of  'mother'  or  'housewife'.  The  notion  of jibun  rashii encourages women to determine their own lives - to choose their own sense of how to live. (Sasagawa 2004: 184)\n\nThe term jibun rashii is frequently heard from my informants, as well as the media. As the above authors have suggested, many Japanese women feel social pressure and, therefore, 'to be oneself' has become a motto for them. The evasion of social expectation is an important factor for the recent phenomenon of keeping themselves looking young and attractive, as can be read from Ohinata's (2003) argument on social expectations thrust upon Japanese mothers, something that many Japanese women are now challenging.\n\nIt  has  been  four  decades  since  the  influx  of  kawaii  culture,  and  now  it  is  not only  for teenage girls but also for older generations. No longer is a person's social status dependent on age, thanks to these women challenging conventional norms. The boundary between adult and non-adult is blurred by prolonged youth. A 40-year-old mother (or father) could have the same mentality as people in their twenties. A significant number of married women the author was in touch with expressed that becoming a mother is not necessarily connected to becoming an adult, which is also argued by Iwakami (2010).\n\nThe media that especially targets women also encourages women to challenge the 'ideal life course'. As a matter of fact, the term 'jyoshi' has recently been used to refer to women in their thirties. Originally, the term jyoshi could refer to women of any age group; however, the term conventionally refers to girls up to the age of high school students. There is another term called 'otonajyoshi' which means adult girls. In many cases women in their forties are referred to as this  in the  media. According to Yonezawa (2012),  'yonjyūdai jyoshi' or 'girls in their forties' began to be seen in Japanese fashion magazines, and she argues that one can sense the attitude that she puts herself first in her life, regardless if she is a mother, a wife or a single yonjyūdai jyoshi.\n\nThe recent tendency to expand the usage of jyoshi to women in their forties runs parallel to the trend that the term 'obasan' is being used less nowadays. Obasan literally means an aunt but it also refers to middle-aged women. Obasan could be a mother, a wife or a single woman, but they were considered to be mature adult women and were more often than not treated as asexual persons by the media. In 1989 the word 'obatarian' was selected as the most popular word of the  year by the Japanese publishing company  Jiyukokumin-sha at their event held annually in December. The word was a combination of the words obasan and Battalion / The Return of the Living Dead (O'Bannon, 1985 , an American horror movie that had hit Japan at ) the time.   Like the zombie in the movie, obasan are shameless, pushy and immortal (Tanaka 3 2011). The visual image of an obatarian was a fat middle-aged woman with strange permed hair and no fashion sense.\n\nBecause of obatarian's negative image, according to Tanaka (2011), the term obasan is likewise associated with such. Tanaka (2011) points out that more than 65 per cent of women in their forties and more than 54 per cent of women in their fifties would feel uncomfortable if they were referred to as obasan; they would not like to be called middle-aged women either. Some of my informants say that they would also feel uncomfortable if they were called obasan. One informant mentions that although she knows that she is not as young as a 20-year-old girl, she  does  not  think  of  herself  as  a  middle-aged  woman. As  Tanaka  (2011)  argues,  aging  is considered to be a negative thing in Japan; women do not want to be considered as middleaged women, let alone to be referred to as obasan. The youth culture in Japan emerged in the mid-1950s, but the divide between the young and adults existed until the 1980s (cf. Miyadai, Ishihara and Otsuka 1993). This division in part existed due to consumer tastes. The tastes of the youth, including media consumption, were different from those of adults (Miyadai 1994). However, now differences between the young and adults in terms of this are not as clear as they once were. Moreover, the physical fitness of women in their forties has improved compared to that of women 30 years ago. It is natural that many women in their forties nowadays do not feel comfortable when they are referred to as middle-aged women.\n\nAs  we  have  seen  above,  Japanese  society  imposes  high  pressure  on  women  to  behave according to the stages of life; a mother should behave like a mother, and a middle-aged woman should behave like a middle-aged woman. Many women feel uncomfortable with this social pressure and subtly resist; jibun rashii is a key term for their resistance against society.\n\nIn the next section, the article will examine bimajyo cases and consider how these women practise de Certeau's notion of tactic.\n\n\n## TRANSCENDING  HER  AGE:  BIMAJYO,  THE  BEAUTIFUL  MIDDLE-AGED WOMAN\n\n\nThis article so far has examined women in their thirties and forties who refuse to behave as society dictates. They highly prioritize the 'individual' or 'self', a trend that media coverage has  intensified.  In this  section, the  article  examines  media  portrayal  of  women  in  their  late thirties and above, called 'bimajyo', followed by my interview with them.\n\nAs mentioned, the term bimajyo was coined by the magazine Bi-STORY (now Bi-ST ). The magazine's  editor  Yuki  Yamamoto  (2012)  was  very  impressed  with  the  forty-something women's youthful looks when he saw their pictures. He tweeted that they looked so young that it is as if they were using a spell, and called them bewitching women or bimajyo (Yamamoto 2012). The term consists of two words 'bi' ( 美 ) and 'majyo' ( 魔女 ), which means 'beautiful' and 'witch' respectively. Yamamoto (2012) mentions that these beautiful witches transcend their actual age; upon first seeing these women, he thought he could establish a rapport with his readers if he issued a magazine targeting this age group. Yamamoto then came up with an idea to hold a beauty contest organized by Bi-ST magazine. He frowned upon Japanese culture having become too childish, what with the media praising only teenage girls, unlike in France where grown-up women are valued (Yamamoto 2012). As 'beauty coming from the inner-self rather than from actual youth' was a criterion of the selection, Yamamoto did not set an upperage limit for applicants but set the minimum age at 35 years old. His attempt has been quite successful, and the contest was picked up by TV and other media. Yamamoto (2012) mentions that the bimajyo business was a success because he was able to work out what people desire. The book does not explicitly mention what this desire is, but he mentions in an interview with me that it is the desire to be recognized.\n\nThe  magazine  organized  a  group  called Team  Bimajyo  which  consists  of  women  who remain  in  the  competition  until  the  final  round  of  the  All  Japan  Bimajyo  Contest.  Some members of Team Bimajyo appear on TV shows, in magazines and at promotional events for new  beauty  and  anti-aging  products.  In  fact,  some  have  formed  a  musical  group  and  have released an album. Each member of Team Bimajyo has her own blog which is organized by BiST publisher  Kobun-sha. They  write  about  their  activities,  including  their  presence  on  TV shows, in magazines and at promotional events, as well as about their everyday lives.\n\nThe author has interviewed two women in Team Bimajyo, Naoko and Sara. Naoko is 49 years old and married. She works as a freelance translator, with technical manuals being her specialty, which was the career she started after graduating from college. Naoko also works as a jazz singer and sings in Yokohama jazz cafes. Sara, who is 44 years old, is a life counsellor in Chiba prefecture, adjacent to Tokyo. She gives advice to her clients who worry about their love lives, career directions and so on. She was working as temporary staff in an office, but she then  decided  to  cut  down  her  hours  in  her  office  job  and  spend  more  time  working  as  a counsellor. When she has time she goes to ballet lessons to maintain her physical appearance. Sara started practising ballet when she was 6 and continued until she was 15, though she has recently resumed this art. 4\n\nWhen I interviewed Naoko and Sara I found that they had quite different personalities. Although  she  sings  in  public,  Naoko  speaks  softly  and  slowly.  She  basically  sees  things positively; however, she gets hurt when people say bad things about her and becomes negative. Sara's mood also fluctuates sometimes, but she basically does not care what other people say about her. She is a positive person and speaks her mind. When Sara was a college student, she enjoyed going to discos as other young girls did at that time, while Naoko seldom went to these places because she could not enjoy herself when she went. 'I was the one who went to college every day and took notes for every single class,' Naoko says.\n\nAs we have seen above, Naoko and Sara are different. However, there is one thing which they have in common, which is that both of them emphasize individuality. When I asked them about their motives for applying for the bimajyo contest Naoko stated:\n\nI wanted to try something new. In my generation, after we graduated college we would work for a company as an office lady and then would marry a man who had substantial income. That was our normal life course. A lot of my friends also followed this passage, and I was not the exception either. I was happy that I could follow the same life course as everyone else did; however, at the same time I had something which made me feel uncomfortable. Is my life shining? Will my life finish without challenging anything? These  questions  came  up  in  my  mind.  I  started  learning  jazz  piano  inspired  by watching a TV programme about a famous jazz pianist. I was getting involved with a jazz  band,  there  I  started  my  singing  career.  I  had  been  singing  in  jazz  cafes  in Yokohama area, but one day I found an advertisement about a bimajyo contest, which I thought I could make a new challenge. I was an extremely shy girl when I was little, so  singing  in  front  of  an  audience  was  a  huge  challenge  for  me. Applying  for  the bimajyo contest was another challenge. I am  happy that I made a challenge and I achieved something because I could become a finalist of the contest.\n\nFor Naoko, applying for the bimajyo contest was a chance to change herself; to overcome her shyness. In Sara's case, spicing up her life is a common motive that she shares with Naoko; however, she places more emphasis on her pursuit of individuality as her key motivation for entering the context. Sara says:\n\nI thought the contest was a good chance to express myself. My father was a prosecutor, and I grew up in a strict family and they expected me to follow an orthodox life course. But I was looking for an alternative way. I did not work as a full-time regular employee after graduating college, but I worked as a temporary staff instead because I thought I could  use  my  time  more  freely.  When  I  mentioned  about  my  application  for  the bimajyo contest, some of my friends and acquaintances expressed negative views on the contest. But I didn't care. This is who I am. I followed my own feelings rather than listening to the 'wise' opinions of others.\n\nFor  Sara,  it  was  more  natural  to  apply  for  the  contest  than  suppress  her  feelings.  She understood that people might criticize a forty-something woman who was applying for a beauty contest but she thought she would regret it if she did not follow her own inclinations. The media was also key in trying to promote 'kosei' or 'individuality', when they introduced bimajyo to a wider audience. In the lyrics of the 'bimajyo song' (2012, Team Bimajyo), 'watashirashiku' or 'being myself' is sung about and encouraged.   However, when watching the music video, 5 one may find that the women featured look similar. Although each member is different, like Naoko and Sara, the media, rather ironically, encourages homogeneity through its branding of individuality.  In  the  interview,  Sara  suggests  that  'kagayaku'  or  'to  shine',  is  an  important matter in her life, and this desire seems to be intensified by the media and consumerism. Also, kagayaku is strongly connected with kosei. 'Being an individualistic woman' is being a woman who is considered to be a 'shining' woman and who is admired by many other women.\n\nFigure 1: Several members of Team Bimajyo.\n\n<!-- image -->\n\n\n## JAPANESE CONSUMERISM IN THE 1980S AND 1990S\n\n\nThe women in the previous section were brought up in conservative families and they were 'good  girls'  during  their  childhood.  However  this  does  not  mean  that  they  were  totally immersing themselves in conventional thoughts. The latent feeling of questioning conventional thoughts came out when they grew older. Nevertheless, they did not explicitly rebel against the society but instead tactically avoided social expectations and found ways to live comfortably; jibun rashii is their creed for not following social expectations. In this section, the article will discuss the process by which jibun rashii has become a prevalent discourse among Japanese women, which is strongly related to the development of their consumer culture.\n\nThere are economic and social factors for the growth of consumer culture among Japanese women. In 1985, the Equal Employment Opportunity Law was implemented, which led to more women getting office  jobs.  In  addition,  around  that  time,  the  Japanese  economy  was booming  and  the  government  promoted  the  expansion  of  domestic  demand.  The  average marrying age of women is  increasing. Women  have  begun to  possess  more time and  more disposable income so naturally their attention has turned to consumption. Looking at this trend, marketers began to focus on young women. In 1988, a weekly magazine titled Hanako was launched.   The magazine targeted young single women living in the Tokyo area. The content 6 mainly included the introduction of stylish shops, restaurants, cafes and bars in Tokyo or nearby cities. Women began to visit bars, restaurants and cafes with their female friends, and, as a result, retailers began to target this younger, increasingly affluent female market.\n\nHanako was certainly  an  influential  magazine  for  young  women  at  the  time;  however. young women's consumption of fashion had been recognized by the media, including other fashion magazines, well before Hanako was first released. Of these, an-an and non-no ( sic ) were  two  popular  magazines  issued  in  1970  and  1971  respectively.  These  two  magazines synchronized with the increase in the number of women going to university (including junior college). The magazines were so phenomenal that the new term 'an-non zoku' or 'an-non tribe' was coined as a result. According to Nanba (2007), an-non zoku are young women who are influenced by the an-an or non-no fashion promoted by these magazines. They went to places like  Harajyuku  or Aoyama  in  Tokyo.  The  magazines  were  also  literally  called  catalogues because of their pages full of fashionable clothing and housewares. An-an and non-no played a significant role for Japanese young women to live a life that connects one's consumption lifestyle with one's identity.\n\nThis phenomenon grew during the 1970s and continued into the 1980s. Yasuo Tanaka's novel Nantonaku Kurisutaru Somehow Crystal / effectively captures this trend at the time. The novel  was  published  in  1980  when  Tanaka  was  a  university  student  in  Tokyo.  Like  the protagonist of the novel, young people who were studying at university in Tokyo and enjoying the  consumer  lifestyle  without  really  thinking  about  what  they  were  doing  were  called 'kurisutaru zoku' or 'the crystal tribe'. One of the traits of the crystal tribe was their disregard for traditional  values, such as  filial obedience. Older generations of Japanese had difficulty communicating with these young people carrying a whole new set of non-traditional values. Being unable to relate to them, they called these  youngsters  'shinjinrui'  meaning  'the  new humans'.\n\nUnlike  the  youth  of  previous  generations  who  still  held  to  the  value  collectivism,  the shinjinrui generation valued the individual the most. Having observed consumer society in the 1970s and 1980s, Ueno (1992 [1987]) points out the trend of pursuing kosei at that time in Japan, and discusses how it is related to the individual's consumption style. She argues that kosei is highly valued among young people and that it is expressed by differentiating oneself from others in one's consumption style. One consumes stylish clothes and housewares that differ from the drab styles of others. This notion of making oneself 'koseiteki' (individualistic and original), results  in positive  feelings. Observing Japanese  young women's collection of nice housewares, Ueno (1992 [1987]) points out that they are looking at themselves through other people's eyes. Japanese people, Ueno argues, live in small houses like rabbit hutches, and unlike Americans they do not have the custom of inviting others into their homes. This means that even if Japanese housewives collect nice housewares, there is no one to come and see these things. Moreover, Ueno sarcastically mentions that their husbands are not interested in their wives let alone their housewares, and their children are not interested in their parents, including their housewares. However, Japanese women pursue 'watashi rashisa'   or 'being oneself' by 7 collecting  nice  housewares  to  distinguish  themselves  from  others,  imagining  an  invisible audience in the process.\n\nUeno's  argument  about  Japanese  women's  obsession  with  pursuing  kosei  and  the internalized gaze of others is important in understanding the characteristics of contemporary Japanese women in their thirties and forties. Ueno's book is titled 'Watashi' sagashi gēmu: Yokubō shimin shakairon The Search for 'Me' Game: A Social Theory of Desire for Selfhood / , and  was  first  published  in  1987.  As  the  title  indicates,  Ueno  quickly  noticed  the  nascent phenomenon  of  Japanese  people's  narcissistic  view  and  writes  that  the  main  concern  of\n\nJapanese youth was to receive attention from other people.\n\nUeno's view of the Japanese youth in the late 1980s can still be applied to young people today. It is true that the prolonged recession since the early 1990s has made the current youth generation consume more conservatively and that the tendency of young people's expression of kosei through consumption has weakened. However, their pursuit of kosei and their 'jibun sagashi', or their 'search for self', still remain. Their expression of kosei is not done through material consumption but through experience, such as travelling/studying abroad, undertaking voluntary work or moving to more exotic locations such as Okinawa.   Hayamizu (2008) points 8 out that Japanese society expects a young person to be themselves and to do the job that they really want to do. When job hunting, young people are asked to look for their 'hontō no jibun' or their 'real self', and to look for a job that aligns with this sense of self. As a result, youths who  are  more  critical  can  become  entrapped  if  they  are  not  able  to  find  their  'real  self' (Hayamizu 2008). Hayamizu (2008) also points out that young people who are struggling to find their hontō no jibun keep searching for it, with a good number of people in their thirties and forties still looking for it.\n\n\n## PROLONGING YOUTH IN FORTY-SOMETHING JAPANESE WOMEN\n\n\nThis section will look at three single women and a married woman who are around the age of 40,  each  of  whom  the  author  considers  to  be  a  good  example  of  the  complexities  that contemporary  Japanese  women  face.  Bimajyo  are  a  supreme  example  of  women  who  are prolonging their youth and have become a kind of 'celebrity' because of their presence in the mass  media. These  four  women  are  'ordinary  women'  in  a  sense,  but  by  using  non-media figures  as  examples,  the  author  would  like  to  argue  how  the  discourse  of  staying  young  is widespread among Japanese women that are around the age of 40.\n\nYukie is a 40-year-old woman living in the Tochigi prefecture, which is 100 kilometres north of Tokyo.  She  lives  with  her  parents  in  her  hometown.  Her  father  is  retired,  having worked for an electronics company, while  her  mother runs a shop selling handcrafts. After graduating from high school in Tochigi, she went to junior college in Tokyo. She joined an apparel company after finishing her education but only stayed there for a year because she did not get on well with her colleagues.\n\nYukie met a man who was running a company and stayed at his place in Tokyo; however, they did not get married because her boyfriend's father was opposed to it. After a few years, the two broke up. She then went to beauty school in order to work in a salon. A few years ago, she renovated part of her house back home and opened a beauty salon. The business is small, but she has enough regular customers to keep the business running.\n\nAs a beauty therapist, Yukie cares for her body. She is fit and young looking. She jogs regularly  and  sometimes  competes  in  the  triathlon.  Recently,  she  has  become  interested  in travelling abroad. For example, she went to Thailand and stayed there for a few months to learn Thai  massage  so  that  she  could  add  a  new  product  to  her  salon's  range. Y ukie  deals  with customers of various age groups, but many of them are in their thirties to their early fifties. She mentions  that  many  of  her  customers  keep  themselves  looking  quite  young,  and  they  are uncomfortable with being called obasan. Yukie says that she is enjoying her current job, but she  is  also  enjoying  the  activities  mentioned  above.  'I  would  like  to  marry  someday  in  the future, but I don't want to rush,' Yukie tells the author. 'Marriage is not my ultimate goal. I would like to do what I want to do, and I want to be myself.' Yukie also told the author about her view on the marriages of her friends.\n\nWell, Tochigi is not like Tokyo. When a woman gets married and becomes a mother, she  is  expected  to  behave  like  'mother'.  My  friends,  who  became  'mother',  are behaving like 'mother', too. They care about their kids, and they do not care about their fashion. They do not use make-up and they have become plump. I don't want to become like that. I want to stay young and attractive. People say that the 'good time' does not last forever, but I don't feel that I have become old, in fact I can run faster and longer than I used to, and I am feeling happy about being as I am.\n\nKazuko is a 43-year-old housewife living in an upscale area of Tokyo. Her father was a banker, she attended a private girl's school for her secondary education and went to a private university in Tokyo. After graduation, she worked for an insurance company for two years and then left the company to get married. Her husband works for one of the most prestigious trading companies in Tokyo and receives a handsome salary. She has a daughter who studies at a private junior high school in Tokyo, which is connected to the university from where Kazuko graduated. Kazuko  goes  to  the  gym  frequently  and  she  is  very  fit.  She  jogs  almost  every  day  and participates in half marathon competitions. Kazuko has a boyfriend. When the author talked to her two years ago, she was dating a man in his fifties whom she met at the gym, but in a recent conversation, she suggests that she now has a new boyfriend.\n\nI love my daughter but I do not feel sexual desire towards my husband. My husband is kind to me and looks after me, but I do not want to be touched by him. I enjoy my sex life with my boyfriend. I go to the gym regularly, and I am quite fit. I keep myself young; being in love with someone is one tip to keep myself shining.\n\nAccording to Kazuko, marriage has not changed her life too much. She takes care of her family but she mentions that it is not her style to restrict herself to the home and a complete change of her status due to her role of mother. 'It does not make sense to me to change myself to play the role of a 'mother' just because I have a daughter,' she says. Kazuko uses the phrase 'watashi wa watashi', which means 'I am what I am'.\n\nAsami is a 41-year-old woman who lives in Tokyo and works for an American company. Her father worked for a prestigious Japanese trading company, and because of her father's job she lived abroad for seven years during her childhood. After graduating from university she worked for a mobile phone networking company but resigned after a few years so she could study abroad. After finishing her Master's degree in the United Kingdom she came back to Japan and worked for an American-based  multinational company  for a  few  years  and then changed to another multinational company before joining the company she currently works for.\n\nAs an employee of an American multinational company, Asami earns enough money to enjoy the single woman's life. She lives in a flat in Tokyo that is owned by her sister who lives in Malaysia with her Dutch husband. Although Asami lives in her sister's flat, she visits her parents' house whenever she feels like it. She had a boyfriend her age, but she also had several affairs while dating him. In the end, the two broke up because they wanted different things. Then she began to date a married man whom she had had an affair with when she was dating her boyfriend. Asami has been dating this man for four or five years, but sometimes she has flings with other men. The man has said to Asami that he was thinking about divorcing his wife to be with her, but he also has mentioned that it is difficult to do so immediately because he and his wife have a daughter.\n\nHe keeps telling me that he will get divorced but I don't think that he will. He cannot abandon his daughter, after all. I would like to get married someday, and I have dated some other younger men, but since dating a man with experience, I cannot be satisfied with younger men; they cannot provide as much as he can. I would rather stay single than marry a man with a small income. I do not want to decrease my standard of living.\n\nAs stated in the comment above, Asami would like to marry someday, but she does not want to change her economically affluent lifestyle because of marriage. Asami has also told me that  although  she  may  continue  working  at  her  job,  she  is  not  too  interested  in  getting  a promotion. According to her, she is not the type of person who takes care of subordinates; rather, she prefers to be taken care of by those senior to her. 'If you become a senior, you are expected to act like such in Japan. But I feel uncomfortable with this role. Watashi rashiku-nai,' or 'this is not like me,' she says.\n\nFinally, there is Hiromi, a 40-year-old nurse in Okinawa. She grew up and finished high school on a nearby island before going to nursing school in Naha, the prefectural capital of\n\nOkinawa. She worked for several hospitals on the main island of Okinawa after graduating. When she was 30 years old, she went to England to enter into an English programme while working at a hospital there. She lives in a flat near Naha city and commutes by car to a smalltown hospital near Naha.\n\nHiromi is slim and looks young. Because she is not the bossy type, she gets along with young nurses well. Although she is older than most of her nurse colleagues, she is called kawaii because of her naive character. Hiromi had a boyfriend who was four years younger than she was, but broke up with him a few years ago. However, she still meets up with him regularly. Hiromi is looking for a husband and is trying to meet a new man, but she has not completely dismissed the possibility of getting back with her former boyfriend. Hiromi occasionally says to me that she is not in a hurry to get married because she thinks she still has some time. She also mentions that she is not unpopular among younger men.\n\nBecause I am surrounded by young people, I don't feel I am getting old. In fact my junior likes to joke with me, saying that I should grow up, but I don't think I can. It is unnatural  for  me  to  act  like  a  grown-up  woman  because  I  am  not.  My  parents sometimes ask me how long I will continue such a life of staying single and enjoying my single life and I understand what they say. I want to marry someone someday, but I simply haven't met the right man.\n\nFor Hiromi, being natural is important, and it is in her nature to stay as she is and not force herself to act like what people expect a 40-year-old woman to act like.\n\nThe women mentioned above have a substantial income and can use their money for leisure. They are all slim and fit and look younger than their actual ages. Furthermore, they genuinely think that they are young. They consider themselves still to be in their youth, and they feel that their youth will last for a bit longer. Single women are looking for a marriage partner, but they are not desperate because they think they 'still have some time'.\n\nThis  finding  shares  similarities  with  the  results of  Nagashima's  investigation  on  single Japanese women in their thirties (Nagashima 2000). Nagashima's informants would like to get married if the opportunity arises, but they do not feel pressured to do so right now. Many of the informants in her book prioritize their individuality rather than forcing themselves to follow what  Japanese  society  expects  them  to  do  (Nagashima  2000).  Although  Nagashima's informants  are  single  women  and  three  of  the  informants  in  this  article  are  single  as  well, marital status is not so important here. The point is that these women's code of conduct is 'to be oneself'. As in Kazuko's case, as well as the informants in Hamada's (1997), Tokuhiro's (2010) and Sasagawa's (2004) articles mentioned above, jibun rashii is an important factor for the lives of married women as well.\n\n\n## CONCLUSION\n\n\nThis article has examined recent changes of the notion of maturity in Japan. The tendency of Japanese people to remain immature was noted by the Japanese psychiatrist Keigo Okonogi in the  early  1980s.  He  called  this  increasing  number  of  Japanese  youth  refusing  to  grow  up 'moratoriamu ningen' or 'moratorium people' (Okonogi 1981). It has been more than thirty years since Okonogi pointed out these characteristics of young Japanese. Since then, Japan has reached its pinnacle of consumerism, doing so in the late 1980s. As mentioned above, kosei has been valued since the late 1970s, and its discourse has become even stronger. As can be noted from the women mentioned above, to shine or kagayaku can be achieved through being oneself or watashirashiku, which can be observed in the lyrics of the bimajyo song. In order to 'be oneself', a 'real self' must be presupposed. This presupposition has prevailed in Japanese society without any critical discussion on it, while searching for the 'real self' has become an obsession among young people, as Hayamizu (2008) points out. As they believe their current status is a false self, they must search for their real self, which they presume exists, until they find it.\n\nAfter modernization, the life course of Japanese people was divided by kodomo (the child), seinen (the adolescent/the youth) and otona (the adult), and maturity was achieved by moving on to the next stage in one's life. Because of this rigid life course, the youth have challenged this social expectation, though not explicitly, and as a result the divisions between the stages of  life  have  blurred.  This  applies  to  bimajyo  as  well,  as  my  informants  are  not  explicitly rebelling against social norms by explicitly trying to change the situation of women. Instead, as de Certeau's (1984) theory of tactics indicates, they are discreetly getting away from the social expectation of behaving according to one's social position. They live their lives by what they feel is 'natural' or 'comfortable' for them. The recent phenomenon of Japanese women extending the seinen period, continuing this way of life and mentality by keeping themselves looking young, may be a by-product of their pursuit of 'jibun rashisa' or 'being on one's own', and trying to make oneself different from others. And the extension of the seinen period results in the deferral of maturity, which is prevailing in Japanese society.\n\n",
         "Recently, ‘bimajyo’ (美魔女) came into focus in Japan. Bimajyo are women 35 and above who look much younger than their actual ages. They put on nice make-up, their hair is nicely arranged, and they are very fashionable. On top of that they maintain their skin very well, hardly have wrinkles and age spots, and keep their body fit. The term was coined by the Japanese magazine Bi-STORY (美 STORY) in 2009, and became more widely recognized because of a TV variety show that introduced the concept of these ladies. Bimajyo is an extreme example of women who want to stay young, but the author has observed that many Japanese women around 40 years old, regardless of their marital status and occupation, look very young. They try to be young not only in their appearance but also try to make the way they speak and the tone of their voice young. The article also argues that the recent phenomenon of the quest of keeping young-looking among Japanese women could be one of the causes of the postponement of maturity, which is also prevalent in Japanese society and can be related to various social problems.",
         ""
        ],
        [
         "5",
         "5",
         "Introduction\n\n\nStrategically planned health research is crucial for improving the health conditions of citizens in a country (WHO, 2014). However, the lack of a systemic approach relating research efforts to public health needs in India is a prominent hurdle in improving health outcomes (Dandona et al., 2011). In a recent interview, Dr Swaminathan, an Indian scientist who is the former chief scientist of the World Health Organisation (WHO), stated that it is essential for India to adopt a systems approach to promote advanced research in the health and biomedical sciences (Kupferschmidt, 2022). To streamline efforts toward improving India's health system, it is crucial to understand the funding landscape, research outputs, and current priorities in health and biomedical research. Given India's limited research investment, it is even more vital that policymakers distribute resources in a well-informed manner.\n\nThe prioritisation of research efforts according to societal needs is an issue that has become increasingly relevant in health and science policies (Gross, 1999; Gillum et al., 2011; Evans et al., 2014; Chalmers et al., 2014; Xu et al., 2014; Wallace and Rafols, 2015; Hsiechen et al., 2017; Confraria and Wang, 2020; Yegros-Yegros et al., 2020; Zhang et al., 2020; Zhao et al., 2022). Theoretical issues revolve around how knowledge production ‘is shaped and shapes local, national and global inequality’, particularly in relation to (neo-)colonialism and dependent development (Hess et al., 2017, p. 320).\n\nThe political economy of research and innovation is constituted of durable structures which have a strong influence on which types of problems (e.g. which diseases) are tackled and which kinds of knowledge (e.g. on prevention versus treatment) are produced (Tyfield, 2012; Yegros-Yegros et al., 2020).  Yet, despite institutional forces pushing towards mainstream research topics, political and social movements can sometimes influence research towards ‘undone science’ (i.e. research topics not addressed by science but for which there is a need) and thus respond to societal demands and needs (Frickel et al., 2010). To better engage in democratic discussions on which priorities should be addressed (Stirling, 2014), it is important to have empirical estimates of existing priorities and needs (Ciarli and Rafols, 2019).\n\nEstimates of disease burden can help steer the priorities for health and biomedical research (Gross, 1999). A prior study by Dandona and colleagues (2017) indicated a misalignment between research funding (i.e. inputs) and disease burden in India. This study continues along a similar trajectory. We explore the potential misalignment of India’s disease burden and research attention as measured by research outputs, using biomedical publications related to those diseases as a proxy. Our findings show that numbers of biomedical research publications are weakly correlated with the country’s disease burden, with notable disparities in many areas of disease. In particular, we demonstrate that a significant number of Indian publications are focused on the diseases of high-income countries (HICs), mainly cancers, that have a relatively low disease burden in India.\n\nWe aim to reveal how publications correlate with disease burden, enabling the identification of gaps in existing research efforts to guide the attention of policymakers and researchers toward under-explored areas of disease. In doing so, this study will contribute to evidence-informed agenda-setting for research priorities in Indian health research.\n\n\nBackground: India’s health services and health research funding\n\n\nIndia has made considerable progress in increasing life expectancy and decreasing the child mortality rate over the past few decades. However, numerous health challenges are still of grave concern. India’s disease burden includes communicable diseases (CDs) such as tuberculosis (TB), diarrhoea, lower respiratory infections, and non-communicable diseases (NCDs) such as cardiovascular diseases, chronic pulmonary disease, and diabetes (Narain 2019). The country is facing a dual challenge: while the country’s CD burden has not been reduced, the burden of NCDs is increasing at an alarming rate (Yadav &amp; Arokiasamy, 2014) which has been pointed out by multiple studies, e.g. from 37.9% to 61.8% in the past three decades, between 1990-2016, according to Ram &amp; Thakur (2021).\n\nLow expenditure on health in India is a serious concern. Although public health expenditure increased from 0.9% of GDP in 2015-16 to 1.1% in 2020-21 (Demand for Grants 2021-22 Analysis, n.d.), this figure is still meagre compared to other upper middle-income countries (UMICs) (The National Health Policy, 2017). Its national health policy recommends increasing public health expenditure to 2.5% of the GDP by 2025 (Backdrop to the National Health Policy, 2017).\n\nExpenditure on research for health is also low. The nodal agency for health-related policies and programs in India is the Ministry of Health and Family Welfare (MoHFW). The MoHFW comprises the Department of Health and Family Welfare and the Department of Health Research (DHR). The DHR is responsible for conducting medical research. The Indian Council of Medical Research (ICMR) falls under their purview. In the financial year 2021-22, the MoHFW was allocated about 9 billion USD (739 billion Indian Rupees (INR)). The Department of Health and Family Welfare’s allocation is about INR 712 billion, which accounts for 96% of the total, leaving only a tiny fraction for the DHR, which received about INR 26 billion, 4% of the allocation. A significant portion of this was earmarked for the ICMR (Demand for Grants 2021-22 Analysis: Health and Family Welfare, n.d.).\n\nThis study focuses not on the total expenditure in health research in India but on whether the resources allocated for health research address the country’s health needs. It asks how funding agencies utilise funds to tackle health issues and which disease areas are prioritised. Awareness of which diseases cause significant burdens yet remain understudied is essential to making research more relevant to India’s health care and policies. This knowledge could inform decisions, directing research efforts toward lesser-studied but significant diseases.\n\nIn the US, considerable attention has been paid to understanding the funding landscape of the National Institute of Health (NIH) for addressing national and global disease burdens. A 1997 NIH working group recommended public health needs as a criterion for priority setting in health research (Gross, 1999). Studies have since highlighted the lack of appropriate attention given to some conditions given their disease burden (Gross et al., 1999; Gillum et al., 2011; Manton et al., 2009). Counterarguments state that the NIH employs a dynamic, need-based funding strategy that considers public health needs, scientific opportunities, budgetary considerations, and portfolio balance as critical factors (Collins, 2016). According to Collins, the NIH strategises its funding priorities through the inclusive participation of various communities while allowing for a high proportion of investigator-initiated research. However, a report by the Government Accountability Office (U.S. Government Accountability Office, 2014) highlighted the lack of transparency in the NIH’s fund allocation strategy.\n\nA world report on knowledge for better health (WHO, 2004) recommended a well-planned strategy to support health research. Improving health research fund allocation based on disease burden as a reference is one of its established strategies (Viergever, 2010). Researchers also pointed out that to increase the benefits of public spending on health research in South Asia, the disease burden among the population must be one of the guiding factors (Swaminathan et al.  2017).\n\nPrevious studies by Dandona et al. (2009) on disease burden and public health research output from India showed that several diseases with high burden were under-represented in health research-related publications between 2002 and 2007. Another study, which focused on bibliometric analysis of the global burden of disease and health research output from India (2000-2010) using the PubMed and IndMed databases (Kalita, 2015), reported the same issue of underrepresentation of research on leading causes of disease in India. It also demonstrated a skewed relationship between the burden of disease and the geographic distribution of research.\n\nOne way to address the disease burden in India would be for Indian academic institutions to conduct research on existing knowledge gaps in health. Other strategies could involve improving the healthcare system, education or nutrition, but are beyond the scope of this paper. Since scholars mainly use peer-reviewed journal research articles to communicate their findings, journal articles are viewed as an indicator of research efforts. Hence, studying the relationship between disease burden and research publications originating in India can provide helpful information about whether and how research efforts address the country’s health research needs. Previous studies have highlighted the imbalances in global health research, which focuses more on the disease burden of HICs (Yegros-Yegros et al., 2022). Research on diseases that have a high burden in low-income countries (LICs) and UMICs is, in relative terms, heavily understudied.\n\nIn this article, we analyse disease burden against research efforts in India compared to other countries. We have employed the WHO’s Global Health Estimates (GHEs) on Disability-Adjusted Life Years (DALYs) as a proxy for disease burden and Web of Science (WoS) publication data to represent research efforts, following an approach well-established in the literature (Evans et al., 2014; Yegros-Yegros et al., 2020). Our findings highlight the misalignment between disease burden and research efforts.\n\n\nMethods\n\n\nHealth research can be measured in various ways. Here, we have used scientific publications as a proxy to measure how much research each country does for various diseases. We have taken the 2000-2019 global burden of disease (GBD) estimates published by the WHO (Global Health Estimates 2020) and used DALYs as an indicator of disease burden. These are the result of summing the number of years lost due to premature death and the number of years lived with ill health or disability due to a specific condition. One DALY represents the loss of one year of full health.\n\nAll CDs and NCDs in the GBD estimates have been considered in this study, with the exception of ‘other’ categories, e.g. ‘Other infectious diseases’. All injury-related causes have also been excluded. We have considered the average country-level estimates of DALYs per 100,000 inhabitants corresponding to the entire population (i.e. both sexes and all ages) in 2015-2019.\n\nTo compare research efforts on specific diseases and corresponding disease burden, we build on the approach developed by Yegros-Yegros et al. (2020) of mapping scientific publications to particular diseases as given in the WHO GBD estimates. This approach consists of selecting one or several Medical Subject Heading (MeSH) descriptors (in combination with qualifiers when necessary) from the US National Library of Medicine MeSH database. These descriptors represent each disease category included in the WHO GBD estimates. Mapping in this way enables the retrieval from PubMed of publications related to specific diseases using the selected MeSH descriptors. The MeSH descriptors selected by WHO disease can be found in the supplementary file (check data availability statement, see Correspondence GHE Cause MeSH). For additional details on constructing the correspondence between MeSH and WHO diseases, see Yegros-Yegros et al. (2020).\n\nWe first retrieved the scientific publications from PubMed by searching for all publications in 2015-2019 using the selected MeSH descriptors and all specific descriptors beneath them in the MeSH tree structure. Next, we identified all publications retrieved in PubMed within the Centre for Science and Technology Studies (CWTS) version of WoS to obtain curated information on author affiliations.\n\nThe number of publications per country was fractionalised according to the amount of unique contributing countries with the assumption that the relative effort of each collaborating author was lower in publications with many co-authors. For example, for an article with co-authors from India and the Netherlands, we assigned 0.5 publications to each of the two countries (irrespective of the number of authors from each country). Likewise, we fractionalised publications according to the number of diseases they related to. A paper classified as ‘acute hepatitis B’ and ‘liver cancer’, for instance, counted as 0.5 publications for each disease.\n\nThe assignment of countries to income levels (i.e. HICs, UMICs, and LICs) used the historical classification of countries by income provided by the World Bank for 2017. Given the fractionalisation of publications by country, the figures obtained for income levels also take into account the proportion of the publications produced by countries of a given income level. For example, a paper co-produced by Brazil (UMIC), the Netherlands (HIC) and Spain (HIC) would count as 0.66 publications by HICs and 0.33 by UMICs.\n\n\nResults\n\n\nOur first observation was that India publishes substantially less in health areas than the world average. Whereas broadly defined health-related areas account for about 41% of the world’s WoS publications in the period studied, fields related to health only constitute 25% of India’s total output. Similarly, publications classified with a disease associated with a GHE burden represent 9.1% of all WoS papers but only 5.5% of Indian publications.\n\nNext, we analysed the distribution of publications across diseases compared to their disease burden. Table 1 shows the correlation between publications and DALYs of India, the world, HICs, UMICs and LICs, Brazil, and China. We found that the lowest correlation of DALYs with their publication is exhibited by India (0.28). HIC publications have a higher correlation with their disease burden (0.60) than any other regions. This result indicates that research efforts in India have a far worse alignment to its disease burden than research in HICs. Previous studies also showed that research publications worldwide align with the national health needs of HICs, as represented by DALYs (Evans et al., 2014). Kinge et al. (2014) also report that Norwegian research investment across therapeutic areas correlates well with the local disease burden, but that correlation is much lower for the global disease burden. Similarly, Auon et al.’s 2004 study calls attention to the significant correlation between Australia’s burden of disease and funding allocations by its National Health and Medical Research Council.\n\nInterestingly, Brazil and China, show a much better alignment between research efforts and disease burden than India. They have correlation factors of 0.41 and 0.52, respectively, compared to only 0.28 by India. LICs also show higher alignment than India with disease burden and publications; here, the correlation factor is 0.40.\n\nTable 1: Pearson correlations between disease burden (rows) and publications (columns) of disease categories for various countries and country groups.\n\n|       |   IN |   World |   HIC |   UMIC |   LIC |   BR |   CN |\n|-------|------|---------|-------|--------|-------|------|------|\n| IN    | 0.28 |    0.3  |  0.3  |   0.28 |  0.13 | 0.24 | 0.23 |\n| World | 0.34 |    0.45 |  0.44 |   0.41 |  0.32 | 0.34 | 0.34 |\n| HIC   | 0.34 |    0.6  |  0.6  |   0.59 | -0.01 | 0.39 | 0.57 |\n| UMIC  | 0.38 |    0.57 |  0.57 |   0.54 |  0.24 | 0.42 | 0.47 |\n| LIC   | 0.21 |    0.18 |  0.18 |   0.13 |  0.4  | 0.18 | 0.07 |\n| BR    | 0.36 |    0.55 |  0.56 |   0.51 |  0.08 | 0.41 | 0.45 |\n| CN    | 0.22 |    0.47 |  0.46 |   0.49 | -0.02 | 0.27 | 0.52 |\n\nNote: IN = India, HIC = High-income countries, UMIC = Upper middle-income countries, LIC = Low-income countries, BR = Brazil, and CN = China. Disease Burden is represented by DALYs.\n\nFigure 1 shows India’s relative disease burden versus its research efforts (estimated by % of publications) for the diseases with the highest burden. A variety of patterns can be observed for both CDs – such as TB and HIV/AIDS – and for NCDs, like heart disease, diabetes, and Alzheimer’s. These show understudied topics, where % of DALYs significantly overshoot the % of publications, and overstudied topics, where % of publications is substantially greater than the % of DALYs.\n\n<!-- image -->\n\nIndia’s disease burden seems paradoxical. On one hand, cardiovascular diseases associated with overeating and an affluent lifestyle are on the rise. On the other hand, the prevalence of diseases like TB and diarrhoea, associated with undernutrition, is also of concern (Patel et al., 2019). Discussion of the disease burden in India has historically focused on comparing the impact of CDs and NCDs. In recent decades, India has been experiencing an epidemiological shift, where NCDs have risen as a major health concern, leading to significant repercussions for the nation's overall health status. (Yadav, 2014). Nevertheless, our analysis shows that simply classifying the diseases into binary groups of CDs and NCDs does not reveal the nuance of misalignments between burden and research efforts. For example, TB still has a high burden, but it also benefits from significant amounts of research. Conversely, some other CDs, such as AIDS/HIV and malaria, have a relatively low burden in India, but considerable efforts are directed toward investigating them. This is welcome from a global health perspective as it is required for LICs with little research capacity. Within NCDs, some are under-studied, like ischemic heart disease, whereas others – like diabetes – are highly researched.\n\nOverall, we can see that there are relatively low research efforts for many diseases where the burden is high for India, which indicates a general misalignment between disease burden and research. To explore the relationship between disease burden and research efforts in more detail, we have divided our discussion into five categories.\n\n\nDiscussion\n\n\nThe analyses above have limitations associated with data, as discussed by Yegros-Yegros et al. (2020): disease burden estimates can be contested (Anand et al., 1997); publications do not necessarily reflect the amount of investment, and WoS underestimates the number and share of publications of many countries in the Global South (Rafols et al., 2015).\n\nHowever, the patterns observed are very likely to be robust. For example, a study by Dandona et al. (2017) also reported a misalignment between disease burden and research efforts in India's health research by collecting funding data. According to their study, neonatal disorders, cardiovascular disease, chronic respiratory disease, mental health, and musculoskeletal disorders substantially contribute to India’s disease burden. Still, research funding in these areas is considerably lower than the burden. Our findings are consistent with these observations.\n\nAnother downside of the approach we took in this study is that, by focusing on specific diseases, it may overlook the importance of studies that could benefit health in a more holistic manner: research on health systems, prevention, or social and environmental determinants, for example (Coburn et al., 2023; Van de Klippe et al., 2023).\n\nAnother issue to consider is that we used the disease burden from 2015-2019, but research from the same period is not likely to have an impact until 15-25 years in the future when there will be a different disease burden. In this regard, there was a considerable increase in the DALYs for cancer and diabetes between 2000 and 2019. This indicated a growing need for more investigation in these areas even though they already had considerable research efforts directed towards them. However, cardiovascular and respiratory diseases, which are understudied areas, have also seen a significant rise in DALYs. Therefore, it cannot be concluded that overstudied or understudied diseases relate to increases in disease burden. It is mainly in some CDs like TB and diarrheal diseases where there have been notable decreases. An analysis fully considering the dynamics of these patterns is highly complex and would need to rely on solid assumptions and such a discussion is outside the scope of this paper.\n\nTo improve health research priorities in India, it is essential to inquire into the causes of the misalignments observed. The patterns identified in this paper suggest four main reasons.\n\nFirstly, the higher burden of diseases in India for which solutions are available in HICs – like neonatal conditions, diarrhoeal diseases, and anaemia – can be regarded as an outcome of the country's poor health delivery system. The importance of healthcare delivery extends to other major conditions, such as cardiovascular and respiratory diseases. For example, ischemic heart disease was reported to be one of India's leading causes of premature death in 2013 (GBD, 2019). Major risk factors contributing to many such diseases are alcohol consumption, insufficient physical activity, tobacco use, and an unhealthy diet (Sinha, 2017). In these cases, health system improvements and “implementation sciences” should be supported (Coburn et al., 2022).\n\nA second driver for the misalignment is market demands in health. Previous studies have pointed out that market demand predominantly revolves around therapeutic interventions for chronic conditions with high prevalence in HICs. Higher research efforts for cancer can be related to private research and development (R&amp;D) expenditure, mainly by the pharmaceutical industry. Private companies comprise over 50% of global health R&amp;D (around 60%, according to Røttingen et al. (2013)). Considering this large share of expenditure, the research priorities of pharmaceutical companies constitute a substantial push for investigations into specific diseases for which there is market demand, rather than disease burden (Evans et al., 2014). In HICs, where demand is driven by wealthy healthcare providers, research priorities are driven by market demand toward some of the most prevalent diseases. However, this market demand of HICs can also influence research agendas worldwide, including in India, as seen in publication patterns for cancer diseases (Figure 4).\n\nThird is the incentive of publishing in prestigious international journals in ‘hot’ – highly cited – topics, with the associated recognition among peers in the global research community and research evaluation practices. It is not surprising that academic prestige is often related to the diseases most relevant to HICs, considering that knowledge production is highly concentrated in the Global North (Chan et al., 2011). The effect of private funding may be synergistic with the pressure of publishing in prestigious international journals. Prioritisation of the research agenda of certain HICs over countries’ local needs has been observed both in the Global South (Vessuri et al., 2014) and in ‘peripheral’ HICs like Spain (López Piñeiro and Hicks, 2015).\n\nFinally, a driver behind the focus on particular global health issues is the high concentration of funding for global public health in specific disease areas such as TB, HIV/AIDS, and malaria. This preferential attention for a few diseases is already well-studied (Dandona et al., 2010; Moran et al., 2009). Although some of these diseases, such as HIV and malaria, do not address India’s disease burden priorities, they receive high precedence in Indian research programs due to the cascading effect of international attention and funding. This is a worthy contribution, though, and may be worth keeping for the benefit of LICs.\n\n\nConclusions\n\n\nIn this study we found that de facto research priorities, as revealed by the amount of publications, are poorly correlated with disease burden in India. In India, the degree of misalignment is significantly higher on average than in other UMICs, such as China or Brazil.\n\nOur analysis revealed various patterns in the relationship between disease burden and research efforts that do not fit with the old classification into CDs and NCDs. Therefore, we have analysed the data according to five disease groupings:\n\n- Health issues, such as diarrheal diseases and neonatal conditions, for which little research is conducted because medical solutions are available\n- Diseases understudied globally and even more so in India, such as cardiovascular and respiratory diseases\n- Diseases overstudied globally and even more so in India, such as cancers and neurological diseases\n- Diseases with a particularly high burden in India for which there is a substantial Indian research response, such as TB and diabetes\n- Diseases with a high burden in LICs but not in India, in which India is a substantial contributor to global research, such as malaria and HIV/AIDS.\n\nThe present study shows that disease burden and health research priorities are particularly misaligned in India. The correlation between the research priorities of HICs and the patterns of diseases relatively overstudied in India (cancers and neurological diseases, but also malaria and HIV/AIDS) suggests three main drivers: i) market demand, ii) scientific reputation of topics aligned with the health needs of HICs, and iii) funding availability for global health.\n\nOur analysis provides some ideas for policymaking in India. Firstly, the country needs to improve its public health system. This includes to conduct research on public health, health systems, and implementation science in clinical medicine rather than focusing on specific diseases (Coburn et al., 2023). The government of India has taken several initiatives to improve the public health situation in the country. The “National Digital Health Mission”, launched by the government in 2021, aims to create a national digital health ecosystem and provide better health facilities. Proper implementation of various health-related schemes is critical to ensuring the quality of the public healthcare system. Improving healthcare delivery and awareness-building can help reduce the burden of certain diseases.\n\nSecondly, Indian science policy needs to respond to the heavy under-researching of diseases such as cardiovascular and respiratory diseases and perhaps stop expanding its support to areas, like many cancers, which are relatively overstudied. Governance of health research, in general, is an aspect that needs more attention. Setting the right policies and priorities requires serious debate. The primary public agencies that fund health research need to work collaboratively to devise strategies for medium and long-term goals. The lack of alignment between national health research priorities and funding is a common issue across the Global South (Evans et al., 2014). In Latin America and the Caribbean, it has been argued that improvements in governance practices have made a crucial contribution to advancing research for health (Salicrup, 2018). Through establishing clear policies, priorities, and health research governance systems, LAC countries such as Brazil have made substantial progress in addressing local research needs. India could follow with similar reforms.\n\n\nA. Diseases that require improved healthcare delivery in India\n\n\n<!-- image -->\n\nFigure 2a: Relative disease burden (% of DALYs) vs. relative research efforts (% of publications) for neonatal conditions.\n\n<!-- image -->\n\nFigure 2b: Relative disease burden (% of DALYs) vs. relative research efforts (% of publications) for diarrheal diseases.\n\nAn indicator that helps identify diseases in this category is the ratio of the disease burden of a specific country compared to the disease burden of HICs. If this ratio is high, the disease has a low burden in HICs, meaning that knowledge is available to address the disease, but it is not being implemented in India’s healthcare system. In this situation, even a small amount of investigation into applying existing knowledge to improve healthcare delivery could result in substantive health gains. We can, therefore, attribute the higher DALYs in India for diseases like neonatal conditions, diarrhoeal diseases, and anaemia to its poor health delivery system, as solutions are available.\n\n\nB. Diseases understudied both in India and globally\n\n\nIn this category are diseases with low research efforts despite having a high disease burden, both in India and worldwide. We observed a 3 to 5 ratio of relative disease burden (% DALYs) over research efforts (% of publications) in India but lower ratios in HICs and UMICs.\n\nRepresentative examples in this category are cardiovascular and respiratory diseases (Figure 3a &amp; 3b). Cardiovascular diseases are understudied in all income group countries. They contribute over 20% of the disease burden in HICs and even more (~ 22%) in UMICs. However, when we examine their share of publications, HICs and UMICs each have about 10%, indicating low research effort. In the case of India, the research effort for cardiovascular diseases is even lower: less than 5% of the total publication share, even though they make up ~16% of the disease burden. A similar pattern is observed in the case of respiratory diseases, which are understudied in all income groups and even more so in India. These diseases generate about 7% burden in India, while the publication share in India is only 1%.\n\n<!-- image -->\n\nFigure 3a: Relative disease burden (% of DALYs) vs. relative research efforts (% of publications) for cardiovascular diseases.\n\n<!-- image -->\n\nFigure 3b: Relative disease burden (% of DALYs) vs. relative research efforts (% of publications) for respiratory diseases.\n\n\nC. Diseases overstudied in India and globally\n\n\nThis category comprises diseases with high research efforts and a high burden in HICs but a low disease burden in India and the rest of the world. In India, the ratio of relative disease burden to research efforts is 1/5 to 1/3, indicating that they are 3-5-fold relatively overstudied.\n\n<!-- image -->\n\nFigure 4a: Relative disease burden (% of DALYs) vs. relative research efforts (% of publications) for cancer diseases.\n\n<!-- image -->\n\nFigure 4b: Relative disease burden (% of DALYs) vs. relative research efforts (% of publications) for Alzheimer’s diseases.\n\n\nD. Disease with significant burden and considerable research effort in India\n\n\nDiseases with both significant burdens and research efforts in India are TB and diabetes (Figure 5a &amp; 5b). TB receives a lot of attention worldwide. For HICs, its publication share is about 1% despite a very low disease burden. TB’s share in UMICs is ~1.8% compared to a burden of ~1.7%. The disease burden of TB in India is about 7%, and its publication share is about 5%. TB is of severe concern for India and has garnered a great deal of attention due to the severity of the disease, especially its multidrug-resistant variant (Thakur et al., 2020). Similarly, TB is a significant concern for LICs (~4% burden), which demonstrate substantial research efforts toward TB (~8%). Overall, India is thus contributing substantially toward knowledge generation about TB as it is understudied worldwide in comparison to its global disease burden (~2.5% of burden versus ~1% of publication share).\n\n<!-- image -->\n\nFigure 5a: Relative disease burden (% of DALYs) vs. relative research efforts (% of publications) for TB and diabetes.\n\n<!-- image -->\n\nFigure 5b: Relative disease burden (% of DALYs) vs. relative research efforts (% of publications) for TB and diabetes.\n\nIn the case of diabetes, India is again contributing significantly to the global knowledge pool. Diabetes is relatively overstudied in India (~2.5% of burden compared to ~7% of publication share) as well as in LIC (~1.5 % burden versus ~3% publication share), but given its growing health effects, this is a case in which this might be a wise choice. In contrast, publication share versus disease burden shows a 1:1 relationship for both HICs and UMICs.\n\nE. Diseases only prevalent in LICs,\n\nThis category contains diseases with a very low burden but considerable research efforts in India, which have a significant global burden. Examples in this category are Malaria and HIV/AIDS (Figure 6a &amp; 6b). HIV/AIDS or malaria are not major challenges for India, nor in HICs or UMICs in terms of disease burden.  Still, considerable research efforts are directed toward them. These studies help address a global rather than specifically Indian health challenge. For example, the disease burden of malaria in India is ~0.5%, and the publication share is ~2.5%. In the case of HIV/AIDS, the burden in India is ~1%, and the publication share is ~2.5%. By investing in these areas, India is assisting in tackling a disease burden concentrated in LICs with limited research capacity. Detailed analysis reveals that, in the case of LICs, research on these diseases is driven by a high percentage of international collaborations and funding. However, this is not the case in India. Shares of international funding are lower in India than in HICs and UMICs. For example, for HIV/AIDS, international funding is acknowledged in only 12% of Indian papers compared to 31% of HICs’ and 17% of UMICs’.\n\n<!-- image -->\n\nFigure 6a: Relative disease burden (% of DALYs) vs. relative research efforts (% of publications) for malaria.\n\n<!-- image -->\n\nFigure 6b: Relative disease burden (% of DALYs) vs. relative research efforts (% of publications) for HIV/AIDS.\n\n\nPriorities of health research in India: evidence of misalignment between research outputs and disease burden\n\n\n",
         "This study examines whether and how India's research efforts address the country's health needs. It does so by investigating the degree of alignment between the burden of diseases in India and research efforts being undertaken in health and biomedical sciences by Indian institutions. WHO data from Global Health Estimates on Disability-Adjusted Life Years (DALYs) is used as the indicator of disease burden, and the number of publications on Web of Science as the proxy measure of research efforts.\nWe find that the alignment between publications and DALYs in India is much lower than in high-income countries (HICs) and considerably lower than in countries such as China or Brazil. This is due to some areas of disease having little research efforts even though they have a high burden, while others receive large amounts of attention in spite of a low burden. For example, cardiovascular and respiratory diseases contribute to ~23% of the disease burden in India but only have a ~6% share of the total publications. In contrast, cancers contribute to ~5 % of the burden, while their publication share is almost 25%.\nWe discuss some major driving factors behind this misalignment, such as market demand associated with diseases prevalent in HICs, the academic prestige of certain disease areas, and funding opportunities in global health. We also explore whether the disparity is due to weaknesses in healthcare delivery systems in India (e.g., in neonatal conditions) rather than a lack of research.",
         "Introduction Strategically planned health research is crucial for improving the health conditions of citizens in a country (WHO, 2014). However, the lack of a systemic approach relating research efforts to public health needs in India is a prominent hurdle in improving health outcomes (Dandona et al., 2011). In a recent interview, Dr Swaminathan, an Indian scientist who is the former chief scientist of the World Health Organisation (WHO), stated that it is essential for India to adopt a systems approach to promote advanced research in the health and biomedical sciences (Kupferschmidt, 2022). To streamline efforts toward improving India's health system, it is crucial to understand the funding landscape, research outputs, and current priorities in health and biomedical research. Given India's limited research investment, it is even more vital that policymakers distribute resources in a well-informed manner. The prioritisation of research efforts according to societal needs is an issue that has become increasingly relevant in health and science policies (Gross, 1999; Gillum et al., 2011; Evans et al., 2014; Chalmers et al., 2014; Xu et al., 2014; Wallace and Rafols, 2015; Hsiechen et al., 2017; Confraria and Wang, 2020; Yegros-Yegros et al., 2020; Zhang et al., 2020; Zhao et al., 2022). Theoretical issues revolve around how knowledge production ‘is shaped and shapes local, national and global inequality’, particularly in relation to (neo-)colonialism and dependent development (Hess et al., 2017, p. 320). The political economy of research and innovation is constituted of durable structures which have a strong influence on which types of problems (e.g. which diseases) are tackled and which kinds of knowledge (e.g. on prevention versus treatment) are produced (Tyfield, 2012; Yegros-Yegros et al., 2020). Yet, despite institutional forces pushing towards mainstream research topics, political and social movements can sometimes influence research towards ‘undone science’ (i.e. research topics not addressed by science but for which there is a need) and thus respond to societal demands and needs (Frickel et al., 2010). To better engage in democratic discussions on which priorities should be addressed (Stirling, 2014), it is important to have empirical estimates of existing priorities and needs (Ciarli and Rafols, 2019). Estimates of disease burden can help steer the priorities for health and biomedical research (Gross, 1999). A prior study by Dandona and colleagues (2017) indicated a misalignment between research funding (i.e. inputs) and disease burden in India. This study continues along a similar trajectory. We explore the potential misalignment of India’s disease burden and research attention as measured by research outputs, using biomedical publications related to those diseases as a proxy. Our findings show that numbers of biomedical research publications are weakly correlated with the country’s disease burden, with notable disparities in many areas of disease. In particular, we demonstrate that a significant number of Indian publications are focused on the diseases of high-income countries (HICs), mainly cancers, that have a relatively low disease burden in India. We aim to reveal how publications correlate with disease burden, enabling the identification of gaps in existing research efforts to guide the attention of policymakers and researchers toward under-explored areas of disease. In doing so, this study will contribute to evidence-informed agenda-setting for research priorities in Indian health research. Background: India’s health services and health research funding India has made considerable progress in increasing life expectancy and decreasing the child mortality rate over the past few decades. However, numerous health challenges are still of grave concern. India’s disease burden includes communicable diseases (CDs) such as tuberculosis (TB), diarrhoea, lower respiratory infections, and non-communicable diseases (NCDs) such as cardiovascular diseases, chronic pulmonary disease, and diabetes (Narain 2019). The country is facing a dual challenge: while the country’s CD burden has not been reduced, the burden of NCDs is increasing at an alarming rate (Yadav &amp; Arokiasamy, 2014) which has been pointed out by multiple studies, e.g. from 37.9% to 61.8% in the past three decades, between 1990-2016, according to Ram &amp; Thakur (2021). Low expenditure on health in India is a serious concern. Although public health expenditure increased from 0.9% of GDP in 2015-16 to 1.1% in 2020-21 (Demand for Grants 2021-22 Analysis, n.d.), this figure is still meagre compared to other upper middle-income countries (UMICs) (The National Health Policy, 2017). Its national health policy recommends increasing public health expenditure to 2.5% of the GDP by 2025 (Backdrop to the National Health Policy, 2017). Expenditure on research for health is also low. The nodal agency for health-related policies and programs in India is the Ministry of Health and Family Welfare (MoHFW). The MoHFW comprises the Department of Health and Family Welfare and the Department of Health Research (DHR). The DHR is responsible for conducting medical research. The Indian Council of Medical Research (ICMR) falls under their purview. In the financial year 2021-22, the MoHFW was allocated about 9 billion USD (739 billion Indian Rupees (INR)). The Department of Health and Family Welfare’s allocation is about INR 712 billion, which accounts for 96% of the total, leaving only a tiny fraction for the DHR, which received about INR 26 billion, 4% of the allocation. A significant portion of this was earmarked for the ICMR (Demand for Grants 2021-22 Analysis: Health and Family Welfare, n.d.). This study focuses not on the total expenditure in health research in India but on whether the resources allocated for health research address the country’s health needs. It asks how funding agencies utilise funds to tackle health issues and which disease areas are prioritised. Awareness of which diseases cause significant burdens yet remain understudied is essential to making research more relevant to India’s health care and policies. This knowledge could inform decisions, directing research efforts toward lesser-studied but significant diseases. In the US, considerable attention has been paid to understanding the funding landscape of the National Institute of Health (NIH) for addressing national and global disease burdens. A 1997 NIH working group recommended public health needs as a criterion for priority setting in health research (Gross, 1999). Studies have since highlighted the lack of appropriate attention given to some conditions given their disease burden (Gross et al., 1999; Gillum et al., 2011; Manton et al., 2009). Counterarguments state that the NIH employs a dynamic, need-based funding strategy that considers public health needs, scientific opportunities, budgetary considerations, and portfolio balance as critical factors (Collins, 2016). According to Collins, the NIH strategises its funding priorities through the inclusive participation of various communities while allowing for a high proportion of investigator-initiated research. However, a report by the Government Accountability Office (U.S. Government Accountability Office, 2014) highlighted the lack of transparency in the NIH’s fund allocation strategy. A world report on knowledge for better health (WHO, 2004) recommended a well-planned strategy to support health research. Improving health research fund allocation based on disease burden as a reference is one of its established strategies (Viergever, 2010). Researchers also pointed out that to increase the benefits of public spending on health research in South Asia, the disease burden among the population must be one of the guiding factors (Swaminathan et al. 2017). Previous studies by Dandona et al. (2009) on disease burden and public health research output from India showed that several diseases with high burden were under-represented in health research-related publications between 2002 and 2007. Another study, which focused on bibliometric analysis of the global burden of disease and health research output from India (2000-2010) using the PubMed and IndMed databases (Kalita, 2015), reported the same issue of underrepresentation of research on leading causes of disease in India. It also demonstrated a skewed relationship between the burden of disease and the geographic distribution of research. One way to address the disease burden in India would be for Indian academic institutions to conduct research on existing knowledge gaps in health. Other strategies could involve improving the healthcare system, education or nutrition, but are beyond the scope of this paper. Since scholars mainly use peer-reviewed journal research articles to communicate their findings, journal articles are viewed as an indicator of research efforts. Hence, studying the relationship between disease burden and research publications originating in India can provide helpful information about whether and how research efforts address the country’s health research needs. Previous studies have highlighted the imbalances in global health research, which focuses more on the disease burden of HICs (Yegros-Yegros et al., 2022). Research on diseases that have a high burden in low-income countries (LICs) and UMICs is, in relative terms, heavily understudied. In this article, we analyse disease burden against research efforts in India compared to other countries. We have employed the WHO’s Global Health Estimates (GHEs) on Disability-Adjusted Life Years (DALYs) as a proxy for disease burden and Web of Science (WoS) publication data to represent research efforts, following an approach well-established in the literature (Evans et al., 2014; Yegros-Yegros et al., 2020). Our findings highlight the misalignment between disease burden and research efforts. Methods Health research can be measured in various ways. Here, we have used scientific publications as a proxy to measure how much research each country does for various diseases. We have taken the 2000-2019 global burden of disease (GBD) estimates published by the WHO (Global Health Estimates 2020) and used DALYs as an indicator of disease burden. These are the result of summing the number of years lost due to premature death and the number of years lived with ill health or disability due to a specific condition. One DALY represents the loss of one year of full health. All CDs and NCDs in the GBD estimates have been considered in this study, with the exception of ‘other’ categories, e.g. ‘Other infectious diseases’. All injury-related causes have also been excluded. We have considered the average country-level estimates of DALYs per 100,000 inhabitants corresponding to the entire population (i.e. both sexes and all ages) in 2015-2019. To compare research efforts on specific diseases and corresponding disease burden, we build on the approach developed by Yegros-Yegros et al. (2020) of mapping scientific publications to particular diseases as given in the WHO GBD estimates. This approach consists of selecting one or several Medical Subject Heading (MeSH) descriptors (in combination with qualifiers when necessary) from the US National Library of Medicine MeSH database. These descriptors represent each disease category included in the WHO GBD estimates. Mapping in this way enables the retrieval from PubMed of publications related to specific diseases using the selected MeSH descriptors. The MeSH descriptors selected by WHO disease can be found in the supplementary file (check data availability statement, see Correspondence GHE Cause MeSH). For additional details on constructing the correspondence between MeSH and WHO diseases, see Yegros-Yegros et al. (2020). We first retrieved the scientific publications from PubMed by searching for all publications in 2015-2019 using the selected MeSH descriptors and all specific descriptors beneath them in the MeSH tree structure. Next, we identified all publications retrieved in PubMed within the Centre for Science and Technology Studies (CWTS) version of WoS to obtain curated information on author affiliations. The number of publications per country was fractionalised according to the amount of unique contributing countries with the assumption that the relative effort of each collaborating author was lower in publications with many co-authors. For example, for an article with co-authors from India and the Netherlands, we assigned 0.5 publications to each of the two countries (irrespective of the number of authors from each country). Likewise, we fractionalised publications according to the number of diseases they related to. A paper classified as ‘acute hepatitis B’ and ‘liver cancer’, for instance, counted as 0.5 publications for each disease. The assignment of countries to income levels (i.e. HICs, UMICs, and LICs) used the historical classification of countries by income provided by the World Bank for 2017. Given the fractionalisation of publications by country, the figures obtained for income levels also take into account the proportion of the publications produced by countries of a given income level. For example, a paper co-produced by Brazil (UMIC), the Netherlands (HIC) and Spain (HIC) would count as 0.66 publications by HICs and 0.33 by UMICs. Results Our first observation was that India publishes substantially less in health areas than the world average. Whereas broadly defined health-related areas account for about 41% of the world’s WoS publications in the period studied, fields related to health only constitute 25% of India’s total output. Similarly, publications classified with a disease associated with a GHE burden represent 9.1% of all WoS papers but only 5.5% of Indian publications. Next, we analysed the distribution of publications across diseases compared to their disease burden. Table 1 shows the correlation between publications and DALYs of India, the world, HICs, UMICs and LICs, Brazil, and China. We found that the lowest correlation of DALYs with their publication is exhibited by India (0.28). HIC publications have a higher correlation with their disease burden (0.60) than any other regions. This result indicates that research efforts in India have a far worse alignment to its disease burden than research in HICs. Previous studies also showed that research publications worldwide align with the national health needs of HICs, as represented by DALYs (Evans et al., 2014). Kinge et al. (2014) also report that Norwegian research investment across therapeutic areas correlates well with the local disease burden, but that correlation is much lower for the global disease burden. Similarly, Auon et al.’s 2004 study calls attention to the significant correlation between Australia’s burden of disease and funding allocations by its National Health and Medical Research Council. Interestingly, Brazil and China, show a much better alignment between research efforts and disease burden than India. They have correlation factors of 0.41 and 0.52, respectively, compared to only 0.28 by India. LICs also show higher alignment than India with disease burden and publications; here, the correlation factor is 0.40. Table 1: Pearson correlations between disease burden (rows) and publications (columns) of disease categories for various countries and country groups. | | IN | World | HIC | UMIC | LIC | BR | CN | |-------|------|---------|-------|--------|-------|------|------| | IN | 0.28 | 0.3 | 0.3 | 0.28 | 0.13 | 0.24 | 0.23 | | World | 0.34 | 0.45 | 0.44 | 0.41 | 0.32 | 0.34 | 0.34 | | HIC | 0.34 | 0.6 | 0.6 | 0.59 | -0.01 | 0.39 | 0.57 | | UMIC | 0.38 | 0.57 | 0.57 | 0.54 | 0.24 | 0.42 | 0.47 | | LIC | 0.21 | 0.18 | 0.18 | 0.13 | 0.4 | 0.18 | 0.07 | | BR | 0.36 | 0.55 | 0.56 | 0.51 | 0.08 | 0.41 | 0.45 | | CN | 0.22 | 0.47 | 0.46 | 0.49 | -0.02 | 0.27 | 0.52 | Note: IN = India, HIC = High-income countries, UMIC = Upper middle-income countries, LIC = Low-income countries, BR = Brazil, and CN = China. Disease Burden is represented by DALYs. Figure 1 shows India’s relative disease burden versus its research efforts (estimated by % of publications) for the diseases with the highest burden. A variety of patterns can be observed for both CDs – such as TB and HIV/AIDS – and for NCDs, like heart disease, diabetes, and Alzheimer’s. These show understudied topics, where % of DALYs significantly overshoot the % of publications, and overstudied topics, where % of publications is substantially greater than the % of DALYs. <!-- image --> India’s disease burden seems paradoxical. On one hand, cardiovascular diseases associated with overeating and an affluent lifestyle are on the rise. On the other hand, the prevalence of diseases like TB and diarrhoea, associated with undernutrition, is also of concern (Patel et al., 2019). Discussion of the disease burden in India has historically focused on comparing the impact of CDs and NCDs. In recent decades, India has been experiencing an epidemiological shift, where NCDs have risen as a major health concern, leading to significant repercussions for the nation's overall health status. (Yadav, 2014). Nevertheless, our analysis shows that simply classifying the diseases into binary groups of CDs and NCDs does not reveal the nuance of misalignments between burden and research efforts. For example, TB still has a high burden, but it also benefits from significant amounts of research. Conversely, some other CDs, such as AIDS/HIV and malaria, have a relatively low burden in India, but considerable efforts are directed toward investigating them. This is welcome from a global health perspective as it is required for LICs with little research capacity. Within NCDs, some are under-studied, like ischemic heart disease, whereas others – like diabetes – are highly researched. Overall, we can see that there are relatively low research efforts for many diseases where the burden is high for India, which indicates a general misalignment between disease burden and research. To explore the relationship between disease burden and research efforts in more detail, we have divided our discussion into five categories. Discussion The analyses above have limitations associated with data, as discussed by Yegros-Yegros et al. (2020): disease burden estimates can be contested (Anand et al., 1997); publications do not necessarily reflect the amount of investment, and WoS underestimates the number and share of publications of many countries in the Global South (Rafols et al., 2015). However, the patterns observed are very likely to be robust. For example, a study by Dandona et al. (2017) also reported a misalignment between disease burden and research efforts in India's health research by collecting funding data. According to their study, neonatal disorders, cardiovascular disease, chronic respiratory disease, mental health, and musculoskeletal disorders substantially contribute to India’s disease burden. Still, research funding in these areas is considerably lower than the burden. Our findings are consistent with these observations. Another downside of the approach we took in this study is that, by focusing on specific diseases, it may overlook the importance of studies that could benefit health in a more holistic manner: research on health systems, prevention, or social and environmental determinants, for example (Coburn et al., 2023; Van de Klippe et al., 2023). Another issue to consider is that we used the disease burden from 2015-2019, but research from the same period is not likely to have an impact until 15-25 years in the future when there will be a different disease burden. In this regard, there was a considerable increase in the DALYs for cancer and diabetes between 2000 and 2019. This indicated a growing need for more investigation in these areas even though they already had considerable research efforts directed towards them. However, cardiovascular and respiratory diseases, which are understudied areas, have also seen a significant rise in DALYs. Therefore, it cannot be concluded that overstudied or understudied diseases relate to increases in disease burden. It is mainly in some CDs like TB and diarrheal diseases where there have been notable decreases. An analysis fully considering the dynamics of these patterns is highly complex and would need to rely on solid assumptions and such a discussion is outside the scope of this paper. To improve health research priorities in India, it is essential to inquire into the causes of the misalignments observed. The patterns identified in this paper suggest four main reasons. Firstly, the higher burden of diseases in India for which solutions are available in HICs – like neonatal conditions, diarrhoeal diseases, and anaemia – can be regarded as an outcome of the country's poor health delivery system. The importance of healthcare delivery extends to other major conditions, such as cardiovascular and respiratory diseases. For example, ischemic heart disease was reported to be one of India's leading causes of premature death in 2013 (GBD, 2019). Major risk factors contributing to many such diseases are alcohol consumption, insufficient physical activity, tobacco use, and an unhealthy diet (Sinha, 2017). In these cases, health system improvements and “implementation sciences” should be supported (Coburn et al., 2022). A second driver for the misalignment is market demands in health. Previous studies have pointed out that market demand predominantly revolves around therapeutic interventions for chronic conditions with high prevalence in HICs. Higher research efforts for cancer can be related to private research and development (R&amp;D) expenditure, mainly by the pharmaceutical industry. Private companies comprise over 50% of global health R&amp;D (around 60%, according to Røttingen et al. (2013)). Considering this large share of expenditure, the research priorities of pharmaceutical companies constitute a substantial push for investigations into specific diseases for which there is market demand, rather than disease burden (Evans et al., 2014). In HICs, where demand is driven by wealthy healthcare providers, research priorities are driven by market demand toward some of the most prevalent diseases. However, this market demand of HICs can also influence research agendas worldwide, including in India, as seen in publication patterns for cancer diseases (Figure 4). Third is the incentive of publishing in prestigious international journals in ‘hot’ – highly cited – topics, with the associated recognition among peers in the global research community and research evaluation practices. It is not surprising that academic prestige is often related to the diseases most relevant to HICs, considering that knowledge production is highly concentrated in the Global North (Chan et al., 2011). The effect of private funding may be synergistic with the pressure of publishing in prestigious international journals. Prioritisation of the research agenda of certain HICs over countries’ local needs has been observed both in the Global South (Vessuri et al., 2014) and in ‘peripheral’ HICs like Spain (López Piñeiro and Hicks, 2015). Finally, a driver behind the focus on particular global health issues is the high concentration of funding for global public health in specific disease areas such as TB, HIV/AIDS, and malaria. This preferential attention for a few diseases is already well-studied (Dandona et al., 2010; Moran et al., 2009). Although some of these diseases, such as HIV and malaria, do not address India’s disease burden priorities, they receive high precedence in Indian research programs due to the cascading effect of international attention and funding. This is a worthy contribution, though, and may be worth keeping for the benefit of LICs. Conclusions In this study we found that de facto research priorities, as revealed by the amount of publications, are poorly correlated with disease burden in India. In India, the degree of misalignment is significantly higher on average than in other UMICs, such as China or Brazil. Our analysis revealed various patterns in the relationship between disease burden and research efforts that do not fit with the old classification into CDs and NCDs. Therefore, we have analysed the data according to five disease groupings: - Health issues, such as diarrheal diseases and neonatal conditions, for which little research is conducted because medical solutions are available - Diseases understudied globally and even more so in India, such as cardiovascular and respiratory diseases - Diseases overstudied globally and even more so in India, such as cancers and neurological diseases - Diseases with a particularly high burden in India for which there is a substantial Indian research response, such as TB and diabetes - Diseases with a high burden in LICs but not in India, in which India is a substantial contributor to global research, such as malaria and HIV/AIDS. The present study shows that disease burden and health research priorities are particularly misaligned in India. The correlation between the research priorities of HICs and the patterns of diseases relatively overstudied in India (cancers and neurological diseases, but also malaria and HIV/AIDS) suggests three main drivers: i) market demand, ii) scientific reputation of topics aligned with the health needs of HICs, and iii) funding availability for global health. Our analysis provides some ideas for policymaking in India. Firstly, the country needs to improve its public health system. This includes to conduct research on public health, health systems, and implementation science in clinical medicine rather than focusing on specific diseases (Coburn et al., 2023). The government of India has taken several initiatives to improve the public health situation in the country. The “National Digital Health Mission”, launched by the government in 2021, aims to create a national digital health ecosystem and provide better health facilities. Proper implementation of various health-related schemes is critical to ensuring the quality of the public healthcare system. Improving healthcare delivery and awareness-building can help reduce the burden of certain diseases. Secondly, Indian science policy needs to respond to the heavy under-researching of diseases such as cardiovascular and respiratory diseases and perhaps stop expanding its support to areas, like many cancers, which are relatively overstudied. Governance of health research, in general, is an aspect that needs more attention. Setting the right policies and priorities requires serious debate. The primary public agencies that fund health research need to work collaboratively to devise strategies for medium and long-term goals. The lack of alignment between national health research priorities and funding is a common issue across the Global South (Evans et al., 2014). In Latin America and the Caribbean, it has been argued that improvements in governance practices have made a crucial contribution to advancing research for health (Salicrup, 2018). Through establishing clear policies, priorities, and health research governance systems, LAC countries such as Brazil have made substantial progress in addressing local research needs. India could follow with similar reforms. A. Diseases that require improved healthcare delivery in India <!-- image --> Figure 2a: Relative disease burden (% of DALYs) vs. relative research efforts (% of publications) for neonatal conditions. <!-- image --> Figure 2b: Relative disease burden (% of DALYs) vs. relative research efforts (% of publications) for diarrheal diseases. An indicator that helps identify diseases in this category is the ratio of the disease burden of a specific country compared to the disease burden of HICs. If this ratio is high, the disease has a low burden in HICs, meaning that knowledge is available to address the disease, but it is not being implemented in India’s healthcare system. In this situation, even a small amount of investigation into applying existing knowledge to improve healthcare delivery could result in substantive health gains. We can, therefore, attribute the higher DALYs in India for diseases like neonatal conditions, diarrhoeal diseases, and anaemia to its poor health delivery system, as solutions are available. B. Diseases understudied both in India and globally In this category are diseases with low research efforts despite having a high disease burden, both in India and worldwide. We observed a 3 to 5 ratio of relative disease burden (% DALYs) over research efforts (% of publications) in India but lower ratios in HICs and UMICs. Representative examples in this category are cardiovascular and respiratory diseases (Figure 3a &amp; 3b). Cardiovascular diseases are understudied in all income group countries. They contribute over 20% of the disease burden in HICs and even more (~ 22%) in UMICs. However, when we examine their share of publications, HICs and UMICs each have about 10%, indicating low research effort. In the case of India, the research effort for cardiovascular diseases is even lower: less than 5% of the total publication share, even though they make up ~16% of the disease burden. A similar pattern is observed in the case of respiratory diseases, which are understudied in all income groups and even more so in India. These diseases generate about 7% burden in India, while the publication share in India is only 1%. <!-- image --> Figure 3a: Relative disease burden (% of DALYs) vs. relative research efforts (% of publications) for cardiovascular diseases. <!-- image --> Figure 3b: Relative disease burden (% of DALYs) vs. relative research efforts (% of publications) for respiratory diseases. C. Diseases overstudied in India and globally This category comprises diseases with high research efforts and a high burden in HICs but a low disease burden in India and the rest of the world. In India, the ratio of relative disease burden to research efforts is 1/5 to 1/3, indicating that they are 3-5-fold relatively overstudied. <!-- image --> Figure 4a: Relative disease burden (% of DALYs) vs. relative research efforts (% of publications) for cancer diseases. <!-- image --> Figure 4b: Relative disease burden (% of DALYs) vs. relative research efforts (% of publications) for Alzheimer’s diseases. D. Disease with significant burden and considerable research effort in India Diseases with both significant burdens and research efforts in India are TB and diabetes (Figure 5a &amp; 5b). TB receives a lot of attention worldwide. For HICs, its publication share is about 1% despite a very low disease burden. TB’s share in UMICs is ~1.8% compared to a burden of ~1.7%. The disease burden of TB in India is about 7%, and its publication share is about 5%. TB is of severe concern for India and has garnered a great deal of attention due to the severity of the disease, especially its multidrug-resistant variant (Thakur et al., 2020). Similarly, TB is a significant concern for LICs (~4% burden), which demonstrate substantial research efforts toward TB (~8%). Overall, India is thus contributing substantially toward knowledge generation about TB as it is understudied worldwide in comparison to its global disease burden (~2.5% of burden versus ~1% of publication share). <!-- image --> Figure 5a: Relative disease burden (% of DALYs) vs. relative research efforts (% of publications) for TB and diabetes. <!-- image --> Figure 5b: Relative disease burden (% of DALYs) vs. relative research efforts (% of publications) for TB and diabetes. In the case of diabetes, India is again contributing significantly to the global knowledge pool. Diabetes is relatively overstudied in India (~2.5% of burden compared to ~7% of publication share) as well as in LIC (~1.5 % burden versus ~3% publication share), but given its growing health effects, this is a case in which this might be a wise choice. In contrast, publication share versus disease burden shows a 1:1 relationship for both HICs and UMICs. E. Diseases only prevalent in LICs, This category contains diseases with a very low burden but considerable research efforts in India, which have a significant global burden. Examples in this category are Malaria and HIV/AIDS (Figure 6a &amp; 6b). HIV/AIDS or malaria are not major challenges for India, nor in HICs or UMICs in terms of disease burden. Still, considerable research efforts are directed toward them. These studies help address a global rather than specifically Indian health challenge. For example, the disease burden of malaria in India is ~0.5%, and the publication share is ~2.5%. In the case of HIV/AIDS, the burden in India is ~1%, and the publication share is ~2.5%. By investing in these areas, India is assisting in tackling a disease burden concentrated in LICs with limited research capacity. Detailed analysis reveals that, in the case of LICs, research on these diseases is driven by a high percentage of international collaborations and funding. However, this is not the case in India. Shares of international funding are lower in India than in HICs and UMICs. For example, for HIV/AIDS, international funding is acknowledged in only 12% of Indian papers compared to 31% of HICs’ and 17% of UMICs’. <!-- image --> Figure 6a: Relative disease burden (% of DALYs) vs. relative research efforts (% of publications) for malaria. <!-- image --> Figure 6b: Relative disease burden (% of DALYs) vs. relative research efforts (% of publications) for HIV/AIDS. Priorities of health research in India: evidence of misalignment between research outputs and disease burden"
        ],
        [
         "6",
         "6",
         "## 1 Introduction\n\n\nPolitics is all about 'who gets what, when, [and] how' (Lasswell, 1936) and distributive processes are zero-sum: when a finite budget or finite resources are allocated, some people's gains must come at the expense of others. Understanding why politicians treat some groups more favourably than others by allocating them more public services or higher public spending has consequently been a central question for political economists for decades (Weingast, Shepsle and Johnsen, 1981; Persson and Tabellini, 2000; Drazen, 2002; Golden and Min, 2013). Electoral accountability, the ability of voters to reward or sanction politicians for their actions in office, is another central topic for political inquiry (Fearon, 1999; Besley, 2006; Ashworth, 2012). Since such accountability is necessarily based on politicians' past actions, voters' information about these actions determines their ability to hold politicians accountable (Duggan and Martinelli, 2017) and might allow them to infer politicians' preferences or abilities, which they can subsequently use to screen out politicians with undesirable traits and select politicians with desirable traits. However, there is considerable heterogeneity in voters' information about politics: poorly informed masses of voters coexist with more informed groups of voters (Delli Carpini and Keeter, 1997; Lupia, 2016).\n\nTo gain insights into the links between electoral accountability, voter information, and distributive politics, I consider a series of two-period models of political agency in which an office-holder is tasked with allocating resources to a continuum of voters, who vote to retain the incumbent or replace him with a challenger between the two periods. Focusing on distributive issues and voters' ability to screen politicians, I ask: how can more information for all voters affect voters' welfare? How can more information for some voters affect their welfare? How can it affect the welfare of other voters? Who's better off, more informed voters or less informed ones?\n\nIn the models, a windfall is available to the politician to allocate in good times, whereas nothing is available in bad times. 1 Possible interpretations of this windfall include money, resources to spend on constituency services, or legislative work on specific issues. Politicians' preferences are privately known. They may be benevolent , distributing the entire windfall efficiently, uniformly to voters; or strategic , valuing holding office per se and the rents that can be extracted from the windfall. I consider information relevant to voters' evaluation of politicians' actions with three information structures: least informed voters only always observe their own allocation; state informed voters only always observe their own allocation and the state of the world; and most informed voters observe their own allocation, the state of the world, and the entire distribution of allocations in the economy. Finally, I include a reduced-form monitoring mechanism, which can be interpreted as judicial oversight or accountability journalism, in the form of a probability of detection of rent extraction that increases with the amount of rent extraction. Between the two periods, voters get an opportunity to either reelect the incumbent\n\nor elect a randomly drawn challenger. They vote sincerely, based on their rationally updated beliefs.\n\nThe analysis proceeds in two steps. First, I study homogeneously informed electorates. Then, building on the results of this first part, I consider heterogeneously informed electorates, in which a few voters are more informed than the rest. I emphasise more informed voters' ability to communicate with the rest of the electorate and the nature of their informational advantage. Two concepts play an essential role in the analysis that follows: I use the term control to describe the extent to which a strategic incumbent distorts his first-period action away from his preferred action towards actions more favourable to voters (in good times), and the term screening to describe the possibility that voters can use the election as a tool to screen a benevolent incumbent from a strategic one, using the information they receive. 2\n\nAs is standard in two-period models of political agency, in all equilibria a strategic second period office-holder extracts all available resources, as he is devoid of reelection concerns. Interesting strategic considerations take place in the first period and affect the optimal strategy of a strategic incumbent. When the electorate is most informed , the equilibrium can be separating or pooling. In a separating equilibrium, a strategic incumbent extracts the entire windfall in good times. This equilibrium is characterised by full screening, conditional on the windfall being available in the first period, since a strategic incumbent is necessarily voted out. It is also characterised by no control, as a strategic incumbent extracts the entire windfall in the first period. In a pooling equilibrium, a strategic incumbent allocates the windfall uniformly to voters. This equilibrium is characterised by full control, as a strategic incumbent mimics a benevolent one, and no screening, as voters are unable to screen a strategic incumbent from a benevolent one.\n\nWhen the electorate is state informed or least informed , a new kind of equilibrium can emerge, which I call a fooling equilibrium. I characterise the conditions under which a fooling equilibrium exists and is essentially unique and in the rest of the paper assume that these conditions hold. 3 In a fooling equilibrium, only a fraction of voters are allocated by a strategic incumbent the same allocation that a benevolent incumbent would offer them. Provided that rent extraction is not revealed, this allows a strategic incumbent to be reelected even though he does not allocate the entire windfall to voters. This equilibrium is characterised by partial screening, since a strategic incumbent is not reelected if his rent extraction is detected. It is also characterised by partial control, since voters are allocated part of the windfall in the first period.\n\nI then rank these equilibria in terms of aggregate voters' welfare. This ranking depends on the strength of the different screening and control effects and the value of screening. The strength of screening\n\ncorresponds to the equilibrium probability of a benevolent second period office-holder, the strength of control corresponds to voters' ex-ante aggregate first period payoff, and the value of screening is the difference between voters' expected payoff from a benevolent second period office-holder and voters' expected payoff from a strategic one. I provide conditions under which the fooling equilibrium welfare dominates the pooling equilibrium or the separating equilibrium thereby showing that, when voters are homogeneously informed, less information can benefit them, through the interaction of both partial control and partial screening effects. 4\n\nThe structure of a fooling equilibrium is related to the concept of winning coalitions and the literature on 'divide-the-dollar' games in political economy (Cox and McCubbins, 1986; Myerson, 1993; Laslier and Picard, 2002; Roberson, 2008; Bierbrauer and Boyer, 2016). In contrast to political agency models featuring only moral hazard (e.g. Ferejohn, 1986; Zudenkova, 2018), voters do not set their reelection standards to try to be included in the coalition targeted by the incumbent office-holder. Instead, voters simply cast their votes for the politician who is the most likely to be benevolent, à la Fearon (1999). Since all voters are ex-ante identical, there is no incentive for a strategic incumbent to target any specific voter. Despite this homogeneity, information asymmetries and reputational concerns lead to ex-ante identical voters being treated differently by a strategic politician in a fooling equilibrium and ex-post heterogeneity in voter welfare. Higher or lower ex-ante aggregate welfare can hide improvements for some voters at the expense of the rest of the electorate.\n\nBuilding on these results, I next consider the case of heterogeneously informed electorates where some voters are more informed than others. This allows me to investigate additional questions: first, are more informed voters better off than less informed ones? Second, I can examine whether more information for some voters is good for the electorate as a whole, whether it is good for the more informed themselves, and whether it is good for the less informed.\n\nWhen communication is impossible, I first show that if the more informed voters are state informed , more informed voters and less informed voters can be treated identically by a strategic incumbent: both types of voters can be fooled, since neither observes the entire distribution. Thus, the difference in information between voters does not lead to systematic welfare differences. On the other hand, if more informed voters are most informed , their ex-ante average welfare is strictly lower than that of less informed voters, since they can't be fooled into voting for a strategic incumbent who shares only part of the windfall. This is a consequence of their informational advantage: less informed voters are a priority for a strategic incumbent seeking reelection, not more informed ones. Thus, in that particular setting, more information can harm the more informed voters and benefit the voters who do not have additional information.\n\nNext I consider a setting in which more informed voters can communicate with other voters. In\n\npractice, I assume that more informed voters can communicate verifiable information about what they observe to other voters (in the spirit of Milgrom and Roberts (1986); Milgrom (2008)). 5 In this case, the nature of the informational advantage matters. If they are state informed , their ex-ante average welfare is strictly higher than that of least informed voters, because they can be fooled and information disclosure is a threat: more informed voters are a priority, not less informed ones. For the same reasons, in this setting, having a few more informed voters can strictly worsen the ex-ante average welfare of the less informed and strictly increase the ex-ante average welfare of those who benefit from an informational advantage, compared to a setting in which they would not benefit from their informational advantage. If, on the other hand, more informed voters are most informed , their inability to commit to a communication strategy prevents any partial extraction of the windfall in equilibrium. The equilibrium is then either pooling or separating and the average ex-ante welfare of more and less informed voters are equal. In other words, a small group of most informed voters, whatever its size, and when able to communicate with less informed voters, leads to the same equilibrium that the polity would be in with a most informed electorate.\n\nImplications of the analysis. I then draw implications from my analysis of the case of heterogeneously informed electorates. First, I discuss the impossibility of collusion between more informed voters and politicians due to a commitment problem in communication strategies , a mechanism reminiscent of the commitment problem in voting strategies in Fearon (1999). I then explore the interactions between the ability to communicate, informational advantage, and relative welfare: when they can communicate, more informed voters are at least as well off as less informed voters. Discussing the implications of my analysis for information acquisition, I argue that this provides a novel rationale for strategic voter ignorance and a supply-side rationale for the existence of media outlets, linking my work to recent work on the political economy of media. I also discuss possible distributional consequences of informational campaigns. 6 Next, I relate my findings to the recent literature on the political economy of populism (Acemoglu, Egorov and Sonin, 2013; Guriev and Papaioannou, 2022), showing how a form of populism can emerge in the models and benefit the masses. Finally, I reconsider the issue of forming winning coalitions in the context of heterogeneously informed electorates.\n\nContributions. The contribution of this paper is threefold. First, I show how observing less information about policymaking can improve the welfare of a continuum of homogeneously informed voters in a political agency model with moral hazard and adverse selection, through the interaction of partial control effects and partial screening effects. In doing so, I provide a novel theory of coalition formation driven solely by information asymmetries between voters and politicians and politicians' reputational concerns. Second, considering a setting with both more and less informed voters, I\n\nidentify mechanisms that can make more informed voters better or worse off relative to less informed voters and show when this might can happen. Third, I show how an informational advantage for a few voters can affect the welfare of the electorate relative to a benchmark where these would be devoid of their informational advantage. For both these contributions, I emphasise the nature of these voters' informational advantage and their ability to communicate with less informed voters. In doing so, I extend my theory of coalition formation to include information asymmetries among voters, in addition to those between voters and politicians. For all three of these contributions, I relate my findings both to earlier work on political agency and, more broadly, to recent work in political economy.\n\n\n## 2 Literature review\n\n\nThis paper contributes to the political agency literature and in particular to the literature combining moral hazard and adverse selection (for early contributions, see Besley and Case (1995), Coate and Morris (1995), Banks and Sundaram (1998), and Fearon (1999); for overviews, see Besley (2006), Ashworth (2012), and Duggan and Martinelli (2017)). Besley and Smart (2007), Ashworth and Bueno de Mesquita (2014), Fox and Stephenson (2015), Wolton (2019), and Blumenthal (2023) are the closest: they provide conditions under which less information can benefit a representative voter while shedding light on many issues related to policymaking such as the role of interest groups, the influence of the media, fiscal restraints, the effect of non-binding law or the impact of ideology. A common mechanism underlies these results: making a representative voter less informed can shift the equilibrium from one characterised by either full control and no screening or no control and full screening to one characterised by partial screening, partial control, or both. If the partial screening effects, partial control effects, or both are sufficiently strong, being less informed is beneficial for the representative voter. By focusing on a distributive politics model with a continuum of voters rather than a framework with a representative voter, I derive additional implications of this mechanism on voters' welfare and equilibrium outcomes, both when voters are homogeneously informed and when voters are heterogeneously informed. Models with a representative voter are well suited to analysing settings in which voters are homogeneously informed and in which the actions of office-holders affect all voters uniformly, but may be poorly suited to cases in which voters can be differentially affected by politicians' actions, masking a significant heterogeneity in voters' outcomes.\n\nThis paper also contributes to the literature on distributive politics and pork-barrel spending. Focusing on the moral hazard problem in political agency models, Ferejohn (1986), Zudenkova (2018), and Foster and Warren (2023) study how voters or constituencies compete to benefit from targeted spending. Fearon (2006) and Fearon (2011), while focusing on how elections as coordination devices make democracy self-enforcing, feature models where a single politician decides what to allocate to multiple voters. Dixit and Londregan (1996) and Dixit and Londregan (1998) emphasise the role of ideology in allocating targeted spending to ideologically diverse electorates. Ali, Mihm and Siga (2023) show\n\nhow asymmetric information about a policy's distributive consequences can preclude it from being implemented, despite it being both ex-ante and ex-post optimal. Myerson (1993), Lizzeri and Persico (2001), and Genicot, Bouton and Castanheira (2021) consider the incentives for politicians to offer transfers to voters under different electoral systems. Gavazza and Lizzeri (2009) and Eguia and Nicolò (2019) build political competition models where voters have heterogeneous preferences to discuss how the transparency of spending affects office-motivated politicians' incentives to target spending to voters. Similarly, Maskin and Tirole (2019) discusses the effect of transparency of spending targets in a model where politicians have heterogeneous preferences towards different groups of voters. In my model, voters share the same preferences and politicians don't favour specific voters: differences in transfers received by voters can emerge simply from politicians' reputational concerns and information asymmetries.\n\nFinally, the paper contributes to the literature on information and transparency in policymaking. Prat (2005), Fox (2007), Fox and Van Weelden (2012), Fu and Li (2014), Prato and Wolton (2016), Prato and Wolton (2018), and Trombetta (2020) consider agency relationships between a principal and an agent and discuss the costs and benefits of transparency over actions. Since I consider a political agency model with multiple voters, a closely related paper is Lohmann (1998), which features heterogeneity in politicians' abilities and heterogeneously informed voters and shows how these, coupled with heterogeneous voter preferences, lead to benefits for more informed voters. Agranov, Eilat and Sonin (2023) studies the relationship between the size of an endogenously formed elite, the trust voters have in the elite's endorsement of a candidate, and inequality. Schipper and Woo (2019), Prummer (2020), and Titova (2024) study how micro-targeted messages , rather than transfers, can affect voters' voting behaviour. Here I focus on a political agency setting with distributive politics, consider politicians with heterogeneous preferences, introduce heterogeneity in the level of information voters have and do not consider heterogeneous preferences among voters or the endogenous formation of an elite. I derive a new set of results on both the gains and, importantly, the losses more informed voters can derive from their informational advantage. In addition, I derive results pertaining to the consequences of the existence of a more informed group of voters for the electorate as a whole.\n\n\n## 3 Baseline model\n\n\nThe baseline model focuses on a two-period interaction between an incumbent politician, a challenger and a continuum of voters of measure one. 7 In each period, an amount R may be available for the office-holder to allocate, depending on the realisation of a binary state of the world. Between the two periods an election with majority voting takes place, in which the incumbent faces the challenger.\n\nActions, preferences, timing, and informational structure. In each period t ∈ { 1, 2 , a state of the } world ω t is drawn by Nature from the set Ω = { 0, 1 , with } Pr ω ( t = 1 ) = η ∈ ( 0, 1 ) . I often refer to state ω = 1 as good times and to state ω = 0 as bad times, to reflect the availability of a windfall in either of these states of the world. The politician in office observes the availability of the windfall and has to allocate transfers to voters, under the condition that the total value of the transfers not be greater than the amount available to distribute: a (pure) strategy for a politician is a mapping Φ t : [ 0, 1 ] × { 0, 1 } → [ 0, ∞ ) such that:\n\n<!-- formula-not-decoded -->\n\nI denote by r the rents extracted by the politician. This is the difference between R and ∫ 1 0 Φ j dj t ( ) . I denote voter i 's utility (per period) by U Φ ( t ( )) i , where Φ i t ( ) denotes the allocation offered by the office-holder to voter i in period t . I assume that U ( ) . is a strictly concave, increasing, and continuous function and, without loss of generality, I normalise U ( 0 ) to 0. Nature draws politicians' types at the beginning of the game, with a prior probability that a politician is benevolent equal to π ∈ ( 0, 1 ) , and the same for both. With complementary probability, the politician is strategic. A politician's type is his private information. Benevolent politicians allocate the entire windfall uniformly to all voters when available (i.e. Φ i t ( ) = R for all i ), a behavioural strategy that maximises voters' instantaneous aggregate welfare. 8 Strategic politicians value the rents that can be extracted from the windfall. They also value holding office, which I denote by W .\n\nVoters can be in one of three possible information structures. In the first one, voters are fully informed about the policymaking process: they observe their individual allocation Φ i t ( ) , the state of the world ω t , and the distribution of allocations in the economy Φ t ( ) . . I call voters in that case most informed . In the second informational structure, voters observe both ω t and Φ i t ( ) , but not Φ t ( ) . . I call voters in that case state informed . In the last informational structure, voters observe Φ i t ( ) , but not ω t and Φ t ( ) . . I call voters in that case least informed . Politicians know in which information structure the voters are, as do voters. 9 To complement these informational structures, I assume that there is an endogenous probability of detection of rent extraction denoted ρ r ( ) , which is strictly increasing in r . I make a number of technical assumptions on the shape of the function in order to streamline the exposition. I assume that ρ ( 0 ) = ρ ′ ( 0 ) = 0; that ρ R ( ) = 1; and that ρ ( ) . is strictly convex and twice continuously differentiable on [ 0, R ] . 10 Voters update their beliefs based on the information they observe and vote sincerely, between the two periods, for the challenger or the incumbent.\n\nFinally, I make a number of further assumptions for the sake of a clearer exposition: if voters are\n\nindifferent between the incumbent and the challenger, they vote for the incumbent; if exactly half the electorate votes for the incumbent, the incumbent is reelected; 11 the probability distribution for the state of the world is the same in both periods; 12 finally, I assume that players value the present and the future equally i.e. I abstract from discounting. 13\n\nEquilibrium concept. Mysolution concept is pure strategy Perfect Bayesian Equilibrium (equilibrium henceforth). To solve for an equilibrium I have to specify actions for strategic politicians and voters' strategies and beliefs. A strategies-beliefs pair is an equilibrium if (1) strategic politicians' strategies maximise their expected payoffs given benevolent politicians' behavioural strategy and voters' equilibrium strategies, (2) for each observation of the incumbent's action, the voters' posterior beliefs that he is benevolent are derived via Bayes' Rule when possible, and (3) voters' voting strategies are optimal given their beliefs and the equilibrium strategies of politicians.\n\nThe multiplicity of equilibria that often plagues political agency models can be problematic for some parameter values. I impose a selection criterion that guarantees the (generic) uniqueness of the equilibrium when needed: if there are multiple equilibria, I select the equilibrium or equilibria that guarantees the highest expected vote share to a strategic incumbent. It could easily be micro-founded by considering voters who have a small probability of making a mistake in the voting booth: an incumbent politician could then increase his likelihood of reelection by forming a larger coalition of potential supporters.\n\nModelling assumptions. The windfall can most easily be seen as an amount of money that the office-holder can allocate (e.g. Ferejohn, 1986; Zudenkova, 2018). It can also be interpreted as resources available to an office-holder to spend on constituency services or on policy work when voters have policy preferences that are such that the advancement of the policy preferred by a voter does not affect the welfare of other voters (in a related context, but with a representative voter, Ashworth (2005) adopt these interpretations). Similarly, the assumption that the amount of the windfall extracted by strategic politicians positively affects their payoffs can be interpreted in several ways. The most literal is to assume that the rents extracted go directly in the strategic politicians' pockets, or that they use these resources to further their own interests (Finan and Mazzocco, 2021). However, less literal interpretations may also fit: extracted rents may represent transfers to special interests aligned with them or resources spent to further the goals of these special interests, or could be reinterpreted as targeted transfers towards some voters aligned with them or towards the interests of these aligned voters, at the cost of a slight rewrite of the model, to account for the changes in the voting patterns\n\n## that would follow. 14\n\nAnumber of the papers I discuss in the literature review also contrast the cases of voters who can only observe their own allocation and of voters who can observe the entire distribution of allocations, such as Fearon (2006), Gavazza and Lizzeri (2009), Eguia and Nicolò (2019) or Maskin and Tirole (2019). These two alternatives relate to the complexity of the office-holder's allocation decision: depending on the complexity of the procedure by which benefits are allocated to voters, the assumption that every voter observes the allocations received by other voters can be more or less plausible. In contrast, the observability of a state that determines the availability of a windfall is, to the best of my knowledge, an innovation on the past literature. Zudenkova (2018) and other papers in the \"divide-the-dollar\" literature similarly consider a resource of fixed value that an office-holder gets to allocate, but assume that the resource is always available. Fearon (2011) considers a setting in which a common random shock can affect citizens' payoffs, but assumes that neither citizens nor the politician observe its realisation. I partly follow his approach by interpreting the state of the world ω = 0 as \"bad times\" for the society that occur for idiosyncratic reasons. Thus, to assume that voters observe the state of the world is to assume that they pay some attention to aggregate conditions affecting society, in addition to the attention they pay to their own fate.\n\nThere are two dimensions to the decision to include an endogenous probability of detection of rent extraction in the model: first, I assume that there is some process, not explicitly modelled, through which politicians' actions are monitored. I interpret it as a form of accountability journalism or judicial oversight that can detect and report to the public the misbehaviour of the politician. This could, for example, take the form of a news story with evidence of improper actions by the officeholder. Such a process has been included in other models of political accountability, such as Besley and Smart (2007), Avis, Ferraz and Finan (2018) or Blumenthal (2023) (Avis, Ferraz and Finan (2018) provides evidence in support of the empirical relevance of this parameter). Second, I assume that this probability of detection increases with the amount of rents extracted, up to the point where detection becomes certain. The purpose of this assumption is to represent in a very flexible way the idea that a politician who diverts a single penny is less likely to get caught than a politician who diverts millions. This increasing probability of detection plays an important role in the results derived below, as it allows for partial screening in equilibrium, rather than full or no screening.\n\n\n## 3.1 Equilibrium characterisation and welfare analysis\n\n\nA second period strategic office-holder diverts R whenever he can, since he has no reputational concerns. I summarise this as follows:\n\nLemma 1. In equilibrium a strategic second period office-holder extracts R in good times.\n\nGiven Lemma 1, voters vote for the incumbent if and only if their posterior belief on the likelihood that the incumbent is benevolent is at least as high as their prior belief on the likelihood that the challenger is benevolent. Thus an incumbent is reelected if and only if at least half of voters have a high enough posterior belief on the likelihood that he is benevolent. I summarise this as follows:\n\nLemma 2. An incumbent is reelected if and only if half of the voters have a posterior belief of the likelihood that he is benevolent that is greater than or equal to the prior probability that a challenger is benevolent.\n\nObserve that the strategic second period office-holders' equilibrium strategy, the voters' reelection rule, and the conditions under which the incumbent is reelected do not depend on whether voters are most informed , state informed or least informed . Next, consider the first period when voters are most informed .\n\nProposition 1. Suppose voters are most informed. In the essentially unique equilibrium, a strategic incumbent in good times:\n\n- 1. Allocates R uniformly to all voters if W &gt; ( 1 -η R ) , a pooling equilibrium.\n- 2. Extracts R if W &lt; ( 1 -η R ) , a separating equilibrium. 15\n\nVoters, being most informed , can infer from any non-uniform allocation of the entire windfall in good times that the incumbent is strategic. Moreover, of all the strategies in which a strategic incumbent extracts a positive amount of the windfall, the best for him is to extract the entire windfall, as he is then not reelected but maximises his first period payoff. There are then only two relevant strategies to consider. Full allocation ensures his reelection for the subsequent period, with office-rents and the opportunity to appropriate the windfall in the good state, ensuring an expected payoff of W + ηR . Full extraction ensures that he is not reelected, but allows him to extract the entire windfall in the first period, instead of allocating it entirely to voters, ensuring a payoff of R .\n\nLet me now consider the case of state informed and least informed voters. Note first that since voters don't share the same information ex-post , their posterior beliefs about the incumbent's type can differ: a strategic incumbent can target only a subset of voters, extract a positive amount of the windfall in the first period, and still be reelected - which is impossible when voters are all most informed . He has to balance two opposing effects: on the one hand, extracting more rents in the first period benefits him in the first period. On the other hand, it increases the likelihood that the rent extraction is revealed, ensuring that voters are able to correctly identify him as strategic and not reelect him, thereby reducing his second period expected payoff. Finally, he must earn the support of at least half of the voters to be reelected (Lemma 2). These observations provide the intuitions underlying the existence of a new type of equilibrium, a fooling equilibrium, which differs from the pooling and separating equilibria of\n\nProposition 1. In a fooling equilibrium, a strategic incumbent allocates R uniformly only to a subset of voters in good times, rather than to all voters (as in a pooling equilibrium) or to none of them (as in a separating equilibrium). He also extracts some of the windfall, instead of none of it (as in a pooling equilibrium) or all of it (as in a separating equilibrium). I next introduce three new pieces of notation that will be essential for the formulation of the following proposition:\n\n<!-- formula-not-decoded -->\n\nIn words, r ∗ is the optimal level of partial rent extraction, i.e. the payoff-maximising amount of rent extraction for the strategic incumbent, provided that he extracts less than R . The last two pieces of notation in the definition are here simply to simplify the expression of the result. The following proposition formally characterises a fooling equilibrium when voters are homogeneously state informed or least informed , and provides conditions under which it is the essentially unique equilibrium. 16 In the rest of this section, I assume that these conditions hold.\n\nProposition 2. In a fooling equilibrium with homogeneously informed voters, a strategic incumbent, in good times, allocates R uniformly to a share κ ∗ of voters and 0 to a share 1 -κ ∗ of voters. If voters are not most informed, a fooling equilibrium exists and is essentially unique:\n\n- 1. When voters are state informed and W &gt; Λ R ( ) , or\n- 2. When voters are least informed and W &gt; Λ r ( ) ∀ r ∈ ( R 2 , R ] ,\n\nWhen voters are state informed , they always reelect the incumbent in bad times. In the absence of any additional information about his type, they can't update their beliefs and so vote to reelect him. In good times, the reelection of the incumbent depends on the equilibrium strategy of a strategic incumbent and the information voters can extract from it. If the value from holding office is high enough, the equilibrium is necessarily fooling: a strategic incumbent shares part of the windfall uniformly to a subset of voters and he is reelected, provided that his rent extraction is not revealed. Targeted voters' posterior beliefs about the likelihood that the incumbent is strategic, when rent extraction is not revealed, are strictly higher than their prior belief: indeed, since in a fooling equilibrium a strategic incumbent has a positive probability of being detected because of his rent extraction, conditional on not observing such a detection, targeted voters update positively their beliefs about the incumbent and vote to reelect him. A strategic incumbent must strike the right balance between gambling on his reelection, at the cost of spending some of the windfall to fool voters and at the risk of not being reelected if his rent extraction is revealed, or take all the available windfall right away and abandon the possibility of reelection. A fooling equilibrium exists and is essentially unique when the expected payoff from such a gamble is sufficiently high.\n\nWhen voters are least informed , an additional issue arises: as voters don't observe the state of the world, they can't infer with certainty that the politician is strategic upon observing no allocation. Indeed, it could be that times are bad and that the incumbent, despite being benevolent, couldn't allocate anything because the windfall was unavailable. This leads to stricter conditions for the existence of a fooling equilibrium, compared to the case of state informed voters. To see why, observe that, in a fooling equilibrium, incumbents are always reelected in bad times: voters who would have been targeted in equilibrium in good times keep their prior belief on the likelihood that the incumbent is benevolent, which is sufficient to ensure the reelection of the incumbent. I must now account for the possibility of deviations by a strategic incumbent to all levels of rent extraction that are different from the equilibrium level of partial rent extraction, and not just the possibility of deviations to full extraction of the windfall in good times, which gives the condition on W and Λ r ( ) in Proposition 2. Provided that this condition holds, the essentially unique equilibrium is fooling.\n\nWelfare analysis. I now compare the welfare of voters when they are most informed , state informed , and least informed . To do this, I use voters' ex-ante aggregate welfare - voters' expected aggregate welfare before the incumbent and challenger types are realised and before any action is chosen - as a measure of voters' welfare. I use this metric because all voters are ex-ante identical. The differences in welfare between equilibria arise from differences in both a strategic incumbent's equilibrium strategy and in the information available to voters for their reelection decision. The following proposition provides conditions under which voters are better off being state informed or least informed rather than most informed .\n\nProposition 3. 1. If W &gt; ( 1 -η R ) and κ ∗ + ρ r ( ∗ ) × π × η &gt; 1 , voters are better off when state or least informed than when most informed.\n\n- 2. If W &lt; ( 1 -η R ) and κ ∗ + ( ρ r ∗ ) × π × η &gt; η × π , voters are better off when state or least informed than when most informed.\n\nVoters' ex-ante aggregate welfare in the different equilibria can be decomposed into three components, representing the level of control, the level of screening, and the value of screening. The level of control can be obtained by computing voters' expected first period welfare; the level of screening can be obtained by computing the ex-ante probability of a benevolent second period office-holder; and the value of screening can be obtained by computing the difference between voters' second period welfare under a benevolent office-holder and under a strategic office-holder.\n\nThere is full control in a pooling equilibrium, since a strategic incumbent mimics a benevolent incumbent and allocates R uniformly to all voters in good times; partial control in a fooling equilibrium, since only a fraction κ ∗ ∈ [ 1 2 , 1 ) of voters are allocated R by a strategic incumbent in good times; and no control in a separating equilibrium, since a strategic incumbent extracts R in good times. There is no screening in a pooling equilibrium, since voters gain no information on the equilibrium path, and a strategic incumbent is necessarily reelected; there is partial screening in a fooling equilibrium,\n\nconditional on a good state of the world, since the rent extraction of the strategic incumbent can be detected and his type revealed; there is full screening in a separating equilibrium, conditional on a good state of the world, since more than half of voters infer a strategic incumbent's type from their allocations. Finally, the value of screening is equal to η × U R ( ) in all three equilibria, since benevolent politicians are a behavioural type and strategic politicians are devoid of reputational concerns in the second period.\n\nUnder the appropriate conditions, the fooling equilibrium welfare dominates the separating equilibrium, the pooling equilibrium, or both. This happens when the strength of the partial control and partial screening effects in the fooling equilibrium are sufficiently high, compared to voters' ex-ante welfare in a pooling equilibrium or in a separating equilibrium. This shows how and when more information for all voters may harm them: given that a change in the informational structure can affect the equilibrium strategy of a strategic incumbent, whether such a change is valuable for voters depends on the welfare ranking of the different equilibria, as derived in Proposition 3. 17\n\n\n## 3.2 Discussion\n\n\nFooling equilibrium and winning coalitions. The structure of a fooling equilibrium is related to winning coalitions and to the literature studying winning coalitions in political agency models. In contrast with papers in that literature that feature only moral hazard (e.g. Ferejohn, 1986; Zudenkova, 2018; Foster and Warren, 2023), voters do not set their reelection rules to try to be included in the coalition targeted by the incumbent office-holder. Facing an adverse selection problem, and because of the two-period structure, voters' reelection rule is simply to vote for the politician who is the most likely to be benevolent (Fearon, 1999). Thus there is no competition between voters to be included in the coalition. Moreover, since all voters are ex-ante identical, there are no specific incentives for a strategic incumbent to include a particular voter over another one in his winning coalition. 18\n\nDespite this homogeneity, voters are not all treated identically in a fooling equilibrium, in contrast to the cases of separating and pooling equilibria. In a fooling equilibrium, an endogenous coalition of fooled voters emerges, i.e. voters who are allocated the same amount a benevolent incumbent would allocate them, even though a strategic incumbent extracts rents. The strategic incumbent seeks to balance his need for a minimum number of votes to be re-elected at the lowest cost and the risk of being exposed for rent extraction, which increases with rent extraction. A strategic incumbent will\n\ntarget anywhere from half of the electorate to almost all of the electorate, depending on the likelihood of being caught extracting rents. Thus I show how politicians can create inequalities among otherwise homogeneous voters by favouring some groups rather than appealing equally to all voters. My results are in the vein of Myerson (1993) or Lizzeri (1999), with some major differences: whereas these papers and others in the \"divide-the-dollar\" literature in political economy study models of political competition, I analyse a model of political agency. The driving forces for my results are thus not voters' competing demands and the horse race between candidates but rather reputational incentives for politicians and informational asymmetries between voters and politicians.\n\nInequality and aggregate welfare. The inequality of treatment among voters in a fooling equilibrium has subtle implications for the conclusions one can draw from the results of Proposition 3. Indeed, beyond the aggregate welfare level changes, there are differences in the fate of different groups of voters when, depending on voters level of information, the equilibrium moves from being separating or pooling to a fooling one. Consider for instance the case in which, with most informed voters, the equilibrium is pooling and in which the equilibrium is fooling when voters are state or least informed . In that case, the voters who are targeted in a fooling equilibrium get the same level of targeting in the first period as in the pooling equilibrium, and additionally get the benefit of partial screening, whereas they didn't have any under a pooling equilibrium. By contrast, non-targeted voters get a strictly lower level of targeting (they move from R to 0) and benefit from a strictly higher level of screening, which is not enough to compensate their first period loss. Aggregate level outcomes, while clearly informative, can thus mask a significant heterogeneity in voters' outcomes, a topic which I further explore in the following section in the case of heterogeneously informed electorates.\n\n\n## 4 Heterogeneously informed electorates\n\n\nIn the previous section, I considered a model in which voters shared the same information structure: voters could have different beliefs ex-post , but were homogeneously informed. I could not therefore investigate whether welfare differences between voters could arise from differences in their level of information or the nature of these welfare differences, if they existed. I use the results derived in that case for the exposition and the derivation of the results in this section, in which I consider models with heterogeneously informed electorates to study how the informational advantage of a few voters over other voters affects the welfare of the more informed compared to the welfare of the less informed. Are more informed voters better off compared to less informed ones? I also explore how the welfare of all voters is affected by the existence of this informational advantage for a few voters, compared to a benchmark where these would not have an informational advantage. Is more information for some voters good for the electorate as a whole? Is it good for the more informed themselves? Is it good for the less informed?\n\nFormally, I assume that a fraction λ ∈ ( 0, 1 2 ) of voters is strictly more informed than the rest of the electorate. I study three different cases, following the distinction established in the previous section: the case of a few most informed voters and a majority of state informed voters; the case of a few most informed voters and a majority of least informed voters; and finally, the case of a few state informed voters and a majority of least informed voters. Adapting my assumption from the previous section, I assume in this section that, had all voters been less informed, the equilibrium would be fooling. That is, when the majority of voters are state informed , I assume that W &gt; Λ R ( ) . When the majority of voters are least informed , I assume that W &gt; Λ r ( ) ∀ r ∈ ( 1 2 , R ] .\n\nModelling assumptions. I consider the case in which a few voters have an informational advantage over the majority of voters. There are two important dimensions to this modelling strategy. First, I consider only two groups that differ in their level of information. This is done for two main reasons: it is the simplest way to introduce heterogeneity in the level of information that is relevant to the policymaking process into the model and it makes the comparison across groups straightforward, as there are only pairs of quantities to compare. Note, however, that because of the discrete nature of the set of possible information structures, it is straightforward to generalise the results to the case of three groups of voters, with a majority of voters benefiting from the lowest level of information. Second, I assume that the smallest of the two groups is the one that benefits from an informational advantage. I consider this case, rather than the reverse, since it is the most realistic setting. Indeed, scholars have previously shown that most voters are poorly informed but that some voters, sometimes called 'watchdog voters', are more informed. 19\n\nExtending the assumption made above that information structures are common knowledge with homogeneously informed voters, I assume in the following that information structures are also common knowledge for heterogeneously informed voters. 20 This assumption has two important implications: first, politicians know which voter is observing what, which allows them to target specific voters depending on their information. As I show below in Proposition 4 and Proposition 5, this has important implications for the identity of the voters that a strategic incumbent includes in his winning coalition. Second, voters also know which voters observe what. While this is not consequential in either the no-communication or the communication model, given my focus on verifiable communication in the latter, 21 it also implies that less informed voters know that wellidentified voters can provide them with some information that they might subsequently use in their voting decisions. 22\n\n\n## 4.1 Amodel without communication\n\n\nIn this subsection, I consider a model where voters can't communicate. In particular, and in contrast with the subsequent subsection, more informed voters can't communicate with less informed voters. Thus, the only novelty with respect to the model from the previous section is the existence of heterogeneity in voters' level of information: the timing is identical, as are the actions available to voters and politicians and their preferences. To ease the exposition of the results, I first consider the case of a few state informed voters in Observation 1, leaving the case of a few most informed voters for Proposition 4.\n\nFirst, note that, as stated above, strategic second period office-holders' equilibrium strategy, voters' reelection rule, and the conditions under which the incumbent is reelected do not depend on the voters' level of information. Previously, this meant that these were identical whether voters were homogeneously most informed , state informed or least informed . In the present case, this means that they are identical regardless of whether I consider a few most informed voters and a majority of state informed voters, a few most informed voters and a majority of least informed voters, or a few state informed voters and a majority of least informed voters, the reasoning behind these results being the same. Thus, I only need to consider the first period equilibrium strategy of a strategic incumbent. Regarding the case of a few state informed voters, the following holds:\n\nObservation 1. If more informed voters are state informed and can't communicate with less informed voters, all voters are equivalent for a strategic incumbent.\n\nWhen the more informed voters are state informed and less informed voters are least informed , a strategic incumbent can target the more informed voters and expect them to vote for him in the election provided that rent extraction is not revealed. He can also not target them, without any adverse consequences. This is because they don't observe the entire distribution of allocations in the economy, but only their own individual allocations and the state of the world, and can't communicate with less informed voters. The nature of the equilibrium is thus unaffected compared to a setting with a population of homogeneously least informed voters, which would be fooling here, by assumption. There are no direct nor indirect consequences of the informational differences on the equilibrium average ex-ante welfare of members of both groups: the informational advantage of the former does not translate in welfare differences with the latter, and vice-versa for the informational disadvantage of the latter. Importantly, note that this does not imply that the average ex-ante welfare of both groups are equal in equilibrium. Depending on the identity of those targeted by a strategic incumbent in good times in equilibrium, the average ex-ante welfare of the few more informed voters can be equal to, strictly greater than, or strictly lower than, the average ex-ante welfare of the less informed voters.\n\nThe following proposition considers the case of a a few most informed voters and a majority of either state informed or least informed voters. I focus on two main questions: are more informed voters better off than less informed voters? How does the informational advantage of a few voters affect the welfare of voters?\n\nProposition 4. If more informed voters are most informed and can't communicate with less informed voters:\n\n- 1. Less informed voters' average ex-ante welfare is strictly higher than more informed voters' average ex-ante welfare.\n- 2. Compared to a benchmark where all voters would be homogeneously less informed, more informed voters' informational advantage weakly benefits less informed voters.\n\nWhen a few voters are most informed and the majority of voters are either least informed or state informed , voters' susceptibility to being fooled into voting for a strategic incumbent who does not share entirely the windfall plays a crucial role. Since more informed voters are most informed , they infer that the incumbent is strategic whenever there is some partial rent extraction because they observe the distribution of allocations in the economy. In any candidate equilibrium in which a strategic incumbent does not allocate all of the windfall to voters, most informed voters do not vote for the incumbent. Therefore a strategic incumbent will give priority to the less informed voters who can vote for him in equilibrium. Thus, most informed voters' average ex-ante welfare is strictly lower than less informed voters' average ex-ante welfare, given that the equilibrium is fooling. 23 Most informed voters' inability to be fooled, stemming from their informational advantage, harms them.\n\nLet's now consider how voters' welfare is affected by the existence of the informational advantage of a few most informed voters when communication between voters is impossible, compared to an environment in which they would not benefit from it. Note first that the amount of rent extraction in equilibrium by a strategic incumbent with a few most informed voters is the same as what it would have been under a homogeneously state informed or least informed electorate: the existence of an informational advantage for a few most informed voters does not affect the nature of the equilibrium. However, more informed voters' informational advantage can affect the distribution of targeted spending in the first period by a strategic incumbent. In particular, it can lead to a reallocation of targeting, away from (newly) most informed voters, since they can't be fooled. Compared to a case where more informed voters would be devoid of their informational advantage, less informed voters' average ex-ante welfare can increase, because they become a priority for a strategic incumbent, whereas all voters are equivalent for a strategic incumbent when they all share the same level of information.\n\nThere is a crucial substantive difference between the mechanism through which more informed voters are made worse off here and the mechanism behind Proposition 3 or those from various other political agency papers which show how transparency can be a curse for voters. 24 Traditionally, these papers have considered a single representative voter and studied how the level of information the voter\n\nbenefits from affect the extent to which politicians might engage in undesirable behaviour in the present (e.g. pandering, posturing...), harming the voter's ability to obtain their preferred outcome today and their ability to screen out politicians with bad traits for tomorrow, by affecting the nature of the equilibrium. The idea here is different: I'm looking at groups of voters whose level of information differ, instead of studying aggregate level changes in voter information. I show how, when voters differ in their information, the more informed can be harmed by being too informed, since that makes them a lost cause for a strategic incumbent seeking reelection while extracting rents. Importantly, and in sharp contrast with Proposition 3 or most of the papers mentioned in footnote 24, there is no shift in equilibrium: the effect is only through the incentives of a strategic incumbent to target less informed voters rather than more informed ones. 25\n\n\n## 4.2 Amodel with communication\n\n\nIn this subsection, I assume that the few more informed voters can communicate costlessly with less informed voters by means of verifiable information. The timing of the game is adapted accordingly: before the election, but after the incumbent's allocation decision, more informed voters have the opportunity to communicate some information to less informed voters. I consider a specific type of communication: each more informed voter can report evidence of rent extraction by the incumbent politician or lack thereof to less informed voters: for instance, if a more informed voter observes that the state of the world is good and that she was allocated an amount different from R , she can share this information to less informed voters who then know that the incumbent is strategic. To ease the exposition of the results, I first consider the case of a few state informed voters in Proposition 5, leaving the case of a few most informed voters for Proposition 6.\n\nModelling assumptions. There are two main dimensions to the assumption I make about the communication stage in this subsection. First, I assume that only more informed voters can communicate with less informed voters (and not the reverse). This serves two purposes: to emphasise the relationship that can exist between an informational advantage and the ability to communicate and to reflect the assumption of a large electorate, in which only a subset of voters can reach others, for instance through access to media organisations or ownership thereof. Moreover, I assume that the information communicated is verifiable. There are therefore no problems of trust between voters. This assumption simplifies the analysis of the communication game between more and less informed voters: I don't need to take into account the beliefs of less informed voters about the truthfulness of the messages they receive. However, doing so is without much loss of generality. Indeed, the interests of all voters are aligned at the stage where more informed voters get to communicate: they only care about choosing the politician who is most likely to be benevolent between the incumbent and the challenger. Thus, even if communication were cheap talk and the communication stage were adjusted\n\naccordingly, there would be an informative equilibrium in which the reports of the more informed voters would be believed by the less informed voters and identical results would hold.\n\nAs in the previous subsection, the results of Lemma 1 and Lemma 2 both still hold in the new setting. Since I consider a setting with strategic communication, I now have to not only study the equilibrium strategy of a strategic incumbent in the first period but also the equilibrium communication strategy of more informed voters, along with the less informed voters' beliefs about it. The following proposition considers the case of a few state informed voters and a majority of least informed voters. As in Proposition 4, I focus on two main questions: are more informed voters better off than less informed voters? How does the informational advantage of a few voters affect the welfare of voters?\n\nProposition 5. If more informed voters are state informed and can communicate costlessly with less informed voters:\n\n- 1. More informed voters' average ex-ante welfare is strictly higher than less informed voters' average ex-ante welfare.\n- 2. Compared to a benchmark where all voters would be homogeneously less informed, more informed voters' informational advantage:\n- (a) Doesn't affect voters' ex-ante aggregate welfare.\n- (b) Weakly benefits more informed voters.\n- (c) Weakly harms less informed voters.\n\nWhen more informed voters are state informed and less informed voters are least informed , state informed voters can be fooled into voting for a strategic incumbent who does not share the entire windfall with voters, since they do not observe the entire allocation in the economy, but only their own individual allocations and the state of the world. In addition, more informed voters' ability to communicate with less informed voters plays a crucial role: because of it, more informed voters are necessarily part of the subset of voters to whom a strategic incumbent allocates part of the windfall in a fooling equilibrium. If they were left out, a strategic incumbent could not be reelected while extracting rents, since state informed voters would then reveal to less informed voters the rent extraction. Thus, state informed voters' average ex-ante welfare is strictly higher than least informed voters' average ex-ante welfare. 26 Note an important subtlety here: the advantage of the state informed voters does not come from collusion between them and a strategic incumbent, with the latter buying the former off. Instead, a strategic incumbent simply ensures that state informed voters do not observe anything that could allow them to prevent his reelection when he extracts rents in the first period. There is neither an explicit nor an implicit quid-pro-quo. 27\n\nSince state informed voters are necessarily part of the subset of voters targeted by a strategic incumbent, their average ex-ante welfare is at worst equal to, and at best strictly higher than, what it would have been in a benchmark under which they would be least informed instead of state informed . To see why, recall that the identity of the voters targeted by a strategic incumbent in equilibrium with a homogeneously informed electorate in a fooling equilibrium is not pinned down. In the worstcase scenario, thus, in a hypothetical setting in which these voters would not benefit from their informational advantage, they either wouldn't be part of the subset of voters who are targeted by a strategic incumbent in equilibrium, or only a minimal fraction of them would be part of the subset of fooled voters. The flip side of this result is that the reverse is true for the least informed : the existence of the informational advantage for these few voters can strictly worsen the ex-ante welfare of less informed voters, compared to a setting where these few state informed voters would be devoid of its informational advantage. Finally, note that in any case, voters' aggregate ex-ante welfare is the same with or without this few voters' informational advantage coupled with their ability to communicate.\n\nThe next proposition completes the analysis of this second part of the paper by considering the case of a few most informed voters and a majority of state informed or least informed voters when more informed voters can communicate with less informed voters. As in Proposition 4 and Proposition 5, I focus on two main questions: are more informed voters better off compared to less informed voters? How does the informational advantage of a few voters affect the welfare of voters?\n\nProposition 6. If more informed voters are most informed and can communicate costlessly with less informed voters, the equilibrium is the same as with a homogeneously most informed electorate: the average welfare of more informed voters and less informed voters are equal.\n\nWhen a few voters are most informed , any level of partial rent extraction allows them to report a discrepancy between what voters receive and what they should receive. Thus there is no partial rent extraction in equilibrium, which means that the equilibrium is never fooling. Indeed, after the incumbent's first period allocation, most informed voters have a clear incentive not only to vote for the challenger if they observe partial rent extraction, but also to communicate to other voters that the incumbent is strategic and thus shouldn't be reelected. This follows from a commitment problem on their part. They can't commit vis-à-vis a strategic incumbent not to reveal his type to other voters, given that they strictly prefer an untested challenger to a known strategic incumbent. This result is related to the Fearon critique (Fearon, 1999), 28 as the screening concern for the final period prevents the existence of equilibria with partial control in the first period, even when such partial control would be desirable for more informed voters.\n\nGiven that the equilibrium is either pooling or separating, the average ex-ante welfare of both more informed voters and less informed voters are equal. Whether this is good or bad for voters at the\n\naggregate level, compared to a benchmark where more informed voters would be devoid of their informational advantage, depends on the ranking established in Proposition 3. There is a crucial substantive difference between the set-up in the first part of the paper, which focused on aggregate level changes in the level of information of voters, 29 and the analysis here, which focuses on groups of voters which differ in their level of information and on the ability of more informed voters to communicate with the less informed. An informed elite, provided that they observe the right information and can communicate it, can keep ensure that politicians behave in the same way they would have had all voters been as informed as them. The contrast here with the results of Proposition 4 is illuminating: when they are able to communicate, a sufficiently well-informed elite can shift the nature of the equilibrium the polity is in.\n\n\n## 5 Discussion\n\n\nCollusion and lack of commitment power. Like homogeneously informed electorates, heterogeneously informed voters prefer higher levels of control and higher levels of screening. Consider the preferences of more and less informed voters: in the first period they are better off when a strategic incumbent targets them. In particular, they are better off if they are allocated by a strategic incumbent in a fooling equilibrium the same amount a benevolent incumbent would allocate them. For the second period, they want to screen out strategic incumbents to increase their likelihood of receiving some of the windfall when it is available, which is only the case with a benevolent second period office-holder. Thus, the objectives of more informed and less informed voters are in conflict in the first period, but aligned in the second period. It is not a priori clear how these conflicting objectives interact with one another. In particular, might collusion between more informed voters and a strategic incumbent be sustained in equilibrium, thereby giving pre-eminence to the distributive conflict in the first period over the common interest of voters in the second period? 30\n\nI show that such collusion is not sustainable in equilibrium. When communication is impossible, it follows from a standard argument in the literature (Fearon, 1999) that most informed voters can't sustain collusive behaviour, because they can't commit to voting strategies. 31 When communication is possible, a new commitment problem appears: more informed voters can't commit to communication strategies, in addition to their inability to commit to voting strategies. In particular, when a few voters are most informed , it is the inability of most informed voters to commit to a communication strategy that, alone, prevents the existence of collusion in equilibrium. Put differently, since more informed voters have a strict incentive to reveal a strategic incumbent's type whenever they observe partial rent\n\nextraction in the first period, they can't be bought. If they were to observe partial rent extraction, even with larger transfers from the windfall to them, they would prevent others from voting for him, in addition to not voting for him, thereby preventing his reelection.\n\nInformation, communication, and relative welfare. There may be important interactions between the informational advantage of some voters, their ability to communicate their additional information to the rest of the electorate, and differences in welfare between more informed voters and less informed voters. In particular, I show that in the models I consider here, more informed voters are at least as well off as less informed voters if they can communicate with them (Proposition 5 and Proposition 6), and possibly better off (Proposition 5), unlike when communication is impossible (Proposition 4). This is because, in equilibrium, differences in welfare between voters can only arise from differences in allocations in the first period by a strategic incumbent in good times. Indeed, in any equilibrium, the average ex-ante welfare of more and less informed voters in the second period are always equal, since it depends only on the type of incumbent in the second period and whether the windfall is available or not. Thus, in order to be worse off than less informed voters, more informed voters must, on average, be less targeted by a strategic incumbent in the first period. But if this were the case, some of the more informed voters might pass on their knowledge that the politician is a strategic type to the less informed voters - ensuring that this scenario can't hold in equilibrium.\n\nInformation acquisition. Since I assume in the models that information structures are given exogenously, a natural question that follows from the analysis is: what incentives might voters have to become more informed about policymaking? While I do not attempt to provide a formal investigation of this question in the context of this paper, a number of implications nonetheless follow from my analysis. 32 First, my results suggest a novel rationale for strategic voter ignorance: by remaining ignorant about policymaking outcomes (at the aggregate level), voters can make themselves more attractive targets for politicians seeking reelection (Proposition 4). Next, the mechanism described in the paragraph above suggests a supply-side rationale for media ownership by certain groups of citizens: 33 the control of a media outlet that truthfully discloses information may in itself be sufficient to improve the fortunes of the outlet's owners by making them a necessary target of politicians' largesse. 34\n\nIn contrast, the case of most informed voters who can't communicate is prima facie more puzzling: these people are worse off because they are better informed. Explaining why voters would rationally acquire information that makes them worse off is difficult strictly within the framework used in this paper.\n\nGoing a little further, however, there may be a number of simple explanations for such a phenomenon: voters may value information about policymaking intrinsically and wish to base their vote on the best information available; 35,36 alternatively, the information they acquire may be a by-product of their occupation or consumption patterns (Prat and Strömberg, 2005; Gentzkow, 2006; Prior, 2007; Hobbs and Roberts, 2018; Angelucci and Prat, 2024).\n\nInformation and populism. Myfindings also relate to a recent literature on voter trust in institutions such as the media or experts and its link to the political economy of populism (e.g. Guriev and Papaioannou, 2022; Agranov, Eilat and Sonin, 2023; Crutzen, Sisak and Swank, 2024). These papers discuss how information can be transmitted by more informed actors (e.g. the media, Elites...) to less informed groups. This information can be about the state of the economy and the impact of possible policies (Crutzen, Sisak and Swank, 2024), politicians' competence (Agranov, Eilat and Sonin, 2023), or politicians' character (Chakraborty and Ghosh, 2016). Implicitly or explicitly, these papers assume that, all else equal, benefiting from more information transmission about these various aspects would benefit voters: if voters could receive unbiased information by trusted sources, they would be better off. These models thus suggest that not trusting unbiased messages would be harmful to voters. My model suggest otherwise: the results of Proposition 4 imply that the impossibility of information transmission can be beneficial to informationally disadvantaged voters, by making them a priority for strategic politicians. At the individual level, thus, it can be beneficial for a voter not to trust more informed voters or the media, even if they share the same objective (the screening of politicians with undesirable traits) and even if, at the aggregate level, it would be beneficial for all voters to trust the information provided. 37 In other words, populist attitudes, in the form of lower trust in the informed elites, can be beneficial for voters.\n\nWatchdog voters, informational campaigns and electoral accountability. Aline of literature has argued that, despite the informational shortcomings of most voters, electoral accountability can be ensured by watchdog voters who inform the masses about politicians' actions in office (see Aytimur and Bruns (2019) and the references cited herein). In these accounts, watchdog voters are delegated the task of monitoring politicians, with the masses following their cues to ensure accountability. Implicit in this defence of electoral accountability through an informed elite is the claim that it is best for voters to subject politicians to higher levels of scrutiny. In a similar vein, informational campaigns disseminating information about politicians' behaviour in office have become increasingly\n\npopular in recent years as \"civil society organisations, international donors, and democracy promotion activists [see] transparency as a disinfectant and cure for what ails democracy\" (Dunning et al., 2019). While there is mixed evidence on whether these campaigns are effective in reducing corruption and improving democratic processes, 38 my findings suggest that these campaigns may have unintended consequences or be ineffective in certain contexts, especially if they do not reach all voters.\n\nFirst, the results of the model without communication underscore the importance of information transmission by more informed voters in order for them to have an impact on the level of accountability (this is consistent with findings in Arias et al., 2019). More informed voters alone may not be enough, especially if they don't represent a majority of the electorate. The nature of the additional information also matters, since even when communication is possible, some informational advantage for some voters may not affect the level of electoral accountability and may even benefit these voters, at the expense of less informed voters, by making the task of securing their support a necessity for a politician's reelection (Proposition 5). Distributional consequences are often not taken into account in this literature, in part because of a theoretical focus on politicians' actions that affect voters uniformly. 39 Moreover, by combining the results of Proposition 3 and Proposition 6, it becomes clear that the existence of more informed voters and their ability to ensure the same political outcomes as with a fully informed electorate can be detrimental to the electorate at the aggregate level, compared to a benchmark where they would be devoid of their informational advantage, by leading to shifts in equilibrium that can be detrimental to voters. 40\n\nFooling equilibrium and winning coalitions. As noted above, with homogeneously informed voters, there is no incentive for a strategic incumbent to include a particular voter over another in his coalition, since all voters are ex-ante identical. Moreover, since in equilibrium a strategic incumbent's expected vote share must be maximised for a given payoff, who is targeted in a fooling equilibrium is very simple: on the one side are fooled voters, who are allocated uniformly R , and on the other side are non fooled voters, who are not allocated anything. The winning coalition, i.e. the set of voters who could vote to reelect a strategic incumbent in a fooling equilibrium, is equivalent to the set of targeted voters, i.e. the set of voters who are allocated a strictly positive amount in a fooling equilibrium. Things are different for winning coalitions and the fooling equilibrium in the models I consider in section 4 with heterogeneously informed electorates.\n\nWhen a few voters are most informed and can't communicate (Proposition 4), only less informed voters\n\ncan be fooled into voting for a strategic incumbent who extracts part of the windfall, since most informed voters observe the entire allocation. Since my equilibrium selection rule does not preclude most informed voters from being targeted by a strategic incumbent, they may receive some spending. 41 However, they can't be part of the winning coalition, because they would never vote for a strategic incumbent in a fooling equilibrium. When a few voters are state informed and can communicate costlessly with less informed voters, a different conclusion emerges: the few state informed voters are necessarily included in the winning coalition formed by the strategic incumbent. This follows from the combination of their informational advantage, which allows them to see any deviation from the equal sharing rule in good times in their own allocation, and their ability to communicate with less informed voters, which makes disclosure a threat for the strategic incumbent. Moreover, targeted voters and the winning coalition coincide.\n\nRobustness. The models I analyse are cast at a high level of abstraction, for the sake of parsimony and to keep their inner workings as transparent as possible. 42 However, my results can easily be generalised to other settings. In particular, similar results hold with biased strategic politicians who favour specific groups of voters; with a finite number of voters; with no bad state; or when the more informed voters are a majority of the electorate. This highlights the elements of the models that are crucial to the results: heterogeneity in politicians' types, different levels of information about the policymaking process for voters, allowing for a partial observation of the policymaking process by the electorate, and the ability or inability of more informed voters to communicate with the less informed voters. Putting these elements together, I offer a novel theory of coalition building in a distributive context, driven entirely by politicians' reputational concerns and information asymmetries, both between politicians and voters and within the electorate.\n\n\n## 6 Conclusion\n\n\nIn this paper, I presented a simple model of political agency and distributive politics. Armed with this model, I explored several questions about the relationship between voter information, electoral accountability and distributive politics. I identified a number of mechanisms through which more information can benefit or harm voters. I first studied homogeneously informed electorates and showed how voters could benefit from less information, through the possibility of partial control and partial screening of politicians in equilibrium. I then analysed the case of heterogeneously informed electorates: there, I showed how voters' ability to communicate their superior information to their less informed counterparts and the nature of their informational advantage can play a significant role in affecting politicians' incentives to allocate resources to specific voters. In particular, I showed how too\n\nmuch information for voters who can't share their information with the broader electorate can make them unswayable, harming them, while the ability to communicate ensures that they are not treated worse than less informed voters.\n\nTaking stock of my theoretical analysis, I tried to show how my results can shed light on several issues in political economy. First, I argued that my analysis with homogeneously informed voters offers a novel theory of coalition formation, explaining why politicians may treat ex-ante identical voters differently in equilibrium, because of information asymmetries and politicians' reputational concerns. For heterogeneously informed electorates, I drew implications regarding the impossibility of collusion between voters and politicians; offered a novel rationale for voter ignorance within a heterogeneously informed electorate; discussed a novel supply-side rationale for the existence of media outlets; argued that populist attitudes, in the form of a lack of trust in institutions such as the media or elites, can be welfare improving for voters; showed how information campaigns can backfire or work in unintended ways, especially in distributive processes; and discussed how my theory of coalition formation can be extended to include information asymmetries between voters.\n\n",
         "I consider a series of models of political agency with moral hazard and adverse selection, in which politicians allocate resources to voters. Within these models, which combine electoral accountability and distributive politics, I ask: is more information good for voters? With homogeneously informed electorates, I first show how and when less information can benefit voters, through the interaction of both partial control and partial screening effects. Building on this mechanism, I subsequently consider heterogeneously informed electorates and ask: how can voters’ welfare be affected by the informational advantage of a few voters? Is it better to be among the more informed few or the less informed many? I show that the ability of more informed voters to communicate with less informed voters and the nature of their informational advantage can play a significant role in affecting voters' welfare by influencing politicians' incentives to allocate resources to specific voters.",
         ""
        ],
        [
         "7",
         "7",
         "## INTRODUCTION\n\n\nNearly 1 in 5 people in the US have a disability (more than 57 million), and people with disabilities use the automobile as a travel mode at significantly lower rates than people without disabilities ( Travel Patterns of American Adults with Disabilities | Bureau of Transportation Statistics , n.d.). For example, people aged 18 to 64 with disabilities make 28% fewer trips per day (2.6 v. 3.6 trips) on average than people without disabilities. The disparity is even more significant for non-workers. These statistics highlight the notable technological, design, and policy failings in today's transportation system - that disabled individuals have considerable suppressed demand for travel that is currently not being met. Even among people who are able to take the trips, a significant proportion of people with disabilities rely on modes of transportation that were not explicitly designed for their needs ( Travel Patterns of American Adults with Disabilities | Bureau of Transportation Statistics , n.d.).\n\nThough the technology to substitute conventional cars with the much talked about autonomous vehicles (AVs) is not entirely ready, some existing technologies might be helpful for persons with disabilities. That said, several companies are creating prototypes of AVs specifically designed to cater to the travel needs of disabled individuals. Once autonomous vehicle technology is sufficiently mature, they have the potential to help disabled Americans achieve their desired level of mobility - assuming developers accommodate varieties with different mobility needs (Claypool et al., 2017).\n\nThis paper aims to identify gaps and opportunities for researchers, policymakers, and state/local agencies to best address accessibility in AV developments-particularly for microtransit and paratransit applications. Paratransit is an on-demand shared-ride public transportation specifically for people with disabilities that complements fixed-route transit service provided by the transit agency operating in an area. Paratransit generally covers the same service area and service times as the transit service (Miah et al., 2020). On-demand microtransit provides shared rides in a van or minibus to any passenger. Microtransit has the potential to improve the flexibility of paratransit operations by allowing users to request service in real-time through a smartphone application (Volinski, 2019).\n\nThe paper is organized as follows: The next section provides a review of background research that includes a cautionary tale about treating accessibility as an afterthought, a discussion on accessibility organized by trip-making stages, and the state of policy and research on accessibility consideration for the AV environment. Conclusions from the Background research are then followed by the case for focusing on microtransit and paratransit service models. Nine different prototypes and pilot deployments are reviewed to assess if/how these deployments are addressing accessibility requirements for various disability types in the absence of an operator/driver. Recommendations for future policy research are provided in the Conclusions section.\n\n\n## BACKGROUND\n\n\n## Lessons from ADA and the 20 th  century\n\nThe disparities between the travel experience of the able-bodied and disabled individuals continue to persist today, three decades since the passage of the Americans with Disabilities Act (ADA). This state of affairs is partly due to the fact that the automobile revolution that dominated the mobility trends in the 20 th century preceded the ADA by several decades. As a result, accessibility was treated as an afterthought in the nation's transportation system. The passage of the ADA created general awareness about the needs of individuals with different ability levels. It has led to welcome changes in the nation's transportation system, but making those changes to an established system has been cumbersome and expensive. Integrating access at this stage of the AAV (Accessible Autonomous Vehicles) revolution as it unfolds provides an opportunity to develop a transportation system that treats accessibility as a guiding principle, not an afterthought .\n\nMinimum accessibility requirements as set forth by the regulations should be treated as a subset of the inclusive design principles that the AAV revolution should aim at (See Figure 1). Ensuring access at this stage of the AV revolution is more cost-effective in the long run compared to retrofitting in light of subsequent regulations. This may be a precondition to achieving the potential of AAVs to substantially increase independent mobility for consumers with disabilities, as noted by Claypool et al. (Claypool et al., 2017). Cregger et al. (Cregger et al., 2018) recommended the development and testing of new alternatives and aids for accessibility features onboard AAVs that consider a full range of disabilities. Unfortunately, the existing literature on human factors does not provide a framework to empirically examine the inclusive design needs of the emerging AAV ecosystem (Tabattanon et al., 2019).\n\nFigure 1: Minimum accessibility requirements as a subset of inclusive design principles\n\n<!-- image -->\n\n\n## Accessibility: The Complete Trip\n\n\nUnder Title II and III of the ADA, people with disabilities legally have a right to access the same transportation opportunities as people with no disabilities (Claypool et al., 2017). In order to realize this right for all individuals, regardless of ability in the age of AVs, it is helpful to look at each trip from a passenger-centric perspective. The AAV playbook developed by the Santa Clara Valley Transportation Authority (VTA) as part of their AAV pilot project ( VTA Serving as a Model for Accessible Autonomous Vehicle Use , n.d.)  provides seven trip-making stages that may be divided into three distinct categories: Pre-trip Concierge, Wayfinding and Navigation, and Robotics and Automation.\n\n- ● Pre-trip concierge (Information System Design)\n- o Trip planning and booking\n- ● Wayfinding and Navigation (Accessible Infrastructure Design)\n- o Navigating to the AAV pick-up point\n- o Waiting at the AAV pick-up point\n- o Navigating from the AAV drop-off point to the destination\n- ● Robotics and Automation (Vehicle Design)\n- o Boarding AAV\n- o Riding AAV\n- o Alighting AAV\n\nIn terms of accessibility requirements, these categories involve three distinct but interconnected areas of concern. The pre-trip concierge relates to the design of information systems that will inform the travelers; wayfinding and navigation relate to accessible infrastructure design; and the boarding, riding, and alighting from AAV without any human attendant relates to the design of the vehicles themselves.\n\nThis categorization corresponds to the actionable accessibility checklist for autonomous vehicles provided by Disability Rights Education &amp; Defense Fund ( Autonomous Vehicles (AVs), Also Known as Self-Driving Cars - Disability Rights Education &amp; Defense Fund , 2018). The checklist covers the three distinct areas of concern identified above: Information System Design, Infrastructure Design, and Vehicle Design. These factors have immediate feasibility for implementation by the public agencies (e.g., curb infrastructure) and private sector parties (e.g., vehicle design).\n\n\n## AV Policy at the Federal, State, and Local Level\n\n\nPresently, there is no specific federal law that governs AVs (National Center for Mobility Management (NCMM), 2018). Though legislation has been initiated in Congress, there is still an\n\nongoing debate within the Senate on the regulation level, safety concerns, and preemption of the state regulations. However, it is evident that a majority of both US Congress chambers are strongly in favor of passing laws that offer the automotive and tech industries the flexibility to carry out innovative vehicle tests and operate AVs on the road.\n\nGiven its jurisdiction over different transportation modes and vehicle safety standards, the US Department of Transportation (USDOT) is paying great attention to encouraging the development of AVs. USDOT has hosted stakeholder forums on AVs for modal administration and people residing all over the country. The National Highway Transportation Safety Administration (NHTSA) has also issued federal regulatory guidance on AVs, most recently in the form of the report titled 'Ensuring American Leadership in Automated Vehicle Technologies: Automated Vehicles 4.0' in December 2019 ( AV 4.0 | US Department of Transportation , n.d., p. 0).\n\nOn the state level, several jurisdictions have passed laws addressing AVs. However, most of those laws support the conducting of impact studies, provide rules for AV operations on public roads, or govern the creation of committees that might explore issues on automated vehicles. Some states have provisions for automated vehicles to function on public roads, while others offer a testing framework. Some states like California have managed to establish a graduated system of regulations with a separate permit for automated vehicles to be operated without the help of a human and those that require a human driver for backup.\n\nOverall, accessibility-related regulatory guidance issued by the states and federal government attempts to strike the right balance between seemingly competing interests of the state, interest groups, and companies working in the AV development/deployment space. For example, in their November 2020 decision, California Public Utility Commission (CPUC) did not include specific accessibility standards but required AV companies to submit Passenger Safety Plans that will outline the steps the companies will take to provide accessible service. In other words, autonomous mobility companies will be able to implement accessible service at their discretion but would only be required to submit reports that address what types of safety measures they provide and ensure that safety measures apply to all passengers, including those with disabilities ('Op-Ed,' 2020).\n\n\n## The Endeavor Towards Autonomous Vehicles for Disabled People\n\n\nIn 2012, Google released a video of its automated car transporting a blind man to a taco shop as well as to his dry cleaners (Douma et al., 2017). The CEO of Santa Clara Valley Blind Center, Steve Mahan, a legally blind individual, stated that an automated vehicle could grant him the flexibility and independence to travel to places he both needs and wants to go. At the heart of his discussion lies the ability of disabled people can to access life and travel options at par with individuals without disabilities. Under the right circumstances, automated vehicles can offer a\n\ndecrease in social isolation, access to vital services, and personal independence (Douma et al., 2017).\n\nA detailed report titled 'Self-Driving Cars: Mapping Access to a Technology Revolution' was produced by the National Council on Disabilities in 2015 (Henderson &amp; Golden, 2015). It explored, in great detail, the potential of self-driving cars to transform the lives of the disabled. Nevertheless, the report also highlighted that these benefits are not guaranteed. The creation of AVs has been rather fast-paced and secretive. While developers have expressed an interest in supporting greater accessibility for AVs, there is not much information available to the public to figure out how close manufacturers and designers are to this technology. This unavailability of information raises critical questions on how self-driven vehicles might cater to the requirements of disabled people. Furthermore, while AVs are being built to curb people's need to operate vehicles, it is important to note that lack of ability to drive is not the only barrier people with disabilities face while traveling. The simple acts of entering and getting out of the vehicle might pose difficulties for many disabled people, not just wheelchair users. This makes well-thoughtout considerations for people with disabilities essential at the early stages of design and development.\n\n\n## AV Research on Accessibility\n\n\nInclusive Mobility Design Lab (IMDL) at the University of Michigan provides an interactive portal ( Task-User Matrix , n.d.) to document existing research and identify knowledge gaps in the context of accessibility of  AAVs (specifically a low-speed Autonomous Shuttle (LSAS)). The portal categorizes 66 studies along two dimensions, i) tasks associated with using AAV as a travel mode and ii) disability type. The tasks, categorized here by the distinct areas of accessibility concerns, include information systems design factors (e.g. plan route, pay fare, identify correct vehicle or station) and vehicle design factors (e.g. boarding, securing seats/passengers, stop identification, vehicle ingress/egress).\n\nThese tasks may be mapped to the seven trip-making stages identified earlier in the paper based on the VTA's AAV pilot ( VTA Serving as a Model for Accessible Autonomous Vehicle Use , n.d.). However, this list from the IMDL portal does not address the elements of infrastructure design of transportation facilities, including sidewalks, curbs, and street crossings (Tabattanon et al., 2019). Hence, the portal does not adequately cover three of the trip-making stages, Navigating to the AAV pick-up point, Waiting at the AAV pick-up point, and Navigating from the AAV drop-off point to the destination.\n\nThe disability types discussed in the review provided by IMDL are quite comprehensive and include: cognitive and/or developmental disability; auditory impairment; visual impairment; wheeled mobility devices; ambulatory impairment; older adults; extremes of size and weight.\n\nIn general, wheeled mobility devices and ambulatory impairments have significant literature addressing the challenges, whereas research on cognitive and developmental disabilities is sparse. The combinations of disability type and trip-making stages for which no research is documented on the portal are listed below:\n\n- ● Trip planning and booking stage: Auditory Impairment\n- ● Boarding AAV stage: Cognitive and/or developmental Disability; Auditory Impairment; Extreme Size and Weight\n- ● Riding AAV stage: Auditory Impairment; Visual Impairment\n- ● Alighting AAV stage: Cognitive and/or developmental Disability; Auditory Impairment;\n\nIt should be noted that almost all of the research listed on the IMDL portal is conducted on traditional transit modes because a very limited set of studies exist on paratransit shuttles.\n\n\n## Accessibility Considerations: Information System Design\n\n\nAccording to the National Center for Mobility Management, even though ADA predates the internet, smartphones, apps, and emerging transportation modes, the regulatory framework developed for other laws, e.g., the Telecommunications Act and subsequent judicial interpretation, have extended accessibility mandates to the newest technology (National Center for Mobility Management (NCMM), 2018). The courts have held that the websites are effectively places of public accommodation, and commercial websites are required to comply with ADA regulations. The Telecommunications Act (47 USC §§255, 716, and 718) requires telecommunications equipment and services (now including smartphones, apps, and text messages) to be accessible to and usable by individuals with disabilities 'where readily achievable.' Further, Section 508 of the Rehabilitation Act of 1973 (29 USC § 794 (d)) requires federal agencies to make their electronic and information technology accessible to all people with disabilities. Complying with these regulations will undoubtedly support the accessibility of interfaces developed for wayfinding, ride-hailing, and requesting transportation services through AAVs. Many existing MaaS tools use native iOS and Android accessibility features to accomplish this in the ride request rides, and it is probable that this pathway could provide a comparable standard of service for mobile application/information systems UX design.\n\n\n## Accessibility Considerations: Vehicle Design\n\n\nMany of the onboard issues for people with sensory and cognitive impairments are currently addressed with help from the vehicle operator (e.g., availability of a vacant seat, expected arrival time to the destination stop). Absent a human driver or operator, AAVs will increase the need for providing onboard information to such passengers. Furthermore, even when compliant with federal accessibility standards, the interior configuration of vehicles presents a wide variation in challenges experienced by passengers with disabilities (Tabattanon et al., 2019). In a driverless environment, the vehicle design will need to address these challenges.\n\nThe vehicle design elements for boarding the AAV include the walking surfaces, ramps and bridge plates, slopes, lifts, level boarding, doorways, and illumination. While onboard the vehicle, the key design elements include walking surfaces, passenger access route, maneuvering through the vehicle, securement location, and means of securement ( US Access Board - Inclusive Design of Autonomous Vehicles , n.d.). The criticality of these elements depends on the size of the AAVs. Maneuvering the vehicle while en route is less of a concern in a smaller vehicle (typical of fixed-route neighborhood circulator, on-demand microtransit, and paratransit) than for the buses used for high-capacity fixed-route transit services. Independent wheelchair securement requires significant space and designs that accommodate various mobility devices. Bharathy and D'Souza (Bharathy &amp; D'Souza, 2018) provided an online design tool for calculating the clear floor space dimensions to accommodate the desired proportion of wheelchair users.\n\nWhile riding, the haptic feedback mechanism on the vehicle and/or mobile devices may provide route guidance to visually/mobility impaired, people with cognitive disabilities, and senior citizens (Shalaik et al., 2012). Haptic feedback refers to technology that can engage people's sense of touch to enhance the interaction with onscreen interfaces ( Haptics - User Interaction IOS - Human Interface Guidelines - Apple Developer , n.d.). On driverless vehicles, reconfigurable spaces/seating will need to accommodate a wide range of rider needs and preferences. Sensing passenger status (appropriately located, secured, etc.) will also be necessary. Furthermore, literature shows fare payment tasks add to the challenges and should be eliminated during trips ( US Access Board - Inclusive Design of Autonomous Vehicles , n.d.). That does not imply that costs for innovating fare payment systems should be borne solely by transit operators or contracted service providers. Eliminating points of friction to ridership should be a shared value that balances service effectiveness with economic efficiency (Appleyard &amp; Riggs, 2018).\n\nThe ramp slope and configuration are critical for disabled individuals to independently board and alight the vehicles. Research webinars from the US Access Board in Spring 2021 (US Access Board - Inclusive Design of Autonomous Vehicles, n.d.) documented the effects of ramp slope and multi-segment ramp configuration on human performance during ramp ascent and descent. The research supports a maximum 1:6 slope for transit ramps with less severe slopes preferred to support manual wheelchair users.\n\nThe US Access Board also documented findings based on focus groups with individuals with disabilities. The major concerns relevant to the communication interface included the ability to schedule a trip, engage in a 'conversation' with the interface, the ability to secure live assistance, and design cost &amp; availability. Communication-related concerns were paramount for individuals with sensory disabilities. For example, hearing-impaired individuals who want to talk but the voice interface may not recognize their speech may prefer a tactile interface. For the hearing\n\nimpaired, visual alternatives to the vehicle's speech that provide appropriate detail and alerts are needed. The audio provided must be compatible with the hearing devices ( US Access Board Inclusive Design of Autonomous Vehicles , n.d.). A key research priority would be vehicle interface design with a robust yet limited set of gestures and signs for command &amp; control.\n\nIn terms of cognitive disabilities, the challenge is that they are often combined with other disabilities, including vision (low vision, blindness), hearing (Hard of hearing or aphasia), speech disability (non-vocal, dysarthria, aphasia, stutter/stammer, etc.). Many of the 'general' solutions won't work for these individuals. Therefore, the design needs a spectrum of interface solutions within each person's abilities ( US Access Board - Inclusive Design of Autonomous Vehicles , n.d.).\n\n\n## Accessibility Considerations: En-route changes and Privacy\n\n\nIf there is a need to change the trip plan en-route, the task is cognitively more complex. The solution to en-route problems would potentially involve an on-call human attendant. The most difficult cases may include designs and interface options that need to cover travelers who may have no memory, be easily confused, or cannot give clear instructions. A trained-human-in-theloop option may be required for such scenarios. A hands-free, voice-activated tool to communicate with Dispatch or Customer Service should be a prerequisite for providing service. Providing human-in-the-loop may require data collected on disabled individuals. However, any data collected about users with special accommodations have the potential to be used to harm the traveler. The potential harms include discrimination, identification as a target for fraud, robbery, etc.\n\nThis privacy issue may require all data sharing on users' abilities to be overseen by an external third-party regulatory body that serves as a data ethics council. In the case of government regulators at the state or federal level governing this council may represent a conflict of interest. It may be most appropriate that this data council serve as an independent, similar to the concept of the Facebook Oversight Board ( Oversight Board | Independent Judgment. Transparency. Legitimacy. , n.d.), and providing an independent assessment of complex issues such as privacy, surveillance, individual expression, and data sharing.\n\nRelevant ADA Regulations Following the review of the existing resources on the needs of disabled individuals in the context of AAVs, a rigorous background of how the Americans with Disabilities Act and relevant research could inform trends of autonomous vehicles-particularly autonomous microtransit and paratransit. A detailed review of the Americans with Disabilities\n\nAct of 1990 and Section 504 of the Rehabilitation Act of 1973 was conducted with special emphasis on the following regulations:\n\n- ● 49 CFR Part 37 -Transportation Services for Individuals with Disabilities (ADA)\n- ● 49 CFR Part 38 - Americans with Disabilities Act Accessibility Specifications for Transportation Vehicles\n- ● New Final Rule:  Reasonable Modification of Policies and Practices (Federal Transit Administration Office of Civil Rights)\n\nA careful review of various documentation from pilot projects, as well as a review of 49 CFR Sections 37 and 38, helped determine if they are applicable to future AAV fixed route or paratransit systems and review the applicability of accessibility policy to following potential platform / technological innovations:\n\n- 1) Fixed-route neighborhood circulators;\n- 2) On-demand microtransit;\n- 3) Paratransit;\n- 4) High-capacity fixed-route transit services.\n\nThese services and vehicles are regulated under Title 49 CFR Part 37, Transportation Services for Individuals with Disabilities, and Title 49 CFR Part 38, Americans with Disabilities Act (ADA) Accessibility Specifications for Transportation Vehicles.\n\nBuilding on this background, a rating framework was developed to evaluate how and to what extent technological frameworks and vendors (itemized as Case Studies in the next section) address accessibility requirements. It is used to provide insights beyond an assessment of a specific project or technology and allows for a detailed exploration of the gaps and opportunities for these advancing technologies.\n\n\n## Conclusions from Background Research\n\n\nBased on background research and literature, at full vehicle autonomy resulting in the absence of an onboard operator, tasks such as ingress-egress, securement of passengers and carry-on items, and the communications with passengers will need to be safe, efficient, and independent. The biggest challenge in this area may be the need to handle these tasks for a wide range of disability types, most currently supported by the vehicle operator.\n\nTo ensure that the disabled individuals are appropriately served at each trip-making stage identified by the VTA pilot, the design of transportation facilities, sidewalks, and street crossings is also essential to consider (Tabattanon et al., 2019). The environmental facilitation that may support easier boarding and alighting includes deploying ramps to curbs at corners or sidewalks with enough clear space and standardization of pick-up and drop-off conditions. ( US Access\n\nBoard - Inclusive Design of Autonomous Vehicles , n.d.). This presents an opportunity for better curb management and collaboration between agencies/entities in using limited curb space.\n\n\n## Applicability of AAV Vehicle Capacity by Service Model\n\n\nIn this context of Information System Design, Vehicle Design, and Infrastructure Design, various platforms can meet service standards based on different standard service models governed under Title 49 CFR Part 37. We considered four other service models that may have distinct accessibility considerations: fixed-route neighborhood circulator, on-demand microtransit, paratransit, and high-capacity fixed-route transit services.\n\nThe most straightforward service model to be deployed using autonomous technology would be fixed-route circulators or high-capacity fixed-route transit services. Automation of these services on fixed guideways using standard ADA-accessible vehicles was piloted as early as 1980 during the Los Angeles Olympics (Kellerman, 2018). Yet, as automated technology has progressed, most vendors have been primarily focused on microtransit and paratransit services, given the efficiency and cost-effectiveness of operations and increased reliability and convenience of the model (Riggs &amp; Beiker, 2019). As a result, research indicates that these two will be the primary business models of these technologies. Hence, we have focused on these two service models in our case study review.\n\nParticularly concerning their general design and operational standards, it is anticipated that these vehicles will be able to meet or exceed applicable platform and service design standards. Table 1 summarizes the required and desirable elements of accessible service (based on our review of relevant regulations and background literature) and whether the state-of-the-art microtransit and paratransit service meets the standard. As shown in Table 1, both platforms could meet most standard vehicular thresholds, but due to the nature of the service, voice control systems and drop-off orientation may need more technological development or additional service specifications through on-demand or on-call help services. These services are sometimes referred to as trained-human-in-the-loop. These onboard issues for people with visual and hearing impairments are currently addressed with help from the transit vehicle operator. These will be critical for policymakers and vehicle service providers to address in the AAV context.\n\nTable 1. Applicability of AAV Technology to On-demand Microtransit and Paratransit Services\n\n\n## On-Demand Microtransit Cases\n\n\n## Case 1 -  Prototype of a Wheelchair-Accessible AV\n\nOne company has started working on a wheelchair-accessible prototype of  an autonomous shuttle car and has completed its initial round of collecting feedback from community members in  the  region  of  Columbus,  Ohio,  and  Grand  Rapids,  Michigan,  where  the  shuttle  will  be operating ( May Mobility Reveals Prototype of a Wheelchair-Accessible Autonomous Vehicle | TechCrunch , n.d.). The design will provide space for exit and entry, along with securing the wheelchair for a passenger once it is brought on board some time during the entire trip phase. The company realized the need for design improvements from an initial round of feedback. Specific enhancements suggested in the feedback were increasing the length of the mounting ramp to offer steadier boarding and alighting and optimized drop-off and pick-up points. The company planned to make these improvements prior to deployment.\n\n\n## Case 2 - Customized Minivans\n\n\nA leading autonomous driving technology development company recently announced that it would be including 100 customized hybrid Chrysler Pacifica minivans in its experimental fleet of automated cars. These minivans will be customized in partnership with one of the leading providers of wheelchair vehicles and mobility solutions ( Automated Vehicles &amp; People with Disabilities , n.d.). This venture aims to demonstrate that the automation technology does not have to be utilized only in pod-like vehicles that could never accommodate a ramp for wheelchairs. Individuals with disabilities could use automated cars in their everyday lives if they collaborated with more oversized vehicles, allowing passengers of all types.\n\n\n## Case 3 - A Luxury Concept Car\n\n\nThe concept car from one of the German automakers is one of the more luxurious autonomous vehicles reviewed here as a case study. It was first introduced in 2017 as a public transportation option, but as of 2020, it is being marketed for private use or carsharing. With its tall roofs and wide doors, wheelchairs can easily fit, although no details are available on access and securement logistics. The automaker is collaborating with the National Federation of the Blind, the Disability Rights Education &amp; Defense Fund, and the National Association of the Deaf in its Inclusive Mobility initiative ( Volkswagen Developing Mobility Solutions for People with Disabilities - Newsroom , n.d.). This collaboration initiative will help the automaker incorporate\n\nfeedback into their autonomous car design to ensure that they meet mobility requirements for underserved disabled populations.\n\n\n## Case 4 - An Urban Robo-taxi\n\n\nFirst introduced in 2018, this concept vehicle from another European automaker has level 4 autonomy (Savov, 2018). The concept vehicle has been developed to serve as an urban 'robotaxi' that can be hailed using a phone application or from a designated city station. This communal taxi service will operate similarly to pooled options in Transportation Network Companies (TNCs) such as Lyft or Uber. The vehicle features a large door opening with an adjustable ramp and claims that it is wheelchair and stroller-accessible and there are straps for securing the wheelchair or stroller inside.\n\n## Case 5 -A Single-occupancy Design\n\nThis case study describes an accessible automated car design initiated in Eastern Europe (Templeton, n.d.). The vehicle is small, hollow, and for one-person best suited for city travel. With self-drive and electric power, it is convenient to develop a car with a hollow shell and a flat floor. The vehicle is wheelchair accessible, allowing users to roll in their chairs more easily than someone walking and getting into the car. Once a user is inside, they can clamp down the chair, strap on the belt and start the ride, which is a lot more convenient than cars with handles and seats or vans that have lifts. According to reports, wheelchair users have provided positive feedback for this vehicle.\n\n\n## Paratransit Cases\n\n\n\n## Case 6 - Detroit Medical Campus Shuttle\n\n\nThe Detroit Medical Center Heart Hospital campus automated shuttle Evo was unveiled in August 2020. It has been previously deployed in downtown Las Vegas, the University of Michigan campus, the Texas A&amp;M campus, and Oslo, Norway ( Autonomous Vehicles , n.d.). The electric shuttle can fit fifteen people and run for nine hours. This hospital shuttle service was designed to be accessible for paratransit and elderly riders thanks to the custom addition of an ADA wheelchair ramp. Although the shuttle is self-driving, there is always a human safety operator on each shuttle at this stage of prototype deployment.\n\n\n## Case 7 - US Army Catapult\n\n\nIn an experiment by the US Army with vital implications for American service members and people of the nation, a driverless shuttle is being piloted at Fort Bragg. The shuttle will aid wounded soldiers, especially ones suffering from traumatic brain injuries, to reach hospitals and clinics to make medical appointments ( Driverless Shuttle at Fort Bragg Is 'Army's Future' News - The Fayetteville Observer - Fayetteville, NC , n.d.). The US Army Tank Automotive\n\nResearch, Development, and Engineering Center (TARDEC) is operating specifically equipped Cushman Shuttles that are essentially remodeled golf carts. The shuttles receive injured soldiers from their barracks and carry them to the medical center about half a mile away.\n\n\n## Case 8 - JTA/Olli 2.0\n\n\nThe Jacksonville Transportation Authority (JTA) is testing the Olli 2.0 autonomous vehicle from Beep, Local Motors by LM Industries, and Robotic Research LLC. The testing is being conducted under the umbrella of the 4-phase Ultimate Urban Circulator (U²C) program. JTA developed Golden 20 along with an extensive test protocol for the AVs being deployed and tested for use by the transit agency under this program ( AVs Pave the Way for Future Mobility , 2020). JTA specified 'Full ADA compliance' as the first of the 'Golden 20' requirements in the Request for Proposal issued in October 2019 for AV solutions appropriate for the U²C Project.\n\n\n## Case 9 - ELATE project and VTA Service at VA Palo Alto\n\n\nThe Enhancing Life with Automated Transportation for Everyone (ELATE) project will support the goals of the Federal Transit Administration's (FTA's) Accelerating Innovative Mobility (AIM) initiative by successfully demonstrating a purpose-built, high automation common-spec Accessible Automated Electric Vehicle (AAeV) in two locations with varying climates: Youngstown, OH and Santa Clara, CA. The VTA Service will be from the Veterans Administration Palo Alto Health Care System to the Palo Alto transit center. The average trip of 4.5 miles is expected to take no more than 15 - 20 minutes. Due to the number of buses, shuttles, and trains using the Palo Alto transit center, the project will require the development of a transit center curb management solution.   VTA plans to leverage the innovative tech industry by utilizing the latest in passenger management technologies such as interactive speech and video analytics. VTA will work with microtransit software providers to develop an accessible mobile app and web and phone backend system.\n\nIn Table 2 below, each of these case studies is evaluated on the ability to provide potential accessibility features needed in the absence of a driver/operator.\n\nTable 2. Accessibility Features by Case Study\n\nY = has feature  N = does not have feature  P = feature possible\n\n\n## DISCUSSION AND CONCLUSIONS\n\n\nAs this evaluation illustrates, AAVs offer a considerable promise of mobility to the disabled population through increased service with new forms of on-demand passenger travel options. However, to realize this promise, a careful review of the regulatory regime and guidance on potential changes to the rules is required.\n\nMany of the standard features in vehicles have the potential to be enhanced and improved with automation. AAV may also increase the significance of providing onboard information to such passengers. And these technologies are being deployed globally. For example, Stockholm has recently introduced the prototype of an automated shuttle bus. The bus, since its initiation, has been sharing the roads and functioning alongside cyclists, pedestrians, and other vehicles ( Driverless Vehicles , n.d.). It can travel at a 24 km/hr speed and has access ramps for individuals with disabilities. Potential improvements from AAVs that can deliver multimedia content enroute to passengers include the ability to provide features such as:\n\n- ● Inclusion of video/safety analytics\n- ● Ramp deployment and actuation\n- ● Voice warning for securing passengers, rider/stop information\n- ● The ability for multi-lingual support\n\nApps and other technologies providing onboard and/or pre-trip information to the passengers should be certified as 508 compliant  About Us | Section508.Gov ( , n.d.) for web content accessibility, and communications must be HIPAA (Rights (OCR), 2009) compliant. The best practices in this area also include assessing the accessibility of all content against the latest international Web Content Accessibility Guidelines (WCAG)  Web Content Accessibility ( Guidelines (WCAG) 2.1 , n.d.).\n\nThe evaluation shows the need for refinement to the existing technology privacy considerations where a trained-human-in-the-loop may be required. Additional points of consideration include factors such as voice-controlled systems for certain operations (e.g., change route, unlock doors, lower/raise windows, etc.), orientation and access features, weather and route conditions, as well as information about the environment surrounding the vehicle ( Autonomous Vehicles (AVs), Also Known as Self-Driving Cars - Disability Rights Education &amp; Defense Fund , 2018).\n\nMost vendors are assuming fares and fare boxes become digital. This should be a universal standard to eliminate fare boxes from the vehicle/vehicle vestibule. The design simplicity of vehicles must also account for individuals with cognitive disabilities with simple and intuitive layouts and system controls. Voice control systems and drop-off orientation may need more technological development or additional service specifications through on-demand or on-call help services.\n\nThe transit agencies should include exploration of slope standards in requests for qualifications from vendors. A University at Buffalo study on ADA slope requirements and wheelchair capabilities would be critical to highlight in any contracts or regulations ( US Access Board Inclusive Design of Autonomous Vehicles , n.d.). Over the coming years, policymakers and planners will need to ensure that vehicles are designed to accommodate roadway users (especially those with disabilities) not using or interacting with those vehicles. And most importantly establishing a dialogue with AAV developers on user experience studies and focus groups could be a valuable source of learnings for both industry as well as the concerned agencies, and establish greater informational symmetry on diverse user needs.\n\nSimilarly, local transportation agencies have an opportunity to partner with AAV developers to facilitate the ease of providing accessible service through targeted policy actions in the built environment. These efforts could include:\n\n- ● Coordination with local governments on enhancing and building appropriate transit infrastructure (curb ramps, bus stops, etc.) for AAV travel, particularly for mobilityimpaired riders.\n- ● Coordination, collaboration, prioritization, and sharing of curb availability for accessible services (including, but not limited to, AAVs) can create a greater density of established pick-up and drop-off locations and more collaboration in using limited space in urban areas.\n- ● Digitization of transit trip data to encourage greater multimodal integration of future AAV services with existing transportation infrastructure.\n\nThese items will ensure that vehicles balance safety and accommodation and that regulators are prepared so that they not only guide deployment that meets the intent of the (ADA) Accessibility Specifications but deployment that potentially exceeds them. In other words, ADA standards should be used as one of the tools in addition to universal design principles and assistive technologies in order to maximize accessibility. For AAV applications, this means using advanced solutions that provide incentives for public transit operators or contracted service providers to enhance services and amenities to better serve users in the most economically prudent and environmentally sustainable manner possible.\n\n",
         "Autonomous vehicle (AV) technology can help disabled Americans achieve their desired level of mobility. However, realizing this potential depends on vehicle manufacturers, policymakers, and state and municipal agencies collaborating to accommodate the needs of disabled individuals at different stages of trip making through information system design, vehicle design, and infrastructure design. Integrating accessibility at this stage of the AV revolution would finally allow us an opportunity to develop a transportation system that treats accessibility as a guiding principle, not as an afterthought. This paper documents accessibility considerations for disabled individuals followed by a review of relevant Americans with Disabilities Act (ADA) regulations. The review of regulations is followed by a review of nine case studies, five corresponding to the on-demand microtransit service model and four corresponding to the paratransit service model. These case studies are essentially different prototypes currently being deployed on a pilot basis. Each of these specific case studies is then evaluated for its ability to provide potential accessibility features that would fulfill the requirement set forth by relevant ADA regulations in the absence of an operator/driver. Based on this review of relevant research, ADA regulations, and case studies, recommendations are provided for researchers, private firms, policymakers, and agencies involved in AV development and deployment. The recommendations include better collaboration and adoption of best practices to address the needs of individuals with different disability types (e.g., Cognitive, Visual, Auditory). ADA regulations should be used as one of the tools in addition to universal design principles and assistive technologies in order to maximize accessibility.",
         ""
        ],
        [
         "8",
         "8",
         "## Introduction\n\n\nThe classical theorists of metaphors believed that metaphor functions as a literary device to create an artistic effect. Nevertheless, Lakoff and Johnson (1980) argued that metaphor could also be used in an everyday language because its presence is ubiquitous in daily life, even to the most mundane details. In addition, metaphor is also an excellent tool to disseminate ideology, express emotion, and communicate moral purposes (da Silva, 2016) to intended audience. It is also used to craft gender identities in society (Alhumaid, 2017). Hence, it is no surprise that it has been investigated in many types of discourse in different communications fields. Nevertheless, such research is scarce in certain types of discourse.\n\nCorpus linguistics is a method in language study which does not necessarily link to any specific theory (Semino, 2017). Researchers can use this method alongside various theoretical descriptions in  numerous  fields  to  explain  how  a  particular  language  is  used.  The  corpus  approach  uses sophisticated corpus tools to analyze language in a collection of naturally occurring (either written or spoken) texts. There has been a recent trend in using the corpus approach to analyze metaphor (e.g., Adnan, 2014; Ahrens &amp; Jiang, 2020; Sardinha, 2007; Semino et al., 2015). This conventional trend is due to the corpus tool which speeds up the linguistic analysis of a huge amount of data through language patterns and word frequencies.\n\nMoreover, analysis of word frequencies and collocations allows the linguists to learn aspects of language based on empirical evidence (Charteris-Black, 2004) instead of relying on their judgment alone. This matter reduces the tendency of researcher's biases when performing qualitative analysis that  involves  the  researcher's  intuition  and  perception.  Nonetheless,  both  quantitative  and qualitative approaches play an equally significant role in linguistic analysis because a more indepth  analysis  via  qualitative  methods  can  explain  the  results  drawn  from  quantitative  corpus analysis (Partington, 2007).\n\nTo date, corpus methods have contributed a lot to developing metaphor theory and analysis in various ways. Charteris-Black (2004), for instance, developed Critical Metaphor Analysis (CMA), which  integrates  corpus  linguistics  with  cognitive  linguistics  and  Critical  Discourse  Analysis (henceforth CDA) in identifying metaphors. He used CMA in analyzing metaphors in diverse discourse (e.g., sports, religious, political, business, etc.). This method is performed by following a  three-step  critical  approach:  (i)  metaphor identification, (ii) metaphor interpretation, and (iii) metaphor explanation. Meanwhile, some researchers consider Corpus-Assisted Discourse Studies (CADS) as another method to study metaphor. CADS is an approach of the corpus linguistics methodology,  and  there  is  an  increasing  body  of  research  in  discourse  that  adopts  the  corpus linguistics approach (Jaworska, 2016). The method has been extensively employed to examine various types of discourses.\n\nMultiple studies have been conducted to investigate metaphors in various types of discourse. This paper intends to review 23 studies to learn noteworthy perspectives on the research trends of metaphors, specifically using the corpus approach for the last six years (2015-2020). To be more specific, the study aims to answer the following research questions:\n\n- 1. What is the trend of metaphor study that uses the corpus approach in the last six years (2015 - 2020)?\n\nwww.awej.org\n\nISSN: 2229-9327\n\nCorpus-based Studies of Metaphor: An Overview\n\nAbdul Malik, Ya Shak, Mohamad &amp; Joharry\n\n- 2. What are the potential gaps and under-researched areas in the analyzed literature?\n\n\n## Methodology\n\n\nIn  the  first  phase  of  the  search  strategy,  key  terms  (and  any  combination  of  these  terms) 'metaphor',  'metaphor  study/analysis'  and  'corpus',  'corpus-based',  'corpus  linguistics',  and 'corpus-assisted' were used in the search items. The research publications were mainly selected by considering  the  title,  key  terms,  and  abstract  (Tamilchelvan  &amp;  Rashid,  2017).  The  technique revealed research publications with content that was partially or fully linked to metaphor study using the corpus approach. In the next phase, a screening process was executed to eliminate the irrelevant articles. The research publications that meet these criteria were further analyzed later.\n\n- a) Published in the English language or at least have an abstract in English\n- b) Providing data related to the study of metaphor using the corpus approach\n- c) Research studies must be published from 2015 until December 2020 so that this review would reveal recent insights into the investigated phenomenon.\n- d) The studies must be published in a journal or conference proceeding.\n\nThe two-step analysis suggested by Ahmed and Matthes (2017) was applied for data analysis. The analysis involves a detailed quantitative analysis that permits researchers to learn research trends and make comparisons. At this stage, the compiled studies were coded into the following categories:\n\n- 1. Publication year\n- 2. Corpus involved\n- 3. Instruments/Tools used\n- 4. Theoretical lens\n\nApart from that, the analysis also involved qualitative analysis by drawing significant themes from the compiled literature. Each study was categorized according to its overall theme. The past literature  was  segmented  and  classified  under  the  same  themes  and  categories.  The  thematic categorization  was  checked  and  certified  by  an  inter-rater,  a  senior  researcher  in  this  field,  to diminish any issues relating to the validity and reliability of the qualitative findings.\n\n\n## Results\n\n\nThe objectives of this systematic review were (i) to discover the trend of metaphor research that used the corpus approach in the last five years and (ii) to identify the potential gaps and underresearched  areas  in  the  analyzed  literature,  particularly  in  terms  of  methodological  and  topic findings.  In  meeting  the  first  objective  of  the  review,  the  discussion  of  the  trend  of  metaphor research from 2015 to 2020 was done based on a quantitative analysis of these categories: (a) publication year, (b) corpus involved, (c) instrument/tool used, and (d) theoretical lens, while the data from thematic analysis helped the researcher to meet the second research objective based on the identified themes. Table 1 summarises the publication year, type of corpus, instrument/tool used, and theoretical perspective raised in the chosen past literature.\n\n\n## Distribution of Published Journals (2015-2021)\n\n\nThe findings revealed that the overall mean of 3.83 research studies related to metaphor using the corpus approach per year seems low for six years. Figure 1 highlights a fluctuated trend of research studies on the said topic. There is an increasing trend of research studies from 2015 (N=2) until 2017 (N=6). Nevertheless, the number decreased in 2018 (N=3) before escalated again in the following year (N=6) and declined again in 2020 (N=2).\n\nFigure 1 . Research trends of metaphor study using corpus approach (2015-2020)\n\n<!-- image -->\n\n\n## Corpus Used\n\n\nApart from the distribution of published journals, the quantitative analysis revealed the trend of research studies regarding the corpus used in the selected literature. As illustrated in Figure 2, most of the literature analyzed existing corpus as 39% of the past studies examined data taken from existing reference corpus or corpus database. For example, He and Wen (2017) analyzed the Corpus of Historical American English (COHA), the Corpus of Contemporary American English (COCA), and the British National Corpus (BNC). Meanwhile, Potts and Semino (2019) examined the British National Corpus (BNC), the Corpus of Contemporary American English, and an ad hoc corpus of reportage collected from Nexis (1 June-1July 2017). On the other hand, Jaworska (2017) investigated  descriptions  of  tourist  destinations  in  Britain  (Home-Corpus),  Europe  (EuropeCorpus), and faraway tropical countries (Faraway Corpus), while Afrashi and Ghouchani (2018) studied the Persian Linguistic Database corpus. This is followed by news articles with a total of 13%  that  include  news  and  opinion  articles  (Da  Silva,  2016),  British  business  English  press (Herteg, 2019), and economic reports in English and Spanish press (Gil, 2019). In the meantime, business, literature, and health corpora have a similar percentage (9%). Academic corpus followed with 5%. The lowest percentage, 4%, is shared by four corpora types: political, sports, artwork, and mixed corpus.\n\n\n## Instruments Employed\n\n\nAs shown in Figure 3, most studies did not mention the specific instrument or tool employed in  analyzing  the  data,  with  26.1%  (N=6).  Then,  21.7%  (N=5)  of  the  studies  used  multiple instruments to analyze the data. Then, five different tools were used, namely WordSmith Tools, Antconc, Wmatrix, Sketch Engine, and search queries, with a similar percentage, 8.7% (N=2). Fewer studies (N=1, 4.3%) employed the #Lancsbox and concordance programme to analyze the collected data.\n\nFigure 3 . Instruments Employed in the Analyzed Studies\n\n<!-- image -->\n\nFor example, Da Silva (2016) did not state the instrument used in analyzing news and opinion articles corpus. Similar evidence was found in Dodge's (2016) research, which examined concepts of poverty-related metaphors in the MetaNet metaphor repository.\n\nInterestingly, it is also found that the other past studies that did not mention the instrument used were analyzing non-English corpus. For instance, Raffaelli and Katunar (2016) studied sports discourse in Croatian. They only noted that frequency analysis identified conceptual metaphors in the Croatian corpus. Meanwhile, Gandomkar (2019) and Afrashi and Ghouchani (2018) analyzed the Persian corpora. Gandomkar examined thematic categorization and conventional metaphor and metonymy among Persian speakers. He only mentioned deductive method and frequency analysis were employed in the study. In the meantime, Afrashi and Ghouchani (2018) compared the FEAR metaphor between Persian and English languages. Luo (2018) also studied a non-English corpus,\n\nwww.awej.org\n\nISSN: 2229-9327\n\ni.e.,  Chinese  TALK  metaphor  using  the  Center  for  Chinese  Linguistics  (CCL)  Corpus,  while Stampoulidis  and  Bolognesi  (2019)  studied  a  non-language  corpus,  i.e.,  (verbo-)  pictorial metaphor  in  street  artworks  in  Athens.  Apart  from  that,  many  researchers  used  multiple instruments in studying metaphors in their research. For instance, in Ahrens and Jiang (2020), corpus-based  linguistic  tools  such  as  SUMO  (Suggested  Upper  Merged  Ontology),  WordNet, collocational  patterns,  and  an  online  dictionary  were  employed  to  verify  keywords  for  the BUILDING metaphors.\n\n\n## Theoretical Lens\n\n\nFigure 4 illustrates the theoretical lens employed in the examined past literature. The figure shows that 73.9% (N = 17) of the studies used either a grand or middle-range theory as a theoretical lens.\n\nFigure 4 . The Theoretical Lens Employed in the Analyzed Studies\n\n<!-- image -->\n\nMost  of  these  past  works  of  literature  (e.g.,  Afrashi  &amp;  Ghouchani,  2018;  Dodge,  2016; Gandomkar, 2019; Güldenring, 2017; Herteg, 2019; Potts &amp; Semino, 2017; Raffaelli &amp; Katunar, 2016;  Semino,  Demjen,  &amp;  Demmen,  2018;  Zhao,  Han,  &amp;  Zhao,  2019)  employed  Conceptual Metaphor Theory (CMT) in their studies. Some studies used the CMT and paired it with other theories, such as Naicker (2017), who analyzed an ancient Hindu scriptural lore using the CMT and the theory in Cognitive Linguistics. Another study conducted by Da Silva (2016) employed the  CMT  with  Critical  Discourse  Analysis  (CDA)  and  the  theory  in  Cognitive  Linguistics  in studying persuasive metaphors in the Portuguese press, while Potts and Semino (2019) used both the CMT and Discourse Analysis (DA) in studying the CANCER metaphors. Other than CMT, it is  evident  that  Critical  Metaphor  Analysis  (CMA)  was  also  preferred  by  the  researchers  of metaphor based on the analyzed past literature. For example, Gil (2019) used it as a theoretical lens in studying ideology and persuasion in economic reports in English and Spanish press, while Zibin  (2020)  used  the  theory  to  examine  metaphors  describing  Syrian  refugees  in  Jordanian newspapers.  Apart  from  the  CMT  and  the  CMA,  the  theory  of  Grammatical  Metaphor  was employed in two past studies.  It  was  used  in  He  and  Yang's  (2017)  study  that  examined  text technicality  and  ideational  metaphor  and  in  He  and  Wen's  (2017)  study  that  investigated grammatical and textual metaphor. Finally, Luo (2018) used theory in Cognitive Linguistics to analyze the Chinese TALK metaphor.\n\nwww.awej.org\n\nISSN: 2229-9327\n\nMeanwhile, another 26.1% (N = 6) of the studies did not employ any grand or middlerange theory, as shown in Figure 4. For example, Ahrens and Jiang (2020) and Krennmayr (2015) both used corpus linguistics, i.e., a method in language study which does not essentially relate to any specific theory (Semino, 2017). Apart from that, even though no theory was used in a study conducted  by  Semino  (2016),  she  used  corpus  analysis,  i.e.,  lemma  search  and  concordance analysis, to identify metaphors in Oxford English Corpus (OEC). Meanwhile, Jaworska (2017) and  Stampoulidis  and  Bolognesi  (2019)  identified  metaphors  using  Metaphor  Identification Procedure (MIP) guidelines without using any theoretical lens. The same goes with Skorczynska and  Ahrens  (2015),  who  used  metaphor  signaling  and  MIP  guidelines  to  examine  words  and phrases metaphors in different genres.\n\n\n## Thematic Analysis\n\n\nThis  analysis  phase  provides  the  possible  gaps  and  omissions  in  terms  of  the  focus  of  the metaphor studies that employed the corpus-based approach. The findings at this stage also offer some insights into recommended issues of the under-researched areas in metaphor study, which help close the identified gaps. The data from the thematic analysis revealed several themes to meet the second research objective, i.e., to determine the potential gaps and under-researched areas in the analyzed literature. Table 2 illustrates the identified themes from the synthesis of the research studies in response to the second research objective of this study.\n\nTable 2. Overview of the findings of qualitative thematic screening\n\nAs  illustrated  in  Table  2,  most  of  the  examined  past  studies  were  highly  focused  on  the conceptualization and patterns of metaphor. Across the 23 studies, 13 studies concentrated mainly on analyzing the word(s) or phrase(s) that could be the source domains of metaphor in a discourse\n\nwww.awej.org\n\nISSN: 2229-9327\n\n\n## Discussion\n\n\nBased on the data of the distribution of published journals, the research standpoints on metaphor study using corpus approach did not show a consistent and steady increment over the years, i.e., 2015 until 2020. Nevertheless, the upsurges with the highest numbers in 2017 and 2019 indicate positive interest trend of research studies of the area.\n\nApart from that, the corpus used in the distribution of the synthesized studies proposes a trend among the researchers of metaphors in using existing large-sized corpus compared to building their own specialized corpus, specifically spoken discourse. It is understood that the supremacy of written  data  in  corpus  studies  is  due  to  the  complications  and  expense  related  to  recording, transcribing,  and  compiling  corpora  of  the  spoken  discourse  (Römer,  2006;  McCarthy,  2008). Nevertheless, metaphor research in spoken discourse should not be neglected regardless of the reasons. It can contribute to the body of knowledge in understanding the construction, function, and  impact  of  metaphor  in  such  discourse.  In  further  understanding  metaphor,  researchers  of metaphor should examine it in the written corpus and the spoken material within specific and distinguishable  genres  (Goatly,  2007).  Henceforward,  it  allows  the  researchers  to  learn  how language such as metaphor is used in real-life situations. The distribution also reveals several gaps in the knowledge and understanding of metaphor use in other types of discourse that are not listed in the synthesised studies. For example, no single study of metaphor used the corpus approach focusing on religious discourse. There has been only a handful of studies conducted on metaphor in  spoken  religious  discourse  compared  to  other  types  of  discourse  (Wardani,  2019)  which indicates a scarcity of research conducted in the area of study.\n\nMeanwhile, the findings related to the corpus tool preferred by the researchers of metaphor in their studies highlights another gap. Since most of the researchers did not specifically mention the corpus tool used to analyze their data, it reflects the instrument used is not a significant element in corpus research, specifically in studying metaphors. If the devices can produce a basic frequency list,  keyword  list,  collocates,  and  concordance  lines,  they  are  viable  and  adequate  to  help researchers study metaphors in a discourse. It was also revealed that some of these past studies analyzed non-English corpus which explains the…. Since the latter part of metaphor analysis is still done qualitatively, contemporary researchers of metaphors are trying to find systematic and efficient ways to examine metaphors in discourse. This matter helps to reduce the researcher's biases  and  influence  in  identifying  metaphors  in  discourse.  Then,  it  can  also  be  concluded WordSmith Tools, Antconc, Wmatrix, and Sketch Engine are the common corpus tools used to analyze metaphor in a discourse.\n\nIn terms of theoretical lens, most of the analyzed past literature employed Conceptual Metaphor Theory (CMT) even though it has received a lot of criticism from contemporary researchers of metaphors.  Kövecses  (2008)  stressed  that  the  theory  is  mainly  criticized  due  to  the  issue  of methodology,  direction  of  analysis,  schematicity,  embodiment,  and  relationship  with  culture. However, the breakthrough of the CMT paves the way for the avid researchers of metaphor to discover the manifestation of thought through the conceptual mappings of linguistic metaphors.\n\n\n## Conclusion\n\n\nThis  review  exposed  several gaps in the selected studies.  First, the  corpus-based studies of metaphor in this review focused on written discourse. Other specialized corpora are understudied, especially the ones that involve spoken discourse. As suggested by Mauranen (2006), analyzing spoken  discourse  that  happened  naturally  could  provide  fresh  insights  into  language  while revitalizing  linguistics  and  challenging  \"the  adequacy  of  sentence-based  models  which  have developed from analyzing written [discourse] - or invented sentences\" (2006, p.143).\n\nSecondly,  the  researchers  of  the  reviewed  past  studies  utilized  analytical  tools  that  are  not explicitly intended for metaphor analysis. These researchers used tools that could produce basic frequency and concordance lists, such as #Lancsbox, WordSmith, Wmatrix, and GloWbE web interface.  This  situation  could  be  attributed  to  the  lack  of  specific  analytical  tools  to  analyze metaphors. However, at least two tools are available on the internet for this purpose. The first one is  VU Amsterdam Metaphor Corpus, a corpus tool for metaphor identification by Steen et al. (2010).  The  second  one  is  FinMeter,  a  tool  for  analyzing  Finnish  poetry's  meter  and  rhyme, semantics, and metaphors.\n\nThird, the Conceptual Metaphor Theory (CMT) was still highly referred to across the selected studies. Lakoff and Johnson (1980) who proposed the theory has had more than its fair share of criticism over the years (Cameron, 2007, 2010; Gibbs,2011; Kövecses, 2020; Zhang, 2021). Gibbs (2009),  for  instance,  reported  that  this  theory  had  been  widely  criticized  \"both  as  a  theory  of metaphor use and for its claims about the embodied, metaphorical character of abstract thought\" (2009, p.14). Cserep (2014) seemed to agree with this by suggesting that this theory lacks clarity in some of its statements and only a little attention was devoted to cross-cultural and linguistic aspects\" (2014, p.283). Not only that but after more than thirty years the theory was introduced, more recent theories of metaphors have emerged (Barnden, 2006; Gibbs, 2008; Ortony, 1993; Vega, 2007; Wilson &amp; Carston, 2006, 2008).\n\nFourth, the selected studies from the year 2020 in this review did not focus on investigating metaphors used to report the COVID-19 pandemic, even though it is an exciting area to be looked at. The situation, however, could be linked to the fact that in early 2000, the pandemic was still in\n\n\n## Suggestions for Future Studies\n\n\nThis review examined the recent trend of corpus-based approaches to analyzing metaphor and offered possible gaps and under-researched topics that might be identified in the topic's prior work. It  is  suggested that future studies on this topic could include more specialized corpora that are currently under-researched, especially the spoken ones. Future studies could also initiate analyses of metaphors between different languages or genders to see whether such factors can play a role in how metaphors are employed in discourses. On the other hand, studies on metaphors using the corpus approach have concentrated highly on their conceptualisation and patterns in a corpus or discourse. Therefore, it is high time for such studies to focus on its functions in culture, public communication, ideology or propaganda dissemination, and health, especially during the COVID19 pandemic.\n\nIn  relation  to  the  use  of  metaphor  in  the  pandemic  era,  researchers  can  analyze  plenty  of thought-provoking aspects. These aspects could include different ways on how metaphors explain the virus, how it spreads, where it is being spread to, and how to contain the virus. Furthermore, the types of metaphors used to explain COVID-19, such as war, disaster, and visual metaphors could also be examined.  Apart  from  that, emerging  symbols  and  alternative forms  of communication used metaphorically to symbolize the situations around the pandemic could be another fascinating aspect of metaphor analysis in the pandemic era. This includes symbols such as the 'White Flag' campaign in Malaysia, where Malaysians who were struggling amid a strict lockdown were flying white flags outside their homes as a plea for help,\n\n",
         "The researchers performed this systematic review to offer insights into the trend of the corpus-based approach in studying metaphor in recent years and investigate the potential gaps and under-researched areas in the past literature on the topic. Two research databases, namely Google Scholar and Academics, were explored to collect data. The analysis of metaphor-related research studies published between 2015 and 2020 revealed more than 78 studies dealing with the topic of investigation. After the screening process, 23 studies that met the research criteria were retained for analysis. The selected articles were further analyzed using the two-step analysis involving quantitative and qualitative approaches, i.e., descriptive statistics, and thematic analysis. The findings revealed that metaphor studies employing the corpus approach tend to use existing corpus like the Reference Corpus instead of a specialized corpus. In addition, metaphor studies in this review centered more on written discourse than spoken data. Furthermore, there is also a lack of information on the corpus tool employed in the examined studies. Meanwhile, the thematic analysis unearthed potential gaps and under-researched areas, such as limited studies on COVID-19 metaphor even though the outbreak had started at the end of 2019. Future studies on this research could include more specialized corpora, specifically in the under-researched topics, to fill in the gaps in this area of study.",
         ""
        ],
        [
         "9",
         "9",
         "## 1 Introduction\n\n\nEven a cursory glance at accountancy data shows that German farmers are exposed to high income fluctuations over time (cf. BMEL, 2022). Such fluctuations, with a focus on negative deviations, are known as ' whole-farm risk ' (Berg and Schmitz, 2007; Huirne et al., 2007; Binswanger-Mkhize, 2012; Broll et al., 2013; Tauser and Cajka, 2014; Doms et al., 2018). Whole-farm risk results from the fact that - depending on the production and financial structure - a multitude of upstream random variables ('risk factors') jointly influence how a farm performs economically. Important risk factors include volatile costs, yields, and prices of various farm products. Whole-farm risk in Germany (and other countries) is believed to have increased over the last few decades for three main reasons: (1) Climate change is increasingly leading to yield fluctuations and losses in many regions of the world (Lobell and Gourdji, 2012; Hristov et al., 2020; Schmitt et al., 2022). (2) The phasing out of agricultural price\n\nsupport in the EU exposes farmers to the volatile prices of global markets (von Ledebur and Schmitz, 2011; Bohl et al., 2015). (3) In the aftermath of natural and man-made disasters, shocks in global supply  and  demand  can  cause  vast  price  fluctuations  and  even  temporary  disruptions  in  supply chains.  Exogenous  shocks  that  have  caused  major  disturbances  in  the  world  markets  include  the Covid-19 pandemic (OECD, 2021) and Russia's war on Ukraine (FAO, 2022). However, it is believed that uncertainty in global supply and demand and thus price volatility will continue to increase in the future, even without disruptive shocks (OECD and FAO, 2022).\n\nAs other entrepreneurs, farmers are generally assumed to be risk-averse decision-makers who strive not only for high levels of income but also for low-income volatility (Ziegelbäck and Breuer, 2011; Iyer et al., 2020; Mußhoff and Hirschauer, 2020, p. 339). In other words, they are prepared to accept some loss of income (i.e., pay a ' risk premium ') in return for lower income volatility. To identify the best decisions under risk, not only the level of risk associated with various entrepreneurial decisions must be taken into account but also the individual farmer's degree of risk aversion .  Although much research has gone into the elicitation of individual risk preferences, the accuracy of these elicitations is still in doubt (Moschini and Hennessy, 2001; Eckel, 2019; Hertwig et al., 2019; Grüner et al., 2023). Therefore, practical decision support for farmers is usually limited to quantifying and communicating the risks that are associated with various choices.\n\nMost farms are complex enterprises in that they not only use different inputs, but also produce multiple outputs. As entrepreneurs, it is not the fluctuations of a single upstream risk factor, such as the price or yield of a single product, that farmers are averse to and try to avoid. Rather, they are averse to negative income fluctuations that could jeopardize their standard of living, the development of their farm or even its existence. To make informed choices under risk, farmers must know the wholefarm economic risks ('whole-farm risks') that are associated with those choices. Otherwise, cognitive errors can lead to incorrect decisions that have unintended consequences or even perverse effects. Such effects can occur, for example, when measures aimed at reducing entrepreneurial risk destroy a natural hedge , i.e., a risk reduction mechanism that is effective without the farmer's intervention. Take the pronounced negative correlations between potato yields and prices (BLE, 2022; USDA, 2023, p. 12) that are caused by the market mechanism of supply and demand. A perverse effect occurs, for example, when farmers unintentionally - and possibly unnoticed - increase whole-farm risk precisely because they use costly price hedging instruments that obstruct the 'natural' compensation of low crop yields through high prices (Urban, 2019; Duden et al., 2019).\n\nBefore measuring whole-farm risk - and the impact of a risk management activity on whole-farm risk - two decisions must be made: first, we must specify a metric of the farm's economic performance ('performance indicator') that is meaningful in the respective context. Examples are the total gross margin or cash flow (in diversification, insurance or hedging contexts) or the net present value (in investment contexts). Second, we must identify statistical dispersion measures (e.g., standard deviation, lower partial moments) that adequately capture the volatility of this performance indicator. Following these decisions, the hedging efficiency ( 𝐻𝐸 ) can be used to quantify the relative reduction of the volatility of the performance indicator obtained by a particular risk management activity in a particular farm (OECD, 2000).\n\nVarious internal and external instruments can be used to reduce the risk in farming (Frentrup et al., n.d.; FAO, 2006; Offermann et al., 2017). On the one hand, after decades of increasing farm specialization, the diversification of the production program is again considered as a relevant tool for farm\n\nrisk management (Augère-Granier, 2016; DESTATIS, 2020; Snorek et al., 2023)  On the other, trading . in commodity futures exchanges (CFEs) is increasingly seen by economists and policymakers as a valuable risk mitigation tool for farmers (Veerman et al., 2016; Prager et al., 2020; DBV, 2021, p. 239). Farmers can use CFEs to fix their producer prices months or even years in advance of the production date, without the need for physical commodity exchange and without being exposed to counterparty risk as with bilateral forward contracts.\n\nSo far, the adoption of futures trading by German farmers is quite modest (Schaffnit-Chatterjee, 2010; Adämmer et al., 2014; Möllmann et al., 2018). Furthermore, some farmers who enter into futures contracts seem to use them as speculators hoping to make short-term profits, rather than as producers seeking to mitigate their long-term income fluctuations (Michels et al., 2019). In other words, they bet on negative price developments during the lifetime of the futures contract (Anastassiadis et al., 2014). The generally low uptake of trading in CFEs by farmers raises the question of whether it is as suitable a tool for mitigating whole-farm risk as many non-farmers seem to believe.\n\nAs early as 1848, the largest CFE for agricultural commodities, the Chicago Board of Trade ('CBOT'), was established (CFTC, 2023; CME Group, 2023). In contrast, CFEs for agricultural commodities in Europe were established only in the last quarter of the 20th century (USDA, 2004). A large, marketoriented part of the literature on CFEs focuses on its price-transparency function, price transmission, and the development of forward prices for agricultural commodities over time (Stevens, 1887; Hardy and Lyon, 1923; Morgan et al., 1994; Carter et al., 2011; World Bank, 2022; Miljkovic and Olson, 2023). Another, farm-oriented strain of the literature deals with the potential of CFEs to mitigate risk in farming. This includes the consideration of basis risk, which arises from fluctuating differences between futures prices and local spot prices (Graf, 1953; Pennings and Meulenberg, 1997; Bina et al., 2022).\n\nHedging in CFEs has generally attracted less attention in Europe, including Germany, compared to the US. This can be attributed both to the shorter history of CFEs in Europe and the EU price support system, which for a long time protected the mostly small family farms in Germany from volatile market prices (Pflugfelder, 1991). Prior to 2000, the literature by and large did not concern itself with futures trading by German farmers. But following the phasing out of the price support system after 2000, agricultural specialist journals started to recommend trading in CFEs as a suitable risk management tool for German farmers, without this being scientifically verified (Irps, 2007; Brüggemann, 2008; Steffin, 2008; Hares, 2009a, 2009b; Stöver, 2016; Loy et al., 2017). Most of these articles even failed to recognize that the suitability of a risk management tool depends on its ability to reduce whole-farm risk (Hares, 2009b; Reinsch et al., 2011; Hirschauer et al., 2014a, 2014b). This is probably because the infant scientific literature on futures trading in farming (cf. Mahul, 2003; Ziegelbäck and Breuer, 2010; Ziegelbaeck and Breuer, 2014; Zuppiroli and Giha, 2016; Bohl et al., 2017; Loy et al., 2017; Kellermann, 2018; Penone et al., 2021) had limited itself to highly simplified farm models (with one producer price as the only risk factor), rather than examining the impact of futures trading on the economic risk of the farm as a whole. Focusing exclusively on the price volatility of one product would only be adequate for farms that produce this single product in fixed quantities and at fixed costs (cf. Salhofer and Zoll, 2005).\n\nIn complex agricultural operations, rational risk management decisions must take into account the uncertainty of all output prices and quantities involved as well as the uncertainty of all input prices and quantities involved (Just and Rausser, 1981; Moschini and Hennessy, 2001; Doms et al., 2018).\n\nMcKinnon (1967) was one of the first to go beyond the exclusive focus on output price volatility by considering the uncertainty of both output price and output quantity. However, the study still focused on the sales revenues from a single product and abstracted from the uncertainty in input prices and quantities.  Other  studies  that  jointly  modelled  the  uncertainty  of  sales  revenues  followed  (Rolfo, 1980; Anderson and Danthine, 1983; Lapan and Moschini, 1994; Moschini and Lapan, 1995).\n\nOnly a few studies on futures hedging adopted a whole-farm risk approach and considered that the risk reduction obtained by a risk management activity needs to be measured against the volatility of the economic performance of the whole farm. Turvey and Baker (1989, 1990) investigated the importance of hedging in different financial structures. They used a stochastic model in an expected utility approach to show that hedging activity is positively related to risk aversion and farm financing. Collins (1997) highlighted the innovative, holistic approach of these studies but also emphasized that individual (real farm) data are needed to provide farmers with practical decision-support. Motivated by the search for an economically meaningful lower-partial-moment risk measure, Erchinger et al. (2020) analyzed how diverse hedging strategies would change the probability and extent of falling below the break-even point. While looking at the break-even point - and thus profit - seems to represent a conceptual methodological advance towards a whole-farm risk perspective, the study's unrealistic model assumptions (with the wheat price as the only volatile factor) reduce the study back to an analysis of price volatility. In contrast, Neyhard et al. (2013) acknowledged that the analysis of risk management activities must not be separated from the farm's financial and production structure. Consequently, they took a whole-farm risk approach and examined how futures and options trading in the dairy feed and commodity markets would affect a dairy farm's cash flow variability and thus its ability to service debt. But the study's informational value is limited as it is based on a single farm and simplified assumptions that abstract from real farm data.\n\nOverall,  the  literature  on  the  risk  effects  of  futures  hedging  appears  to  lack  whole-farm  risk  approaches, especially ones based on real-farm data. In the analysis of weather index insurance, in contrast, some studies adopted a whole-farm risk approach based on real-farm data. For instance, Urban (2019) analyzed the hedging efficiency of 20 German farms using different forms of weather index insurance over a 20-year time frame. Duden et al. (2019) further developed this methodological approach and expanded it to a larger sample of 377 farms from the German Farm Accountancy Data network ('Testbetriebsnetz') (BMEL, 2024; Thünen-Institut, 2024). To our knowledge, however, there are no studies that have systematically investigated the efficiency of futures contracts for the mitigation of whole-farm risk in a substantial number of real farms. Hence, little is known about the practical benefits of futures trading for farmers - despite the 'conventional wisdom' that farmers should include more futures hedging into their risk management. We therefore conducted a small pilot study on the risk effects of hedging in a sample of 30 farms in Bavaria (cf. Sigl and Hirschauer, 2022). Contrary to expectations, hedging was associated with an increase of profit volatility in most of these farms. In view of these challenging findings, we now scrutinize the conventional wisdom in a largescale study and investigate how futures trading would have affected the whole-farm risk of 2,197 German farms in the past. The farms under study are located in Bavaria and the new federal states and have different production orientations. Surprisingly, we found that hedging would have increased the variability of farmers income in most cases. This might trigger hedging analysis in other regions and farm types.\n\n\n## 2 Methodological approach and data\n\n\n\n## 2.1 Methodological approach\n\n\nOur analysis is based on accounting data (financial statements) of 2,197 farms over a 21-year period (agricultural business years from July to June, for the period 2000/01 to 2019/20). We use the data in  a  historical  simulation  and  assess  how  various  hedging  strategies  would  have  influenced  each farm's whole-farm risk. The methodology takes into account the brevity of the time series as well as potentially disruptive developments ('discontinuities'). That is, we deliberately refrain from estimating and predicting parametric distributions from the historical data. Instead, we content ourselves with answering the question of how the cash flows that would have been generated by futures contracts would have changed the income fluctuations of each individual farm, and of various types of farms, in the past. Our approach does not explicitly consider the individual risk management regimes (including futures trading) of the farms in the past. Instead, we analyze the risk effects of the hedging strategies under study as additional risk management tool. This provides a meaningful information base from which to derive promising avenues of future research and from which to make educated guesses as to whether and in which contexts hedging can reduce farming risk in in the future. Before carrying out the historical simulation, the following methodological steps are taken.\n\nSpecification of performance indicator: Accounting for the fact that the evaluation of risk management activities cannot be separated from the farm's production and financial structure, we adopt a whole-farm risk approach. To be more precise, we use 'adjusted farm profit' ( 𝐴𝑃 ) as performance indicator, the fluctuations of which are assumed to be the subject of risk mitigation. The 𝐴𝑃 is calculated by adjusting the farm profit from the financial statements for out-of-period income and expenses, and by deducting the opportunity cost of family labor based on the BMEL's standardized wage rates (BMEL, 2023a, p. 136):\n\n<!-- formula-not-decoded -->\n\n(1)\n\n- -Income belonging to other periods\n- + Expenses belonging to other periods\n- -Opportunity costs for family labor\n\nA farm's 𝐴𝑃 represents the ordinary earnings, obtained from its operating activities in a business year, that are available for net investments (farm growth) after the private withdrawals for the living of the farm family. These withdrawals are equated with the standardized opportunity costs for family labor. An 𝐴𝑃 of less than zero thus indicates a loss from ongoing operations and thus a loss of substance, unless capital is raised from external sources. The 𝐴𝑃 is normalized per hectare (ha) to facilitate comparisons between farms of different size.\n\nMeasurement of risk reduction and its costs: We use the 𝐻𝐸 in terms of the relative reduction of the standard deviation ( 𝑆𝐷 ) of the 𝐴𝑃 as main measure indicating the suitability of different hedging strategies for whole-farm risk mitigation. The 𝑆𝐷 is computed from the trend-adjusted time series of the 𝐴𝑃 of each farm . In each year, we compute a fictitious 1 𝐴𝑃 !\"#$\"# by adding the profit or loss from the hedging transaction (including transaction costs) to the 𝐴𝑃 %&amp;!\"#$\"# . All hedging costs and profits\n\nare  allocated  to  the  accounting  period  on  an  accrual  basis.  The 𝐻𝐸 is  determined  for  each  farm through historical simulation ('what-if analysis') spanning from 2000/2001 to 2019/2020. The computation of the 𝐻𝐸 involves contrasting the 𝑆𝐷 of  the  annual 𝐴𝑃 %&amp;!\"#$\"# in  €/ha  with  the 𝑆𝐷 of annual 𝐴𝑃 !\"#$\"# over the 21-year period of analysis:\n\n<!-- formula-not-decoded -->\n\nA positive (negative) 𝐻𝐸 indicates a percentage reduction (increase) in the standard deviation of the trend-adjusted 𝐴𝑃 s that would have been caused by a given hedging strategy.\n\nTaking into account that the distribution of the 𝐴𝑃 might be asymmetric, we complement the 𝐻𝐸 -analysis based on the 𝑆𝐷 with 𝐻𝐸 -analyses based on two downside-risk measures: shortfall risk (frequency of a negative 𝐴𝑃 ) and average shortfall (average level of negative 𝐴𝑃 ). In addition, we assess the costs of each strategy by comparing the 21-year average 𝐴𝑃 * * * * !\"#$\"# to  the  average 𝐴𝑃 * * * * %&amp;!\"#$\"# (after consideration of transaction costs). If a strategy causes a positive 𝐻𝐸 (i.e. a risk reduction) but an income loss on average ( 𝐴𝑃 * * * * %&amp;!\"#$\"# -𝐴𝑃 * * * * !\"#$\"# &gt; 0 ), this loss is interpreted as 'the costs of risk reduction.'\n\nSpecification of hedging strategies: We analyze identical hedging strategies on all farms to ensure comparability across different locations and farm types. All examined hedging strategies are based on taking a short position on the wheat futures contracts 'Milling Wheat No.2' (from Euronext Paris). For all strategies, we choose the future contract with the latest maturity in the year of harvesting. And all strategies are based on the assumption that a long position is taken on July 15th of the respective harvesting year to close out the contract. Both for long and short positions we use the final daily settlement price. If Euronext was closed on the day of the planned execution, the price from the next trading day is selected.\n\nVarying other parameters, such as hedging volume and term, a countless quantity of hedging strategies can be conceived. This study limits itself to examining the 𝐻𝐸 of nine distinct strategies (3×3) by differentiating three hedging volumes ('hedge ratios') and three hedging dates ('hedge durations'):\n\n- 1 Hedging volumes ('hedge ratios')\n- -Routine hedge = 50% of farm-specific average yield\n- -Full hedge = 100% of farm-specific average yield\n- -Levered hedge = 200% of farm-specific average yield\n- 2 Hedging dates ('hedge durations')\n- -Fixed-time hedge: short on October 15 th\n- -Split-time hedge: short (1/3) on October 15 th , January 15 th , and April 15 th\n- -Limit hedge: short (October 15 th - July 15 th ) if futures price &gt; 195 €/ton\n\nFirst, the strategies differ in the dimension 'hedging volume.' Take the 'full hedge' (100%) as example. A full hedge means that the farmer enters into a short position for 100% of the expected wheat quantity in the respective year based on the acreage and the long-term average yield of wheat. The same rationale applies to the other two hedging volumes. The second dimension of a strategy is the hedging date. 'Fixed-time' means that a short position is taken for the respectively specified volume\n\non October 15th in the year before harvesting. In contrast, 'split-time hedge' means that short positions are taken on October 15th, on January 15th, and on April 15th for one third of the specified volume. Finally, 'limit hedge' means that a short position is taken for the specified volume on the first day that a predefined minimum price on the CFE is exceeded, between October 15 and July 15. In this study, we chose a minimum price of 195 €/ton.\n\nDerivation of farm types: To answer the question of whether there are farm types that show particularly low or high 𝐻𝐸 s, we form ex ante clusters based on key indicators that characterize the acreage, the financial and production structure, and the performance of the farms under study. In the cluster analysis (see section 3.2 for details), we identify four distinct farm types based on eight farm-specific characteristics: (1) acreage for farm size, (2) equity share ratio for farm financing, (3) 𝐴𝑃 for  farm performance, (4) average soil quality2 for local production conditions, (5) plant revenue share and (6) aggregated plant+animal revenue share for farm production orientation, and (7) wheat revenue share as well as (8) wheat acreage share as we analyze hedging based on wheat futures. To be more precise, we consider the initial and final level of each indicator by computing their respective averages for the first three and the last three business years of the study period.\n\nK-means cluster analysis (in Python), following the algorithm of Lloyd (1982), is used for clustering the farms ('units') under study. The objective of this grouping approach is to reduce within-cluster variance, that is, to ensure that the observations for each characteristic ('indicator') in the same cluster are as similar as possible and, hand in hand with this, that the observation means ('centroids') of different clusters are as dissimilar as possible. A fundamental decision in cluster analysis concerns the number of clusters into which to group the units under study. While the decision depends on context and the investigator's subjective judgment without there being a clear decision rule, 'cluster inertia' is widely used to help make the decision. Cluster inertia is based on the Total-Within-ClusterSum-of-Squares (TWSS). It describes the fact that the sum of the squared distances - across all characteristics and clusters - between the observations in a cluster (e.g., the acreages of the farms in the cluster) and the cluster centroid (e.g., the mean acreage in the cluster) decreases as the number of clusters increases. After visualizing cluster inertia through the 'Elbow Plot KMeans' (see Appendix 1), we opted for a number of four clusters. This corresponds to the end point of the steepest drop of inertia before the curve flattens out when further increasing the number of clusters.\n\n## 2.2 Data\n\n\n## 2.2.1 Farms under study\n\n\nWe use a dataset containing the individual financial statements of approximately 3,600 farms in Bavaria and the new federal states between the agricultural business years 2000/01 and 2019/20. The dataset represents a large portion of farms in the regions under study. The financial statements conform to the accounting standards of the German Farm Accountancy Data Network (cf. BMEL, 2023b). Due to missing or implausible data, we excluded farms that did not meet the following pre-defined criteria: (1) minimum average wheat yield of 5 tons per hectare, (2) wheat cultivation in at least 17 out of the 21 years of the study period, (3) 𝐴𝑃 between -4.000 € and +4.000 € per hectare and year.\n\nUsing these criteria resulted in a sample of 2,056 farms in Bavaria and 141 farms in the new federal states (see Figure 1). These farms exhibit widely differing acreages and production orientations.\n\nFigure 1: Loca.on of the farms under study and average farm size in Germany by county in 2020\n\n<!-- image -->\n\nSource: own representation based on map and data from DESTATIS (2023).\n\nIn the fiscal year 2019/20, the 2,056 farms from Bavaria under study farmed around 165,000 hectares of farmland and the 141 farms from the new federal states around 31,000 hectares. The sample covers roughly 5% of the farmland in Bavaria and 1% of the farmland in the new federal states Destatis, 2022). Table 1 describes key features of the farms under study.\n\nTable 1: Descrip.ve sta.s.cs of the farms under study in 2019/20 (n=2,197)\n\nSource: own calculations.\n\nIn 2019/20, the farms under study farmed on average 89 hectares (thereunder 9 hectares of wheat) and they used 1.9 person-years of labor (including 1.6 person-years of family labor). The average farm profit amounted to 57,306 €/farm -= ' &amp; ∑ 𝑝𝑟𝑜𝑓𝑖𝑡 5 ( &amp;)*'+, ()' or 641 €/ha -= ' &amp; ∑ -./0(1 ! 23.\"2$\" ! 5 &amp;)*'+, ()' . After factoring in extraordinary effects and the opportunity costs of family labor, the resulting average 𝐴𝑃\n\nper farm amounted to -3,712 € -= ' &amp; ∑ 𝐴𝑃5 ( &amp;)*'+, ()' or -41 €/ha -= ' &amp; ∑ 45 ! 23.\"2$\" ! &amp;)*'+, ()' 5 . Only 13 % of farms showed a negative profit, but 61% of farms had a negative 𝐴𝑃 . With an average profit of 334 €/ha as opposed to 699 €/ha in Bavaria, the farms in the new federal states seem to perform worse than those in Bavaria. But farm profit does not yet take into account the value of family labor which represents the most important form of labor input in the mostly owner-run family farms in Bavaria (sole proprietorships). This is why farms in Bavaria actually perform worse after taking into account the opportunity costs of family labor in the amount of BMEL's standardized wage rates (BMEL, 2023a, p. 136). They have an average 𝐴𝑃 of -54 €/ha whereas the farms in the New Federal States, which are larger and often run as legal entities, realize an average 𝐴𝑃 of 27 €/ha.\n\nFigure 2 displays the 𝐴𝑃 s of all 2,197 farms over the 21-year study period. The farms are sorted in ascending order according to their mean 𝐴𝑃 . To visualize not only the level of the individual performance but also its variability over time, each farm is represented by a whisker-plot.\n\nFigure 2: The level and the variability of adjusted profits ( 𝐴𝑃 ) across all farm (n = 2,197) over the 21-year study period\n\n<!-- image -->\n\nSource: representation based on own calculations.\n\nComplementing the information on the 𝐴𝑃 and its spread in the individual farms, the bar chart in Figure 3 shows how many farms in the sample exhibited which shortfall frequency during the 21-year study period. Each bar represents the number of farms that suffered losses (in terms of negative 𝐴𝑃 s) in the specified number of years. A small share of less than 4 % (100 out of the 2,197 farms) never fell short and achieved a positive 𝐴𝑃 in each year. On the other extreme, 175 farms (or nearly 8 %) fell short in every single year and never achieved a positive 𝐴𝑃 .\n\nAs final descriptive statistic, we determined the skewness of the farm-specific, trend-adjusted 𝐴𝑃 s over the course of the 21-year study period. We provide the skewness information because the 𝑆𝐷 might not adequately inform decision-makers about their downside income risk if the 𝐴𝑃 s are asymmetrically distributed. In approximately 40 % of the farms, the 𝐴𝑃 s are moderately skewed, with absolute skewness being between 0.5 and 1.0. In more than 10% of farms, the 𝐴𝑃 s are highly skewed, with absolute skewness being above 1.0. This result prompts us to complement the 𝑆𝐷 -based analysis of the hedging efficiency with an analysis based on shortfall frequency and average shortfall (see Section 3.3).\n\nFigure 3: Occurrence of farm-individual shorMall frequencies (n=2,197) over the 21-year study period\n\n<!-- image -->\n\nSource: representation based on own calculations.\n\n\n## 2.2.2 Data of futures prices\n\n\nThe daily prices of the relevant wheat futures contracts 'Milling Wheat No.2' from Euronext Paris were obtained from EIKON (2022) database. The short futures contracts with the latest expiration dates of each year were used, and we assumed that a corresponding long position that closes out the contract is entered into on July 15th of the respective harvesting year. This means that a short contract that matures in Dec 2019, for example, is linked with a long position on July 15th 2019. The daily settlement prices for short and long positions were used. If the Euronext was closed on the date of the planned execution, the settlement prices of the next trading day were used.\n\nWheat futures contracts are traded as fixed units of 50 tons. For convenience, we assumed that portions of this quantity can also be hedged (as would be the case for producer groups, for example). The assumed transaction costs include the financing costs for the initial margin (4 % per annum for 10 % of the hedged amount) and the closing costs (60 € per contract or 1,20 € per ton of wheat). Any additional financing costs, for example for margin calls, were not taken into account due to their minor relevance.\n\n\n## 3 Findings\n\n\n\n## 3.1 Impact of hedging on the volaHlity and level of farm profit across all farms under study\n\n\nUsing a box-whisker-plot to visualize the heterogeneity across farms, Figure 4 shows which hedging efficiency in terms of the percentage reduction in the 𝑆𝐷 of the annual 𝐴𝑃 (measured in €/ha; cf. eq. (2)) the nine hedging strategies would have caused across the 2,197 farms in the 21-year study period.\n\nIt is striking that hedging would have only marginally reduced profit volatility on average for the farms under study. The nine strategies caused a mean 𝐻𝐸 between 0 % and 2 %, with the median 𝐻𝐸 being always close to 0 %. The median 𝐻𝐸 was lower than the mean 𝐻𝐸 for all strategies due to the predominance of positive outliers compared to negative ones. Increasing the hedge ratio - from 'routine hedge' over 'full hedge to 'levered hedge' - amplifies the effects of hedging in both directions. The levered hedge, with its larger interquartile range, its longer whiskers, and its wider spread compared to the strategies with smaller hedge volumes, shows this most clearly.\n\nFigure 4:The hedging efficiency ( 𝐻𝐸 ) of all nine hedging strategies across all farms under study (n=2,197)\n\n<!-- image -->\n\nSource: representa@on based on own calcula@ons.\n\nWe also checked whether the 𝐻𝐸 s were substantially different between farm sizes (upper, middle, and lower tercile) and regions (Bavaria as opposed to the new federal states). While the differences in the average 𝐻𝐸 were relatively small when comparing different farm sizes and regions (see Appendix 3 for more details), it is notable that the 𝐻𝐸 s varied more among the generally larger farms in the new federal states than in Bavaria (see Appendix 2 for more details).\n\nBesides 𝐻𝐸 ,  we  also  analyzed how hedging would have affected the level of farm profits. Table 2 shows that the nine hedging strategies would have resulted in losses on average, both in terms of the mean and the median of the annual 𝐴𝑃 in €/ha. This was primarily due to the costs associated with hedging. In order to generate a profit from hedging, the futures market would have to be outperformed. This was not the case. The 'fixed-time strategy' and the 'split-time strategy' resulted in considerable losses in most farms (with a maximum loss of 83 € per ha), whereas an increase of the profit level was observed only in few farms. The 'Limit strategy' showed a nearly break-even outcome.\n\nTable 2: The impact of all nine hedging strategies on the level of adjusted profit (in\t€/ ha and year)\n\nSource: representa@on based on own calcula@on.\n\n\n## 3.2 Heterogeneous effects of hedging in different farm types\n\n\nTo see whether hedging works differently in different farm types, we constructed four clusters following the approach described in section 2.1. The clusters can be described as follows (see Table 3 for more information).\n\n- 1. The ' Specialized livestock farms ' (cluster 1) are characterized by a high proportion of plant+animal revenue (98 % on average), with a share of only 9% coming from plant production. With an average equity ratio of 93%, leverage is very moderate.\n- 2. The ' Specialized  crop  farms '  (cluster 2)  also  have  a  high  proportion  of  plant+animal  revenue (94% on average), but they focus on crop farming, with plant revenue share amounting to 88 % on average. With an average equity ratio of 96%, leverage is even lower than in cluster 1.\n- 3. The ' Leveraged-growth farms ' (cluster 3) are also characterized by a high proportion of plant+animal revenue (97 % on average) and, similar to cluster 1, their main revenue share is from animal production (83% on average). But with a 75% increase in acreage and a 21% relative decrease in equity ratio, they had undergone considerable debt-financed growth. Compared to the other clusters, they exhibit the highest acreage (127 ha on average) and the lowest equity ratio (60% on average).\n- 4. The ' Atypical farms '  (cluster 4)  have a comparable but somewhat lower equity ratio (86% on average) than clusters 1 and 2. Compared to all other clusters, they have a relatively low share of revenue from plant and animal production (46 % on average). During the study period, this share had  decreased  considerably  (by  46%  on  average).  This  indicates  that  farms  in  cluster 4  have changed their business model in the direction of non-agricultural business alignments (e.g., energy production).\n\nTable 3: The medians of the parameters used for clustering in the iden.fied clusters (farm types)\n\n(a) mean of the last three years of the study period; (b) percentage change compared to the mean of the first three years.\n\nSource: representa@on based on own calcula@ons.\n\nWe chose the three full hedge strategies to illustrate the heterogeneous effects of hedging in different farm types. Similar results were found for the other hedge ratios (see Appendix 3 for more details). The comparison of Figure 5 and Figure 4 shows that the results of hedging are very similar both for the different farm types and the aggregate of all farms: on average across farm types and strategies, hedging would have only marginally reduced income volatility. In addition, it would have reduced income levels (see Table 2) As regards differences, however, it is worth noting that the highest level and the greatest heterogeneity in 𝐻𝐸 was observed among the specialized crop farms, with mean 𝐻𝐸 ranging from 2 % to 5 %. In contrast, the average 𝐻𝐸 in the other farm types was close to 0 %.\n\nFigure 5: The hedging efficiency ( 𝐻𝐸 ) of the full hedge strategy in different types of farms (n=2,197)\n\n<!-- image -->\n\nSource: representa@on based on own calcula@on\n\n\n## 3.3 Impact of hedging on shorNall frequency and average shorNall\n\n\nTo determine the 𝐻𝐸 concerning the shortfall frequency, we first determined the frequency of shortfalls in each farm over the 21-year study period. Next, we measured the change in shortfall frequency. The results are shown in Table 4.  A change in shortfall frequency of 3 +1 means that farms would have\n\nsuffered losses (in  terms  of  a  negative 𝐴𝑃 )  in  one  additional  year  due  to  hedging.  Accordingly,  a change in shortfall frequency of -1 means that a negative 𝐴𝑃 would have occurred in one year less.\n\nTable 4: Change in shorMall frequency (no. of nega.ve 𝐴𝑃 s) in the 21-year study period for all farms (n=2,197)\n\nSource: representa@on based on own calcula@ons.\n\nOver the 21-year study period, most farms experienced no change in shortfall frequency across the different hedging strategies. The proportion of farms in which the shortfall frequency changed by more than one year is negligible, with the exception of the levered fixed-time and split-time strategies, which caused shortfalls to increase by more than one year in 9% and 7% of farms, respectively. Depending on strategy, between 5% and 11% of farms achieved a reduction of the shortfall frequency by one year, but between 3% and 22% suffered an increase by one year.\n\nAlong with the small impact on shortfall frequency, the effect on average shortfall (average negative 𝐴𝑃 over all shortfall years) was, as expected, also rather small. On average across all farms, a slight decrease in the average shortfall would have been achieved by the fixed-time and split-time strategies, while a slight increase of average shortfall would have been inflicted by the limit strategy (see Table 5).\n\nTable 5: Change in average shorMall (average nega.ve 𝐴𝑃 over all shorMall years) in € per hectare in the 21-year study period for all farms (n=2,197)\n\nSource: representa@on based on own calcula@ons.\n\nFinally, we can state that the impact of the hedging strategies on shortfall frequency and average shortfall increased as the hedge ratio increases, similar to the impact on the 𝐴𝑃 fluctuations.\n\n\n## 4 Conclusions\n\n\nThe agricultural economics literature dealing with commodity futures hedging does not include many approaches that actually resort to a whole-farm risk approach. Many studies are based on simplified models that abstract from the interdependence of the many risk factors that jointly influence the economic performance of farms with a large number of interdependent inputs and outputs. A widespread, but apparently premature normative view associated with these models is that farmers are too unwilling to innovate and that they should more readily embrace futures hedging as an \"innovative\" risk management tool. Motivated by anecdotal evidence and an explorative study that challenged the established view, we use a large-scale historical simulation to study how various hedging\n\nstrategies would have influenced the income fluctuations ('whole-farm risk') in 2,197 German farms in the 21-year period from 2000/01 to 2019/2020. Based on the accountancy data of these farms, we measure annual farm income via the adjusted profit ( 𝐴𝑃 ). The 𝐴𝑃 factors in extraordinary effects and the necessary withdrawals for living expenses via the standardized living costs (opportunity cost) of unpaid family labor. A negative 𝐴𝑃 thus indicates a situation in which there are equity losses from the current business activities.\n\nContrary to popular belief, hedging would have only marginally reduced or even increased wholefarm risk in most cases and across different farm types and sizes. In addition, on average across farms, most hedging strategies would have reduced income levels due to hedging costs and/or speculative losses, with the exception of the 'Limit strategy' which showed a nearly break-even outcome. In other words, farmers would often not have been able to 'beat the market' and hedging would have led to perverse effects, as it would have caused costs, but would have increased the variability of farm  income  instead  of  the  desired  reduction  of  whole-farm  risk.  Our  simulation  study  provides strong evidence that the general advice that farmers should use more commodity futures hedging to mitigate their income risk is misleading.\n\nWhile we have analyzed a large number of 2,197 real farm operations in different regions of Germany, our study is limited to the particular sample, region, and period of time. The important question therefore is whether and to which other farms and contexts the results can be generalized. The results, in conjunction with the limitations of this study, provide indications for meaningful future research avenues that could shed further light on the usefulness of future hedging for practical farm risk management:\n\nFirst, this study, as any other, could inevitably analyze only a limited number of potential hedging strategies. It must be recognized that other hedging strategies could lead to different results. Therefore, analyzing strategies based on different parameters (e.g., other hedging volumes or dates) and especially strategies based on other types of futures (e.g., grain, corn, rapeseed), up to complex hedging portfolios, and even other types of contracts such as options, could shed further light on the suitability and performance of hedging in agricultural risk management.\n\nSecond, there is the question of the impact of different contexts. Each farm and region possess unique structural characteristics that will impact the outcomes of hedging. While this study has shown that a general recommendation to increase the use of hedging in farm risk management cannot be seriously made, it remains to be seen whether there are particular types of farms or specific environmental and economic conditions where hedging could prove to be an efficient risk management tool that outperforms or can be usefully combined with alternative risk mitigation instruments.\n\nThird, it must be noted that historical simulation is retrospective and that effects that would have occurred in the past if a particular strategy had been used do not automatically translate into valid predictions of future outcomes. This is particularly true in the case of disruptive events, such as climate change might be in certain regions, or Russia's war in Ukraine, as such discontinuities have the potential to substantially alter future trajectories. Nonetheless, it might be worth exploring the potential of established and modern prediction methods including time series analysis and machine learning for the evaluation of hedging strategies in individual farms. At this stage, we would use the results of this study to derive the educated guess (hypothesis) that the performance of futures hedging for the mitigation of whole-farm risk is limited. It appears that there are other, more useful levers on farm level (e.g., diversification).\n\nLast but not least, the heterogeneity of the results between farms emphasizes the fact that each farm and its decision environment is specific. Decision support for a particular farmer on whether or not to use a risk instrument, such as a particular hedging strategy, must therefore always be based on a farm-specific analysis of its cost and its benefits in terms of its potential to reduce whole-farm risk.\n\n",
         "Farmers are often advised to hedge their commodity prices on the commodity futures exchange, without sound scientific evidence to support this. This paper questions this rash advice and ana-lyzes the impact of various hedging strategies based on wheat futures for a large sample of farms in Germany. Historical simulation and a whole-farm risk approach are used to evaluate the hedging efficiency for 2,197 German farms over a 21-year study period. We use “adjusted farm profit” as perfor-mance indicator and measure which relative change in profit volatility these farms would have obtained by nine different hedging strategies. Additionally, a cluster analysis was used to find out whether there are farm types that have particularly low or high hedging efficiencies. Hedging would have only marginally reduced or even increased profit volatility in most cases and across different regions, farm types, and farm sizes. In addition, many farms would even have ex-perienced perverse effects, as hedging would not only have led to increased profit volatility, but also to a reduction in profit levels due to hedging costs and/or speculative losses. This paper presents an in-depth analysis of the effects of hedging based on wheat futures con-tracts. Unlike previous hedging studies that used synthetic farm models or rather small samples, we use a whole-farm risk approach and conduct a large-scale study of 2,197 farms over a 21-year study period. The study results cast substantial doubt on the conventional wisdom that farmers should be generally more willing to include hedging as “innovative” tool into their risk manage-ment.",
         ""
        ],
        [
         "10",
         "10",
         "## INTRODUCTION\n\n\nIn the first half of 2020, when pharmaceutical measures were not yet available, protective behaviour was the only way to contain COVID-19.[1] The prevalence of protective behaviour targeting COVID-19 varied across countries, reflecting distancing policies such as stay-athome orders, social gatherings limitations, or requirements to wear face masks.[2] However, under the same policies, the propensity to use protective measures differed among social categories. This paper contributes to the literature by studying how the interplay of individual characteristics and policies shaped protective behaviour among older adults in 27 European countries.\n\nWe conceptualize protective behaviours during COVID-19 pandemic using the Health Belief Model (HBM).[3,4] HBM lists factors which may shape the probability of health behaviour: (1) perception of threat (comprising the expected risk and severity of infection), and (2) evaluation of behaviour's effectiveness and perceived costs and barriers.[5] Additionally, cues to action (e.g. governmental recommendations) and individual characteristics (e.g. risk aversion) may also affect behaviours.[3]\n\nSupporting HBM, past research showed that people who considered themselves more vulnerable (higher risk of infection) and more at health risk (higher expected seriousness of infection) of COVID-19 were more likely to use protective behaviours, including physical distancing, hand sanitizing, and mask wearing.[6-10] As COVID-19 was a greater health risk among older adults and those with co-existing diseases, protective behaviours were more common among older adults and those in bad health.[8-13] Also risk aversion increased protective behaviours.[14] Consistently with the lower propensity of women to take risky behaviours, women were shown to be more compliant with distancing regulations than men: they were more prone to reduce mobility, sanitize hands often, and wear masks.[10,12,15-18] On the other hand, barriers, such as being employed and obliged to work outside of home, reduced the rate of protective behaviours.[6-8]\n\nHowever, not all protective behaviours are equal. In particular, the literature differentiates between avoidant behaviours, which are focused on avoiding situations perceived as risky (e.g., never leaving home, reducing frequency of walks or social meetings), and preventive behaviours (e.g., mask wearing, hand sanitizing), which aim to reduce the probability of infection in risky situations.[19] Although both avoidant and preventive behaviours were recommended (sometimes enforced) by governments in response to COVID-19 pandemic, the barriers to avoidant behaviour could be higher than barriers to preventive behaviours, especially in more active segments of population. For example, being employed could have made it impossible to never leave home, but was likely compatible with mask wearing. Moreover, although preventive and avoidant behaviours all serve as protective measures, some substitution between them is possible. This happened in Italy when the end of the stay-at-home order forced people to return to their workplaces, which substantially increased mask wearing.[20] Extending this argument, different social groups may be more prone to use different protective behaviours. Specifically, employment or other types of activity may increase the rate of preventive behaviours but act as a barrier against avoidant behaviours. In contrast, being at higher health risk may increase the rate of both avoidant and preventive behaviours. Supporting this, risk-avoidance seems to be the main motivation of using protective measures among older adults and those in poor health.[21] Considering the propensity of women to avoid risky behaviours in general, this also suggests a higher rate of preventive and avoidant behaviours alike. [10,12,15-18]\n\nTo our knowledge, no past research documented the differences in individual predictors of avoidant and preventive behaviours. Providing such evidence for Europe is the first goal of this article. Following the theoretical framework of the HBM and our reading of the literature, we formulate the following hypotheses:\n\n(H1a)  Employment (or other activity) acts as a barrier to avoidant behaviours.\n\n- (H1b)  Employment (or other activity) facilitates preventive behaviours.\n- (H1c)  Older age and worse health (predictors of health risk of COVID), as well as being a woman (associated with less aversion) facilitate avoidant behaviours.\n- (H1d)  Older age and worse health (predictors of health risk of COVID), as well as being a woman (associated with less aversion) facilitate preventive behaviours.\n\nBeyond individual characteristics, also the corresponding policies should affect the propensity of protective behaviours. In terms of HBM, policies and recommendations constitute cues for action, but enforcing policies (e.g. through fines) may also affect costs of certain behaviours. Research confirmed that policies shaped the rate of mask wearing and mobility reductions.[12,17,22] However, strict distancing policies may not be necessary to shape individuals' behaviour. An American study showed that distancing policies explained almost none of mobility reduction in industries with high risk of virus transmission: people reduced their mobility in these sectors before introduction of policies, in response to mere recommendations.[22]\n\nPlausibly, the effect of policies differed across social categories. Research showed that the gender gap in the intention to wear a mask almost disappeared if mask wearing was mandatory.[15,23] It is likely that distancing policies increased behaviours especially in social categories that were most resistant to given behaviour; such mechanism would reduce the importance of individual characteristics under distancing policies. On the other hand, however, policies might serve as a cue on how dangerous the epidemiological situation is. This implies that distancing policies may exacerbate the importance of individual characteristics for protective behaviours. Testing these competing predictions is the second goal of this paper:\n\n- (H2a)  Distancing policies reduced individual differences in protective behaviours.\n- (H2b)  Distancing policies increased individual differences in protective behaviours.\n\nThis study is to our knowledge the first analysis considering individual and countrylevel predictors of protective behaviours on a large cross-national sample. Most studies covered a limited (up to 8) number of countries, which hampered the possibility to systematically study the effects of policies.[16,24] Among exceptions, some studies relied on large international samples (77 or 60 countries), but these analyses did not explicitly measure policies.[3,10] To our knowledge, the only large-scale comparative study that accounted simultaneously for policies and behaviours, measured behaviours merely on regional and not on individual level.[21]\n\n\n## METHODS\n\n\nThe data on individual behaviour came from the Survey of Health, Ageing and Retirement in Europe (SHARE).[25,26] SHARE is a cross-national, multidisciplinary panel study of people aged 50+ initiated in 2004 and coordinated by European Research Infrastructure Consortium. This analysis used data from the special 'Corona Survey' module, run on a subsample of regular panellists between June and August 2020. The data was collected using Computer Assisted Telephone Interviews in 26 European countries and Israel; the sample included people aged 50 or more and their spouses.[27] The total sample included 52,061 respondents; country samples varied between 787 in the Netherlands and 4,519 in Estonia.\n\n\n## Measures\n\n\nOur dependent variables recorded protective behaviour of respondents. Avoidant behaviours comprised (a) not leaving home since the beginning of the pandemic (yes / no), (b) frequency of walks (never / less often than before COVID-19 / the same / more often), and (c) frequency of social meetings (never / less often than before COVID-19 / the same / more often).\n\nPreventive behaviours included (d) frequency of mask wearing when outside of one's home in a public space (always / often / sometimes / never). The Corona Survey recorded also other types of behaviour (such as keeping physical distance from others or sanitizing hands),\n\nhowever the four behaviours mentioned above corresponded most closely to policies implemented by governments.\n\nAmong individual-level characteristics we studied age (linear and quadratic components) and health before the pandemic as measures of potential health risk associated with COVID-19 infection. We included linear and quadratic components of age to allow for non-linear relationship between health and protective behaviour: plausibly, age difference play a smaller role among people in their 60s, but may be much more important at advanced old age. (In the main analysis we estimate linear effects of poor pre-pandemic health; an additional analysis in Supplementary Table 1 showed that including health as a categorical variable produced results fully consistent with our main analysis.) Additionally, we included two measures of activity which might constitute barriers to avoidant behaviours: employment status at the beginning of the pandemic and providing help to other household during the pandemic. Finally, we accounted for gender, as women were shown to be more prone to protective behaviours.\n\nIndividual controls included household structure (single person household / with partner only / with partner and other people / with other people only) to control for the crosscountry differences in population structure of older adults, which could be correlated with the propensity to use protective measures. We also controlled for past experience with COVID-19 ('Did you or anyone close to you experience symptoms that you would attribute to Covid, e.g. cough, fever, or difficulty breathing?' with answers: yes / no), a likely confounder because COVID-19 experience might correlate with protective behaviour and distancing policies. All cases with missing data on any of the individual variables were excluded listwise.\n\nData on policies came from 'Our World in Data' database (Oxford Policy Tracker, https://ourworldindata.org/coronavirus), which provides harmonized statistics on the development of COVID-19 pandemic and tracks the policy responses.[2,28] As individual\n\ndata described behaviour over a period of about 4 months ('since the beginning of the pandemic') we measured policies as duration of period when strict distancing policies were in force. We focused on policies which regulated the behaviours of interest: (1) requirement not to leave the house with exceptions (as opposed to 'recommendation only' or 'no policy'), (2) requirement to wear masks when social distancing was not possible (vs. 'required in some specific places only', 'recommendation only,' or 'no policy'), and (3) restrictions on gatherings of fewer than 10 people (vs. 'less strict restrictions'). For each policy, we used the length of the period (between March, 1 and June, 30) when the policy was in force in given country, expressed in months. Out of 27 countries considered in this paper, 7 counties did not make masks obligatory in spring 2020, and 6 countries did not introduce stay-at-home order (i.e. in these countries the duration of policies was 0). For details of country-level variables see Supplementary Table 2.\n\nTo control for severity of pandemic in a country, we included the maximum recorded daily number of deaths per million of population [2,28]; this is a possible confounder because it may correlate with distancing policies and with the prevalence of protective behaviour. All variables are summarised in Table 1.\n\nTable 1. Sample characteristics\n\nSource: Own calculation based on SHARE Corona survey (June-August 2020) and Ritchie et al. (2020).\n\nNotes: 'S.D.' - standard deviation, 'Min' - Minimum, 'Max' - Maximum, 'Nr obs'- number of observations\n\n\n## Analytical methods\n\n\nWe used the statistical method of multilevel regression. Multilevel regression controls for clustering of individual observations within countries, and it is the method of choice for crossnational comparative data, especially for estimating effects of country-level characteristics, such as policies.[29] We estimated random intercept models, which assume that the crosscountry variation of protective behaviour has a random component. To investigate the effects of individual characteristics and policies on prevalence of protective behaviours, we inspected the main (fixed) effects of relevant variables. To investigate social differences in the effects of policies (H2a-b), we inspected cross-level interactions, i.e. interactions between individual characteristics and policies. For dichotomous outcome (never leaving home), we estimated multilevel logistic regression models; for ordered categorical dependent variables we estimated ordered logit models. As effect sizes from such models are difficult to interpret, we additionally present the predicted probabilities of protective behaviour.\n\n\n## RESULTS\n\n\n\n## Descriptive results\n\n\nFigure 1 presents the cross-country variation in the prevalence of protective behaviours and duration of distancing policies. Little over 18% of respondents declared that they never left home between the outbreak of the pandemic and the study period (June/July 2020). The variation among countries was large, with the lowest value in Denmark (2.2%) and the highest value in Malta (49.7%). Among older adults who ever left their homes, 46.2% reduced frequency of walks (11.8% in Denmark, 91.4% in Romania), 56% never met five or more persons from outside of their household (22.1% in Slovakia, over 70% in Luxembourg, Slovenia and Italy), and 58% declared always wearing a face mask in public (1% in Netherlands and Denmark, 90% in Luxembourg, Portugal, and Italy).\n\nNot only behaviour but also policies showed considerable cross-country variation. Between March, 1 and June, 30 2020, stay-at-home policies lasted on average 1 month (from zero in Denmark, Sweden, Finland, Switzerland, Latvia, and Slovenia to 2.5 months in Israel), restrictions on gatherings of 10 or fewer people lasted on average 2.1 months (from 0.7 in Bulgaria up to 3.5 in France), and face mask were required for on average 1.4 months (from zero in Denmark, Finland, Hungary, Estonia, Germany, the Netherlands, and Sweden up to 3.1 months in Israel).\n\nFigure 1 suggests a link between duration of distancing policies and protective behaviours: overall, longer policies correlated with a higher propensity of behaviour. However, the variations in behaviours for a specific duration of policies was considerable. For instance, with over 2-months of stay-at-home order, over 80% of respondents reduced walk\n\nfrequency in Spain, but only 40% reduced walks frequency in Belgium. Among countries where face masks were not required by national policies, over 70% of respondents in Hungary and Germany always wore them, whereas almost nobody always wore masks in Finland, Denmark and the Netherlands. In Malta, where about 50% of respondents never left their homes, stay-at-home order lasted less than a month. These examples suggest that policy restrictions were only one among various factors shaping people's behaviours: people voluntarily adjusted their behaviour (probably in response to recommendations or information) even if distancing policies were absent or short-term.\n\n## &lt;&lt; FIGURE 1 HERE &gt;&gt;\n\n\n## Multivariate analysis\n\n\nTable 2 shows the results of multivariate regression of protective behaviours on individual and country-level characteristics. (For a simpler model without cross-level interactions, see Supplementary Table 3.) We expected (H1a) that employment or other activity (providing help to other households) may constitute a barrier to avoidant behaviours, such as never leaving home, reducing walks, and reducing social meetings. Consistently, the odds of avoidant behaviours were lower among employed than among non-employed, and were lower among people providing help to other households than among people not providing help. The effects of employment and providing help to other households were statistically significant for all types of avoidant behaviours, which supports the hypothesis.\n\nWe also postulated (H1b) that employment or other activity facilitated preventive behaviours. In fact, probability of mask wearing was higher among employed than among non-employed. However, the probability of mask wearing was not related to providing help to other households. Hence, the support for H1b was only partial.\n\nFurthermore, we expected (H1c) that higher health risk of COVID-19, as approximated by older age and worse health, as well as women's propensity to avoid risks, positively\n\ncorrelated with avoidant behaviours. Indeed, the odds of avoidant behaviours were higher at older age and for individuals with worse pre-pandemic health. The effect of age was quadratic for never leaving home and for reducing the frequency of walks, whereas propensity to reduce social meetings increased linearly with age. (For detailed analysis modelling health as a categorical variable, see Supplementary Table 1.) Moreover, the odds of all avoidant behaviours were higher among women. The above patterns are consistent with hypothesis H1c.\n\nHypothesis H1d postulated that health risk of COVID and women's risk aversion facilitated also preventive behaviours, i.e. mask wearing. However, in our estimates, the odds of mask wearing did not differ linearly with age: they were highest around the age of 70, and they were lower among the younger and older respondents. (For an illustration of health effects for protective behaviours see Supplementary Figure 1.) Nonetheless, the probability of mask wearing was higher among people with worse pre-pandemic health, and it was higher among women than among men. The support for H1d is therefore partial.\n\nModels in Table 2 show also the effects of policies. Two policies seem to have systematically affected behaviour: longer duration of gathering restrictions increased the odds of reducing social meetings, and longer duration of policies requiring mask wearing increased the propensity to wear a mask. The duration of stay at home order was not related to the odds of never leaving home, and correlated with the odds of reducing walks only in the model without cross-level interactions (Supplementary Table 3). Additionally, the longer the duration of stringent policies, the higher was the prevalence of mask-wearing, which suggests that aspects of policies not directly related to mask wearing served as cues informing people that the epidemiological situation was serious, which could indirectly encourage wearing masks.\n\nAn additional analysis excluded the countries which did not introduce the respective policies (see Supplementary Table 4), and showed that the effect of mask wearing policies was driven by the difference between countries where masks were and were not compulsory. In other words, once the policy has been introduced, the duration of policy did not correlate with propensity to wear masks. However, the cross-level interactions in Supplementary Table 4 inform that longer mask wearing policies increased the propensity to wear masks in specific groups: among women and older respondents.\n\nTo inspect the interplay of policies and individual characteristics, we focus on the crosslevels interactions (Table 2), which inform about differential effect of policies in various groups. The pattern of results was mixed. First, for some outcomes, longer duration of distancing policies reduced social differences in protective behaviours. This applied to never leaving home: longer stay-at-home order reduced mobility among older people less than among the young, which contributed to closing the age gap. Similar pattern showed up also for reducing the frequency of social meetings: longer gathering restrictions reduced social meetings among employed people (OR=1.38, p&lt;0.001), among men (OR=0.89, p&lt;0.001), and healthier persons (OR=0.95, p&lt;01) more than among (respectively) the inactive, women, and people in worse health. This decreased social differences (between employed and nonemployed, between men and women, and between people with excellent and poor health) in reduction of social meetings. Similarly, longer enforcement of mask wearing reduced health differences in the propensity to wear a mask. These patterns are consistent with the hypothesis (H2a) that longer duration of distancing policies reduced social differences in protective behaviours.\n\nHowever, this pattern was not universal. In particular, longer stay-at-home order reduced women's propensity to walk more than it reduced men's, thus increasing gender differences in reducing walks. Also the differences in walk reduction between employed and\n\ninactive people were greater under longer stay-at-home order. This pattern is consistent with hypothesis H2b, suggesting that in some cases distancing policies served as a cue that epidemiological situation is serious.\n\nFigure 2 shows predicted probabilities to give an overview of effect's sizes. The predictions show that the gender gap in avoidant behaviours amounted to less than 10-15 percentage points, whereas the activity gap (i.e. the effect of being employed or providing help to other households) only exceptionally exceeded 10 percentage points. The biggest was the effect of pre-pandemic health: the gap in avoidant behaviours between those in poor and those in excellent health was in most cases above 15 or 20 percentage points. The gaps were visibly smaller for preventive behaviour (i.e. mask wearing) than for avoidant behaviours. Finally, social differences in never leaving home were larger in countries with longer duration of distancing policies. In contrast to that, social differences in meetings frequency and mask wearing typically reduced with longer duration of distancing policies.\n\nRecognizing the importance of gender differences, we run an additional analysis inspecting gender differences in the effects of cross-level interactions (see Supplementary Table 5). Our results showed few gender differences in the determinants of protective behaviours, suggesting that the patterns described in this paper hold for men and women alike.\n\nTable 2. Prevalence of protective behaviour as a function of individual and country-level predictors. Multilevel logistic (Model 1) and multilevel ordered logit (Models 2-4) models with cross-level interactions of individual characteristics and national policies.\n\nSource: Own calculation based on SHARE Corona survey (June-August 2020) and Ritchie et al. (2020).\n\nNote: * p&lt;0.05; ** p&lt;0.01; *** p&lt;0.001. OR - odds ratios, S.E. - standard errors.   all country-level variables are centred on grand average a\n\n\n## DISCUSSION\n\n\nThis study assessed how the interplay of individual characteristics and national policies shaped the prevalence of COVID-19 protective behaviours among older adults during spring 2020. Social groups differed in the propensity to use protective behaviours. Being employed and providing help to other households increased (although slightly) the probability of mask wearing, but reduced avoidant behaviours, such as never leaving home, reducing frequency of walks or social meetings. In contrast, old age and poor health were associated with higher propensity of almost all protective behaviours (the only exception was mask wearing which was not higher among older people). Additionally, the rate of all protective behaviours was higher among women than among men. Longer duration of distancing polices correlated with more frequent protective behaviours, but behaviours seemed to be shaped also by other factors, probably recommendations and information. Moreover, the effect of duration of policies imposing mask wearing captured mainly the difference between countries which introduced compulsory masks and the countries that did not. Finally, distancing policies reduced social differences in the rate of protective behaviours only in case of social meetings and mask wearing.\n\nThe strength of this analysis lies in the broad cross-national data for 27 countries, which allowed us to simultaneously account for national policies and individual characteristics. Such a set-up, integrating policy-level and individual-level predictors is rare in the literature. The main limitation of our study is that the measures of policies were unavoidably a simplification of a very complex reality. For instance, the rules might have been to a various degree enforced by authorities (e.g. the risk of receiving a fine in case of noncompliance could differ among countries), which plausibly affected protective behaviours. Moreover, some policies were introduced on sub-national level (e.g., regional), but neither the individual nor policy measures used in this analysis allowed an analysis across regions.\n\nSecond limitation is that policies and behaviours changed over time. Our data did not allow a dynamic analysis, and provided a snapshot summarizing the period between March and June 2020. Finally, our results pertain to the early stage of the pandemic, and may not accurately represent the patterns of behaviour in later periods.\n\nIn practical terms, our study contributes to the body of evidence on the effectiveness of policies in shaping people's behaviour. Our results suggest that, although policies shaped protective behaviour, their role was limited: some social groups, in particular those at health risk, used protective behaviours even in the absence of policies or if the distancing policies were introduced for brief periods. Probably such behaviours responded to recommendations and information. This conclusion is aligned with previous research [22], showing that protective behaviours were chosen voluntarily before introduction of distancing policies. This suggests that not only the policies, but also softer measures (such as recommendations and information) may effectively shape people's behaviour.\n\nThe second results with practical implication are the social differences in the rate of protective behaviours. This is especially important considering that some behaviours, especially the avoidant ones, may negatively affect mental health.[30] Especially people at health risk were likely to resort to avoidant behaviours even in the absence of policies. Despite vaccination programs, COVID-19 infection will remain a health risk for a fraction of society. Monitoring and reducing the mental health consequences of long-term avoidant behaviours in these groups should be among policy goals.\n\nOur results describe behaviours during spring and summer 2020, and may not be valid in later periods. Verifying these patterns for other periods and countries may be the topic of future studies. Moreover, our results suggest that - above and beyond distancing policies also recommendations and information were driving protective behaviours. However, due to data limitations, we were not able to verify of these conclusions. Future research may do this\n\nif suitable data becomes available. Finally, understanding mental health consequences of restrictive policies and protective behaviours is indispensable for informed policy choices during the further stages of this, and perhaps other pandemics. For this reason, a systematic evaluation of mental health consequences of behaviours and policies is a promising avenue for future studies.\n\n",
         "OBJECTIVES: Evidence on how individual characteristics and distancing policies during the first wave of COVID-19 together influenced health behaviours is scarce. The objective of this study is to fill in this gap by studying how the propensity to engage in protective behaviours in Europe was shaped by the interplay of individual characteristics and national policies. \nDESIGN: Data on individual behaviour in 27 countries came from the “Corona Survey” module of the Survey of Health, Ageing and Retirement in Europe, collected in summer 2020. As outcomes, we considered avoidant behaviours (never leaving home, reducing frequency of walks, reducing frequency of social meetings) and preventive behaviour (wearing a face mask). Among relevant policies we considered stay-at-home restrictions, mask wearing policies, and gatherings’ restrictions. Individual characteristics comprised gender, health risk of COVID-19 (older age and poor health), and activity (employment and providing help to other households).\nPARTICIPANTS: Nationally representative samples of older adults (50 years and over); N=51,540 respondents (58% of women).\nRESULTS: Active people (employed and helping other households) were more likely to wear face masks, but less likely to use avoidant behaviours. People at health risk (older people and those in poor health) were more likely to use all types of protective behaviours. Protective behaviours were also more frequent among women than among men. Longer duration of distancing polices correlated with more frequent protective behaviours. Distancing policies reduced social differences in the rate of protective behaviours only in case of social meetings and mask wearing.\nCONCLUSIONS: Protective behaviours responded to distancing policies, but our results suggest that people used them voluntarily, especially if they were at health risk.",
         ""
        ],
        [
         "11",
         "11",
         "## 1. Introduction\n\n\nPreprints are well-established in some fields but not in all. Preprint servers make scientific work available rapidly (albeit usually in a form prior to peer review) and also openly, enabling scientific work to be accessed in a timely way not only by scientists but also by policymakers, journalists and others. The COVID-19 pandemic led to an unprecedented rise in the use of preprints by the biomedical research community. Preprints were an essential part of the communication of research about COVID-19, useful in particular as a way of accelerating communication of research results. Another potential benefit of preprints is that they allow authors to receive and incorporate feedback from the wider community prior to journal publication (Fraser et al., 2021). Nevertheless, due to the non-peer-reviewed nature of preprints, concerns about the lack of quality assurance remain (Blatch-Jones et al., 2023; Ni &amp; Waltman, 2023). Partly in response to these concerns, there are a growing number of services that facilitate evaluative peer feedback (e.g., comments, recommendations, reviews) on preprints. Some of these services may even be seen as alternatives to journal-based peer review, pointing towards possible future approaches to overcoming weaknesses of the journal-based peer review system.\n\nIn Figure 1, we summarise some of the potential benefits of services facilitating the review of preprints, as they are commonly presented in sources such as the websites of preprint review services, blog posts and scientific articles. In this paper, we will explore how preprint review services are trying to achieve these benefits and how they may add value to the scholarly communication system, pointing out to a cultural shift in peer review (Avissar-Whiting et al., 2023).\n\nOur aim is to develop a systematic understanding of the main characteristics of preprint review services in order to evaluate how these services manage preprint review and to position these services in the wider scholarly communication and peer review environment, including journal publishing. By a preprint review service, we mean a journal-independent peer review service for articles posted on a preprint server, where the peer review process is publicly visible. We report here a descriptive study based on a qualitative analysis of data available in the ReimagineReview registry and other online sources, such as the websites of preprint review services, blog posts and scientific articles. This paper is complementary to a study recently reported by Lutz et al., (2023) of an ongoing survey of Alternative Publishing Platforms. By providing additional information on preprint review services, we are contributing to the work of gaining a better understanding of the landscape formed by these platforms and how they can be placed in the open scholarly communication ecosystem.\n\nWe have opted not to use the term 'peer' when discussing platforms for the review of preprints, adopting instead the designation 'preprint review services', distinguishing them from 'journal-based peer review'. This better reflects the diversity of review approaches facilitated by preprint review services - from the spontaneous posting of feedback by individuals to community-driven review platforms - and considering that feedback on preprints is not bound by the conventions often associated with journalbased peer review - in fact, a variety of forms of preprint feedback are evident,\n\nranging from minimal 'ratings' and informal approaches to in-depth formal peer review (Avissar-Whiting et al., 2023).\n\nIn our work, we use as an analytical lens a framework recently proposed by some of us (Waltman et al., 2023) in which a distinction is made between four schools of thought on peer review. The four schools, referred to as the Quality &amp; Reproducibility school, the Democracy &amp; Transparency school, the Equity &amp; Inclusion school, and the Efficiency &amp; Incentives school, provide a framework for organising innovations in the peer review space, grouping them in terms of how they perceive problems of peer review and develop solutions in response to these problems. We discuss these in detail in the analysis below. We suggest that the four schools framework offers a useful way to better understand the complexity of innovation in preprint review. Based on our analysis, we reflect on possible future models of peer review and scholarly communication that may arise from the experimentation we are currently witnessing.\n\nFollowing a description of our methods in Section 2, Section 3 provides an overview of services facilitating the review of preprints. Section 4 discusses the contribution of preprint review services in addressing the various issues raised by the four schools of thought on peer review. Section 5 explores how preprint review services are managing apparent tensions between different aims, namely the ones resulting from the anonymisation of reviewers and authors. Section 6 discusses how preprint review services fit into the publishing landscape and how they may influence the development of this landscape, and Section 7 presents some concluding remarks.\n\n\n## 2. Methods\n\n\nWe carried out a descriptive study using qualitative analysis. We used ReimagineReview (RR) as a starting point to identify services and initiatives to facilitate the review of preprints. RR is a registry of services and experiments around peer review of scientific outputs created by ASAPbio (n.d.). For additional information, we supplemented the directory data with desk research using online sources such as the websites of preprint review services, blog posts and scientific articles. Using ATLAS.ti Windows (version 23.0.8.0), we carried out a qualitative analysis of text from the relevant sites, assigning codes covering what they do and why they have chosen to do it that way. Where there was ambiguity in project descriptions, we contacted the service managers to clarify and confirm some details.\n\nAs of April 2022, the RR directory listed 35 services for preprint review. For our study, we considered only the services where the process of reviewing preprints was visible. ReimagineReview also includes services that do not publish reviews. We did not consider these services. We finalised the selection and analysis of services for our study in November 2022. The web sites of two preprint review services included in our initial set became unavailable after November 2022. These are the CrowdPeer and the Red Team Marked. As CrowdPeer became unavailable before we finished the analysis, we could not check and describe its main characteristics, as we did for the other services, including the Red Team Marked. Therefore, we decided not to include CrowdPeer in our final set of 23 services for review of preprints. Nevertheless, based on our initial analysis and the information available in the RR directory, we have included some comments on CrowdPeer as an illustration of possible future models of peer review and scholarly communication, where relevant. Red Team Marked was taken out of operation later and so we were able to include it in our analysis. On the other hand, some services have evolved and for these services our analyses, as a snapshot, may not be fully up-to-date. This is the case for Rapid Reviews: COVID-19, which has expanded beyond COVID-19. And so, Rapid Reviews: COVID-19 is now Rapid Reviews\\Infectious Diseases, an open-access overlay journal that accelerates peer review of important infectious disease-related research preprints (RR\\C19, n.d.).\n\nTo provide an overview of the 23 services included in our final set, we first described their main characteristics according to six categories: 1) project name, 2) developed by, 3) scientific disciplines, 4) goals and intentions, 5) peer review approach, and 6) approach to transparency. Under 'developed by', we used three categories: publisher, university or individual researcher or group of researchers. When detailed information was not available online or was available but not sufficient to support our classification, we contacted the service managers, asking them to tell us how they would describe who the project is led by. We used the 'other' category for those who did not answer us and where ambiguity remained.\n\nFor the definition of scientific disciplines, we grouped all disciplines identified among our set into five categories considering the usual organisation of the scholarly communication landscape: Physical Sciences, Biomedical and Life Sciences, Engineering and Technology, Social Sciences, and Humanities. We considered the All Disciplines category for services hosting any scientific discipline or having a multidisciplinary approach without a clear definition of the disciplines or sub-disciplines included.\n\nTo discuss how preprint review services fit into the publishing landscape and how they identify possible future models of peer review and scholarly communication, we then analysed the stated goals, review approach and transparency, using previous studies as a baseline to discuss and validate our findings, addressing the following questions:\n\n- ● How do these services differ from, and what do they have in common with traditional peer review? How are they linked with the four peer review schools of thought recently proposed by some of us (Waltman et al., 2023), and how do they manage connections between schools when adopting ideas from multiple schools?\n- ● How can preprint review supplement journal-based peer review or offer an alternative for journal-based peer review?\n\nOur use of the four schools of thought framework enabled us to explore how innovation and experimentation promoted by preprint review services can address the journalbased peer review challenges identified by Waltman et al. (2023) and provide possible solutions and future directions. We assessed the contribution of preprint review services against the key issues identified in the four schools of thought framework, considering the stated goals and intentions of each service, their approach to peer review, and their commitment to openness and transparency. As Waltman et al. (2023) state, these schools have different views on the key problems of the peer review system and the innovations needed to address these problems. While the schools may at times complement each other, the differences in their views may also give rise to tensions. Based on this idea, we aim to understand how preprint review services are able to manage possible tensions when bringing together the key issues of different schools.\n\nFinally, we identified possible future models of peer review and scholarly communication that may arise from the experimentation we are currently witnessing.\n\n\n## 3. Overview of preprint review services\n\n\nOur final set, presented in Table 1, consists of 23 services for review of preprints some developed by newly-established groups, others by pre-existing organisations, such as publishers or universities. Some of them are focused only on reviewing preprints (7 services), others review preprints and journal articles (14) or privately shared manuscripts (5) or other types of scholarly outputs (11). The most represented\n\ncategory of developers is individual researcher or group of researchers (15 services), followed by others (5), publishers (2) and universities (1). The most represented scientific disciplines are all disciplines (12 services) and biomedical and life sciences (8), followed by physical sciences (3), social sciences (3), engineering and technology (2), and humanities (1).\n\nTable 1: Overview of the services for review of preprints\n\nTable 2 lists the different approaches to peer review transparency and openness taken by the preprint review services. Offering alternative publication options or alternative approaches to quality assessment compared with the traditional journal-based model is a common goal for all services. One of the key motivations in encouraging review of preprints is to enable authors to benefit from having their work reviewed and improved before submission to a journal. This is often seen as having the potential benefit of reducing rounds of journal re-review. Some services also often give credit to reviewers as a way of incentivising participation. Review of preprints is often explicitly said to address the need for quality control of preprints, reinforcing confidence in the use of preprints and making the evaluation of scientific work more efficient and more open and transparent. Transparency is an evident priority in services that implement one or a number of different aspects of open peer review identified by Ross-Hellauer (2017) including 'open reports' (where reviewer reports and author responses are published), 'open identities' (where the identities of authors and reviewers are known to each other), 'open interaction' (direct unmediated exchange between authors and reviewers is enabled), 'open participation' (where reviewers can self-nominate and add comments without being invited to do so), amongst others. In some cases, like in Review Commons, transparency applies only to review reports and not the reviewer's identity. In others, like in SciPost and Peer Community In, reviewers have the option to withhold their identity, becoming visible only to editors or editorial staff. There are two services, Peer Community In and Hypothesis, that support double-anonymous peer review, in which not only reviewers but also authors can withhold their identity.\n\nThe services promote new communication patterns regarding quality assessment and reviewer selection (Table 2). Public post-publication reviews, recommendations, comments, free-form commenting or quantitative scores are among the different assessment approaches we identified. When considering the seven services that are restricted to reviewing preprints, the most frequent quality assessment approach is the structured review form (where reviews are input using standardised structured headings). This approach is used by 4 services: PREreview, PeerRef, Review Commons and Sinai Immunology Review Project. In respect of the reviewer's selection, apart from 2 services (Peeriodicals and Peer Community In), selection of reviewers does not depend on the editor's decision only. We identified 7 services that allow reviewers to be selected by an editor, the editorial staff, or the community and 2 services where reviewers are selected by an automated tool. There are 12 services where reviewers can be self-nominated. Although the use of an automated tool constitutes an innovative approach to the selection of reviewers, it is not limited to preprint review services. When compared to journal-based peer review, the selfnomination of reviewers is an important innovative aspect of preprint review services, enabling reviewers to get involved in an ostensibly more participative and interactive review process. Self-nomination means that basically anyone can serve as a reviewer on a platform, without intervention from an editor, editorial staff or anyone else. In most cases, reviewers just have to be registered on the platform to make a comment or recommendation, or to endorse a preprint based on a pick and choose format (e.g., the Plaudit endorsement tool).\n\nSome initiatives offer services that go beyond the review process itself. PreLights and PREreview, for instance, invest in reviewer training for early-career researchers and in other initiatives focused on promoting and recognising reviewers.  Prelights provides assessments of reviewers (peer review of peer reviews), or recognition for reviewers' contributions. PREreview organises training workshops centred on issues of equity, diversity, and inclusion.  Another focus of some services is reproducibility, a key issue relating to the quality of scientific outputs. The aim of overcoming or mitigating the lack of quality control associated with preprints and of addressing issues of reproducibility is visible in the policies and procedures of some of the services. This is the case for Queios, Scibase and Peer Community In, which request authors to make code and data openly available and then ask reviewers to consider the code and data in their review.\n\n*Information not available or not identified\n\nTable 2: Different approaches to peer review transparency and openness\n\n\n## 4. Preprint review services through the lens of four peer review schools of thought\n\n\nWe use the four peer review schools of thought recently proposed by some of us (Waltman et al., 2023) as a framework to discuss the developments around preprint review services. Waltman et al. (2023) proposed four schools of thought on innovation in peer review, each of which has a different emphasis on what the key problems are within current peer review systems and what the priorities should be for improving these systems. Below, we present the focus of each school of thought, as previously described by Waltman et al. (2023):\n\n- ● The Democracy &amp; Transparency school focuses on making the evaluation of scientific research more democratic and transparent. Concerned that peer review systems are often elitist and opaque, this school advocates broader participation in the review process to increase the accountability of editors and peer reviewers and enable information produced in peer review to be reused by others.\n- ● The Quality &amp; Reproducibility school focuses on the role of peer review in evaluating and improving the quality and reproducibility of scientific research. Based on concerns about inconsistent quality associated with peer review processes, this school is interested in innovations in peer review that improve the quality of review reports and published research. Another focal issue for this school is safeguarding research integrity and identifying scientific misconduct.\n- ● The Equity &amp; Inclusion school focuses on making peer review processes more equitable and inclusive. This school is given impetus particularly by concerns about bias in peer review systems. It emphasises the need for a balanced representation of different groups of researchers in the peer review system to reduce or eliminate biases related to gender, geography, race, ethnicity, etc.\n- ● The Efficiency &amp; Incentives school focuses on improving the efficiency of peer review processes and the incentives for peer reviewers. This school is concerned about the pressure on the peer review system, which makes it increasingly difficult to find peer reviewers, emphasising the need to increase the efficiency of peer review and to better incentivise reviewers.\n\nWe assessed the characteristics of the 23 preprint review services against the key issues raised by the four schools of thought, considering the stated goals and intentions of each service, their approach to peer review, and their commitment to\n\nopenness and transparency. Based on those criteria, we identified how each service could be associated with each of the four schools of thought. This gives us insight into key issues, such as where the priorities of the different services lie, how they are managing apparent tensions between different aims, and to what extent they are delivering on their objectives. These designations are discussed in more detail in the following sub-sections.\n\n\n## 4.1 Making peer review more democratic and transparent\n\n\nCalls for more transparent and open peer review approaches are a common feature of discussions about peer review. Recently, Kelly-Ann Allen et al. (2022) presented the lack of transparency as one of the three main challenges of peer review, together with the exploitative nature and the slowness of peer review. Based on a wide-ranging conversation on X (the social-media platform previously known as Twitter), they identified the need to open the 'black box' of the current peer review system as the most constructive way to 'fix peer review'. According to Fernandez-Llimos (2023) to minimise the peer review crisis, we should start recognising peer reviewers by acknowledging their contribution in every single paper they reviewed, and we can do this most effectively in open peer reviews.\n\nBy assuming a commitment to openness and transparency, preprint review services are already arguably trying to 'fix peer review', challenging authors, reviewers, editors, and publishers to rethink and adjust their practices. Openness and transparency are common goals for all services included in our study, meaning that they all support the ideas of the Democracy &amp; Transparency school. All services in our study provide open review reports and promote open interactions among authors, reviewers and users. Still, Table 2 presents several variations in the peer review approach, selection of reviewers, management of their identities, transparency and openness. It is evident that transparency and openness have different meanings and are applied differently by different services. Managing reviewers' identities is perhaps one of the biggest challenges the services face. As highlighted by Chloros et al., (2023) open peer review involving open identities enables better recognition of the contribution reviewers make. However, for many researchers, revealing their identity may raise concerns, like the fear of retaliation, and this may result in them providing less critical feedback. In Section 5, we discuss how preprint review services deal with this tension and how they balance transparency and openness with the interests and concerns of reviewers.\n\n\n## 4.2 Improving quality and reproducibility\n\n\nThe Quality &amp; Reproducibility school emphasises the crucial role of peer review in improving and certifying the quality of scientific work. A focus on quality is evident in preprint review services that train reviewers, evaluate reviewers' work, check for competing interests, and pay attention to ethics and integrity. As can be seen in Table 2, in addition to unstructured reports, preprint review services also use structured review forms, quantitative scores, and scales or ratings, showing the broad range of approaches taken by preprint review services to assess and improve the quality of scientific work. Many preprint review services have adopted ideas of the Quality &amp; Reproducibility school, thereby showing their commitment to rigorous preprint review and positioning themselves as promoters of high-quality and reproducible research. Faculty Opinions for instance states that the 'caliber' of its reviewers and the 'rigour' of the validation they provide ensure the quality of the research recommended by them. At Peer Community In, reviewers evaluate preprints in their thematic fields based on 'rigorous peer review' and 'conflicts of interests are carefully checked at each step of the process'. Plaudit considers that 'publisher-independent endorsements' provided by 'known and trusted academic community members provide credibility for valuable research'.\n\nHigh-quality standards in peer review are often highlighted as essential for improving research quality and reproducibility (e.g., Chambers &amp; Tzavella, 2022).  As the attention given to the lack of reproducibility in research grows (e.g., Brendel, 2021; Errington et al., 2021),  improving the reproducibility of research is increasingly seen as one of the responsibilities of peer review. This is reflected in the goals and intentions of some preprint review services and their policies and procedures. Examples of services for which this is the case are Scibase, Qeios and Peer Community In.\n\nSciBase states that 'science has a reproducibility problem\" and argues that 'only through honest public discussion can post-publication review become part of the scientific process, meaning that the reviewer's identity is known to the public.' Reproducibility is one of the dimensions evaluated in SciBase's review approach, which combines a report and an approval status (scale or rating). The overall rating provided by a review is a weighted average of the ratings of each of the individual dimensions, with the reproducibility dimension having the highest weight (25%). The other dimensions are logic/design, impact, transparency, clarity and versatility (15%\n\neach). SciBase also enables users to rate reviews themselves on a 1-5-star scale, with the intention of promoting transparency, rigour, accountability and reviewer recognition.\n\nWith the aim of improving quality and reproducibility, some services, like Qeios and Peer Community In, require authors to make all study data, digital materials, and computer code publicly available at the time of submission to the maximum extent permissible by the relevant legal or ethical restrictions. Scripts, simulation code, software parameters, etc., are prerequisites for submission. Also, reviewers are asked to check that authors provide sufficient details for the methods and analysis to allow replication by other researchers, considering statistical analyses and consistency of raw data and scripts, among other critical issues. As Peer Community In states, with these prerequisites, it aims to 'establish a high-quality, free, public system for identifying high-quality preprints, after rigorous peer-review.' In addition to these examples, other services like Hypothesis and Peer Library make guidelines, recommendations or other support documents available to reviewers.\n\n\n## 4.3 Making peer review processes more equitable and inclusive\n\n\nJournal-based peer review is often perceived to be susceptible to disparities, inequities, and bias (e.g., Bancroft et al., 2022). The need to make peer review processes more equitable and inclusive is the focus of the Equity &amp; Inclusion school. Supporters of this school often emphasise the need for a balanced representation of different groups of researchers in the peer review system to avoid biases related to gender, geography, race, ethnicity, etc.\n\nAn increasing amount of attention is paid to underrepresented groups in publication and peer review processes, aiming to contribute to diversity, equity, and inclusion (Royal Society of Chemistry, n.d.). Increasing diversity amongst editors, reviewers and authors is starting to be reflected in some editorial policies and practices. A key aim is to address biases in peer review against underrepresented groups. Concerns around peer review bias highlight the complexity of social interactions among actors involved in peer review and raise questions about the nature of the various forms of bias discussed in the literature (Lee et al., 2013).\n\nAn important example of a preprint review service explicitly addressing inequities and biases, with special attention to reviewers, is PREreview. By providing opportunities for\n\ntraditionally marginalised research communities to get involved, train, connect, and be recognised for their contributions to scholarship, PREreview aims 'to bring more equity and transparency to scholarly peer review.' At the same time, with the stated aim of helping researchers think deeply about how assumptions or biases may affect their assessment of manuscripts, PREreview developed the Bias Reflection Guide (Foster et al., 2021).  This tool reflects the perspective of the Equity &amp; Inclusion school. This guide is provided to help students and researchers to make their approach to peer review more inclusive and less biased.\n\nPREreview enables reviewers to publish reviews with their public names (connected to ORCIDs) or pseudonyms provided by the platform. This is intended to allow reviewers to critique the work they review without fearing negative consequences, particularly if the author is more senior than the reviewer. In this way, 'PREreviewers', particularly those belonging to vulnerable communities, may 'contribute to open preprint review without fearing retribution or judgment that may occur when their full name is attached to the feedback, whilst retaining an element of accountability'. From the point of view of reviewers, protecting their identities can be expected to reduce the likelihood of bias based on factors such as gender, ethnicity, or institutional affiliation. Arguably, it protects reviewers against retaliation and encourages rigorous and honest feedback. Preprint review services take several different approaches to handle issues related to the identity of reviewers. Even for services that invite reviewers to embrace 'full transparency (i.e., critics' names and their criticisms are made publicly available)', as Read Team Marked does, revealing one's identity is not always mandatory (Table 2). Reviewers' identities may be protected if they wish. Some services enable reviewers to choose whether they want to sign their review reports, others protect the identity of reviewers with a nickname or a pseudonym. Another approach is taken by Crowd preprint reviews, which aggregates the comments of different reviewers in a final synthesised review that is 'publicly posted, without linking specific comments to the commenter.' Rapid Reviews: COVID-19 (RR:C19) emphasises global diversity. It works with a 'global team, including board members and reviewers from all regions', and reviewers can be anonymised upon request.\n\nAnother approach promoted by the Equity &amp; Inclusion school is double-anonymous peer review, in which not only reviewers but also authors are anonymous. This approach is hard to implement in the context of preprint review. Nevertheless, some services make an effort to facilitate double-anonymous peer review in special situations. We will discuss this in more detail in Section 5.2.\n\n\n## 4.4 Improving peer review efficiency and reviewer incentives\n\n\nPeer review is often seen as overloaded (e.g., Nguyen et al., 2015; Okuzaki et al., 2019), and there is a lot of discussion about faster and more efficient approaches to peer review. Reducing inefficiencies in peer review constitutes a big challenge for journals, where the expectation typically is that a separate review process is carried out for each submission to each journal, including submissions previously rejected by other journals. By providing journal-independent portable review, preprint review services may reduce re-reviewing at multiple journals and increase the efficiency of peer review. On the other hand, depending on the extent to which journals are willing to adjust their processes and consider re-using preprint reviews, we might ask whether preprint review initiatives are, in fact, adding to an already overburdened system by creating even more work? In Section 6, we address these questions in more detail.\n\nWith regard to portable peer review, ten years ago, Swoger, (2013) argued that rejection takes time and energy from authors, reviewers and editors, and that portable peer review reduces re-reviewing at multiple journals, increasing the efficiency of the process. Swoger pointed out the role that new \"portable peer review\" services, independent of specific journals, could play in cutting down on redundant work by separating the review process from the publication process.\n\nThis illustrates one of the key issues emphasised by the Efficiency &amp; Incentives school, which focuses on improving the efficiency of peer review processes and the incentives for peer reviewers. This school is concerned about the pressure on the peer review system, in which it is increasingly difficult to find peer reviewers. Approaches to make review processes more efficient and reduce re-reviewing at multiple journals are facilitated by various preprint review services, like Rapid Reviews: COVID-19, PeerRef and Review Commons, together with initiatives to incentivise researchers by making their work more visible and recognised. Nevertheless, according to the experience reported by the Rapid Reviews: COVID-19 service, so far, there is no hard evidence that journals would want to take into account their reviews. Despite the effort made to balance rapidity and rigour and making peer review more efficient, not all journals are receptive to establishing formal relationships with preprint review services, to have access to a feed of reviews that could supplement their review process.\n\nPreprint peer review services may also address problems arising from the \"reputation economy\" for reviewers (Swoger, 2013). CrowdPeer, for instance, allowed reviewers 'to build their reputations within the community and benefit professionally.' By implementing a reviewer evaluation system, in which the quality of a reviewer's work is evaluated, CrowdPeer brought together key issues from the Democracy &amp; Transparency school (accountability) and the Efficiency &amp; Incentives school (recognition). Another example is preLights. By providing a 'platform where earlycareer researchers can practise their scientific writing and reviewing skills,\" this service aims to raise the profiles of early-career researchers as \"trusted preprint selectors and commentators.\" preLights provides recommendation letters to support early-career researchers.\n\nThe attribution of a DOI (Digital Object Identifier) to public review reports makes the reviewer's work fully citable and claimable as a scientific output, and promotes recognition of reviewers. This is another way to help reviewers to gain recognition for their efforts. It is implemented by several services, like Rapid Reviews: COVID-19, Interactive Public Peer Review, and preLights. In addition, Rapid Reviews: COVID-19 and Plaudit link researchers, identified by their ORCID, to the research they have evaluated, identified by a DOI.\n\nFor Science Open Reviewed, a 'paid service [for reviewers] combined with published reviewer acknowledgement' may promote higher quality reviews, provide 'fair and motivating compensation' for professional peer review services and 'minimise reviewer bias and promote greater reviewer accountability.'\n\n\n## 5. Managing tensions between schools of thought:\n\n\n## Anonymisation of reviewers and authors\n\nIn some cases, key priorities of different peer review schools of thought can be achieved alongside each other by the same preprint review service. For example, the Efficiency &amp; Incentives school and the Democracy &amp; Transparency school seem to complement each other in various ways. It may therefore be relatively easy for a preprint review service to embrace the ideas of both of these schools. This is, for instance, illustrated by CrowdPeer, although interestingly, this service is no longer operational. By providing 'open review of preprints and engagement of a diverse group of reviewers,' it aligned with the Democracy &amp; Transparency school, making the evaluation of research more democratic and transparent. At the same time, CrowdPeer\n\nalso aimed to improve the efficiency of review processes by providing 'a universal structure for reviews to standardise the review process' and providing an 'educational tool for reviewers.' In that way, CrowdPeer aimed to reduce the pressure on the review system, in line with the Efficiency &amp; Incentives school.\n\nIn other cases, however, there are tensions between different peer review schools of thought, reflecting different perspectives on how peer review can best be organised. As we discuss in the next sub-sections, managing the identities of reviewers and authors is one of the biggest challenges preprint review services faces.\n\n\n## 5.1 Anonymisation of reviewers\n\n\nThe Equity &amp; Inclusion school promotes anonymity of reviewers, as we have seen. It sees anonymity as a way to protect reviewers against possible negative consequences of critical reviews. Especially researchers who are in an early career stage or who otherwise find themselves in a vulnerable position may fear such negative consequences. Anonymity makes it easier for these researchers to perform peer review and therefore arguably contributes to more inclusive approaches to peer review.\n\nThe Quality &amp; Reproducibility school may also be supportive of anonymity of reviewers, based on the rationale that anonymity enables reviewers to be more frank and therefore results in higher-quality peer review. However, anonymity of reviewers is in tension with the ideas of the Democracy &amp; Transparency school. This school prefers to organise peer review as an open dialogue in which authors and reviewers participate on an equal basis, with each party accountable for their contributions. Organising peer review in this way is difficult or even impossible when reviewers are anonymous.\n\nAs shown in Table 2, with respect to transparency and openness, preprint review services provide different options. To balance transparency and protect reviewers' interests, some services (13) enable reviewers to decide whether to sign their reviews, becoming anonymous or non-anonymous to the public. Others (8) require a nonanonymous review. In addition to the option of signing or not signing reviews, another solution already mentioned is to protect reviewers under a nickname or a pseudonym. This approach is a way in which preprint review services manage tensions between peer review schools of thought, in particular between the Democracy &amp; Transparency and the Equity &amp; Inclusion schools. PREreview is explicit that it aims to bring 'more equity and transparency to scholarly peer review by supporting and empowering\n\ncommunities of researchers, particularly those at early stages of their career\", but in doing so, it arguably also limits transparency. For Hypothesis, enabling reviewers to use a pseudonym promotes 'transparency and credibility without public identity,' although it is evident that they are managing a tension between these two aims. In relation to reviewers' identity, these services attempt to balance the idea of transparency and the accountability it brings with protections for reviewers where they might experience negative consequences if their identities were disclosed.\n\nAnonymity of reviewers also poses a challenge for the Efficiency &amp; Incentives school. To incentivise reviewers, this school emphasises the importance of giving recognition to reviewers. However, when reviewers are anonymous, it is difficult to publicly recognise them for the efforts they make, other than to say a particular reviewer has reviewed for a particular service without any more detail than that. In particular, associating reviewers with the text of the review, and recognising their contribution at that level of detail, becomes difficult. In addition, anonymity of reviewers may also complicate the reuse of reviews, making it difficult for editors to recognise the competency and credibility of reviewers, thereby undermining the desire of the Efficiency &amp; Incentives school to make peer review more efficient.\n\nThis highlights how complex and challenging it can be for a preprint review service to manage tensions between different priorities, like transparency, rigour, recognition, and equity and inclusion, with tensions related to anonymity in peer review being among the most challenging ones.\n\n\n## 5.2 Anonymisation of authors\n\n\nFor the Democracy &amp; Transparency and the Efficiency &amp; Incentives schools, performing peer review after publication, not before, offers an important way to enhance the transparency and efficiency of peer review. Hence, these schools take a critical stance towards double-anonymous approaches to peer review, in which not only reviewers but also authors are anonymous. Anonymity of authors is incompatible with the idea of performing peer review after publication. On the other hand, the Equity &amp; Inclusion school supports double anonymity, arguing that anonymity of authors reduces bias in peer review and therefore contributes to making peer review more equitable and inclusive. As already pointed out, the Quality &amp; Reproducibility school may perceive reducing bias as a way to improve the quality of peer review and may therefore also support double anonymity.\n\nIn our set of preprint review services, there are two, Peer Community In and Hypothesis, that state they offer double-anonymous peer review (Table 2). For Peer Community In, double-anonymous peer review is not a regular practice but may happen exceptionally by request to fulfil the author's needs. To submit an article anonymously to Peer Community In, the authors must use a private web-based interface (e.g., Google Docs, Dropbox or GitHub). Data, scripts and codes must also be made available through a private web-based interface. In this way, the names of the authors do not need to be disclosed to the reviewers evaluating the article, making it possible to have a double-anonymous evaluation. If the article is eventually recommended by the recommender overseeing the peer review process, the authors must deposit a final, non-anonymised version of their article in an open archive. Although Hypothesis also claims to facilitate double-anonymous peer review, it is not clear to us how this is actually done.\n\nDouble anonymity is essentially incompatible with preprint review. Still, although it is less transparent, it may be argued to be more inclusive because it attempts to avoid biases related to gender, geography, race, ethnicity, etc. This is clearly a compromise an attempt to manage the tensions between the drive for transparency, characteristic of preprinting, with that of inclusiveness. By offering double-anonymous evaluation of an article, Peer Community In and Hypothesis offer a peer review process that is very similar to traditional closed journal-based peer review, making us question if one should refer to this as preprint review.\n\n\n## 6. How do preprint review services fit into the publishing landscape?\n\n\nPreprint review services typically position themselves as complementary to journalbased peer review. The idea of being a 'complementary service with no intention of competitiveness' (Peer Community In) is present in the stated aims of almost all preprint review services, which for instance, make the argument that they enable researchers to 'innovate and explore new approaches to scientific dissemination, in parallel to the traditional publishing industry' (Peeriodicals). PeerRef states its aim to 'provide researchers with greater choice in how their research is shared and evaluated, and eliminate the need for repeated peer review in successive journals' is a key way in which this complementarity works. Some services implement their complementary role in the system by working directly with affiliate, friendly or partner journals, including the emerging overlay journals model (Rousi &amp; Laakso, 2022), such as the ones hosted by\n\nEpiscences, where open-peer review reports must be available on an open repository, data repository or software heritage. Other services support journals in more indirect ways, for instance by helping editors find 'new research they may not have otherwise discovered' (Rapid Reviews: COVID-19) and reducing re-reviewing. In this way, preprint review services arguably help to organise peer review in more efficient ways.\n\nHowever, the success of preprint review initiatives as a complementary service to journal-based peer review depends on the extent to which journals are going to adjust their processes and are going to make use of preprint reviews. According to Saderi and Greaves (2021), editors may be open to these new developments only under certain conditions. To better understand if and how preprint reviews may help make journalbased peer review processes faster and more efficient, Saderi and Greaves asked editors of the journals involved in the COVID-19 Rapid Review (OASPA, 2020) initiative to fill out a short survey. Based on a small number of responses, they concluded that any progress towards an integrated workflow between preprint reviews and journalbased peer review would take a coordinated effort by different stakeholders and that this effort must focus on building mutual trust: on the one hand, the trust by editors in preprint reviews and, on the other hand, the trust by authors and reviewers that their contributions will be valued and recognised.\n\nIf journals are not interested in making use of preprint reviews, preprint review services arguably leave themselves open to the criticism that they put even more pressure on an already overburdened system by adding another layer of review on top of journalbased peer review. Rather than developing ways to improve publishing and peer review workflows, the services might be seen as unnecessarily adding further complexity to the system. The viability of preprint review services may depend on how they address this criticism - for example by arguing that they offer alternative publication options to authors and help to turn peer review into a more rewarding experience for authors and reviewers.\n\nNevertheless, while almost all preprint review services we examined ostensibly aim to supplement the current journal-based publishing system, some also identify the possibility of more radical change, aiming for more ambitious reforms of scientific publishing, considering that 'the quality of published work must stand on its own, without the crutch of impact factors, journal prestige, `likes', `thumbs up', or the artificial stamp of approval signalled by the label 'peer review'  (Researchers.One), or to relieve the pressure on authors to publish their work in 'top-tier', but often paywalled journals\"\n\n(Plaudit). Despite some resistance from editors to partner with preprint review services, some journals are already exploring review of preprints by themselves, or partnering with preprint review services. This raises a key question: Should preprint review services just be seen as a complement to journal-based publishing, or could they potentially offer an alternative to journal-based publishing?\n\nAt present, preprint review services seem to opt for a cautious approach, avoiding a radically disruptive position that could compromise their future development. However, after this first stage of experimentation, the increasing maturity of preprint review services and the involvement of and recognition from the research community may possibly enable these services to position themselves as an alternative, rather than a complement, to journal-based publishing. As discussed by Kramer et al. (2022), the dissemination function of journals may be taken over by preprint servers (although the term 'preprint' may no longer be appropriate), while preprint review services may take over the evaluation function of journals. In the most extreme outcome, conventional journals may cease to exist, and scientific publishing may take place entirely on preprint servers and preprint review platforms.\n\nEdmunds (2022), editor in chief at GigaScience Press, argues that as standalone movements, the several models and experiments developed to improve the journal system, 'were a harder sell, but now, working together, they interact and support each other synergistically'. Like Edmunds, we believe that preprint review services offer important opportunities to improve the publishing process by improving transparency, accountability, efficiency and speed. Moreover, Edmunds highlights that 'research culture has also been changing, with younger researchers seeing transparency and openness as a norm, and funders and publishers endorsing and promoting such efforts'. Edmunds is probably right that 'time seems to have finally arrived' for preprinting combined with open and portable peer review.\n\n\n## 7. Conclusions\n\n\nTo provide a systematic understanding of the main characteristics of preprint review services, we carried out a descriptive study of 23 services. We described how the services have been set up to manage preprint review and how they fit into the publishing landscape. Based on this, we identified possible future models of peer review and scholarly communication.\n\nWe used the four peer review schools of thought framework (Waltman et al., 2023) to explore how innovation and experimentation promoted by preprint review services can address the challenges of traditional journal-based peer review and provide possible solutions and future directions. Our analysis gave us insight into key issues, such as where the priorities of the different services lie and how they manage tensions between schools, reflecting different perspectives on how peer review can best be organised.\n\nThe most important tension that we identified relates to anonymisation of reviewers and authors. In line with the ideas of the Democracy &amp; Transparency school, preprint review services promote more open forms of peer review in which authors and reviewers participate on a more equal basis. However, from the perspective of the Equity &amp; Inclusion school, this raises concerns. To make peer review processes more equitable and inclusive, this school emphasises the importance of enabling anonymisation of reviewers and possibly also authors, which is in tension with the focus on openness and transparency of preprint review services.\n\nPreprint review services have the potential to address a number of key issues in scholarly communication and peer review. By providing quality control, preprint review services can enrich the value of preprints, reinforce confidence in their use, and make the evaluation of research more efficient and more open and transparent. In addition, preprint review services may improve accountability and recognition of reviewers, supplement journal-based peer review, reduce the need for re-submissions, and review at multiple journals.\n\nThe scholarly communication landscape seems to be moving toward a mixed system in which preprint servers, preprint review services and journals operate mostly in complementary ways. Preprint review services currently seem to avoid a radically disruptive position. Still, after a period of experimentation, their increasing maturity may enable these services to position themselves as an alternative, rather than a complement, to traditional journal-based publishing. In the longer term, preprint review services may, therefore, disrupt the scholarly communication landscape in a more radical way.\n\nDespite the potential to either complement existing scholarly communication services or even replace them, it is apparent that at present many preprint review services face problems of sustainability. During the period of our analysis, two services, CrowdPeer and Red Team Marked, were taken out of service. Whilst the reasons for their closure\n\nare not entirely clear, it is obvious that many of the services we studied are built with small budgets and have uncertain funding streams. They typically rely on the enthusiasm and commitment of volunteers. Achieving financial stability will be a challenge for many of these services, particularly if they wish to maintain the independence from large commercial interests, which many of them currently have.\n\n",
         "Preprinting has gained considerable momentum, and in some fields it has turned into a well-established way to share new scientific findings. The possibility to organise quality control and peer review for preprints is also increasingly highlighted, leading to the development of preprint review services. We report a descriptive study of preprint review services with the aim of developing a systematic understanding of the main characteristics of these services, evaluating how they manage preprint review, and positioning them in the broader scholarly communication landscape. Our study shows that preprint review services have the potential to turn peer review into a more transparent and rewarding experience and to improve publishing and peer review workflows. We are witnessing the growth of a mixed system in which preprint servers, preprint review services and journals operate mostly in complementary ways. In the longer term, however, preprint review services may disrupt the scholarly communication landscape in a more radical way.",
         ""
        ],
        [
         "12",
         "12",
         "## The mediating role of school absenteeism in the socioeconomic achievement gap\n\n\n\n## 1. Introduction\n\n\nThe  strong  relationship  between  socioeconomic  status  (SES)  and  academic  achievement  is  a  wellestablished finding worldwide (Chmielewski, 2019; Chmielewski &amp; Reardon, 2016; Kim et al., 2019; Sirin, 2005). However, the underlying mechanisms of SES-achievement gaps are less well understood. A variety of factors contribute to socioeconomic disparities in achievement, including differences in parents' investments in their children's human capital, parenting and parent-child interactions, home learning environment, school segregation, and peer effects (e.g., Conger et al., 2010; Cooper &amp; Stewart, 2020; Guryan et al., 2008; Langenkamp &amp; Carbonaro, 2018; Mayer, 1997; Shaw &amp; Shelleby, 2014; van Ewijk &amp; Sleegers, 2010). Despite extensive research, over half of the SES-achievement gap remains unexplained, even after accounting for these known mechanisms (Dräger &amp; Pforr, 2022; Rodríguez Sánchez, 2023; Washbrook et al., 2014).\n\nTo  advance  our  understanding  of  the  mechanisms  underlying  SES-achievement  gaps,  we  focus  on children's absences from school. Quantifying its role has significant implications for policy and practice as it can inform the need for targeted attendance interventions to reduce these gaps. If differences in attendance are found to play a significant part in achievement gaps, policymakers and educators can prioritize initiatives to improve attendance among students from lower socioeconomic backgrounds. School attendance is thus a potential way for schools to contribute to intergenerational social mobility (UK Social Mobility and Child Poverty Commission, 2014).\n\nIt is reasonable  to  assume  that  school  attendance  mediates  the  relationship  between  SES  and achievement given that students from lower socioeconomic backgrounds are more likely to miss school\n\n(e.g., Gee, 2018; Gennetian et al., 2018; Gottfried &amp; Gee, 2017; Klein et al., 2020; Lim et al., 2019), and that school absences are detrimental to academic achievement  (e.g., Aucejo &amp; Romano, 2016; Gottfried, 2010, 2011; Gottfried &amp; Kirksey, 2017; Kirksey, 2019; Smerillo et al., 2018). Despite the vast evidence of these empirical relationships, only two studies  have examined the extent to which absences contribute to SES-achievement disparities (Gershenson et al., 2017; Morrissey et al., 2014). We  build  on  these  studies  by  using  more  comprehensive  measures  of  SES,  moving  beyond  the commonly used proxies such as eligibility for free or reduced-price lunch found in school administrative data, which are notably limited in capturing the full complexity of SES (Domina et al., 2018; Harwell &amp; LeBeau, 2010). Most importantly, we appropriately account for other potential mediators of the SESachievement  gap,  such  as  early  cognitive  ability  and  behavior,  which  may  also  influence  school absences (i.e., exposure-induced mediator-outcome confounders).\n\nSpecifically,  our  research  seeks  to  provide  a  comprehensive  understanding  of how  school  absences contribute to SES-achievement gaps at the end of key stage 1 (KS1) in England when children are aged seven.  Early  schooling  is  particularly  important  to  consider  because  foundational  skills  developed during these years set the stage for future academic success, and disparities that emerge early on can widen  over  time.  We  draw  on  linked  survey  and  school  administrative  data  from  England  to comprehensively measure SES, pupils' school absences, and academic achievement. We use natural direct  and  indirect  effects  and  a  regression-with-residuals  approach  (Wodtke  &amp;  Zhou,  2020)  to appropriately  deal  with  exposure-induced  mediator-outcome  confounders  and  to  test  for  effect heterogeneity.\n\n\n## 2. Literature review\n\n\n\n## 2.1 Family SES and school absences\n\n\nChildren from lower socioeconomic status (SES) families face various structural barriers that negatively impact their development and educational outcomes, including increased risks of school absenteeism. The bioecological model (Bronfenbrenner, 1993) explains how SES shapes children's interactions with their  environment,  influencing  their  attendance  through  factors  like  neighborhood  conditions  and available  resources  (Gottfried  &amp;  Gee,  2017).  The  specific  mechanisms  by  which  SES  influences absences can be further understood through micro-level theories such as family investment, family stress, and cultural capital theories. For instance, the investment model suggests that financial hardship limits families' ability to invest in health, nutrition, and housing, affecting children's well-being and, subsequently, school attendance (Mayer, 1997; Shaw &amp; Shelleby, 2014). The family stress model, on the other hand, highlights how economic pressure heightens parental stress, leading to family discord, punitive parenting, and inadequate monitoring, all of which drive children's school attendance (Conger et al., 2010; Kiernan &amp; Huerta, 2008). Finally, cultural capital theories posit that schools favor middle-\n\nclass  norms,  which  can  alienate  children  from  lower  SES  backgrounds,  thereby  reducing  their engagement  and  attendance  (Bourdieu,  1977).  Collectively,  these  psychological  and  sociological theories illustrate how SES determines the conditions in which children grow, influencing their school behavior and absenteeism through developmental, health, family, and school-related mechanisms.\n\nAlthough research directly linking SES to school absenteeism via different mechanisms is limited (Gee, 2018), studies show that SES links to many predictors of school absences. For instance, children from low-income families are more likely to develop behavioral problems, which is a common predictor of absenteeism (Classi et al., 2012; Corville-Smith et al., 1998; Gubbels et al., 2019; Ingul et al., 2012). Health issues in childhood and adolescence also play a mediating role, with conditions like obesity (Rappaport et al., 2011), asthma (Mizan et al., 2011; Moonie et al., 2006), as well as physical (Currie, 2009; Evans &amp; Kim, 2007) and mental health challenges (Burton et al., 2014; Richards &amp; Hadwin, 2011;  Wood  et  al.,  2012)  being  more  prevalent  among  children  from  lower  SES  backgrounds, contributing to higher rates of absenteeism.\n\nIn addition to behavioral and health issues, several other factors associated with low SES influence school absenteeism. These include a higher likelihood of substance abuse (Engberg &amp; Morral, 2006; Goodman &amp; Huang, 2015), frequent school transfers (Alexander et al., 1996; Nolan et al., 2013), and exposure to environmental hazards (Chen et al., 2002; Conte Keivabu &amp; Rüttenauer, 2022; Gilliland et al., 2001). Poor school facilities (Durán-Narucki, 2008), reduced access to reliable public transportation (Gottfried, 2017; Stein &amp; Grigg, 2019), and living in neighborhoods with higher crime rates (BurdickWill et al., 2019) are additional challenges that disproportionately affect students from disadvantaged socioeconomic backgrounds, further exacerbating their risk of absenteeism.\n\nConsequently, students from lower socioeconomic backgrounds miss school more frequently than those from higher socioeconomic backgrounds (Gennetian et al., 2018; Gottfried &amp; Gee, 2017; Morrissey et al.,  2014).  Further,  Klein  et  al.  (2020)  found  that  different  dimensions  of  SES  (parental  education, parental  class,  free  school  meal  registration,  neighborhood  deprivation, and  housing tenure)  have  a unique impact on the risk of absenteeism. Recent systematic reviews report effect sizes for SES on absenteeism ranging from 0.11 to 0.16 standard deviations (Gubbels et al., 2019; Sosu et al., 2021).\n\n\n## 2.2 School absences and achievement\n\n\nThe primary explanation of why absences harm achievement is a loss of exposure to learning inputs caused by students' absence from school. Absent students miss out on teacher-led lessons and classroom activities  that  foster  learning  and  development  (Kirksey,  2019;  Morrissey  et  al.,  2014). The  Faucet Theory states that children's learning is like a faucet that flows when they are regularly exposed to educational inputs (Entwisle et al., 2001). When students are absent, this tap is effectively turned off, disrupting the flow of learning opportunities and impeding academic progress. Regular attendance is\n\nthus  linked  to  better  educational  outcomes,  as  more  time  in  school  allows  for  continuous  learning (Bodovski &amp; Farkas, 2007; Marcotte &amp; Hemelt, 2008).\n\nAbsenteeism has an impact on achievement not only because of missed academic content but also due to the loss of social and developmental opportunities. Students who are often absent are less likely to engage with peers, may feel less connected to them, and struggle with classroom engagement, which negatively affects their academic growth (Korpershoek et al., 2020). Absenteeism is also associated with problem behaviors (Ansari &amp; Pianta, 2019; Rocque et al., 2017) and reduced socio-emotional skills, such as self-efficacy and self-management (Gottfried, 2014; Santibañez &amp; Guarino, 2021), both of which can have negative effects on children's academic achievement (e.g., Chowdry et al., 2011; DiPrete &amp; Jennings, 2012; Kanopka et al., 2020; Mcleod &amp; Kaiser, 2004). Consequently, absenteeism does not only hinder immediate academic performance but also undermines critical skills essential for future success.\n\nSome  researchers  argue  that  school  absences  serve  more  as  a  marker  for  students'  underlying disadvantages rather than direct causes of lower achievement (Pyne et al., 2021; Singer et al., 2021). Factors such as poverty, family instabilities, health problems, and negative schooling experiences often confound the relationship between absences and achievement. For instance, (Pyne et al., 2021) found that  controlling  for  comprehensive  measures  of  SES  significantly  reduces  the  association  between absences  and  achievement. Additionally,  unobserved  factors  like  parent-teacher  communication  or educational aspirations likely confound this relationship (Hancock et al., 2017; Pyne et al., 2021).\n\nNevertheless,  studies  using,  for  instance,  fixed  effects  analyses  or  instrumental  variable  estimation consistently  show  that  school  absenteeism  has  a  significant  negative  impact  on  students'  academic achievement (e.g., Aucejo &amp; Romano, 2016; Gottfried, 2010, 2011; Gottfried &amp; Kirksey, 2017; Kirksey, 2019;  Klein  et  al.,  2022;  Morrissey  et  al.,  2014). According  to  these studies,  a  one  SD  increase  in absences results in a 0.05 to 0.20 SD decrease in achievement, depending on the sample, subject area, and research methods used.\n\nThe  detrimental  effects  of  absenteeism  can  begin  early.  For  example,  frequent  absences  from kindergarten  have  been  linked  to  lower  cognitive  skills,  such  as  working  memory  and  cognitive flexibility, as well as lower literacy skills by adolescence (Ansari &amp; Gottfried, 2021; Ansari &amp; Pianta, 2019). Similarly, studies have linked absenteeism in both elementary and secondary schools to longterm academic challenges, such as lower grade point averages (GPA), a higher likelihood of school dropout, and a lower likelihood of graduating from a four-year college (Smerillo et al., 2018).\n\n\n## 2.3 Heterogeneous absence effects by SES\n\n\nSchool  absences  could  have  a  greater  negative  impact  on  students  from  lower  socioeconomic backgrounds. Children from disadvantaged families frequently face many stressors, including financial insecurity, poor health, and limited access to educational resources. These students may be less able to\n\ncompensate for missed lessons at home because their parents  do not have the time, knowledge, or resources to help them catch up with missed lesson content (Ready, 2010). Low-SES parents may have inflexible  jobs  that  limit  their  ability  to  participate  in  their  children's  education  or  intervene  when attendance issues arise (Domina, 2005). Furthermore, students from low-income families frequently live in high-poverty neighborhoods with under-resourced schools, making absenteeism more common and mitigating its consequences less effective (McCoy et al., 2015). Schools may disproportionately record absences as unexcused among disadvantaged students, which may affect how teachers aim to mitigate learning loss after children return to school (McNeely et al., 2021).\n\nChildren from higher socioeconomic status families, on the other hand, are more likely to have access to additional learning opportunities, such as tutoring or educational materials, which can aid in their recovery from absenteeism. This is consistent with the compensatory advantage hypothesis (Bernardi, 2014), which contends that children from privileged backgrounds are better able to overcome adverse events, such as school absences, without long-term academic consequences. While absenteeism may partly  reflect  broader  socio-economic  challenges,  the  cumulative  disadvantages  faced  by  low-SES students suggest they are less able to overcome the negative consequences of missed schooling.\n\nHowever,  empirical  evidence  on  the  moderating  role  of  SES  for  the  link  between  absences  and achievement is mixed. Whereas Aucejo &amp; Romano (2016), Ready (2010) and Smerillo et al. (2018) found  that  absences  had  a  greater  negative  impact  on  low  SES  students,  Hancock  et  al.  (2017) discovered a similar association across SES. Gershenson et al. (2017) found more negative effects for low SES students based on administrative data from North Carolina but no effect heterogeneity by SES based on ELCS-K data. Klein &amp; Sosu (2024) found that sickness-related absences have larger effects among low SES students but similar effects of truancies and total absences across SES in Scotland.\n\n\n## 2.4 Family SES, school absences, and achievement\n\n\nTwo  studies  have  investigated  the  extent  to  which  socioeconomic  disparities  in  school  absences contribute to SES-achievement gaps. First, Morrissey et al. (2014) used panel data from primary school students  in  Florida  to  determine  whether  school  attendance  contributes  to  achievement  differences between students eligible for free or reduced-price lunch and those not. They discovered that compared to students who paid the full price, children who received reduced-price lunch had around 0.12 SD lower achievement, while children who received free lunch had around 0.24 SD lower achievement scores. However, school absences accounted for only 0.00 to 0.01 SD of the differences in eligibility for  free  or  reduced-price  lunch,  leading  the  authors  to  conclude  that  absences  do  not  meaningfully mediate the association between SES and achievement.\n\nSecond,  using  data  from  the  Early  Childhood  Longitudinal  Study,  Kindergarten  Class  of  1998-99 (ELCS-K) and administrative data from North Carolina, Gershenson et al. (2017) found that 5th-grade students above the poverty line had a 0.6 to 0.7 SD higher math achievement than students below the\n\npoverty line. However, the authors report that school absenteeism accounts for only about 1% of the achievement gap.\n\nWhile these studies provide emerging insights on the potential mediating role of absenteeism in the SES-achievement relationship, important gaps remain.\n\nFirst , both studies relied on a single measure of SES (free or reduced-price lunch; households below or above the poverty line). SES is a multidimensional concept defined as '[…] one's access to financial, social, cultural and human capital resources.' (Cowan et al., 2012, p. 4). Recent research has found that various measures of SES, such as education, occupational class, and income, have distinct effects on achievement (Bukodi et al., 2021; Eriksson et al., 2021) and school absenteeism (Klein et al., 2020). Thus, studies that only take one measure of SES are likely to underestimate the relationship between\n\nSES, absences, and achievement.\n\nSecond , to appropriately address the mediating role of absenteeism, it is important to account for the role of other mediators between SES and achievement that are linked to absences, an issue that previous studies have not fully addressed. As noted in the literature on causal mediation analysis (VanderWeele, 2015), identifying the indirect effect of an exposure (X, here SES) on an outcome (Y , here achievement) via a mediator (M, here school absences) necessitates an appropriate adjustment for factors that are a result  of  SES  and  causes  of  absences  and  achievement  (i.e.,  exposure-induced  mediator-outcome confounders L), as shown in Figure 1. If L is ignored, it confounds the relationship between M and Y and opens up non-causal paths from X to M to L to Y (i.e., collider bias), resulting in biased estimates of indirect and direct effects. However, if L is on the causal path between X and Y, controlling for these L will result in overcontrol bias, eliminating parts of the direct effect between absences and achievement (i.e., X → Z → Y). Traditional mediation techniques, such as the product or different methods, ignore these issues and produce biased estimates in this scenario.\n\nThe  literature  suggests  many  other  mechanisms  for  SES-achievement  gaps  that  influence  school absences. For instance, childhood characteristics such as early cognitive skills (Feinstein, 2003; Skopek &amp; Passaretta, 2021), behavioral problems  (Piotrowska et al., 2015), parental involvement, educational aspirations  (Sewell  et  al.,  1969),  or  child  health  (Case  et  al.,  2002)  are  all  socially  stratified (corresponding to the X → L path in Figure 1). At the same time, these factors have been identified as significant risk factors for school absences (Gubbels et al., 2019) and have known links to children's academic achievement (Cunha &amp; Heckman, 2007; Jackson, 2015; Murray et al., 2011; Wang &amp; SheikhKhalil, 2014; Zee et al., 2021). Therefore, exposure-induced mediator-outcome confounders pose a significant challenge  in  accurately  estimating  the impact  of  school  absences  on  SES-related achievement gaps.\n\nFigure 1. Causal relations between SES (X), school absences (M) and academic achievement (Y)  in  the  presence  of  baseline  confounders  (C)  and  exposure-induced  mediator-outcome confounders (L)\n\n<!-- image -->\n\nThird ,  as  discussed  in  section  2.3.,  the  effect  of  absences  on  achievement  may  vary  across  SES. (Gershenson et al., 2017)  noted in their mediation analysis that the contribution of absences could have been greater if effect heterogeneity had been addressed. Traditional mediation methods, such as the product or difference techniques, typically assume no interaction between the exposure (SES) and the mediator (absences). However, this assumption is overly restrictive, especially given evidence from some studies indicating that absences may have a larger impact on achievement for students from lowSES backgrounds (Aucejo &amp; Romano, 2016; Ready, 2010; Smerillo et al., 2018).\n\nWe address these issues by using linked administrative school data and rich survey data on children and their families to: a) comprehensively measure SES, b) use detailed information with a regression-withresiduals  approach  (Wodtke  &amp;  Zhou,  2020)  to  appropriately  deal  with  exposure-induced  mediatoroutcome  confounders  and,  c)  to  explicitly  account  for    effect  heterogeneity  when  evaluating  the mediating role of absences in the SES-achievement relationship.\n\n\n## 3. Data and methods\n\n\n\n## 3.1 Data\n\n\nFor our analysis, we used the Millennium Cohort Study (MCS, Joshi &amp; Fitzsimons, 2016) linked with the National Pupil Database (NPD, Jay et al., 2019), a register dataset of all pupils in state schools in England. The MCS is a large-scale longitudinal study of children born in 2000 or 2001 who live in the UK. 19,244 families were recruited and first surveyed when their children were 9 months old. Followup assessments were conducted at ages three (sweep 2), five (sweep 3), seven (sweep 4), eleven (sweep 5), fourteen (sweep 6), and seventeen (sweep 7).\n\nAll participants residing in England during sweeps 3-5 (N=9,047) were asked for consent to link their data to the NPD. Because there are no joint survey weights for participation in sweeps 3 through 5, we restrict  our  analysis  to  participants  who  were  asked  for  consent  in  sweep  4  (N=8,986).  N=8,206 provided consent and were successfully matched to the NPD database. In addition, our sample excluded all pupils with incomplete information on their achievement in key stage 1. This results in N=8,024 cases for our analysis.\n\nTo account for attrition, we used MCS weights for participation in England in sweep 4 (age 7). To address non-random selection into our sample, we used inverse probability weighting by calculating the inverse of the probability that participants provided consent for NPD data linkage, were successfully linked, and had complete achievement data. We used logistic regression to estimate this probability of sample  inclusion,  with  family  socio-demographic  characteristics  and  child  characteristics  as  our predictors (see Online Appendix B).\n\nTo deal with item non-response, we used multiple imputation based on categorization and regression trees to impute missing values on covariates (Burgette &amp; Reiter, 2010). We created 20 imputed datasets.\n\n\n## 3.2 Variables\n\n\n\n## 3.2.1 Achievement (Y)\n\n\nWe consider five measures of achievement that are assessed at the end of key stage 1 (KS1, at the end of  school year 2) when children are approximately seven years old. KS1 point scores are based on performance in national curriculum tests and teachers' assessments (see Online Appendix A.1)\n\n- · Level in Math\n- · Level in Reading\n- · Level in Writing\n- · Level in Science\n\n- · Average level across math, reading, writing, and science.\n\nThe possible scores for these tests are 3, 9, 13, 15, 17, 21, and 27. Point scores greater than 13 indicate that pupils have met the expected curriculum level. We standardized all five outcome variables with a mean of zero and a standard deviation of one.\n\n\n## 3.2.2 SES (X)\n\n\nWe used a composite score to comprehensively capture SES. For this purpose, we considered five SES dimensions:  parental  education,  parental  class,  household  income,  neighborhood  deprivation,  and housing tenure.\n\nParental education was  measured using the highest National Vocational Qualification (NVQ) level among parents:\n\n- · NVQ 5: Higher  degree  and  postgraduate  qualifications  (e.g.,  Master's,  PhD)  or  vocational equivalent\n- · NVQ 4: First Degree (e.g., Bachelor's) diploma in higher education or vocational equivalent\n- · NVQ 3: Advanced school-leaving qualifications (A/AS/S Levels, or equivalent)\n- · NVQ 2: Intermediate school qualifications (O Levels or GCSE grades A-C).\n- · NVQ 1: Basic secondary education qualifications (CSE below grade 1 or GCSE below grade C).\n- · No qualifications: No formal educational qualifications.\n\nParental social class was measured using the 7-class version of the National Statistics Socioeconomic Classification  (NS-SEC).  It  captures  variations  in  employment  relationships  that  influence  income security, short-term income stability, and long-term income prospects (Goldthorpe, 2007).\n\n- · NS-SEC 1: Higher managerial, administrative, and professional occupations\n- · NS-SEC 2: Lower managerial, administrative, and professional occupations\n- · NS-SEC 3: Intermediate occupations\n- · NS-SEC 4: Small employers and own account workers\n- · NS-SEC 5: Lower supervisory and technical occupations\n- · NS-SEC 6: Semi-routine occupations\n- · NS-SEC 7: Routine occupations\n\nWe used a measure of household income quintiles provided by the MCS. The measure is equivalized following  the  OECD  equivalence  scale  to  adjust  household  income  according  to  the  size  and composition of the household.\n\nNeighborhood deprivation was measured using deciles of the Index of Multiple Deprivation (IMD). The IMD is a composite neighborhood-based index that combines information across several domains (e.g., income deprivation, employment deprivation) to provide an overall deprivation score for small geographic areas.\n\nHousing tenure was measured in five categories: 1) Owned outright, 2) Owned with mortgage, 3) Rent - Local Authority, 4) Rent - Housing association or private rented, 5) Other arrangements (e.g., staying with family without paying rent).\n\nUsing Cowan et al.'s (2012) approach, we followed several steps to create a composite SES score based on our five dimensions. First ,  we  began  by  regressing  pupils'  key  stage  1  achievement  in  reading, writing, math, and science on our SES dimensions (see Online Appendix C). Because the SES measures can change over time, our regression analyses include all five SES measures in each of the first three sweeps of MCS (ages 9 months, 3 and 5 years, see the distribution of these variables in Online Appendix Table A.2)  and  prior  to  the  measurement  of  absences  and  achievement. Second ,  we  calculated  the predicted values of these four regressions for each pupil. Third , we compute a SES composite score by averaging the four predicted values for each pupil. In the final step, we standardized the SES composite score to have a mean of zero and a standard deviation of one in our weighted sample. This SES score captures as much variance in achievement as if we had included parental education, occupational class, income, neighborhood deprivation, and housing tenure together. In contrast to unweighted indices such as the economic, social and cultural status index used in PISA, Cowan et al.'s (2012) approach considers that some SES dimensions may be more important for children's achievement than others.\n\n\n## 3.2.3 School absences (M)\n\n\nWe measured school absences as the average percentage of total absences across KS1 (years 1 and 2). We calculated the percentage of total absences by dividing the number of absent sessions by the number of possible sessions in each school year. On average, pupils missed 5.4% (SD = 4.6%) of all possible sessions in KS1 (see Online Appendix A.3). One-tenth of pupils in our sample missed more than 11% of all possible sessions, while 1% of pupils missed more than 21% of all sessions. We standardized absences with a mean of zero and a standard deviation of one. Online Appendix D shows correlations between absences, SES, and KS1 achievement.\n\n\n## 3.2.4 Baseline confounders (C)\n\n\nOur baseline confounders are pupils' date of birth, ethnicity, gender, family structure, household size, and the number of children in the household (for more information, see Online Appendix A.4).\n\n\n## 3.2.5 Mediator-Outcome Confounders (L)\n\n\nThe MCS enables us to include a wide range of characteristics in our mediation analysis that may be influenced by SES while also affecting school attendance and academic performance. All mediatoroutcome confounders are measured prior to or at the beginning of enrolment in school. Our intermediate confounders include residential moves, birthweight, complications at birth, alcohol during pregnancy, smoking during pregnancy, parental depression, children's general health, whether the child has a longterm illness, children's externalizing behavior, children's internalizing behavior, educational motivation, parental  involvement,  joint  activities,  school  fees,  school  change,  and  to  what  extent  parents  value children's independence or obedience Most importantly, the MCS allows us to account for children's early cognitive abilities, which were assessed using the Bracken School Readiness test and several tests from  the  British Ability  Scales,  Second  Edition  (Naming  Vocabulary,  Picture  Similarities,  Pattern Construction; for more information, see Online Appendix A.5). These early assessments of children's abilities  will  capture  all  academic  advantages  that  high-SES  children  have  before  starting  school (Feinstein, 2003; Skopek &amp; Passaretta, 2021).\n\n\n## 4.3 Methods\n\n\nWe  used  a  regression-with-residuals  approach  to  mediation  analysis  to  account  for  heterogeneous absence effects and appropriately address exposure-induced mediator-outcome confounders (Wodtke &amp; Zhou,  2020).  This  approach  aims  to  decompose  the  total  effect  of  SES  on  achievement  into  the randomized intervention analogue of the natural indirect effect (rNIE) via absences and the natural direct effect (rNDE).\n\nThe rNIE presents the expected difference in achievement (Y) if all children were exposed to parents with high SES (X=x') but were exposed to a value of school absences (M) randomly drawn from the distribution under high SES rather than low SES (X=x).\n\nThe rNDE presents the expected difference in achievement (Y) if all children were exposed to parents with high SES (X=x') rather than low SES (X=x), while fixing school absences (M) to a value randomly drawn from the distribution under low-SES.\n\nThe regression-with-residuals approach proceeds in five steps:\n\n- 1. For each baseline confounder C, compute 𝐶 ̂ ⊥ = 𝐶 - 𝐶 ̿ , where the overbar denotes the sample mean, i.e., centre C,\n- 2. For each mediator-outcome confounder L, fit a model for L given C and X and extract the residuals: 𝐿 ̂ ⊥ = 𝐿 - 𝐸 ̂ (𝐿|𝐶, 𝑋) .\n- 3. Conditional mean model of M (absences): Regress M on C and X but substitute 𝐶 ̂ ⊥ for  C: 𝐸 ̂ (𝑀|𝐶, 𝑋) =   𝜃 ̂ 0 +𝜃 ̂ 1 𝐶 ̂ ⊥ +𝜃 ̂ 2 𝑋 ,\n\n- 𝐶 ̂ ⊥\n- 4. Conditional mean model of Y (achievement): Regress Y on, C, X, L, and M but substitute for C and 𝐿 ̂ ⊥ for L: 𝐸 ̂ (𝑌|𝐶, 𝑋, 𝐿, 𝑀) = 𝛽 ̂ 0 +𝛽 ̂ 1 𝐶 ̂ ⊥ +𝛽 ̂ 2 𝑋 + 𝛽 ̂ 3  𝐿 ̂ ⊥ +𝛽 ̂ 4 𝑀 + 𝛽 ̂ 5 𝑋𝑀 , Since confounders 𝐿 ⊥ are residualised and thus independent of X and C, their adjustment does not induce over-control bias, i.e., we remove the paths C → L and X → L in Figure 1\n- 5. Compute 𝑟𝑁𝐷𝐸 = [𝛽 ̂ ̂ 2 +𝛽 ̂ 5 (𝜃 ̂ 0 +𝜃 ̂ 2 𝑥)](𝑥 ′ -𝑥) and 𝑟𝑁𝐼𝐸 = 𝜃 ̂ ̂ 2 (𝛽 ̂ 4 +𝛽 ̂ 5 𝑥 ′ )(𝑥 ′ -𝑥) .\n\nStandard errors and confidence intervals are estimated with bootstraps.\n\nIn addition to consistency assumptions and the stable unit treatment value assumption, an unbiased identification of rNIE and rNDE requires three conditional independence assumptions (Wodtke &amp; Zhou, 2020):\n\n- 1. There are no unobserved X-Y confounders, conditional on C,\n- 2. There are no unobserved X-M confounders, conditional on C,\n- 3. There are no unobserved M-Y confounders, conditional on C, X, and L.\n\n\n## 5. Findings\n\n\nResults indicate that large SES-achievement gaps for all outcomes at the end of KS1 exist (see Table 1, Total difference). One standard deviation (hereafter SD) increase in SES is associated with a 0.425 SD increase  in  average  achievement  across  all  subjects,  and  a  0.374  to  0.394  SD  increase  in  reading, writing, math, and science.\n\nTable 1 . Mediation analysis of SES effects on achievement score in key stage 1 via school absences.\n\nSource: Linked MCS-NPD. N=8,024. Notes: Multiple imputed and weighted. 1000 Bootstrap samples. Coef=Coefficient/Estimate, LL=Lower limit of 95%-Confidence interval, UL=Upper limit of 95%-Confidence interval.\n\nAverage  school  absences  during  the  first  two  years  of  primary  school  partially  mediate  SESachievement gaps  at  the  end  of  KS1. Absences  account  for  0.024  and  0.032  SD  of  the  total  SESachievement gap (see Table 1, rNIE), depending on the achievement measure. In relative terms, school absences mediate the SES-achievement gap by 6.45% (science), 6.67% (reading), 7.21% (math), 8.10% (writing) and 7.13% (average achievement), (see Table 1, percent indirect). In other words, SES has statistically significant indirect effects on achievement through absences across all outcomes.\n\nOverall, SES still retain large direct effects on achievement, with effect sizes ranging from 0.347 (math), 0.351 (science), 0.363 (writing), 0.368 (reading) to 0.394 SD (average) (see Table 1, rNDE). This is not surprising given the variety of other mechanisms by which SES can influence achievements.\n\nWe can further disentangle the indirect effect of SES on achievement through school absences into its components. The mediation effect is primarily driven by socioeconomic disparities in school absences, with a smaller but still significant contribution from the negative association between school absences and KS1 achievement. A one SD increase in the SES composite score is associated with a 0.265 SD reduction in absences (see Table 2, SES → Absence, 𝜃2 ; equivalent to a 1.22 percentage points reduction in absences). A one SD increase in absences (equivalent to 4.6 percentage points) is associated with a 0.068 to 0.100 SD reduction in achievement (see Table 3, Absence → Achievement, 𝛽4 ). These effect sizes on the association between absences and achievement are similar to those reported by Aucejo and Romano (2016) and Gershenson et al. (2017).\n\nTable 2 . Mediator model - Constant and effect of SES on absences.\n\nSource: Linked  MCS-NPD.  N=8,024. Notes: Multiple  imputed  and  weighted.  1000  Bootstrap  samples. Coef=Coefficient/Estimate, LL=Lower limit of 95%-Confidence interval, UL=Upper limit of 95%-Confidence interval.\n\nWhen considering effect heterogeneity by SES, our results indicate that the impact of absences on achievement does not vary significantly by children's socioeconomic circumstances (refer to Table 3, Absence * SES → Achievement, 𝛽5 ). School absences have a negative impact on both high and low SES students, with a slightly higher impact on high SES students. However, except for achievement in science, the interaction term is statistically non-significant.\n\nTable 3 .  Outcome model - Effect of SES, absences, and interaction effect of SES and absences on achievement.\n\nSource: Linked  MCS-NPD.  N=8,024. Notes: Multiple  imputed  and  weighted.  1000  Bootstrap  samples. Coef=Coefficient/Estimate, LL=Lower limit of 95%-Confidence interval, UL=Upper limit of 95%-Confidence interval.\n\nOnline Appendix E shows that adjusting for exposure-induced mediator-outcome confounders is critical for obtaining unbiased estimates of the contribution of absences to SES-achievement gaps. If we had ignored the observed exposure-induced mediator-outcomes confounders in our mediation analyses, we would have concluded that the indirect effect through absences is more than 30% larger than when we used the regression-with-residuals approach. If we had simply adjusted for these confounders, we would have underestimated the indirect effect via absences by nearly half.\n\n\n## 6. Discussion\n\n\nThis  study  sheds  new  light  on  SES-achievement  gaps  in  early  primary  schools  in  England, demonstrating that school absences play an important, albeit partial, role in mediating the relationship between SES and academic achievement. The findings show that absences account for 6.45%-8.1% of SES-achievement gaps across various subjects. These effect sizes are significantly larger than previous findings in the US, where absences were found to account for about 1% of the SES-achievement gap (Gershenson et al., 2017) or to have no meaningful mediating role (Morrissey et al., 2014). However, our findings are based on a more comprehensive measure of SES and analyses that appropriately account for exposure-induced mediator-outcome confounding.  They suggest that attendance-focused policies and interventions may be an effective strategy for reducing SES-related disparities in academic achievement in England.\n\nAbsences are equally harmful to children, regardless of socioeconomic status, implying that, in this case, the interaction between SES and absences is less important for producing unbiased estimates of direct  and  indirect  effects.  These  findings  contradict  previous  research  from  the  US (Ready,  2010; Aujeco &amp; Romano, 2016; Gershenson et al., 2017), which shows that school absences are more strongly associated with achievement among students from lower socioeconomic backgrounds.\n\nWhile the study contributes significantly to our understanding of SES-achievement disparities, several limitations should be noted. First , the analysis is based on pre-COVID-19 data, so the role of absences as a mediator of SES-achievement gaps may have been conservatively estimated. After the pandemic, socioeconomic disparities in school attendance have widened significantly (Sosu &amp; Klein, 2021), likely intensifying the mediating role of absences in SES-achievement gaps.\n\nSecond ,  our  focus  is  on  early  primary  schooling,  which  may  not  fully  capture  how  absences affect academic disparities throughout a student's educational career. Although early attendance is critical for developing foundational skills, absences can have varying consequences as students progress through school and encounter increasingly specialized subjects and assessments. Furthermore, socioeconomic inequalities in school attendance may change over time. As a result, as students progress through school, absences may mediate SES-achievement gaps differently. We abstain from analyzing the mediating effect  of  absences  throughout  the  entire  school  career  because  there  is  no  established  method  for\n\nmediation analysis accounting for feedback loops between different mediating factors, which is likely the case for absences, school performance and behavioral problems (Panayiotou et al., 2021).\n\nThird , our study does not differentiate by reason for absence, as most absences in early primary school are excused (Dräger et al., 2024). However, the mediating role of absences in SES-achievement gaps may vary depending on the reason for absence. Some studies have found that unexcused absences are more detrimental to achievement than excused absences (Aucejo &amp; Romano, 2016; Gottfried, 2009), while others report similar effects for both types (Klein et al., 2022).\n\nDespite  these  limitations,  the  findings  indicate  that  addressing  attendance  disparities  is  a  crucial approach to reducing socioeconomic disparities in academic achievement. Targeted interventions to increase  attendance  rates  among  students  from  lower  socioeconomic  backgrounds  could  help close achievement gaps. Effective interventions should address the broader social and familial factors that influence school absences, such as health issues, mental health challenges, transportation barriers, and family  obligations.  Policymakers  should  also  consider  initiatives  to  foster  stronger collaboration between schools and families, creating a shared understanding of the importance of consistent school attendance for both early learning and long-term academic success. By prioritizing attendance-focused interventions as part of broader efforts to reduce educational disparities, schools can address  a key mediating factors in the SES-achievement gap and promote intergenerational social mobility.\n\nIn addition to reducing absences through targeted attendance interventions, it is critical to address the academic consequences of missed school days. The findings of this study show that absences have a significant, negative impact on achievement across all socioeconomic groups, and there is no evidence that higher SES can offset the negative impact of missed instructional time. As a result, in addition to attendance improvement initiatives, schools should implement structured support mechanisms to help students  quickly  and  effectively  catch  up  on  missed  lesson  content  when  they  return,  such  as personalized  catch-up  plans  or  peer  tutoring  programs.  By  providing  structured,  equitable  support, schools can help students maintain academic progress and stay engaged, reducing the negative effects of missed instructional time on achievement.\n\nTo gain a better understanding of how absences contribute to SES-achievement gaps, future research should use longitudinal data that tracks absences, SES, and achievement over multiple school years. Such an approach could reveal whether the mediating role of absences increases or decreases as students progress, as well as the cumulative effects of absenteeism. Future research should also look into whether post-COVID attendance  trends  have  increased  the  role  of  absences  in  mediating  SES-achievement disparities, and whether additional support structures are now required. Finally, more research into how specific types of absences affect learning outcomes could help policymakers develop more targeted interventions. For example, policies aimed at reducing health-related absences may necessitate different approaches than those aimed at addressing family-related absences or disengagement.\n\nIn conclusion, our findings highlight the importance of school attendance as a meaningful, albeit partial, mediator of the SES-achievement gap. Addressing absenteeism, along with other structural inequalities, represents  a  step  towards  more  equitable  educational  outcomes,  allowing  schools  to  better  support students  from  diverse  socioeconomic  backgrounds  while  also  promoting  social  mobility  through education.\n\n",
         "Socioeconomic disparities in children's academic achievement are well established, but the underlying mechanisms are less well understood. We used linked data from the Millennium Cohort Study (MCS) and the National Pupil Database (NPD) with causal mediation analysis to determine the extent to which school absences contribute to socioeconomic achievement gaps. Using different achievement measures (reading, writing, math, science, and average), we found that a one standard deviation increase in socioeconomic status improves achievement by 0.37 to 0.43 standard deviations. Appropriately accounting for a rich set of mediator-outcome confounders, school absenteeism is a significant mechanism (6.45 to 8.10%) for these socioeconomic achievement gaps.",
         ""
        ],
        [
         "13",
         "13",
         "## Introduction\n\n\nThe pervasive influence of big data has profoundly transformed nearly every domain of contemporary  society,  ushering  in  a  fundamental  shift  in  how  we  conceptualize,  analyse,  and leverage information(Chauhan &amp; Sood, 2021; Emmert-Streib, 2021). This data-driven revolution has had a profound impact on the field of education, particularly in the area of language learning (Pérez-Paredes, 2022; Xu, 2023). The exponential growth of digital  resources, online learning platforms, and data-intensive pedagogical tools has catalysed a paradigm shift, unveiling novel frontiers in linguistic instruction and acquisition (Godwin-Jones, 2021). At the forefront of this transformation  lies  the  burgeoning  field  of  Data-Driven  Language  Learning  (DDLL),  which leverages the power of big data analytics to inform and optimize language education (Shah &amp; Singh, 2021). DDLL represents a departure from traditional, prescriptive approaches, embracing a more organic, learner-centric paradigm that utilizes the wealth of digital language data to tailor instruction, enhance engagement, and foster autonomous learning trajectories  (Sun &amp; Hu, 2020; Zhang, 2022).\n\nThe exponential and unprecedented growth of big data in the 21 st century has catalysed a paradigm shift in language learning, fostering the exploration of novel pedagogical frontiers and ushering  in  a  remarkable  transformation  in  language  learning  and  its  profound  influence  on pedagogical approaches (Chen &amp; Wojcik, 2016). This paradigm shift has provided a multitude of potential new avenues for data-driven language learning in Saudi Arabia, warranting a systematic exploration of the research landscape.\n\nThe  Saudi  Arabian  context  presents  a  unique  and  fertile  ground  for  exploring  the applications and implications of DDLL. With a rapidly expanding digital infrastructure, a techsavvy youth population, and a strong commitment to educational reform as per the Saudi Vision 2030 (Al-Shehri, 2020), the Kingdom has demonstrated a keen interest in integrating cutting-edge technologies into its educational ecosystem (Hoq, 2020). However, despite the promising potential of DDLL, its implementation in the Saudi context remains relatively unexplored, necessitating a comprehensive synthesis of the extant literature.\n\nThis systematic review aims to explore the depth and breadth of the landscape of big data and data-driven language learning research, elucidating the multifaceted role of big data in shaping the language learning landscape within the Saudi Arabian context. It seeks to unveil the intricate interplay between  linguistic innovation  and  technological advancements,  illuminating  the challenges and opportunities that arise when data-driven English language teaching and learning pedagogies are introduced into the Saudi educational milieu. The review will also delve into the diverse applications of big data analytics in language acquisition, encompassing natural language processing, corpus linguistics, and adaptive learning systems.\n\nAs such, to guide this investigation, the study addresses the following key research questions:\n\n- · What is the current state of research conducted on data-driven language learning and EFL in the Saudi Arabian context?\n- · What are the challenges and opportunities associated with the integration of big data in language education in Saudi Arabia?\n\nBy answering these two research questions, the study aims to provide an overview of data-driven language  learning  within  the  unique  sociocultural  and  educational  landscape  of  Saudi Arabia, highlighting gaps in existing research and proposing future directions for the field.\n\nUnveiling Linguistic Frontiers in the 21st Century: A Systematic Literature Review                                    Alharbi\n\n\n## Literature Review\n\n\nThis study is underpinned by four major and distinct theories. The first theory is big data analytics in education (Shabihi &amp; Kim, 2021), which posits that the vast amounts of educational data  generated  can  be  leveraged  to  gain  actionable  insights  and  drive  pedagogical  innovation (Fiofanova, 2020). As such, this framework emphasises the potential of data-driven approaches to personalize  learning  experiences,  optimize  instructional  strategies,  and  enhance  educational outcomes (Sharif &amp; Uckelmann, 2024). By applying this lens to language learning, the study aims to explore how big data can revolutionize language pedagogy in the Saudi Arabian context.\n\nThe  second  theory  is  the  language  learning  pedagogy  which  emphasises  the  role  of technology and data-driven approaches in enhancing linguistic competence. The Communicative Language Teaching (CLT) approach (Dos Santos, 2020) and the task-based language teaching (TBLT) approach (Ellis et al., 2020; Jackson, 2022) provide a foundation for understanding how big data can be integrated into language learning environments to foster authentic, meaningful interactions and promote learner autonomy. Additionally, the study draws upon the principles of computer-assisted language learning (CALL) (Chen et al., 2021; Levy, 1997) to examine how big data tools and technologies can support language acquisition.\n\nThe study is further situated within the unique concept of the sociocultural context of Saudi Arabia, recognising the influential role of cultural norms, religious values, and educational policies in shaping language learning experiences. The framework incorporates insights from sociocultural theory (Lantolf et al., 2021; Poehner &amp; Lu, 2023), which emphasises the importance of social and cultural factors in language learning. By considering the specific cultural and linguistic landscape of Saudi Arabia, the study aims to uncover how big data can be leveraged to address the particular challenges and opportunities faced by language learners in this context.\n\nThe theoretical framework of this study also draws on technology acceptance and adoption theories, incorporating elements from models such as the Technology Acceptance Model (TAM) (Kamal et al., 2020; Marangunić &amp; Granić, 2015) and the Unified Theory of Acceptance and Use of Technology (UTAUT) (Sarfaraz, 2017; Venkatesh et al., 2012). These models offer a foundation for understanding the factors that shape the acceptance and integration of big data technologies in language learning contexts, including perceived usefulness, ease of use, and social influences. By exploring  these  factors  within  the  Saudi Arabian  context,  the  study  seeks  to  identify  effective strategies for implementing data-driven language learning approaches.\n\nThe  integration  of  these  theoretical  domains  creates  a  comprehensive  framework  that directs the systematic literature review and informs the analysis of big data's role in data-driven language learning in Saudi Arabia. By synthesizing insights from big data analytics, language learning  pedagogy,  sociocultural  theory,  and  technology  acceptance  models,  the  study  aims  to address the identified research gap and contribute to advancing language education in the 21st century.\n\n\n## Exploring Big Data in Language Learning\n\n\nThe origins  of  data-driven  language  learning  can  be  traced  back  to  the  field  of  corpus linguistics, which emerged in the 1960s as a result of the increasing availability of electronic text corpora  and  advancements  in  computational  processing  power  (Crosthwaite  et  al.,  2023). Pioneering linguists, such as Nelson Francis and Henry Kučera, recognized the potential of using large  collections  of  authentic  language  data  to  study  linguistic  patterns  and  variations  (Zarina, 2024).\n\nAlmost three  decades  ago,  the  'father'  of  Data-driven  Learning  (DDL),  Johns  (1994), advocated  the  learning-cantered  value  of  DDL,  calling  'every  student  a  Sherlock  Holmes' (Boulton  &amp;  Pérez-Paredes,  2024). The  fundamental  premise  underpinning  this  concept  is  that learners can uncover a myriad of linguistic facets, ranging from grammatical patterns and lexical semantics to other nuanced aspects of language, through the process of mining the linguistic data and  delving  into  extensive  repositories  of  authentic  language  (Luo,  2023).  This  exploratory approach to language learning empowers learners to actively engage in the discovery of linguistic intricacies, fostering a deeper understanding of the complex interplay between form, meaning, and function (Bachtiar, 2024). By immersing themselves in the rich tapestry of authentic language data, learners can cultivate a more realistic grasp of language structures and usage, transcending the limitations of traditional, rule-based language instruction. This data-driven methodology not only enhances  learners'  linguistic  knowledge  but  also  equips  them  with  the  tools  and  strategies  to navigate the ever-evolving landscape of language use in real-world contexts (Boulton &amp; Vyatkina, 2021; Lee et al., 2020). Bellaj et al. (2024) state that: 'Adaptive learning analytics (ALA) models have grown in favor of HE due to their claims of enhancing student learning outcomes, providing personalized learning paths, and allowing students to interact with course material at their own pace' (p. 24).\n\nBig data has significantly influenced education, with a focus on improving the education process (Cui et al., 2023; Fischer et al., 2020). Its application in higher education, particularly in analytics, has been identified as a key factor in enhancing the learning experience (Mkrttchian et al., 2021; Samsul et al., 2023). The growing role of big data in education has led to the need for effective decision-making and the use of information intelligence (Hosch, 2020; Kalim, 2021). Boulton and Vyatkina (2021) state that:\n\nA promising direction would be more integration of DDL and SLA. Employing such SLA constructs  as  implicit  and  explicit  knowledge,  receptive  and  productive  knowledge, knowledge  breadth and depth, controlled and free production, and testing DDL effectiveness  for  the  development  of  these  knowledge  types  and  language  skills  would undoubtedly bring both fields forward. (p. 83)\n\nFigure 1 illustrates the author's visualisation of the role of big data in decision-making in education.\n\nFigure 1. Big Data Role in Education - Author's interpretation of Maxwell et al. (2016) and Hartong (2016)\n\n<!-- image -->\n\nUnveiling Linguistic Frontiers in the 21st Century: A Systematic Literature Review                                    Alharbi\n\nXin et al. (2022) and Fahd and Miah (2023) further elaborate on the general steps followed in utilising big data as illustrated in Figure One above as follows:\n\n- 1. Identify Goals : Define the objectives and desired outcomes for implementing big data in education,  such  as  improving  student  performance,  optimizing  resource  allocation,  or enhancing the learning experience.\n- 2. Data Collection :  Gather  relevant  data  from  various  sources,  including  student  records, learning management systems, assessment data, and other educational platforms.\n- 3. Data Processing :  Clean,  transform,  and  preprocess  the  collected  data  to  prepare  it  for analysis.\n- 4. Data Analysis :  Apply  appropriate  analytical  techniques,  such  as  statistical  modelling, machine learning, or data mining, to extract insights from the processed data.\n- 5. Insights &amp; Decisions : Based on the analysed data and visualizations, derive meaningful insights and make informed decisions related to educational strategies, resource allocation, curriculum design, or instructional methods.\n- 6. Implementation : Put the decisions into action by implementing changes or new initiatives in the educational system.\n- 7. Monitoring &amp; Evaluation : Continuously monitor the impact of the implemented changes and evaluate their effectiveness against the defined goals.\n- 8. Continuous Improvement : Based on the monitoring and evaluation results, identify areas for  improvement  and  adjust  the  process  or  strategies,  accordingly,  creating  a  cycle  of continuous improvement.\n\nThe  application  of  big  data  in education  brings  ethical  considerations,  especially concerning privacy and security (Baig et al., 2020). Big data holds transformative potential for education and language learning by providing insights into learner behaviours and performance (Caspari-Sadeghi, 2023; Godwin-Jones, 2021). This potential is particularly valuable in higher education,  where  it  can  enhance  educational  quality  (Alam  &amp;  Mohanty,  2023)  and  improve students' learning experiences (Ang et al., 2020; Fischer et al., 2020).\n\nIn  language  learning,  big  data  presents  both  significant  advantages  and  challenges.  It enables the tracking of learner progress and the analysis of patterns and variables that can lead to enhanced  learning  outcomes  (Godwin-Jones,  2021).  However,  concerns  over  transparency, fairness, and the need for human oversight remain pertinent (Godwin-Jones, 2021). The vast data generated by various online platforms can be analysed to reveal broad usage trends and provide individualized  reports,  thereby  supporting  more  personalized  learning  experiences  (Alam  &amp; Mohanty, 2023).\n\nA review of current literature indicates a growing interest in the use of big data in language learning, with studies emphasizing data-driven approaches for personalizing learning, adapting curricula,  and  delivering  targeted  feedback  (Alghamdi  &amp;  Rahman,  2023).  However,  research\n\nwww.awej.org\n\nISSN: 2229-9327\n\nUnveiling Linguistic Frontiers in the 21st Century: A Systematic Literature Review                                    Alharbi focused on the Saudi Arabian context is limited. Although a few studies have examined technology integration in Saudi language education (Al-Shehri, 2020; Baniawwad et al., 2023), the specific role of big data in Data-driven Language Learning (DDLL) in this setting remains underexplored. Despite the rising use of big data analytics (BDA) in Saudi higher education institutions, these tools are not yet fully utilized, resulting in less-than-optimal outcomes (Aseeri &amp; Kang, 2023). Aljasir (2022) found that Saudi self-learners of English tend to have realistic views about language acquisition, with a strong link between belief in language aptitude and self-assessed proficiency. Aljameel (2022) proposed a framework for applying big data in Saudi higher education, which could be extended to foreign language learning. Nonetheless, further investigation is needed to understand big data's specific impact on language learning in the Saudi context.\n\nDDLL within the Saudi context has various elements of potential benefits, challenges, and future directions. Big data can also facilitate the development of adaptive learning systems that dynamically  adjust  to  learners'  needs  and  preferences  (Singh  et  al.,  2021).  These  data-driven approaches have the potential to enhance linguistic competence, increase learner engagement, and promote self-directed learning.\n\nDespite the promising potential of big data in language learning, its implementation in the Saudi  Arabian  context  presents  unique  challenges.  One  significant  challenge  is  the  limited availability of high-quality language learning data specific to the Saudi context (Baniawwad et al., 2023). The lack of diverse and representative datasets can hinder the development of effective DDLL models. Additionally, cultural and societal factors, such as the prevalence of traditional teaching methods and the varying levels of technological readiness across educational institutions, may impact the adoption and effectiveness of data-driven approaches.\n\nFurthermore,  ethical  considerations  surrounding  data  privacy  and  security  must  be carefully addressed. The collection, storage, and use of student data raise concerns about potential misuse  and  unauthorized  access  (Bamiah  et  al.,  2018).  Establishing  robust  data  governance frameworks and ensuring compliance with relevant regulations are essential to maintain trust and protect learners' rights (Almutairi, 2021; Binjubeir et al., 2019).\n\nThis literature  review  has  highlighted  the  potential  of  big  data  in  data-driven  language learning in the Saudi Arabian context. While the current state of research is limited, the benefits of leveraging data analytics to personalize learning experiences and adapt curriculum are evident. However, implementing DDLL in the Saudi context presents challenges related to data availability, cultural factors, and ethical considerations.\n\n\n## Methodology\n\n\nA systematic literature review is a valuable approach to comprehensively search for, gather, and critically analyse previous studies that are pertinent to a particular research topic or question (Mohamed  Shaffril  et  al.,  2021).  It  involves  a  thorough  examination  and  integration  of  the available evidence base to provide an in-depth assessment aimed at addressing specific research inquiries through a rigorous synthesis of the findings across multiple sources. By systematically collating and evaluating the existing scholarly work, a systematic review enables researchers to consolidate the current state of knowledge, identify gaps, and draw well-informed conclusions within a focused area of investigation. Systematic reviews use explicit and replicable methods to retrieve all available literature and publications related to or pertaining to a specific topic to answer a specific and defined question (Higgins, 2008).\n\nThe  systematic  literature  review  followed  the  PRISMA  (Preferred  Reporting  Items  for Systematic Reviews and Meta-Analyses) four main phases of identification, screening, eligibility and inclusion (Rethlefsen et al., 2021). See Figure Two.\n\n<!-- image -->\n\nFigure 2. PRISMA's main four steps (Higgins &amp; Green, 2008; Rethlefsen et al., 2021)\n\nAlso, the databases search employed a comprehensive search strategy utilising Boolean operators (AND, OR, NOT) and truncation techniques to identify relevant studies across major academic databases and prominent journal publishers. The search strings will combine keywords related to \"big data,\" \"data-driven learning,\" \"language learning,\" and \"Saudi Arabia,\" and their variants  using  wildcards  and  truncation  symbols  (e.g.,  \"big  data*  learn*\",  \"language  learn*\", \"Saudi Arab*\"). These search strings were adapted and refined for each database and publisher to ensure a thorough and inclusive coverage of the relevant literature.\n\nAdditionally, to establish rigorous inclusion and exclusion criteria, the search results were filtered  based  on  a  set  of  predefined  parameters.  Studies  were  included  if  they  focus  on  the integration of big data or data-driven approaches in language learning contexts, with a particular emphasis on the Saudi Arabian educational landscape. The database search only included peerreviewed journal articles, conference proceedings, and academic books published within the last decade were considered to ensure the relevance and currency of the findings. Exclusion criteria will involve (if applicable) removing duplicates, studies not available in English, and those that do not directly address the research questions or the intersection of big data, language learning, and the Saudi context.\n\n\n## Findings\n\n\nThe remarkably low number of search results generated from major academic databases was quite evident in the results obtained (See Appendix A - Figures Five &amp; Six). In table Two, Appendix B, the results of each database search are illustrated. It can be clearly seen that a shortage on the number of studies on big data's role in data-driven language learning in Saudi Arabia exists, which is compounded by the fact that many of the search results (studies) may prove tangential or irrelevant.  Table  3, Appendix  C,  lists  five  studies  obtained  from  the  Springer  Link®  database search. However, upon further examination, these studies were found to be either intangible or irrelevant to the current research objectives.\n\nOut of all  the  searches  that  were  carried  out  with  the  five  major  databases,  the  search conducted  with  Google  Scholar®  generated  10  results  which  surprisingly,  also  led  to  the elimination of 9 irrelevant studies and the inclusion of one single study that fit the criteria of our search. Figures 3 and 4 highlight the resultant search on Google Scholar® and the relevant included study.\n\nFigure 3. Search results on Google Scholar®\n\n<!-- image -->\n\nFigure 4 illustrates the main steps and processes involved in highlighting the inclusion of a sample of the accepted research studies.\n\nFigure 4. The inclusion of the accepted research study\n\n<!-- image -->\n\nwww.awej.org\n\nISSN: 2229-9327\n\nUnveiling Linguistic Frontiers in the 21st Century: A Systematic Literature Review                                    Alharbi\n\nThe included study by Alhammad (2023)  explored the application of Learning Analytics (LA) in the EFL classroom to predict educational benefits as per the data gathered and saved from Learning Management Systems (LMSs) and e-learning platforms. The study analysed the learning behaviours of 25 EFL female learners at Prince Sattam bin Abdulaziz University, Saudi Arabia. Results showed a significant correlation between video lessons and final grades, highlighting the importance  of  technology  in  forecasting  student  performance  as  well  as  the  fact  that  learning analytics  can  help  course  developers,  teachers,  and  learners  improve  educational  outcomes  by identifying learning patterns and predicting performance in assessment tests.\n\n\n## Discussion\n\n\nFor Research Question 1: \"What is the current state of research conducted on data-driven language learning and EFL in the Saudi Arabian context?\", it can be seen that the review reveals a limited number of studies focused specifically on DDLL in Saudi Arabia, with existing research often examining related fields or lacking a focus on big data's role in EFL. This gap underscores the importance of further investigation to understand how big data-driven methodologies can be optimised for this unique educational landscape. While Alghamdi &amp; Rahman (2023) highlight the general potential of data-driven approaches to personalise learning experiences, only a few studies (e.g., Al-Shehri, 2020; Baniawwad et al., 2023) have explored technology integration in Saudi language education specifically. This limited focus underscores the need for further research to tailor DDLL to Saudi Arabia's unique educational landscape. The theoretical frameworks of big data  analytics  in  education,  as  discussed  by  Shabihi  &amp;  Kim  (2021),  suggest  that  data-driven methodologies could be transformational in optimising instructional strategies and personalizing language learning in Saudi Arabia. However, as highlighted, there is still a need for studies that investigate  these  benefits  within  the  specific  cultural  and  linguistic  context  of  Saudi  EFL classrooms\n\nFor Research Question 2: \"What are the challenges and opportunities associated with the integration of big data in language education in Saudi Arabia?\", it can be seen that the findings highlight several challenges in implementing data-driven approaches, such as Baniawwad et al. (2023) who note that a major challenge in Saudi Arabia is the limited availability of diverse and representative language learning datasets, which can impede the development of effective DDLL models. Additionally,  societal  and  cultural  factors,  such  as  the  reliance  on  traditional  teaching methods, may impact the adoption of innovative, data-driven approaches.\n\nAdditionally,  opportunities  for  enhancing  language  learning  through  big  data  include. These findings align with studies like Singh et al. (2021) who underscore the potential of big data to  create  adaptive  learning  systems  that  adjust  to  individual  learner  needs.  This  approach  is particularly promising in Saudi Arabia, where data-driven models could engage students more effectively by tailoring content to their linguistic and cultural preferences.\n\nThe  various  literature  searches  were  conducted  across  multiple  prominent  academic databases, including ScienceDirect®, SpringerLink®, SAGE Journals®, Wiley Online Library®, and Google Scholar®, to assess the current state of research on \"Unveiling Linguistic Frontiers in the 21st Century: A Systematic Literature Review of the Rise of Big Data's Role in Data-Driven Language  Learning  in  the  Saudi Arabian  Context\".  The  search  yielded  an  unexpectedly  low number of relevant publications, strongly suggesting that this specific area remains significantly under-researched. This paucity of scholarly work is particularly noteworthy given the breadth and depth of coverage these databases typically provide across various disciplines, especially in the\n\nUnveiling Linguistic Frontiers in the 21st Century: A Systematic Literature Review                                    Alharbi fields of linguistics, education, and data science. The limited search results underscore a substantial gap in the existing body of knowledge, indicating a pressing need for further investigation and scholarly attention within the Saudi Arabian context. This dearth of research not only highlights the novelty of the topic but also presents a unique opportunity for researchers to make substantial contributions to the field of data-driven language learning in Saudi Arabia. The issue is further substantiated by the fact that the database searches for research studies pertaining to the main topic, which yielded a paucity of results, and exhibited a conspicuous lack of relevance to the central query, failing to adequately address the nexus between big data analytics and technology-enhanced language acquisition within the Saudi context.\n\nThe scarcity of published works may be attributed to several factors, such as the emerging nature of big data applications in language learning, methodological challenges in implementing data-driven  approaches  in  the  Saudi  educational  system,  or  a  lack  of  awareness  regarding  the potential  significance  of  this  intersection  within  the  academic  community.  Consequently,  this under-researched area represents fertile ground for innovative studies, interdisciplinary collaborations, and the development of new theoretical frameworks tailored to the unique linguistic and cultural landscape of Saudi Arabia. Future research initiatives in this domain have the potential to significantly advance our understanding of how big data can revolutionize language learning practices in the Kingdom and potentially yield valuable insights with far-reaching implications for educational policy and practice in the region.\n\nThough there were several search results generated from the chosen databases, the vast majority (if not nearly all) of those results were either unrelated to the focus of this study or, related to different contexts or different purposes. The only research paper which can be said to have been very related to our literature review is the study by Alhammad (2023) which examined the use of Learning Analytics (LA) in an EFL classroom at a Saudi university and emphasized its immense benefits  in  Language  Learning  (EFL)  as  supported  by  previous  studies  such  as  Zhang  (2022), Godwin-Jones  (2021)  and  Crosthwaite  et  al.  (2023).  The  study  analysed  the  online  learning behaviours of 25 female undergraduate students over Six weeks using data from the Blackboard Learning Management System (LMS). It found that lesson videos were accessed most frequently, followed by practice exercises, with textual notes used least. There was a significant correlation between  viewing  teacher  videos/readings  and  final  exam  performance.  Topic  completion  and practice  exercises  also  positively  correlated  with  grades.  The  study  concluded  that  LA  could provide valuable insights into student learning patterns and help predict academic performance in EFL  contexts.  It  recommends  ways  teachers  can  use  LA  to  improve  instruction  and  support students in the Saudi context which is in parallel with previous studies which supported the idea of  utilising  Big  Data  in  education  in  KSA  such  as  Lee  et  al.  (2020),  Almutairi  (2021)  and Baniawwad et al. (2023).\n\nThis systematic review has underscored the importance of big data in advancing language learning in the Saudi Arabian context. While unique challenges exist, the foundational principles highlighted in previous studies on data-driven education and EFL provide valuable insights. These findings suggest that a culturally and technologically tailored approach to integrating data analytics could  help  overcome  current  barriers.  The  review  ultimately  reinforces  the  need  for  further research to realize the full potential of DDLL within Saudi Arabia's educational system\n\nUnveiling Linguistic Frontiers in the 21st Century: A Systematic Literature Review                                    Alharbi\n\n\n## Recommendation for Future Research\n\n\nDue to the limited research on the role of big data in language learning within the Saudi Arabian context, further exploration is essential. Future studies should aim to develop and assess DDLL models that address the unique needs and characteristics of Saudi learners. Additionally, researchers should examine sociocultural factors that could affect the acceptance and effectiveness of data-driven methods in language education. Investigations that combine big data with other emerging technologies, such as artificial intelligence and natural language processing, could offer valuable insights for improving language learning experiences. Addressing these challenges and integrating advanced  technologies  could  strengthen language  education  in Saudi  Arabia. Leveraging big data in this way, educators and policymakers can work toward establishing a datadriven language learning environment that promotes linguistic proficiency and equips learners for the demands of the 21st century.\n\n\n## Conclusion\n\n\nThis study has explored the present landscape of research on data-driven language learning (DDLL) within the Saudi Arabian context, highlighting both the promising advantages and the obstacles related to adopting big data methods in English as a Foreign Language (EFL) education. The findings reveal a significant research gap in understanding how big data-driven methodologies can be optimized for the unique sociocultural and educational landscape of Saudi Arabia. This gap, coupled  with  the  growing  importance  of  personalized  and  technology-enhanced  learning, underscores the need for tailored approaches that consider local educational priorities and learner needs.\n\nThe  review  has  shown  that  while  DDLL  offers  numerous  opportunities  to  improve engagement, adapt learning content, and enhance linguistic competence, challenges such as data availability,  ethical  considerations,  and  the  need  for  culturally  sensitive  practices  must  be addressed. As  noted,  there  is  a  need  for  frameworks  that  effectively  integrate  big  data  with emerging technologies like artificial intelligence and natural language processing, aiming to create adaptive, learner-centred environments that empower students and educators alike.\n\nUltimately, by bridging current research gaps and adopting data-driven strategies, Saudi educators and policymakers have the potential to foster a robust language learning ecosystem that aligns with the nation's Vision 2030 goals. This ecosystem can cultivate linguistic competence, lifelong learning, and technological proficiency, equipping Saudi learners to meet the demands of an increasingly interconnected and digital world. Continued research and innovation in this domain will  be  essential  for  driving  future  advancements  in  language  education  and  for  ensuring  that DDLL methods serve as transformative tools within Saudi Arabia's educational landscape.\n\nFunding\n\n: This research is not funded.\n\nAcknowledgments\n\n:  Not applicable.\n\nConflicts of Interest\n\n:  The author declares no conflict of interest.\n\nAuthenticity:\n\nThis manuscript is an original work.\n\nArtificial Intelligence Statement: AI and AI-assisted technologies were not used.\n\n",
         "This study delves into the potential role of big data and data-driven language learning in shaping the language learning landscape within the Saudi Arabian context. A comprehensive literature review, following the four main phases of PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines involving Boolean operators (AND, OR, NOT) to employ specific inclusion/exclusion criteria as well as truncation techniques across major academic databases and prominent journal publishers, revealed a significant gap in research about how data-driven approaches influence language teaching in the Saudi educational context and sociocultural environment. As such, this study aims to illuminate the need to fill the identified gap by providing insight into future avenues for exploring big data’s role in language pedagogy specific to Saudi Arabia. By addressing the main research question of how big data can influence and enhance language learning, this research underscores the importance of developing innovative, data-informed strategies that align with Saudi Arabia’s educational goals. Ultimately, findings will inform and recommend various approaches to empower language educators, policymakers, and stakeholders in harnessing the transformative potential of big data. This will enable the development of data-driven strategies to foster linguistic competence, promote lifelong language learning, and cultivate a data-driven culture of language proficiency among Saudi students. The research provides valuable insights into an understudied area at the intersection of big data, language pedagogy, and the distinct Saudi educational landscape",
         ""
        ],
        [
         "14",
         "14",
         "## Introduction\n\n\nThe changing landscape that has emerged in the digital age offers academics new ways to work on research and disseminate research outputs (Laakso and Björk, 2022; Scanlon, 2014). Open access (OA) refers to free and unrestricted access to electronic versions of scholarly publications (Björk et al., 2014). There are two main subtypes of OA: gold OA , in which articles are published in open access when they are open directly on the journal website (Piwowar et al., 2018; Tennant et al., 2019) and the green OA route refers to indirect free access to an article or an earlier version of the manuscript that is available on the web at a repository (Harnad et al 2004; Piwowar et al., 2018; Tennant et al., 2016). Traditional green OA refers to the depositing of an article in subject-based or institutional repositories (Björk, 2017). However, academic social networking sites (ASNs), such as ResearchGate and Academia.edu, both founded in 2008, allow scholars to share their work  and  provide  open  access  virtually  to  scholarly  articles  (Lovett  et  al.,  2017). Although some scholars propose to address ASNs as part of the illegal black route to OA due to the copyright compliance issues (e.g., Björk, 2017), others address these platforms as an additional mode of OA publishing similar to academic repositories (Jordan, 2019).\n\nThe terms 'green OA' and 'self-archiving/depositing' are often used interchangeably. However, the decision to make the article openly available does not always depend only on  the  author,  but  rather  on  various  policies  among  publishers,  institutions,  research findings, and the authors (Laakso, 2014; Tennant et al., 2016). Green and gold OA levels vary  greatly  by  discipline,  with  the  highest  levels  being  in  some  STEM  (science, technology, engineering, math) fields and low levels overall in SSH (social sciences, arts and humanities) (Bosman and Kramer, 2018). Green repositories are well developed in STEM  disciplines  compared  to  their  counterparts  in  humanities  and  social  sciences (Bosman  and  Kramer,  2018;  Momeni  et  al.,  2021).  In  addition,  STEM  subscribers' journals  require  a  shorter  embargo  period  before  making  the  published  articles  freely available, compared to SSH journals. Academics often raise concerns about publishers' copyright  terms  and  policies  regarding  self-archiving,  which  prevent  them  from depositing their articles  on green OA platforms (Narayan and Luca, 2017; Zhang and Watson, 2017).\n\nOA publishing benefits the public and authors. Piwowar et al. (2018) emphasized that the number of OA articles' citations, can greatly increase while using the green channels. However, other researchers (Zhang and Watson, 2017) asserted that much of the OA citation advantage experienced by green OA articles might be the result of other factors such  as  disciplinary  affiliation  with  STEM  disciplines  publications.      Hence,  it  is important and interesting to explore the phenomenon of self-archiving in the green OA route from researchers' perspective. Therefore, the present study aims to explore Israeli researchers' perceptions from STEM and SSH disciplines, in order to reveal the types, patterns,  motives,  and  challenges  underlying  their  self-archiving  in  the  green  route  to open-access and in ASNs.\n\n\n## Literature Review\n\n\n\n## The green route to OA: The potential, challenges, and discipline-based context\n\n\nOA describes  a  radical  new  dissemination  model  for  scientific  research  publications (Björk et al., 2014). The Budapest Open Archive Initiative (BOAI) (2002) declaration provided the first community-agreed definition of open access and was closely followed by the Berlin declaration and Bethesda definition, both in 2003, and known as the BBB OA Declarations. According to Suber (2015), OA work has the following characteristics: digital, online, free of charge, and free of most copyright and licensing restrictions. The key elements of these definitions and declarations were neutral as to whether this goal should be achieved through Green (repositories) or Gold (journals) open access (Gadd and Troll Covey, 2019). Thus, Piwowar et al.'s (2018) definitions address OA articles as 'free to read online, either on the publisher's website or in an OA repository' (p. 4).\n\nSimultaneous with the development and establishment of open-access journals since 2005, institutions and organizations began to establish repositories to address the need for discoverability and preservation of self-archived open access copies of papers (Gadd and Troll Covey, 2019). The green route to open access addresses author self-archiving, in which  peer-reviewed  articles  and/or  non-peer-reviewed  pre-prints  are  posted  online, usually without charge,  after  an  appropriate  embargo  period  that  is  agreed  upon  with commercial publishers (Abdelrahman, 2020; Tennant et al., 2016).  The Scopus database allows green articles to be freely read at repositories only ,  and includes two versions: green  accepted  and  green  final.  That  is,  the  manuscript  accepted  for  publication\n\n(manuscript after peer review, but without publisher formatting) and the final manuscript are available at a repository (McCullough, 2022).\n\nAuthors can self-archive their work in institutional repositories which are under the direct  control  of  the  institution,  or  in subject-specific  repositories such  as  arXiv (https://arxiv.org/) for STEM disciplines, BioRxiv (https://www.biorxiv.org/), a preprint server  in  biology,  or  SSRN  (https://www.ssrn.com/)  for  the  social  sciences.    Two databases  provide  a  comprehensive  list  of  institutional  and  subject  OA  repositories: ROAR (Registry of Open Access Repositories, http://roar.eprints.org/) and OpenDOAR (Directory of Open Access Repositories, http://www.opendoar.org/). Additionally,  authors  can  upload  a  version  of  their  work  on  their  personal  website. Although institutional repositories (IRs) have become widespread, they were consistently under-populated and under-utilized (Laakso et al., 2017; Ten Holter, 2020).\n\nFollowing the BBB OA declarations, major research institutions in Australia, China, France, Germany, Greece, Hungary, Italy, Norway, Portugal, Switzerland, the UK, and the US have committed themselves to provide OA for their research output (Edwards, 2016;  Sanjeeva  and  Powdwal,  2017).  More  recently,  grant  stipulations  for  over  100 funding organizations, including Plan S and Europe PMC Funders' Group, increasingly require peer-reviewed research outputs be freely available. These aims can be achieved by publishing in OA journals (gold OA), or archiving publications in an OA repository (green OA). In some cases, both options are required (https://v2.sherpa.ac.uk/juliet/about.html). Further, in March 2021, the European Commission launched an Open Research Europe repository platform for scientific papers funded by Horizon Europe - Horizon 2020 (https://open-research-europe.ec.europa.eu/).\n\n\n## Challenges in self-archiving articles\n\n\nResearchers, students, libraries, organizations, businesses, physicians and patients, and developing countries all greatly benefit from open research and data (Laakso et al., 2011). OA can increase researchers' audience and impact by delivering wider and easier access. According to Piwowar et al. (2018), OA articles receive 18% more citations than average, an effect driven primarily by Green and Hybrid OA. Yet, there is a large gap between the potential  for  self-archiving  permitted  by  publisher  policies  and  the  practice  of  selfarchiving by scholars (Bosman and Kramer, 2018; Piwowar et al, 2018).\n\nAlthough the rate of archiving green papers has increased over time, in 2019 it was only 4% of the total articles published (Piwowar et al., 2019). According to Fry et al. (2011),  researchers  who  associated  open  access  with  'self-archiving'  were  in  the minority. Self-archiving processes in green OA repositories are complex for some authors due to their technological aspect which can be a tedious and difficult administrative task requiring numerous attempts to complete. Thus, authors refrain from depositing articles to repositories (Ten Holter, 2020). Moreover, many researchers lack awareness regarding the value of open access in general and of the green route in particular (Björk, 2017; Zhu, 2017).  Further,  there  is  confusion  and  misunderstanding  about  publishers'  copyright policies (Narayan and Luca, 2017). Studies have shown that researchers lack resources and  information  regarding  self-archiving  and  that  they  struggle  with  exhausting  and difficult administrative processes that may require to complete (Lovett, 2017; Ten Holter, 2020).  Gadd  and  Troll  Covey  (2019)  assert  that  publishers  have  in  theory  become 'greener'  over  time  by  allowing  some  sort  of  self-archiving,  while  simultaneously increasing restrictions around the when, where, and how of self-archiving.\n\n\n## Green open access and discipline-based context\n\n\nGreen open access levels vary by discipline, with the highest levels (over 50%) in STEM (science, technology, engineering, math) fields and low overall levels (under 20%) in Social Sciences and Arts and Humanities (Bosman and Kramer, 2018; Maddi et al., 2021; Momeni et al., 2021; Laakso and Björk, 2022). According to Martín-Martín et al.s' (2018) finding, the disciplines with a larger share of documents in the green OA category were astronomy and astrophysics (56.2%), and mathematics (21.1%), and the lowest were arts (4.1%) and literature (2.9%).\n\nWhitley (1984; 2000) identifies two elements that explain cultural differences between disciplines: mutual dependence and task uncertainty . Mutual dependence addresses the degree of interdependence among researchers as they create valid knowledge.  Mutual dependence has two aspects: functional mutual dependence (FMD) - that addresses the degree  to  which  researchers  are  expected  to  adhere  standardized  ideas.  A  high  FMD implies that a set of methods must be followed in order to gain recognition and reputation. The second aspect is strategic mutual dependence (SMD) which tends to relate to social considerations  such  as  reputation  building.  This  aspect  includes  the  extent  to  which\n\nresearchers have to convince others of the significance of their work. (Fry &amp; Talja, 2007). Low SMD is typical of a discipline that does not have a dominant set of ideas that presents what is considered as an acceptable and valuable scientific output (Whitley, 1984; 2000).\n\nTask uncertainty addresses  the degree  of  uncertainty in  producing  and  evaluating  the valid knowledge. A high degree of uncertainty is influenced by external factors such as lack of consistency of strategies and goals. Whitley (1984; 2000) divided task uncertainty into  two  aspects  The  first  is  technical  uncertainty  (TU)  that  addresses  the  inability  to understand  work  techniques  or  how  to  produce  reliable  results.  The  second  aspect  is strategic uncertainty (SU) that addresses the inability to perceive a consensus about the importance and/or priority of goals. Whitley (1984; 2000) argues that a combination of possible variations in the degree of mutual dependence and task uncertainty can be used to  explain  the  contrasting  organizational  structures  exhibited  by  SSH  and  STEM disciplines.\n\nThe present study, follows previous studies (e.g. Bayer et al., 2019; Fry &amp; Talja, 2004), and tries to explain the variation between disciplines. Researchers proposed Whitley's theory  as  a  theoretical  framework  that  illustrates  the  connection  between  the  cultural identity of a field and the patterns of scientific publication (Fry et al, 2016). While trying to investigate cultural differences between the STEM and SSH disciplines, researchers addressed several aspects. The first is that   publication practices and behavior are shaped by a discipline's traditional cultures (Bosman and Kramer, 2018; Maddi et al., 2021). The second is that research outputs' assessment is influenced by the institutional and national contexts where SSH and STEM research is taken place (Bayer et al., 2019).\n\nAccording to Ochsner et al. (2020), there is difficulty in various SSH disciplines to define and evaluate research outputs compared to STEM disciplines. This may be a result of the lack of a linear process of progress and a much longer time span required to assess the academic impact of SSH publications.  In addition, SSH disciplines are traditionally less focused on demonstrating an 'impact' on external and internal stakeholders compared to  STEM  (Reale  et  al.,  2018).  Thus,  the  different  roles  of  informal  and  formal interdependence in each discipline shapes its publishing norms and practices (Fry et al., 2016; Momeni et al., 2021).\n\nParallel with the accelerated development of gold OA in STEM fields, green OA is well-developed  in  their  fields  compared  to  their  counterparts  in  SSH  (Bosman  and Kramer,  2018;  Serrano-Vicente,  2016).  Researchers  in  STEM  disciplines  are  more confident about the green route process. For some of the STEM disciplines, preprints are essential and for others, self-archiving of the published version have a central role (Bayer et al., 2019; Fry et al., 2016). In addition to the discipline's norm, different publishing houses  impose  different  embargo  periods  before  making  the  published  articles  freely available, which can explain the observed differences between the disciplines.  STEM subscribers' journals require up to a year's embargo, compared to up to 36 months for SSH journals (Martín-Martín et al., 2018). For these reasons, some refer to STEM as 'open access (OA) friendly' disciplines (Fry et al., 2016).\n\n\n## Academic social networking sites\n\n\nOver the course of a decade, academic social networking sites (ASNs) have emerged. In ASNs, articles are shared by authors using commercial online social networks. The most popular  sites,  both  founded  in  2008,  are  ResearchGate  and  Academia.edu  and  allow scholars  to  share  their  work  and  connect  virtually  with  other  researchers  worldwide (Matthews, 2016). There is an ongoing debate as to whether the ASNs are an integral and legitimate part of the OA green route (Björk, 2017). Some argue that publications shared on ASNs are not OA at all because, in contrast to the green OA repositories, ASNs do not check for copyright compliance. Thus, a considerable rate of their content is illegally posted and hosted (Jamali, 2017). Due to these issues, some studies exclude ASN-hosted content from their definition of OA (e.g., Piwowar et al., 2018).\n\nMoreover, Scopus and Web of Science, the two titans of bibliographic information in today's academic world, include published, submitted or accepted versions of articles in the green category only if they are hosted on a legitimate source, namely an institutional or subject-based repository (Pranckutė 2021; McCullough,  2022).  The source  of OA green  and  gold  documents in  Scopus is Unpaywall,  a  non-profit organization  that harvests  OA  content  from  over  50,000  publishers  and  repositories. According  to Unpaywall,  they  harvest  content  from  legal  sources  including  repositories  run  by universities, governments, and scholarly societies, but they \"do not harvest from sources of dubious legality like ResearchGate or Sci-Hub\" (Unpaywall, para. 3). Nevertheless, despite  these  concerns,  ASNs  platforms  as  far  provide  an  online  hosting  space  for\n\nacademics to upload their papers, are used by other scholars, and serve as an additional channel of green OA (Jordan, 2019; Lovett et al., 2017).\n\n\n## The research context, aim, and questions\n\n\nSustainable OA policies and mandates by funders and research institutions have led to a significant shift to OA publication models in academic workflows (Carvalho et al., 2017). According  to the registration of open  access repository mandates  and  policies (ROARMAP), Israel  has  one  institutional  repository  (Weizmann  Institute  IR)  but  no institutional academic OA mandates. In addition, according to Moskovkin et al.'s (2021) index of countries involved in the OA movement, Israel ranks 96th out of 168 countries, far below countries that have similar scientific outputs. According to the Scopus database, 47.9% of the total publications of the Israeli researchers was published in OA routes in 2021.  Of  these,  75.8%  were  defined  as  green  OA  (published  version  or  manuscript accepted for publication, available at repositories); most of these green publications were in STEM fields (85.5%).\n\nThe literature discussed so far has presented a general positive trend towards the OA route;  however,  it  also  presented  large  disparities  among  countries,  resulting  in  the various measures they take concerning OA policy (Maddi et al., 2021; Martín-Martín et al., 2018). In addition, the literature suggests a correlation between the disciplinary profile and  green  OA  publications.  Further,  there  is  an  ongoing  debate  as  to  what  is  being considered as green OA, and whether ASNs are an integral and legitimate part of the OA green route. Therefore, the aim of the current study is to examine Israeli researchers' perceptions from STEM and SSH disciplines concerning the green route to open-access, in  order  to  investigate  the  types,  patterns,  motives,  and  challenges  underlying  selfarchiving articles in the green route to open-access.\n\n## Research questions:\n\n- 1. What are the characteristics (types, patterns, and motives) of self-archiving articles in the green route of researchers from STEM and SSH disciplines?\n- 2. Who is the initiator and responsible for self-archiving an article in the green route?\n- 3. What are the challenges facing researchers when self-archiving articles using the green route?\n\n\n## Types of OA repositories, patterns and motives in self-archiving\n\n\nThe first research question examined the types and patterns of s articles' self-archiving in the green route of researchers, and their motives (n=182, 54% of the total statements). A chi-square for goodness of fit and standardized residuals tests were conducted (Table 2) in  order  to  examine  the  significance  of  the  differences  in  the  number  of  statements observed in each group according to researchers from STEM and SSH fields.  Statistically significant results are presented in the following tables in bold.\n\nTable 2. Types of OA repositories, patterns and motives in self-archiving (182, 54%)\n\nNote: N= the number of statements.\n\nAs seen in Table 2, there are sub-categories regarding the types, the version patterns, and the motives without any significant difference between the proportion of statements in  each  sub-category.    Significant  differences  within  the  sub-categories  were  found between the two groups (i.e., STEM researchers compared to those in SSH). The subcategories and representative statements are presented below.\n\n\n## A. Types of OA repositories\n\n\nSelf-archiving  in  subject-based  repositories  versus  self-archiving  in  ASNs. Most researchers who participated in the study (96%), from all fields, referred to self-archiving articles  in  the  OA  green  route.  However,  while  SSH  researchers  deposit  in  social academic  networks  at  a  marginally  significant  rate,  STEM  researchers  significantly deposit more in subject-based repositories, as expressed in the following statements:\n\nI  do  not  know  repositories  in  my  field,  so  I  put  a  link  to  the  article  where  I  can, especially in ResearchGate and Academia.com databases (SSH.R. 254).\n\nEven the articles that are not published in open access, we upload to arxiv.org. So my articles are open in any way, and anyone can read them (STEM.R.183).\n\nDeposit OA version on author's page. This sub-category refers to depositing articles on an author's personal page or university website page regardless of discipline: I, like most researchers I know, publish their articles on their website or personal page (STEM.R.127).\n\n\n## B. Patterns and motives in self-archiving articles\n\n\nResearchers have referred to articles' deposit patterns as a function of disciplinary norms: Depositing pre-/post-print version versus posting a link to the publisher's site . STEM researchers reported significantly more statements than SSH researchers regarding selfarchiving their articles to subject-based repositories such as arXiv. STEM researchers self-archived their articles in pre- and post-print versions as a norm and an acceptable alternative to publish in open and closed access journals in order to receive recognition, professional prestige, and claim priority for research innovation. This is expressed in the following statements:\n\nIn my field (astrophysics), publishing in an open repository is more important than publishing in a journal. Everyone in the community uploads their work to arXiv while submitting  to  a  journal,  so  the  question  of  whether  the  journal  is  open  or  not  is irrelevant (STEM.R. 82).\n\nThere is a rapid advance in the computer science field, so I publish an initial version of my work in an open repository to declare that I am researching this subject before others. (STEM.R. 261).\n\nCompared to STEM researchers, SSH researchers reported significantly more statements regarding uploading to the ASNs a link to the printed or published version of their article at the publisher website , where the goal is distribution and greater visibility:\n\nI  do  not  know  exactly  what  is  allowed  and  what  is  not,  but  I  want  to  \"open\"  and distribute  the  article  and  increase  visibility,  so  I  upload  an  abstract  -  mainly  to ResearchGate and Academia.com - and put a link to my article on the publisher's site (SSH.R. 36).\n\n\n## Initiators and those responsible for depositing articles in open repositories\n\n\nThe second research question examined who is responsible for depositing an article in OA repositories (72, 22% of all statements). A chi-square for goodness of fit and the standardized  residuals  tests  were  conducted  (see  Table  3)  in  order  to  examine  the significance  of  the  differences  in  the  number  of  statements  observed  in  each  group: STEM and SSH researchers by their occurrence in the study. Table 3 presents the subcategories and research variables.\n\nTable 3. The initiative to deposit an article in the OA repositories (72, 22%)\n\nNote:  N= the number of statements.\n\nAs seen in Table 3,  researchers  had  three  main  reasons  for  depositing  and/or  selfarchiving articles: personal, research funders, and co-authors.  It appears that Author was responsible to deposit in OA repositories was the largest sub-category among the three (standardized residuals= +2.04) with no difference between the disciplines.  Significant differences within the other two sub-categories were found between STEM researchers compared to SSH. The sub-categories and representative statements are presented below:\n\nAuthor responsible for self-archiving in OA repositories .  The largest sub-category referred  to  researchers'  independent  choice  to  submit  their  article  to  a  subject-based repository or to social academic networks: The decision is mine. I choose which article and which database to deposit it as well (STEM.R.89).\n\nGrant conditions require OA archiving . STEM researchers have reported that the grant conditions of funding organizations require peer-reviewed research outputs to be made freely available: The articles were written under a research grant we received from 'The Seventh  Framework  Research  Program  (FP7)  foundation,  and  they  demanded  open access publishing in journals as well as in open repositories (STEM.R.131).\n\nDecision of the co-authors . A number of statements, mostly from the STEM researchers, referred to the fact that co-authors are the ones who upload the article to the repository, mostly a subject-based one: There are articles that my research partners uploaded to arXiv.  For  example,  an  article  from  2018  -  I  did  not  deposit  the  article  there (STEM.R.17).\n\n\n## Challenges in self-archiving articles using the green route to open access\n\n\nThe third research question examined the challenges in self-archiving articles with the green route to OA (80, 24% of the total statements). A chi-square for goodness of fit and the  standardized  residuals  tests  were  conducted  (Table  4)  in  order  to  examine  the significance of the differences in the number of statements observed between each group in the study. Table 4 presents the sub-categories and research variables.\n\nTable 4. Challenges in self-archiving articles to the green route to OA (80, 24%)\n\nNote:  N= the number of statements.\n\nAs seen in Table 4, researchers mentioned four challenges in self-archiving articles in OA repositories. Unawareness  of  copyrights  and  publishers'  terms  of  self-archiving articles was  found  to  be  significant,  and  the  largest  sub-category  among  the  four (standardized  residuals=  +3.80)  with  significant  difference  between  the  disciplines. Significant  differences  within  the  other  sub-categories  were  found  between  STEM researchers and SSH researchers. The sub-categories and representative statements are presented below.\n\nUnawareness of copyrights and publishers' terms of articles' self-archiving . Researchers,  mostly  those  in  the  social  sciences  and  humanities,  have  focused  on copyright issues and lack of awareness of publisher's terms and permitting self-archiving as the main reasons that prevent them from depositing articles to repositories:\n\nAs soon as I uploaded to that repository, they removed the article and also warned me that I would not upload the same article a second time. I was told that the article is  still  unpublished... since I do not deposit articles in open repositories. I do not have time to check for each article what is allowed and what is not (SSH.R.225).\n\nLack  of  awareness  of  appropriate  repositories  in  the  researcher's  field . Some researchers have reported that they are unfamiliar with open repositories in their field: I just do not know well open repositories in my field, where I can deposit my articles there (SSH.R.29).\n\nFear of 'scooping'. STEM researchers significantly reported feeling fear. As a result of depositing a pre-print article in OA repository, someone else may claim the research idea or the findings:\n\nOne of the reasons to self-archiving in OA repositories is to claim priority. But that does  not  stop  people  from  copying  from  you  and  publish  before  you  do.  Most researchers do not want to ruin their good name. But there are other researchers, and they will say that they happen to be researching the same idea in parallel with the one you published in Bioarchive, so I cannot take a risk (STEM.R.91).\n\nLack of time as a reason for non-depositing. STEM researchers have reported lack of time  as  a  reason  that  prevents  them  from  depositing  articles  to  repositories: I  do  not upload to repositories, but basically, if I had time I would upload. It is not because of unwillingness, but simply out of lack of time (STEM.R.24).\n\n\n## Discussion\n\n\nThe green route to open access takes place via self-archiving (depositing) an output into institutional or subject-based repositories, and can greatly benefit authors by increasing scientific output impact, as well as by providing wider and easier access (Bosman and Kramer, 2018; Piwowar et al, 2018). This study incorporated qualitative and quantitative methods for an in-depth  understanding  and  revealed  the  types,  patterns,  motives,  and challenges  underlying  researchers'  perceptions  regarding  self-archiving  articles  in  the green  route  to  open-access.  Interviews  were  conducted  with  20  Israeli  academic researchers, 10 from STEM and 10 from SSH disciplines.\n\nThe  first  research  question  examined  the  types  of  OA  green  routes,  patterns,  and motives  in  self-archiving articles. Researchers  in  the  current  study  reported  the\n\nwidespread use of the green OA model. Due to the lack of institutional repositories in Israel, researchers reported depositing in subject-based repositories, in ASNs or in their personal  or  university  websites.  However,  the  types,  patterns,  and  motives  of  selfarchiving vary greatly by discipline. STEM researchers self-archiving articles to subjectbased repositories (such as arXiv, BioRxiv and PubMed Central), using pre-/post-print versions,  as  a  part  of  their discipline  norm  due  to  grant  conditions,  and  receive recognition, professional prestige and claim priority. As found in a previous study, selfarchiving in the green route is associated with researchers' awareness of OA policy and attitudes  towards  the  importance  of  OA  publishing  (Zhu,  2017).  Here,  as  was  true  of previous studies (e.g., Bosman and Kramer, 2018; De Filippo and Mañana-Rodríguez, 2020),  findings  reveal  a  significant  difference  between  the  disciplines  and  suggest different norms  in  various  disciplines.  Indeed,  as  was  previously  suggested,  the researcher's social environment influences and predicts publication in OA ((Laakso and Björk, 2022; Kocaleva et al., 2015).\n\nIn  addition,  as  a  result  of  different  embargo  periods,  there  are  fewer  established subject-based repositories in SSH than STEM subject-based repositories (Martín-Martín et  al.,  2018;  Narayan  and  Luca,  2017),  a  fact  that  may  explain  STEM  researchers' preference for these repositories. Hence, it seems that such repositories have become part of the established workflow for researchers in STEM fields. Although STEM participants were concerned about their research being 'scooped' by preprints, the overall benefits for those researchers seem to outweigh any perceived risk (Sarabipour et al., 2019).\n\nThe current study used Whitley's (2000) theory as a theoretical framework to show the connection between the cultural identity of a field and the patterns of scientific selfarchiving. Whitley (2000) argues that the epistemic and social organization of scientific fields can be conceptualized  along  the axes of \"task uncertainty\" and  \"mutual dependence\". The study's findings are in accordance with Whitley's (1984; 2000) theory of the differences between the disciplines. Findings reveal that STEM researchers are characterized by a high functional mutual dependence (FMD). They established methods of self-archiving and adhered to disciplinary norms to gain recognition and reputation. Moreover, STEM researchers have consistent goals, they were more confident in sharing their knowledge  and  exposing  it  to  the  scientific  community,  and  are  therefore characterized by a low degree of uncertainty.\n\nIn  contrast  to  STEM  researchers,  SSH  researchers  have  less  familiarity  with  open repositories in their fields. However, they upload a link to the printed-published version of their articles to publisher's websites in ASNs. Their goal is to have greater visibility , which  may  increase  the  number  of  citations.  Lovett  et  al.  (2017)  discovered  that academics prefer to distribute the final version, although this is more likely to violate copyright restrictions. Indeed, this study also found that SSH academics prefer to deposit articles in their final version.  Yet, some SSH researchers seem to be content with simply uploading links to the published closed article, perhaps because they lack an understanding  of  copyright  policies,  as  found  in  other  studies  (Jamali,  2017;  MartínMartín et al., 2018).\n\nAlthough most leading scholars and databases do not include ASNs as an integral and legitimate part of the OA green route, due to copyright issues (Jamali, 2017; Piwowar et al.,  2018;  Scopus  database),  ASN  platforms  are  referred  to  by  some  scholars  as  an additional channel of green OA (Jordan, 2019; Lovett et al., 2017). However, ASNs do not prevent uploading final manuscripts, even though this action may involve a great risk in terms of copyright violation (Jordan, 2019; Serrano-Vicente, 2016). Our current study suggests that ASNs provide SSH researchers the opportunity to have an online hosting space  for  their  articles,  in  addition  to  the  traditional  closed  publishing  model.  SSH researchers  in  this  study  wanted  to  \"open\"  their  articles  in  order  to  achieve  greater visibility and perhaps they consider ASNs a part of the green route, without getting into the legitimacy  issue. In accordance  with  Whitley's  theory  (1984;  2000),  mutual dependence is influenced by reputational control and control over access to resources. According to the research's findings, SSH researchers, with their limited resources,  make efforts to increase their reputation and convince others regarding the significance of their work. Therefore, SSH researchers in the current study are characterized by low degree of strategic mutual dependence (SMD).\n\nThe second research question asked who is responsible for the motivation to deposit an article in the OA green route. This question is important as it finds out whether selfarchiving is a consequence of an autonomous choice or an external requirement (such as that of the research  funders).  Significantly  more  researchers,  regardless  of  their disciplines, reported that the decision to deposit in repositories or ASNs was a self-made one. These findings are consistent with previous results that self-archiving in repositories\n\nand/or  ASNs  is  associated  with  the  author's  personal  belief  in  OA  visibility  and  its citation advantages (Serrano-Vicente, 2016; Zhu, 2017).\n\nSTEM researchers also reported that it was the co-authors' decision to deposit the article in the open repository. In addition, they said that the grant conditions of funding organizations require peer-reviewed research outputs to be made freely available. Indeed, STEM researchers have more access to resources and grants compared to their colleagues in SSH disciplines (Natale, 2019; Olejniczak and Wilson, 2020; Zhu, 2017). Our findings reinforce other studies that have found that green open access is the most economical approach to comply with open access policies (Zhang and Watson, 2017), compared to gold OA journals that normally charge a fee, known as an article processing charge (APC) (Abdelrahman, 2020).\n\nFinally, the third research question examined the challenges of self-archiving articles using the green route to OA and ASNs. More SSH researchers reported being unaware of copyright issues and publishers' terms for self-archiving published articles. This is the main factor that prevents them from depositing an article and a significant inhibitor, as was  found  in  other  studies  (Jamali,  2017;  Laakso,  2014;  Martín-Martín  et  al.,  2018). Further, researchers (mainly from SSH) have reported that they are unfamiliar with open subject-based repositories in their field.  SSH disciplines experience low levels of OA adoption,  and  subject-based  repositories  have  not  yet  become  part  of  the  established workflow  for  these  researchers  (Narayan  and  Luca,  2017).  These  findings  can  be explained by Whitley (1984; 2000) theory. According to this theory, due to the lack of awareness of copyrights, and lack of familiarity  with self-archiving repositories,  SSH researchers  are  characterized  by  a  high  degree  of  technical  and  strategic  uncertainly. STEM researchers, for their part, were concerned that by depositing pre-print articles in an open repository, someone else may claim priority to the research idea or their findings. There is no evidence, however, that 'scooping' research via preprints exists (Sarabipour et al., 2019). Another challenge reported by STEM researchers in this and past studies is the lack of time that prevents them from depositing articles using the green OA route (Lovett et al., 2017; Ten Holter, 2020).\n\n\n## Conclusion and impactions\n\n\nThis  study  displays  a  significate  difference  between  STEM  and  SSH  researchers regarding the types, patterns, motives, and challenges in self-archiving articles in the OA green route and in ASNs. This difference may reflect different norms that prevail each discipline.  The  green  OA  model  provides  opportunities  for  financially  disadvantaged disciplines  to  self-archive  in  open  repositories.  However,  according  to  the  current findings, there is an urgent need to raise SSH researchers' awareness of open subjectbased repositories in their fields.\n\nFurther, authors should be aware of the permissions and publisher requirements for self-archiving pre-/post-print articles. These policies can be found on the SHERPA/RoMEO (https://v2.sherpa.ac.uk/romeo/) database.\n\nRegarding  ASNs,  although  they  provide  SSH  researchers  the  opportunity  to  selfarchive their works, there were SSH researchers who were satisfied with uploading links to the published closed article. Moreover, SSH researchers in this study wanted to \"open\" their articles in order to achieve greater visibility, regardless of the copyright violation issue. Those researchers, as some scholars' assumption, consider ASNs as an additional mode of OA publishing, similar to academic repositories (Jordan, 2019). This comparison should  be  carefully  considered,  followed  by  the  need  to  provide  researchers  with information about the OA green route and its characteristics.\n\n",
         "The green open access (OA) model, which offers the most economical approach to comply with open access policies, can increase researchers’ audience and scientific outputs impact by delivering wider and easier access. This study examined researchers’ perceptions from STEM (science, technology, engineering, math) and SSH (social sciences, art and humanities) disciplines in order to reveal the types, patterns, motives, and challenges underlying their articles’ self-archiving in the green route to open-access (repositories and institutional repositories) and ASNs (academic social networks). Interviews were conducted with 20 Israeli academic researchers. Half were from STEM and half from SSH disciplines. Interviews were mapped using a bottom-up thematic analysis and follow-up quantitative comparisons. According to the findings, STEM researchers self-archived pre/post-print versions of their articles to subject-based repositories as a part of their discipline norm resulting from their funding grant requirements and as a way to receive recognition and claim priority. SSH researchers post a link to the printed-published article at the publisher’s website in ASNs, and their goal is greater visibility. In addition, findings indicate a lack of awareness, mostly by SSH researchers, regarding copyright issues and OA repositories. The green OA model provides opportunities for researchers to self-archive their work. However, there are differences between the disciplines regarding where, when, why, and how to self-archive, and what is considered a legitimate mode of green OA. This indicates an urgent need to raise SSH researchers’ awareness of the existence of open subject-based repositories and of the terms of self-archiving from publishers.",
         ""
        ],
        [
         "15",
         "15",
         "## 2 Introduction\n\n\nHow do innovations spread with and against one another? Most prior work considers whether individuals adopt an individual innovation as it spreads across a network. What remains largely unexamined is how multiple innovations or other phenomena are connected in a broader ecology of percolating diffusive processes, and how individual diffusions might spread with or against one another in a community of potential adoters.\n\nThe prototypical diffusion process involves the gradual spread of a possibly contagious phenomenon such as an idea, technology, or disease, through a certain proportion of a population [Rogers et al., 2014]. The diffusion process is inherently social. When someone catches a virus or accepts an idea, they become a vehicle of transmission, accelerating growth until the decaying base of potential recruits decelerates growth. The 'diffusion curve' this process generates provides a good null model, but ignores the decisions and social processes unique to each diffusion. One review of existing innovation research sorts the components of innovation into three main compartments, the characteristics of innovations, the characteristics of innovators, and environmental context [Wejnert, 2002]. While network science can enhance our understanding of each of these three categories of variables, it has almost entirely focused on the connections between innovators - the individuals who may adapt and spread and innovations -but not connections between the innovations themselves. One needs to look no further than the simultaneous spread of the novel-coronavirus, the adoption of vaccines, and the dissemination of information and disinformation about these processes, to see that the fate of diffusing innovations can be directly intertwined with one another. The spread of one phenomenon across a population may influence and structure the spread of others.\n\nThe spread of technological innovations is of particular interest, as the inherent functional relationships between emerging technologies provides a promising empirical area to observe larger networks of interacting diffusive processes. Prior research on the co-diffusion of technological innovations, which examines the relationship between multiple instances of technological diffusion, has typically (if not entirely) considered only two diffusions at a time. Co-diffusion has been considered from a simulation framework [Chang and Fu, 2018], and empirically with the case of the co-diffusion of UPC codes and Scanners [Bucklin and Sengupta, 1993]. The case of diffusion between competing innovations has also been examined [Jovanovic and MacDonald, 1994, Tzoumas et al., 2012], one popular case being the competition between VHS and Betamax in the 1980s [Den Hartigh and Van Asseldonk, 2004, Tomochi et al., 2005, Arnold, 2011]. While such cases are illuminating, they do not account for the complex relationships that may characterize a larger set of diffusing technologies in which the focal innovations are embedded.\n\nWork on the adoption of different political, cultural, and ideological preferences has offered more work on how processes of social contagion may come to be related to one another. Recent studies on political polarization have proposed mechanisms on how pairs or larger sets of political attitudes or beliefs come to have similar sets of adopters. [DellaPosta et al., 2015, Goldberg and Stein, 2018, DellaPosta, 2020]. These mechanisms are compelling because they do not necessarily rely on the underlying content of the diffusions themselves. Structural and cognitive processes alone are sufficient to generate population-wide associations between diffusing beliefs and preferences that otherwise have no fundamental connection, for example, having a preference for lattes and left-leaning political ideologies.\n\nThe notion that political ideas and cultural preferences can become aligned with one another is an important insight that underscores how social facts may emerge from individual cognitive tendencies. However, just because diffusive processes can become aligned with each other regardless of their content, it does not mean that the inherent relationships between diffusive processes are irrelevant. Certain ideas, products, or practices may be more or less compatible with one another, and an individual's adoption of one may make them more or less susceptible to others. Focusing specifically on the context of innovation and the co-diffusion of new technologies, certain products may be explicitly designed to build on (or undermine) the success of other innovations and spread across their existing user bases. Products may either target another technological innovation by either trying to replace it or by trying to complement it and ride on the coattails of its success. Alternatively, a new innovation may unintentionally exploit or replace existing technologies. Whether functional relationships between technologies or intentional or incidental, the presence of one technology may change the costs or benefits of adopting other technologies.\n\nThe vast number of computer programming languages that have emerged over the years offers a compelling case study for a set of competing and cooperating technological innovations. While spoken languages have been considered as an example of diffusion in prior work[Kandler and Steele, 2008], the frequency and speed with which programming languages can be adopted offers a far more dynamic and data-rich. While there is existing research that has considered the case of computer language co-development as a site of competitive innovations [Yun et al., 2016, Valverde and Sol´, 2015], e we use this case to demonstrate that the success of an technological innovation is partially a product of how it is functionally positioned in a broader ecology of adjacent technologies.\n\nA vast empirical dataset available from the GitHub public repository enables an examination of diffusing innovations on a grand scale. In contrast to other diffusion research, we do not use this data to examine how innovations spread across individuals in a social network. Instead, we analyze how these languages build off and detract from one another and constitute a broader network of innovations. We test the overall network of languages for presence of two types of innovative diffusion: competitive (or 'cannibalistic') diffusion where one innovation tends to replace and impede the spread of another, and complimentary (or 'piggybacking') innovation where one innovation spreads on the shoulders\n\nof another. We utilize projections of bipartite networks of coding languages and coding projects (which feature multiple languages), to develop measures of cohesion and equivalence between pairs of languages, and examine how these functional connections predict the tendency for users of one language to begin or stop using another language. This provides a rare portrait of how large sets of innovations percolate with one another in a community. To our knowledge, this is the first study that considers the network of functional relationships that exists between innovations as a driver of broader patterns of diffusion.\n\nFurthermore, the mathematical techniques developed to handle the challenges of this specific data set offer a contribution to network analysis methodology more broadly. Analyzing the co-occurrence of languages across projects of varying size, while also accounting for the fact that certain languages may be more likely than others to appear in projects with more languages overall, required performing many adjustments that we hope will be useful to other scholars analyzing bipartite network datasets with heterogeneous degree distributions.\n\n\n## 3 Data and Hypotheses\n\n\nThe data we use comes from the GitHub public repository, which is available at GHtorrent.org. GitHub is a public coding repository where groups and individuals collaboratively edit shared coding projects, which typically feature more than one user. This data has been used extensively to study processes of group collaboration, emergent hierarchies, and meaning-making [Hoey et al., 2021]. This study zooms out, and focuses on the broader patterns of how languages spread relative to one another as a whole. We focus on the subset of the data from the beginning of 2010 to the end of 2018. For each project that is entered in the GitHub dataset, an initial user, date, and set of languages are available. This allows us to construct one data set that summarizes how languages cooccur with one another across projects, and another data set which contains the history of yearly language use for individual GitHub users.\n\nThe co-occurrence of languages within projects is assessed for each year independently, and gives us an idea of which languages are frequently used with one another (functional cohesion) and which languages may be interchangeable with one another (functional equivalence). The language usage patterns of individuals in aggregate provides a measure of how languages diffuse with (complementary or 'piggybacking' diffusion') and against (competitive or'cannibalistic' diffusion) one another in the broader GitHub community. These diffusion measurements are dynamic and require data from two adjacent time periods, each one year in length. Specifically, the patterns of how languages are used together during one time period, t , is used to predict how language users will begin using new languages between time period t and time period t +1.\n\nTable 1: Summary of Data Analyzed in the GitHub Dataset - For each two-year window, summaries of total (multi-language) projects and average languages per (multi-language) project are shown for year t , the users active in both years t and t +1, and the number of languages that are included in the final network analysis across both years - languages with fewer than 0.5%, 1% or 2% of users in year t are excluded from final network models of diffusion for that period. (Separate models are estimated with each of these three cutoffs as a robustness check.)\n\n\n## 3.1 Hypotheses\n\n\nGiven the data and context at hand, we expect network co-functionality and diffusion to relate to one another in the following ways:\n\nH1: Functional cohesion between two languages will predict higher rates of complimentary/'piggybacking' diffusion. The use of one language will lead to the use of the other in a later time period.\n\nH2: Functional equivalence between two languages will positively predict competitive/'cannibalistic' diffusion. The interchangability of languages mean that their users will be more likely to jump from one to the another.\n\nH3: Functional cohesion will negatively predict competitive/'cannibalistic' diffusion. If two languages are frequently dependent on one another they are unlikely to steal users from one another.\n\nH4: Functional equivalence will positively (H4a) or negatively (H4b) predict complimentary/'piggybacking' diffusion. We do not have a single prediction on whether functional equivalence will be positively or negatively associated with piggybacking diffusion. Functional equivalence may indicate that two languages are used for the same purpose, thus domain experts in said purpose may add more languages to their repertoire. On the other hand, if a user knows how to fulfilling a purpose with one language, they may gain little benefit from learning another. When statistical significance measures are used, this relationship is considered using two-tailed criteria for statistical significance.\n\n\n## 4 Methods\n\n\nDetermining the relationship between diffusion and functionality requires us to consider how languages are both shared by projects, which shows the extent to which they are used together, and by individuals, which shows how languages spread between and across the minds of individual users. Our main set of independent variables in this case are the overlaps between languages by project, and our main outcome variables are the overall usage and co-usage patterns of language by individual users. We use temporal lagging to ensure that the codiffusion patterns across users are not purely determined by project co-usage.\n\nMore specifically, to test our hypotheses, we use MR-QAP Regression to assess how functional cohesion and functional equivalence influence diffusion. For all languages that hit a minimum usage threshold in year t , we calculate matrices measuring functional relationships between each pair of languages at time t . We also construct matricies estimating rates of diffusion between times t and t +1. A functional cohesion matrix is calculated from the ratio of observedto-expected cases of co-occurrence between each pair of languages. Functional equivalence is derived by calculating the cosine similarity of each pair of language vectors in the functional cohesion matrix. Complimentary (or 'piggybacking') diffusion is calculated by looking at the log-odds increase that using a given language A in year t had on newly adopting B in year t+1. Competitive (or 'cannibalistic') diffusion is calculated by looking at the log-odds increase that using a given language A in year t +1 will have on ceasing usage of language B in year t +1. Below, we summarize our methodological strategy for calculating functional relationships between languages, rates of diffusion, and estimating the latter as a function of the former.\n\n\n## 4.1 Calculating Functional Cohesion and Functional Equivalence\n\n\nThe GitHub dataset allows us to look at how frequently languages are being used together within projects, and how pairs of languages are used for similar purposes across projects (denoted by their use alongside similar other languages). These are analogous to the concepts of structural cohesion and equivalence in research in social networks Friedkin [1984]. Re-appropriating this terminology, 'functionally cohesive' languages are used together and frequently appear in the same projects, whereas 'functionally equivalent' languages are used alongside the same other languages, and may be more interchangable.\n\nWhile counting the number of instances where two languages are used in the same project is simple and straightforward, determining the expected level of co-usage requires more adjustments. For any two languages A and B , a naive calculation of the expected number of co-occurrences would take the following form, where n A is the number of projects featuring language A n , B is the number of projects featuring language B n , AB is the number of projects featuring both, and n is the total number of projects.\n\n<!-- formula-not-decoded -->\n\nHowever, projects that have large numbers of languages contribute far more ties to the network than projects that have smaller numbers of languages. Therefore, this estimate will produce an underestimation of the expected number of co-occurrences, and therefore may disproportionately overestimate the cohesiveness between some pairs of languages. Specifically, this will happen between pairs where one or both languages are used in a large number of projects. Furthermore, in networks of cohesion constructed from pairwise measures, this will inflate the centrality and importance of languages that are more likely to be featured in larger projects.\n\nTo account for this, we separately calculate the expected number of overlaps between pairs of languages within projects that have 2 languages, 3 languages, 4 languages, and so on, and add up these totals for each pair. The calculations for expected values are conducted via simulation, as the mathematics for calculating this formally becomes intractable as the number of languages increases. We repeat this simulation process for each calendar year.\n\nThe expected number of co-occurrences between languages A and B for projects featuring k languages is calculated as follows, where A k and B k are the number of projects featuring language A and B respectively that include exactly k languages. For all of the n k projects that feature exactly k languages, one random draw of k different languages are made, where each language A has a probability of being selected that is proportional to A k n k . For each pair of two languages within the k languages that are selected, a total of expected co-occurrences is calculated. (The number of simulated draws can be scaled up by a factor to make the distribution of expected-observations more smooth, as long as the weight that each draw contributes is down-weighted by the same factor. In our case, we conduct two draws per observed project, and each project contributes half as much weight.)\n\nSince more co-occurrences between pairs of languages will happen in projects that feature more languages, individual co-occurrences are down-weighted with respect to the total number of languages so that each project contributes the same weight to the overall dataset. This means that if two languages co-occur on a project that uses three languages, they will be considered to be more closely bound then two languages that co-occur on a project that uses ten languages. This is also done to make sure that projects featuring many languages do not have more influence on the dataset than projects featuring a smaller number of languages. A project featuring three languages, for example, would only contribute three pairs to counts of co-occurrences ( ( ) 3 2 = 3), but a project featuring ten languages would contribute 45 co-occurrence instances ( ( 10 2 ) = 45). Therefore, weights for both observed project co-occurrences and the simulated projects that generate expected co-occurrences are weighted by 2 k ∗ ( k -1) .\n\nThe calculations of the observed and expected co-occurrences for each pair of languages (and for each year of data) enables the calculation of observed-toexpected ratios, which provide a measure of whether two languages are more or\n\nless likely to co-occur on projects than expected by chance. It does this in a way that accounts for the fact that languages differ in how frequently they appear in projects, and that some languages may be disproportionately more likely to appear in projects that feature a high or low number of languages.\n\nObserved-to-expected ratios are then used to calculate two measures of connectivity for each language: cohesion is calculated directly and equivalence is calculated from the matrix of cohesion calculations between languages.\n\nFirst, functional cohesion, the tendency for each pair to co-occur in projects, is quantified by simply taking the log of the ratio of the observed weight to the expected weighted co-occurrences. A value of zero indicates that the number of observed and expected co-occurrences are equal to one another. These calculations can be used to create a symmetrical matrix I where each row and column corresponds to a single programming language. Each entry I A,B is the log transformed ratio of weighted observed-to-expected co-occurrences for languages A and B . A separate matrix is calculated for each year.\n\nThese cohesion matricies are in-turn used to calculate how similar languages are in terms of their co-occurrence with other languages. Drawing on the matrix I , a matrix J is calculated for equivalence. The equivalence of two languages A and B can be calculated as follows:\n\n<!-- formula-not-decoded -->\n\nThis is the dot product of both adjacency vectors, divided by the length of each vector. The distribution of values in matricies I and J for any given year are of distinctively different shapes, but still provide a range of both positive and negative values and considerable variance. The distribution of values in I has high kurtosis, with most values being very close to zero, and some extreme outliers in either direction. The distribution of values in J is more normal, and has a maximum possible value of exactly 1. The distributions of these two independent dyadic variables remain largely consistent across each time period analyzed.\n\nThese pairwise calculations can also be used as edge weights to construct and visualize larger networks of language coherence for any given year, giving us a larger sense of how languages are used with one another. Figure 1 illustrates the network of language co-usage on projects in 2015 for languages that were used by over 2% of participants, and the corresponding adjacency matrix ultimately used in the estimation of this model. Figure 2 illustrates the network and adjacency matrix of cosine similarity scores derived from the cohesion matrix, which approximates their functional equivalence.\n\n\n## 4.2 Calculating Rates of Complementary and Competitive Diffusion\n\n\nCalculating the dependent variables, rates of competitive and complementary diffusion, requires the careful consideration of user data in two consecutive time\n\nFigure 1: Network of language co-occurrence in 2015, for languages that are used by over 2% of GitHub users in that year. The log of the observed-toexpected ratio is used to determine the color of the edge (yellow indicates more co-occurrence than expected, purple indicates less co-occurrence than expected), and the weight of the edge (which corresponds to the absolute value of the log observed-to-expected ratio).\n\n<!-- image -->\n\nFigure 2: Network of language equivalence in 2015, for languages that are used by over 2% of GitHub users in that year. The cosine similarity is used to determine the color of the edge (yellow indicates higher levels of similarity, purple indicates lower levels of similarity) and the weight of the edge (which corresponds to the absolute value of the cosine similarity ratio).\n\n<!-- image -->\n\n<!-- image -->\n\nperiods. For a pair of languages A and B for any given year t , each individual GitHub user can fit into one of four possible categories: they might be a user of both languages A and B , they may be a user of language A and not B , a user of language B and not A , or they may be a user of neither A nor B . Users shift between these 4 mutually-exclusive and completely exhaustive categories between pairs of consecutive years t and t +1. We focus on users who participated on the platform in both years for any given sequence of two years contained in our dataset, ignoring users who either enter the community in year t + 1 or leave the community after year t .\n\nIf we refer to the set of users of language A as A and the set of user of languages B as B , the 4 categories of users for each year can be expressed as A ∩ B , A ∩ ¯ , B ¯ A ∩ B , ¯ A ∩ ¯ B and ¯ . U For any two consecutive time periods and pair of languages on the platform, this gives us 16 different possible types of users. From this 4*4 typology we can identify and engineer several sets of interest to the phenomenon of co-diffusion.\n\nFor each pair of adjacent years, a randomly selected subset of 250,000 users who participated in a project in both years (or all users when the total number is less than 250,000) are analyzed. Each pair of languages that have a representation of higher than 0.5% in the first year of the sample are considered. (Separate models are eventually estimated for representation-cutoff levels of 0.5%, 1%, and 2%.)\n\nFollowing a similar logic to calculations of language co-functionality, measures of complementary or competitive diffusion account for what rates of movement between languages would reasonably be expected by chance. The complementary ('piggybacking') diffusion measure assesses whether or not a user of language A (and only A) at time 1 is more likely to adopt B than a user of neither language at time 1. The 'piggyback ratio' (PBR) from A to B is defined as follows:\n\n<!-- formula-not-decoded -->\n\nWhich can be defined using set theoretical notation as:\n\n<!-- formula-not-decoded -->\n\nThe competitive ('cannibalistic') diffusion measure assesses whether a user of language A and B at time 1 is more likely to stop using language B at time 2 than a non-user of language A (and a user of language B ) at time 1. The 'cannibal ratio' (CBR) from A to B is defined as follows:\n\n<!-- formula-not-decoded -->\n\nWhich can be defined using set theoretical notation as:\n\n<!-- formula-not-decoded -->\n\nBefore implementing each of these dependent variables in the final set of models, each of the 4 set-theoretic calculations within each formula is given n-plus-one smoothing, and the log of the overall ratio is taken.\n\nThe distribution of both functional predictors, compared to the two diffusion outcomes of interest, is shown in figure 3 and 4 for the year 2014 (with diffusion being measured from 2014 to 2015). Each point in the plots corresponds to one pair, with functional equivalence being plotted on the horizontal axis, functional cohesion being plotted on the vertical axis, and the color corresponding to the observed level of diffusion between the two languages.\n\n<!-- image -->\n\nFigure 3: This image shows the distribution of rates of functional equivalence, as measured by cosine similarity between languages, and functional cohesion, as measured by overlap in user bases, in relation to the overall observed levels of Cannibalistic Diffusion. Green points/density curves correspond to the 25% of language pairs with the highest levels of Cannibalistic diffusion, purple point/density curves correspond to the 25% of language pairs with the lowest levels, and yellow corresponds to the middle 50%. Each (x,y) coordinate that corresponds to a pair of languages A and B also corresponds to the pair of languages B and A , so each point is slightly translucent to allow both points some visibility.\n\n<!-- image -->\n\nFigure 4: This image shows the distribution of rates of functional equivalence, as measured by cosine similarity between languages, and functional cohesion, as measured by overlap in user bases, in relation to the overall observed levels of Piggybacking Diffusion. Green points/density curves correspond to the 25% of language pairs with the highest levels of Piggybacking diffusion, purple point/density curves correspond to the 25% of language pairs with the lowest levels, and yellow corresponds to the middle 50%. Each (x,y) coordinate that corresponds to a pair of languages A and B also corresponds to the pair of languages B and A , so each point is slightly translucent to allow both points some visibility.\n\n\n## 4.3 MR-QAP Modeling of Diffusion Rates\n\n\nWhile visualizations can shed some light on the nature of the data and relationships between variables, the estimation of network-level models of diffusion is necessary in order to contend with and account for the issues of dyadic independence that can confound the results of the relationship between one network and another.\n\nA series of quadratic-assignment procedure multi-linear regressions is estimated for each pair of consecutive years [Krackhardt, 1988, Dekker et al., 2007]. This is a permutation-based procedure that allows the assessment of point estimates of the relationships between predictor and outcome networks. Here, this method is used to measure how networks of normalized functional equivalence and functional cohesion between pairs of languages in year t shape networks constructed from the rates of diffusion between and across languages from time t to time t +1.\n\nFrom 2010-2018, models are estimated for complementary and competitive diffusion that using networks of both cohesion and equivalence. Separate models are estimated for each of the 8 full two-year sequences available in the data. The tests are permutation-based, so from a hypothesis-testing perspective we are primarily interested in how the coefficients generated for each network compare to the distribution of coefficients generated by chance, as opposed to the overall explanatory power of the two variables.\n\nThere are three models for each year corresponding to different cutoff rates for language inclusion. Rates that are too high and exclusive limit analysis to a small number of languages, limiting potential statistical power, whereas rates that are too low will include low-popularity languages whose measures may add too much noise to the overall model. Models using rates of 0.5%, 1%, and 2% are all estimated to illustrate how this cutoff level effects the overall results and as a robustness check.\n\n\n## 5 Results\n\n\nRecalling our hypotheses, we predict functional equivalence will positively predict cannibalistic diffusion, and that functional cohesion will positively predict piggybacking diffusion but negatively predict cannibalistic diffusion. We do not have a one-directional prediction for how equivalence may influence piggybacking diffusion.\n\nThe results of all 24 models (8 years * 3 cutoff values) are displayed in 5. Predictions on the role of functional cohesion is confirmed in both sets of models, nearly regardless of year or coefficient size. The co-occurrence of two languages in time t strongly positively predicts the tendency for users of one language to pick up the other language in time t +1. Furthermore, this negatively predicts the tendency for users of one language to abandon the other language in time t + 1. This finding is statistically significant in 21 of 24 models at a level of p¡0.05.\n\nThe role of functional equivalence is more difficult to ascertain. Recall there is not a single prediction for whether functional equivalence predicts complementary diffusion. There are reasonable mechanisms that could causes this relationship to be postiie or negative. In models corresponding to earlier years in our data, equivalence tends to positively predict complementary diffusion at levels at our near statistical significant, yet this effect fades over time. (This could be evidence of a mechanism that generates a negative relationship gradually becoming more powerful relative to a mechanism that generates a positive relationship, but this cannot be said with confidence.)\n\nIn models predicting competitive diffusion, functional equivalence tends to be a positive predictor, but only at a statistically significant level in 2% threshold models for 2015 and 2016, while nearing positive statistical significance in models for 2% models in 2010 and 2013. While the results in aggregate tend to suggest that this effect is more positive than expected by chance, especially in the 2% cutoff models that are less influenced by low-popularity languages, the predictor does not show the strength that functional cohesion does. That said, this could be considered mild support for the hypothesis that functional equivalence and competitive diffusion are positively related in this empirical context.\n\n<!-- image -->\n\nFigure 5: This table summarizes the coefficients and p-values for each of the 24 models estimated for both complementary and competitive diffusion. Three models are estimated for cutoff points of 0.02, 0.01, and 0.005 for each year. Cohesiveness is a consistent positive predictor of complementary diffusion and a consistent negative predictor of competitive diffusion. Functional equivalence, on the other hand, is a positive but somewhat inconsistent predictor or complementary and competitive diffusion. In the case of complementary diffusion, the effect of functional equivalence shifts from positive to neutral over time, and in the case of competitive diffusion, the effect of functional equivalence tends to be more positive with larger cutoff values.\n\nTable 2: The results of MRQAP regressions of complementary diffusion of languages between users over the course of two consecutive calendar years on the cohesion and equivalence of the two languages in GitHub projects during the first year. While functional equivalence typically is a positive predictor of 'piggybacking', the association between cohesion and this type of diffusion shifts from positive to mixed over time.\n\nTable 3: The results of MRQAP regressions of complementary diffusion of languages between users over the course of two consecutive calendar years on the cohesion and equivalence of the two languages in GitHub projects during the first year. The functional cohesion of two languages negatively predicts cannibalistic diffusion, but the functional equivalence tends to be positively predict cannibalistic diffusion.\n\n\n## 6 Discussion\n\n\nThe socio-cognitive and structural mechanisms of diffusion are rightly the focus of much sociological and psychological study, and can help us understand how different innovations, ideas, beliefs, and norms spread either with or against one another, regardless of their underlying content. However, innovations and ideas also have a life of their own once they are launched into the world, and effectively end up competing for a limited amount of 'mind-share' in the brains of a population or community. The GitHub data analyzed here demonstrates that in at least one context, the compatibility of innovations with one another (as conceptualized by functional equivalence and functional cohesion) can have a significant effect on how these innovations spread.\n\nThe analysis presented here should be applied to not only other ecologies of technological innovation and diffusion, but also can be incorporated into studies of contagion, diffusion, and social influence more generally. The methodological approach and findings presented should both encourage and provide guidance for examining how other related sets of diffusive phenomena, be they innovations, ideas, norms, beliefs, diseases, or fads, co-diffuse with one another. For example: Do political ideas that share philosophical compatibility spread with one another? Do different types of exercise supplant or compliment one another in physical fitness routines? Do university courses on similar topics share or compete for enrollment? Do novel linguistic norms complement or challenge established modes of expression? Our approach can serve as a blueprint for future studies of network ed diffusion s in the social sciences, network science, organizational behavior, marketing, communications, and science and technology studies.\n\nThe findings presented should not diminish the role of social connection and decision making at the level of the individual in diffusion processes. Rather, it introduces a new level of analysis for studies of diffusion, mainly those where functional relationships between diffusing phenomena ma y be a factor. Innovations and ideas do not spread across populations in a vacuum, and while there are sufficient socio-cognitive explanations of co-diffusion processes that are agnostic to the content of the diffusions, scholars can benefit from incorporating the relationships between the diffusive phenomena themselves.\n\nMethodologically speaking, the choices, approaches, and adjustments made and taken here provides guidance for future analyses co-diffusion and bipartite network analysis. For the particular challenges posed in hypothesis testing with this dataset, several confounders required careful mathematical adjustment. The variable number of languages per project and languages per user both have highly positive skews. By making sure that individual users or projects with high numbers of language do not exercise undue influence on the network of languages, discerning meaningful theoretical relationships became possible. Any large scale analysis where relationships between one type of entities (in our case, programming languages) are inferred by their shared relationships with nodes of another type (in our case, projects or users) should consider this carefully.\n\n\n## 7 Conclusion\n\n\nBy conceptualizing diffusive phenomena in their own network schema, as opposed to independently considering their journeys through populations, we stand to gain a better understanding of how ideas and innovations spread with and against one another. While networks of potential adopters are of obvious importance when considering the spread of any given idea, norm, belief, or innovation, network analysis can also account for how diffusive phenomena themselves are connected. As shown with the concepts of complementary and competitive diffusion, considering the contents and compatibility of different ideas can shed light on more complex and multi-faceted ecologies of innovation. Diffusion in networks has been studied for quite some time, but understanding networks of diffusions may shed new light on our understanding of not only technological innovation, but also polarization, disease, misinformation, and more complex social issues that cannot be fully modeled by considering only a singular contagious process.\n\n",
         "The vast majority of research on the diffusion of innovations focuses on how one particular idea or technology spreads across a network of connected individuals, or a population more generally. Diffusive processes are typically considered either in isolation. We consider innovations themselves as nodes in a larger network, and look at how individual innovations can spread with or against one another in a larger community of potential adopters.  Using a large publicly-available data set, custom-designed measurements, and network analysis methods, we present a temporal analysis of a set of technological innovations. Specifically, we examine how coding languages spread across users on GitHub, an online platform for collaborative coding. By looking at which languages co-appear in individual projects, we develop network based measurements of how frequently languages appear together in the same coding projects (functional cohesion), and how similar two languages are in terms of how often they co-appear with other languages in coding projects (functional equivalence). We also assess two types of diffusion, one form where users of one language become users of an additional language (complementary or 'piggybacking' diffusion), and another where users of one language abandon one language for another (competitive or 'cannibalistic' diffusion). Using MR-QAP Regression Techniques, we find strong evidence that functional cohesion positively predicts complementary diffusion. We also find some evidence that functional equivalence predicts competitive diffusion. More broadly, we find support for the idea that the networks of functional relationships between innovations is important for understanding diffusive processes.",
         ""
        ],
        [
         "16",
         "16",
         "## Introduction\n\n\nPolitical self-censorship is increasing rapidly in the United States (B¨ck et al. 2019; Chan a 2018; Chen 2018; Gibson and Sutherland 2023; Schulz et al. 2021). A recent poll found that 62% of Americans report having 'political views they are afraid to share' (Ekins 2020)- an increase from 58% in 2017. Nearly sixty percent of American adults report they find 'political conversations with those they disagree with [to be] 'stressful and frustrating' (Green 2021). 1 There is also widespread evidence of self-censorship on social media, in particular. According to a recent study, seventy percent of social media users in the United States say they 'never or rarely post about politics and social issues,' mainly out of 'concerns that the things they post or share will be used against them and not wanting to be attacked for their views' (Mcclain 2021).\n\nThis trend raises the question of what drives individuals to withhold their political opinions. Existing research tells us that social pressures to conform are not knew. Classic social psychological experiments, like the Asch experiments, conducted in the mid-20th century, demonstrate the profound influence of group consensus on individual choices, even when the group's opinion contradicted obvious truths (Asch 1951, 1956, 1955). Even beyond individual decision-making processes, these pressures can lead to a chilling effect on public discourse. As individuals lean towards opinion conformity, the richness and diversity of public debates may be curtailed, making way for a landscape dominated by more polarized or extreme views.\n\nAmechanism by which conformity plays out is via self-censorship or selectively disclosurethe tendency to share one's opinions to those who agree with them (Cowan and Baldassarri 2018; Gerber et al. 2012). This micro-level phenomenon of avoiding conflict by self-censoring can have macro-level implications, fostering a perception of a polarized public opinion (Baldassarri and Bearman 2007; Cowan and Baldassarri 2018). As fewer people voice dissenting\n\nviews, the silence encourages others with similar opinions to follow suit, akin to the 'Spiral of Silence' effects. This reinforcing loop can elevate the perception that certain extreme perspectives are more widespread than they truly are (Bail 2012; Hawkins et al. 2019). Such misconceptions could fan the flames of false polarization, leading to a distorted understanding of political divisions (Lees and Cikara 2020; Ruggeri et al. 2021). As individuals perceive greater polarization, they may feel compelled to more rigidly align with perceived party views, thus self-censor, and further deepening the divide.\n\nWhile much attention has been directed towards the tension between different political parties, the effects of self-censorship within political parties remain underexplored. Crossparty antagonism can have a detrimental effect on co-partisan dynamics (Orian Harel, Maoz, and Halperin 2020). As certain beliefs become more closely associated with specific political identities, there may be even more pressure for members of the in-group to adhere to the party's opinions on contentious issues. For example, the assumption that Democrats are prochoice on reproductive rights, or that Republicans must oppose all forms of gun control. Such beliefs may feed stereotypes predicated upon what the 'average' Democrat or Republican believes- and thus broader attitudes about the health of democracy and social cohesion more broadly.\n\nYet most people's understanding of what typical Democrats or Republicans believe are ill-formed. 2 Recent studies indicate there are significant factions within each party whose beliefs are inconsistent with their party's leaders (Doherty et al. 2021; Hawkins et al. 2019). For example, Doherty et al. (2021) found nine political subgroups, with 'Progressive Left'\n\nand 'Faith and Flag Conservatives' on the extreme left and right, respectively. 3 These two groups represent just 16% of the population, and yet they are the most politically active across all subgroups (Blazina 2022; Doherty et al. 2021). 4 This has lasting implications, as the opinions of those in the middle tend to go unrepresented. Recent trends further find that as 'polarization has increased, so too has self-censorship' (Gibson and Sutherland 2023:5).\n\nIn this article, I examine self-censorship among members of the same party. I ask: When do people disclose opinions that are not in line with prevailing views in their party? If an attitude is strongly associated with a specific political party--what happens when a member of that party holds an opinion that deviates from their group's typical position? Under what conditions do such individuals disclose their opinions to the co-partisans who disagree with them? For instance, would a Democrat who opposed calls to defund the police after the murder of George Floyd, disclose their opinion to other Democrats who disagree with them?\n\nI recruited 386 Democrats and 372 Republicans to participate in a survey experiment where they were asked to use a simulated chat platform where they were asked to discuss a\n\n4 The report finds that 'nearly half of Progressive Left (48%) say spending on police in their area should be decreased a lot or a little, a view held by just 22% of Establishment Liberals and 11% of Democratic Mainstays.' (Doherty et al. 2021:100). When it comes to issues related to voting, 86% of Faith and Flag Conservatives were not confident that 'people who are not legally qualified to vote are prevented from casting a ballot' and 90% favor requiring 'voting machines to print a paper backup of the ballot'. Approximately 80% of the group believed that making voter registration easier would make elections less secure (Doherty et al. 2021).\n\npolitically contentious subject with two anonymous strangers. Respondents were instructed to complete a survey about their views on a number of contentious issues, including defunding the police and allegations of voter fraud in the 2020 presidential election. Next, participants were directed to a simulated chat platform, where they were asked to discuss their opinions on these two issues. The simulated chat partners were designed so that they always expressed the opposite opinion from the participant (this way, the participant always held the minority opinion). Respondents were randomized to one of two conditions. In the first condition, they were put into a chat with two members of their own party. In the other condition, they were put into a chat with two members of another party. I manipulated the party affiliation of the chat partners in order to examine whether people were more likely to disclose their unpopular opinions to co-partisans or cross-partisans.\n\nI find Democrats are more likely to disclose their true opinions on defunding the police when they were in chats with those who appeared to be Republicans. Yet Republicans were no more likely to express opinions their opinions when they were asked to interact with simulated Democrats. This study thus has important implications for the study of political polarization, conformity, and social psychology. More specifically, I offer a new perspective on how identity dynamics shape self-censorship. This article also offers an example of a behavioral, measure of self-censorship that is particularly important because of widespread concerns that self-reports are not reliable. Finally, my research contributes to the burgeoning field of computational social science by demonstrating how social media platforms can be simulated within survey-experiments that generate large amounts of text-based data.\n\n\n## Self-censorship\n\n\nI define self-censorship as refraining from stating 'one's true opinion from an audience perceived to disagree with that opinion' (Hayes 2005:298, Hayes and Matthes 2017). Selfcensorship is notoriously difficult to measure. By its very nature, it refers to a lack of data;\n\nwe often cannot measure what was not said- and we cannot know how often it went unsaid. Most studies rely on self-reports of self-censorship or vignette designs wherein respondents are asked about whether they would feel comfortable discussing their opinions with a hypothetical discussion partner (Cowan and Baldassarri 2018; Fox and Holt 2018; Kushin, Yamamoto, and Dalisay 2019).\n\nMore recent research indicates individuals are more likely to disclose their true opinions about an issue when they are around someone who agrees with them- a mechanism known as selective disclosure (Cowan and Baldassarri 2018; Gerber et al. 2012). Carlson and Settle (2016), for example, found that people who discuss politics tend to conform their opinions to that of the majority. While this may seem trivial, it is not inconsequential. Selective disclosure, or self-censoring as a means of avoiding conflict, at the micro-level, can lead to 'the macro-level perception of a greatly polarized public opinion' (Baldassarri and Bearman 2007; Cowan and Baldassarri 2018:1). Beyond the perception of polarization, selective disclosure may lead to more polarization through a self-fulfilling prophecy. As people self-censor and only selectively disclose with other like-minded people, it creates the illusion of a homogenous in-group where most people (are perceived to) share the same opinions and attitudes. Thus, exacerbating the risk of self-censoring among those who hold 'minority' views.\n\n\n## The strength of partisanship identity\n\n\nThe drive to conform to one's political party is strong. Research indicates that political identity has become one of the strongest forms of group-identification in the United States today (Bail 2021; Greene 1999; Haidt 2012; Huddy 2003; Klar 2018; Klein 2020; Price 1989). More specifically, political identities tend to shape people's opinions about political issuesand not the other way around (Leeper and Slothuus 2014; Macy et al. 2019; Slothuus and Bisgaard 2021). Partisans are quick to adopt their party's opinions and positions on issues, even if the opinion goes against what they had previously believed (Cohen 2003; Groenendyk\n\n2013; Lenz 2013). This is in-line with broader research on intragroup dynamics, which show that there is a strong tendency for members of a group to conform to the group's attitudes and beliefs (Abrams et al. 1990; Jenkins 2008; McGarty et al. 1992; Slothuus and Bisgaard 2021), and to 'punish those outside its boundaries' (Bail 2021:43). However, this phenomenon does not reflect every members' experience. For some, a change in the party's opinion does not necessarily lead to a shift in their personal opinion (Carsey and Layman 2006; Dejaeghere and Dassonneville 2017; Nordø 2021; Saeki 2019). It is this specific juncture that motivates my research.\n\nAs the animosity between two polarized groups increases, the opinions, attitudes, and policy positions of the outgroup grow tend to be seen in just as much of a negative light (Orian Harel, Maoz, and Halperin 2020). Thus, if a member of an ingroup has opinions which are not shared by the ingroup, or even worse, are shared by the outgroup, the consequences can be much more severe. As Orian Harel et al. (2020) describe, in extreme situations, party leaders deemed to be too compromising or sympathetic to the outgroup saw grave consequences, as was the case of 'Israeli Prime Minister Yitzhak Rabin, Indian leader Mahatma Gandhi, and Egyptian President Anwar Sadat-all of whom were murdered by people from their own society who objected to their peaceful attempts at resolving continuous conflicts' (55).\n\nThis is not to imply that individuals who disagree with the opinions of their party will find themselves at risk of death or violence, but to illustrate the effects of intergroup polarization on intragroup dynamics. When the stakes are high, members of the ingroup may be less likely to share their true opinions, as a way of avoiding any form of sanctioning (Bar-Tal 2017a; Bar-Tal, Nets-Zehngut, and Sharvit 2017; Cowan and Baldassarri 2018; Gerber et al. 2012; Huckfeldt and Mendez 2008). In other words, some members may hold opinions that are not consistent with their party, and due to the very strength of their political identity, they may be more likely to conform or self-censor.\n\nConversely, intergroup animosity can also have an effect on selective disclosure in scenarios that involve a member of an ingroup conversing with a member of an outgroup. The\n\ningroup member may be more likely to disclose their true opinion to the outgroup member because there is no risk of social sanctioning. For example, the ingroup member may not necessarily care what the outgroup members will think of them (Cikara et al. 2014; Cikara, Botvinick, and Fiske 2011; Tarrant, Dazeley, and Cottom 2009), potentially resulting in more disclosure. This leads to my first hypothesis:\n\nHypothesis (1) When individuals hold a minority opinion, they are more likely to disclose their true opinion about contentious political issues to cross-partisans than to copartisans.\n\n\n## Social media and self-censorship\n\n\nThere is a growing body of research that focuses on the role of social media in political discussions (Bail 2021; Bail et al. 2018; Boutyline and Willer 2017; Goel, Mason, and Watts 2010; Hanna et al. 2013; Persily and Tucker 2020; Shi et al. 2017; Tucker et al. 2018). On the one hand, there are concerns about whether the internet is leading to more self-censorship and a worsening of negative effects like the spiral of silence (Hampton et al. 2014; Leeper and Slothuus 2014; McDevitt, Kiousis, and Wahl-Jorgensen 2003; Neubaum and Kr¨ amer 2018). On the other hand, there are questions about whether social media actually allows for greater opportunity to express one's views (Ho and McLeod 2008).\n\nMuch of the recent literature related to computer-mediated communication shows that social media does not necessarily lead to more disclosure (Hampton et al. 2014; McDevitt, Kiousis, and Wahl-Jorgensen 2003; Neubaum and Kr¨mer 2018). a 5 This is not too surprising. Data consistently shows that online discourse tends to be dominated by those on the extreme\n\nends of the political and opinion spectrum (e.g.,Blazina 2022), making it seem like the opinion climate is more extreme than it actually is.\n\nPolitically charged conversations on social media have also been shown to lead to more 'antagonistic, and extreme political preferences' (Fiorina and Abrams 2008; Flores 2017; Stella, Ferrara, and Domenico 2018; Yarchi, Baden, and Kligler-Vilenchik 2020:5) (Fiorina and Abrams 2008; Flores 2017; Stella, Ferrara, and Domenico 2018; Yarchi, Baden, and Kligler-Vilenchik 2020:5). Much of the research I described in the previous section describes the ways in which people have a tendency to want to avoid conflict (either by self-censoring, conforming, or completely avoiding political conversations with those who may disagree with them). In one study, for example, individuals 'sought to avoid conflicts they witnessed when outspoken members of their political networks engaged with people with whom they disagreed' (Powers 2019:3646) (Powers 2019:3646). When extreme political points go unchallenged by conflict-avoidant moderates, it can lead to a 'majority illusion' which may 'overestimate the prevalence' and legitimacy of those more extreme opinions (Yarchi, Baden, and Kligler-Vilenchik 2020; Lerman, Yan, and Wu 2016). For those with the extreme opinions, this majority illusion, may decrease their 'tolerance for competing views,' leading to the 'marginalization of deviant' opinions, where users become less compromising in their beliefs and unwilling to engage in debate (Yarchi et al. 2020:5). This can sharpen the line between the in-group and out-group, such that the in-group grows more hostile and oppositional towards the views of the out-group or views that are not in-line with their own.\n\nRecent surveys suggest this may have an impact on how people behave online. One recent Pew report, described at the start of the paper, for example, showed that 70% of U.S. social media users avoiding posting about political issues out of concerns that the posts may be used against them (Mcclain 2021). A report about Twitter users also showed a similar trend-nearly half of Twitter users 'consider whether the content they post publicly on Twitter could be used against them in the future before doing something that might be visible to other people on the site', with some 45% of Twitter users worrying about whether\n\nthey could potentially be attacked or harassed for their posts (Mcclain et al. 2021). As such, those who use social media more often, may be more likely to see someone with their opinion get shut down and sanctioned, thereby, making them acutely aware of the social repercussions of holding an 'unpopular' opinion.\n\nHypothesis (2) Individuals who report using social media very often will self-censor more than those who use social media less often.\n\n\n## Case studies\n\n\nIn order to test the hypotheses outlined above, I attempted to identify an issue that would be equally divisive within the Democratic and Republican parties in the United States. Unfortunately, I was not able to identify such an issue during the time of this study. Therefore I elected to focus upon two case studies of issues that became contentious within the Democratic and Republican parties, respectively. For Democrats, I examine opinions related to the campaign to Defund the Police that followed the murder of George Floyd by Minneapolis police officers in 2020. For Republicans, I examine allegations of widespread voter fraud during the 2020 Presidential Election. 6\n\n## Allegations of Voter fraud During the 2020 Presidential Election\n\nIn the months leading up to the 2020 US Presidential elections, Donald Trump - along with other prominent Republicans- began to publicly denounce the validity of mail-in voting and the potential for voter fraud during the election (Pennycook and Rand 2021). 7 Most Democrats strongly criticized these allegations. Republicans who believed that voter\n\nfraud was rampant claimed that 'voting machines fraudulently switched votes to Biden, that large numbers of Trump ballots were destroyed, and that Republican election officials were unduly restricted from observing polling stations (leading to malfeasance)' (Pennycook and Rand 2021). After Joe Biden won the election, there was an 'unprecedented number of false claims alleging election fraud and arguing that Donald Trump was the actual winner of the election' (Pennycook and Rand 2021). Media reports and surveys showed that anywhere from one-third to two-thirds of Republicans believed that Biden's win was a result of 'election rigging' (Bump 2021; Byler 2021; Conradis 2021; Dickson 2021; Center 2021; Reutors and Ipsos 2021:6, Romano 2022). These claims are long-lasting; one poll, conducted in August 2021, showed that two thirds of Republicans continue to believe that 'the election was rigged and stolen from Trump' (Dickson 2021). Even though a number of prominent Republican politicians have spoken out against claims of voter fraud, the issue remains contentious within the party.\n\n## Calls to Defund the Police after the Murder of George Floyd\n\nIn response to the murder of George Floyd during the summer of 2020, millions of people around the world took part in Black Lives Matter (BLM) marches. One of the major callsto-action set forth by the BLM was a call to Defund the Police and Invest in Communities (Fernandez 2020; Scales 2020). This led to a series of debates on the benefits of defunding the police, what it would actually mean, and whether such a goal was feasible, with most Republicans openly criticizing the movement. Though the goals of the movement were not always clear, many supporters demanded a portion of police funding be allocated towards community-based resources to address mental health, housing, and poverty. Opponents of defunding the police argued taking money from the police would result in increased crime rates. While support for defunding the police gained traction during those summer months, polls have shown that Democrats remain split on the issue. Polls showed that an average of 50% of Democrats support the movement (28% oppose) (Rakich 2020). Thus, while\n\nthe 'Defund the Police' slogan gained mainstream traction among Democrats, it remained contentious within the party (Ferris, Levine, and Caygle 2020).\n\n\n## Methods\n\n\n\n## Sample\n\n\nIn the spring of 2021, I recruited 758 adult respondents in the United States via CloudResearch to take part in a pre-registered survey-experiment. 8 CloudResearch allows researchers to prescreen Amazon Mechanical Turk workers based on a number of different criteria (e.g., gender, age, citizenship, political party, etc.). I chose to pre-screen for party affiliation, focusing only on Republicans and Democrats. My final sample consisted of 386 Democrat participants, and 372 Republican participants. 9 Table 1 below provides an overview of the sample's descriptive characteristics (for a comparison between the final sample and the American Community Survey, please refer to Appendix E).\n\n\n## Experimental Design\n\n\nFigure 1: Survey experiment design for Democrat respondents. Democrats who supported (opposed) defunding the police were always put into a chat condition with two simulated partners who opposed (supported) defunding the police. The experimental manipulation was whether those simulated chat partners were labeled as Democrats or Republican.\n\n<!-- image -->\n\nParticipants were first asked about their opinions on a number of current political issuesincluding defunding the police and voter fraud as well as a series of other issues in order to mask the purpose of the study. 10 They were asked at least two different questions per issue, so as to get a more nuanced understanding of their opinion (e.g. in some cases, people did not believe that voter fraud is a major problem when it comes to mail-in voting, but they did believe that 2020 elections votes were not accurately counted). In the second phase, participants were randomized into one of two different chat conditions: either with co-partisans or with cross-partisans (that is, with members of one's own party or members\n\nTable 1: Descriptive Statistics of the Study's Final Sample\n\nFigure 2: Survey experiment design for Republican respondents. Republicans who believed (did not believe) there was widespread voter fraud were always put into a chat condition with two simulated partners who did not believe (believed) there was widespread voter fraud. The experimental manipulation was whether those simulated chat partners were labeled as Democrats or Republican.\n\n<!-- image -->\n\nof another party).\n\nAfter completing the survey, respondents were shown a loading icon and asked to wait while we paired them with two other survey participants. After a few seconds, they were notified that they had been matched and were asked to wait a few more seconds to receive their partners' chat messages.\n\nOnce in the chat, participants were asked to either discuss their opinions on defunding the police, if they were Democrat or Democrat-leaning (figure 1), or voter fraud, if they were Republicans or Republican-leaning (figure 2). In all chat conditions, participants held the minority opinion- that is, they were always put into a chat with partners who disagreed with their (the participant's) views. For example, if a hypothetical participant reported that they opposed defunding the police, they were paired with two (simulated) chat partners who\n\nFigure 3: The four panes illustrate the segue into the chat portion of the survey experiment. 15\n\n<!-- image -->\n\nsupport defunding the police.\n\nAll of the chat partners were simulated and the messages, themselves, were static. When participants entered the chat, they were shown messages from their two (simulated) partners. In other words, they were made to think that the partners had already been talking before the participant joined the chat. The text of the chat was identical in all treatment conditions. The only difference in the study's treatment conditions was whether the chat partners were labeled as members of the respondent's own party or not.\n\nThe text used in the simulated chats was created by using a combination of real dialogue from news websites, blog posts, and tweets. I compiled them into an Excel sheet and manually labeled each of them as either for or against defunding the police or for or against the idea that there was widespread voter fraud. I then mixed and matched different parts of different comments to create my first draft of the simulated messages. This was done so that if participants did a reverse search of the chats, they would not be able to tie the messages back to the original commenters. Additionally, since I was manipulating the party label of the chat partners, I had to make sure the text could feasibly be sent from either a Democrat or a Republican. To do this, I neutralized the text so as to remove any negative comments about either political party, I also removed mentions of party affiliation and other partisan giveaways (like strong opinions about policing and the role of the government). For a full list of the dialogue used, please refer to Appendix B.\n\n\n## Outcome Variable\n\n\nThe main outcome variable in my analysis is whether participants disclosed their opinion to their chat partners. In order to create this variable, I created a subset of the data that consisted of each participant's chat response, the chat condition they were randomized into, and the participant's pre-chat survey responses about defunding the police (if they were Democrat) or voter fraud (if they were Republican). I then manually went through each chat message and compared each participant's message to their survey responses about their\n\nFigure 4: Chat portion of the study. Participants were shown two simulated messages. They were made to think that the messages had come from fellow participants and were asked to share their views on the issue. For a full list of the text used by the simulated partners, please see Appendix B.\n\n<!-- image -->\n\nrespective political issue. I compared what they wrote in their chat to what they reported in the previous survey responses.\n\n<!-- image -->\n\nFigure 5: Labeling criteria for participants' chat responses (using Democrat participants as an example). For a more detailed overview of how I labeled whether a participant disclosed or did not disclose their opinion, please see Appendix A where I describe how I coded 4 different responses.\n\n<!-- image -->\n\nAll participants were put into a chat with two simulated partners who disagreed with them. Looking at our example scenario above (figure 5) : If the participant replied that they agreed with their partners [A], then they would be labeled as having not disclosed their opinion- Agreeing with partners who oppose defunding the police is a direct contradiction of the participant's pre-chat opinion. If the participant's reply is neutral [B], that is, if they do not offer any opinion at all, then they would be labeled as having not disclosed their opinion. One participant, for example, replied with their definition of defunding the police. They provided no extra commentary to that message. Looking at that message alone, it is unclear what the participant thinks about defunding the police, hence, they were assigned a 'did not disclose' label. In [C], if the participant's reply included reference to their pre-chat opinion that they support defunding the police (for example, writing something along the lines of 'Police departments across the country are overfunded. Reallocating some of those funds to improving social services and mental health overall is a much smarter investment\n\nthan a new armored vehicle to a suburban town'), then they were labeled as having disclosed their opinion. Similarly, if a participant explicitly told their chat partners that they disagree with them (e.g., 'I completely disagree with you guys'), then they, too, would be labeled as having disclosed their opinion. To ensure that my labeling was reliable, an external coder was also recruited to code a subset of both the Republican and Democrat data. In total, they labeled approximately 12% of the data and we had an intercoder reliability level of 85.8%. For a more detailed breakdown of the labeling process, please refer to Appendix A, where I work through how I coded four different participants' responses, two for Democrat participants and two for Republican participants.\n\n\n## Control variables\n\n\nResearch has shown that political interest, participation, and knowledge are positively correlated with whether someone would willingly engage in general political discussions at all (Converse 1964; Carpini and Keeter 1993; Cowan and Baldassari 2018; Verba et al 1995). To account for these potential confounders, participants were asked about how often they participated in political activities, 11 how important each issue was to them, and how knowledgeable they were about each issue. For the latter question, I did not measure actual knowledge, but rather, self-perceived knowledge about an issue. 12 I used the expressive partisanship questionnaire developed by Huddy et al. (2015) to measure the strength of participants' partisan identity. 13 I also controlled for participants' political ideology, which is a 7-point scale that\n\n12 Studies have shown that people who think they know a lot about a subject may be more likely to engage in conversation about said subject than those who report not knowing enough about it (Anson 2018; Lyons and Henderson 2005).\n\n13 I used the expressive partisanship multi-item scale developed by Huddy et al (2015) to measure strength of partisan identity. Participants were asked four questions about their political identity: how important is\n\nranges from 'very liberal' to 'very conservative.' 14 Finally, I controlled for participants' gender, race, age, social media use, and opinion (e.g. whether they supported defunding the police or believed there was voter fraud). 15\n\n15 With regards to social media use, participants were asked to report whether they used Facebook, Twitter, Parler, Instagram, Reddit, Youtube, Snapchat, Tiktok, and Gab. Unfortunately, they were not asked about the frequency with which they used social media overall.\n\n\n## Results\n\n\nFigure 6: Effect of chatting with co-party partners on whether participants disclosed their opinions in the chat, for experiments with Democrats (n = 386) and Republicans (n = 372). Models control for participant's opinion (e.g. whether they support defunding the police or believe there was voter fraud), race, political participation, self-reported knowledge about the issue, expressive partisanship, age, gender, and number of social media participant uses. Circles describe scaled and standardized point estimates, and bars describe 90% and 95% confidence intervals. Regression model tables are reported in Appendix C.\n\n<!-- image -->\n\nMy main hypothesis was that individuals who hold minority opinions about a contentious issue would be more likely to disclose said opinions to cross-partisans than they would to co-partisans. I ran two-sample t-tests and logistic regressions to analyze the relationship between chat condition and disclosure rates among participants. I ran these separately for the Democrat and Republican participants.\n\nAmong Democrats, the two-sample t-test showed that there was a significant difference in the disclosure rates for Democrats chatting with co-partisans (i.e., other Democrats) (M = 0.64, SD = 0.48) and Democrats chatting with cross-partisans (i.e., Republicans) (M = 0.77, SD = 0.42), t(382.13) = 2.8651, p = 0.0044. Democrat participants tended to disclose to Republican chat partners more frequently than to Democratic chat partners. This difference remained statistically significant in the logistic regression (please refer to 6). When holding all other predictor variables constant, the odds of a Democrat participant disclosing to coparty chat partners was 0.49 times smaller (p = 0.003) than when chatting with cross-party partners. Put differently, the odds of Democrats disclosing their opinions to Republicans was 2.029 (p = 0.003) times greater than when they were chatting with other Democrats. In other words, Democrat participants had a 0.33 probability of disclosing their opinion to co-party partners compared to a probability of 0.67 of disclosing to cross-party partners.\n\nThe results showed that there was also a statistically significant relationship between a Democrat disclosing their opinion and their race, as well as their opinion regarding defunding the police. When controlling for other predictors, the odds of white Democrats disclosing their opinions, in general, was 2.30 (p = 0.002) times greater than non-whites. Similarly, when controlling for other predictors, the model shows that the odds of Democrats who support defunding the police disclosing their opinions was 1.78 (p = 0.027) times greater than Democrats who opposed defunding the police.\n\nAmong Republicans, the two-sample t-test showed no significant difference in disclosure rates between those who were chatting with co-partisans (i.e., other Republicans) (M = 0.75, SD = 0.44) and those who were chatting with cross-partisans (i.e., Democrats) (M\n\n= 0.72, SD = 0.45), t(369.47) = -0.70, p = 0.4842. This difference remained insignificant in the logistic regression (Please refer to figure 6 for the coefficient plot and to Appendix C for the regression table). The regression model did show that there was a statistically significant relationship between those who believed that there was widespread voter fraud and those who did not. Controlling for all covariates, Republicans who believed that there was widespread voter fraud were 1.94 times more likely to disclose their opinions to their chat partners than those who did not believe there was widespread voter fraud (p = 0.03). Furthermore, holding all other predictor variables constant, I also find that the odds of a Republican disclosing their opinion, in general, increased by 23% (p = 0.0261) for a one-unit increase in the number of political activities that the respondent participated in.\n\nMy second hypothesis stated those who use social media frequently are more likely to self censor than those who do not. The results of the regressions for both Democrats and Republicans above show that there was no statistically significant relationship between social media usage and the propensity to self-censor. However, I was able to compare disclosure rates for users of Facebook, Twitter, Instagram, Youtube, Reddit, TikTok, Snapchat, Parler, and Gab. Two-sample t-tests showed that there was a statistically significant difference in disclosure rates between Republicans who used Gab (M = 0.92, SD = 0.26) and those who did not (M = 0.72, SD = 0.45), t(41.444) = -3.86, p = 0.0004, with Gab users disclosing more often. Among Democrats, two-sample t-tests showed that there was a statistically significant difference in disclosure rates among those who use Facebook (M = 0.68, SD = 0.47) and those who do not (M = 0.83, SD = 0.38), t(69.185) = 2.4994, p = 0.0148, with the former disclosing less. There were significant differences among Democrat Reddit users too, with Reddit users (M = 0.75, SD = 0.44) disclosing more than non-users (M = 0.63, SD = 0.49), t(274.92,) = -2.498, p = 0.013.\n\n\n## Discussion\n\n\nTo review, this study examined whether and how political identities shape self-censorship on social media. The results show that partisan identity does indeed play a role (though, notably, only amongst Democrats). When Democrats were chatting with other Democrats (who disagreed with them), they were quick to withhold their opinions rather than challenge the rest of the group (precisely what drove them to withhold their opinions, however, is a task for further investigation). When this same group found themselves chatting with Republicans, those self-censoring inhibitions diminished; the negative consequences of holding a minority opinion did not seem to matter in this scenario. The same could not be said for Democrats who opposed defunding the police, however. This group was less likely to disclose their opinions no matter who they were talking to. Perhaps, when talking to other Democrats, they did not want to show sympathy to Republican talking points or go against the majority view, and when talking to the Republicans, the risks of holding a minority opinion may have been too high. 16\n\nWhile there is no way to know for certain why some participants chose to disclose their opinions, turning to existing literature is instructive. That we saw differences in disclosure rates may be attributed to pressures to conform (akin to the Asch experiments) or to the spiral of silence and the increasing animosity between Democrats and Republicans (i.e., affective polarization). The spiral of silence explanation suggests that participants may have been less inclined to share their opinions with the co-partisans out of fear of being socially sanctioned by members of their own side (Noelle-Neumann and Petersen 2004). This, intertwined with the increasing affective polarization, also suggests that participants who held an 'unpopular' opinion (e.g. Democrats who oppose defunding the police) may have been less inclined to disclose out of fear of being associated with the 'other side' (i.e.,\n\nRepublicans) (Abrams et al. 1990; Bar-Tal 2017b; Hameiri et al. 2017; Eisner, Spini, and Sommet 2019; Eveland and Glynn 2008; Gerber et al. 2012; Huckfeldt and Mendez 2008; Jenkins 2008; McGarty et al. 1992; Merton 1968; Willer, Kuwabara, and Macy 2009). 17 In other words, showing any form of sympathy with the other side's opinions may have been deleterious to the co-partisan, leading to less disclosure when chatting with fellow Democrats. Although, future research is needed to investigate this further.\n\nSimultaneously, affective polarization may also lead to more cross-party disagreements, thereby leading to more disclosure within cross-party chat conditions. That is, a Democrat, who may be less inclined to care about what a Republican thinks of them, would see no risk in explicitly disagreeing with Republican partners. Research on intergroup empathy (and apathy) suggests this may be the case. The greater the conflict between two groups, the more salient the group identities are, and the more hostile the two groups become (Fourie, Subramoney, and Gobodo- Madikizela 2017; Hogg 1993; Hewstone, Rubin, and Willis 2002). For example, Cikara et al. (2011) found that the more 'pleasure' participants reported at seeing an out-group fail, the more willing they were to harm members of said out-group. This type of dynamic may explain the higher disclosure rates among Democrats chatting with Republicans- in such scenarios, the cost of Republican sanctioning is very low.\n\nAmong Republican participants, however, there were no significant differences in disclosure rates between those chatting with co- and cross-partisans. This finding goes against what we currently understand about selective disclosure and holding a minority-opinion. Most studies show that individuals are less likely to disclose their opinions when in conversation with others who disagree with them (Cowan and Baldassarri 2018; Gerber et al. 2012). All participants in this study were put into chats with two simulated partners who disagreed with them. However, I find that Republicans, in general, were equally likely to disclose their opinions to their chat partners, no matter the condition.\n\nThe asymmetry in disclosing behavior between Democrats and Republicans is not unsurprising. Although I am unable to make direct comparisons between the Democrats and Republicans in my sample, there is evidence from existing literature of asymmetry in polarizing behavior among these two groups. Generally, Republicans tend to show more polarizing behavior than Democrats (Desilver 2022; Heltzel and Laurin 2020). For example, Bail et al. (2018) found that Republicans who were exposed to more liberal content on Twitter became 'substantially more conservative,' whereas Democrats who were exposed to more conservative content on Twitter showed 'slight increases in liberal attitudes,' although this wasn't statistically significant. There are also differences in the role that partisan identity plays for Republicans and Democrats. Grossman and Hopkins (2015), for example, find that people are united in the Democratic party 'on the bases of social group identity and specific policy positions.' The party, the authors argue, serves as a tent for diverse groups with diverse interests who view politics as 'an arena of intergroup conflict,' (134) all jointly working together to achieve specific policies. Republicans, on the other hand, are united around a shared 'ideological affinity' of 'limited government' and conservatism.\n\nThese differences could account for the asymmetry in disclosure behavior among the two groups in my study. That the Democrats have a larger tent to accommodate may mean that they are less likely to want to offend others in their group. Furthermore, the Democrats' lack of a cohesive ideology means that they are less likely to challenge fellow partisans 'on the basis of insufficient devotion to [some] ideological principle' (Grossman and Hopkins, 2015: 134). When it comes to specific policies, the diverse base of the Democrats, the authors show, means that they are more likely and willing to compromise on specific policy positions. Combined, these may explain why Democrats in my survey were less likely to disagree with fellow Democrats. On the other hand, Republicans, with their more cohesive ideology, are far more likely to call out a fellow partisan for not being sufficiently ideologicallydevoted (Grossmand and Hopkins 2015; 2016). Republicans also have a history of breaking into different 'purist and pragmatist factions' (e.g., the Tea Party) (130), with the different\n\nfactions disagreeing over which group represents the 'real' Republicans. This propensity for internal conflict may help account for why Republicans were more inclined to challenge their fellow partisans in my study.\n\nIn this study, I also explored the relationship between social media usage and selfcensoring behavior. While some surveys suggest that those who use social media are more likely to report self-censoring behavior (Mcclain 2021; Mcclain et al. 2021), my results show no significant difference in disclosure rates with regards to social media usage. A major explanation for such a finding could be due to the specific sample used in my experiment. MTurk attracts a particular population, one that is generally more internet-literate.\n\nFurthermore, the experiment was such that people were chatting with anonymous others, which may alter one's propensity to disclose. Research on self-censorship in anonymous settings has shown mixed results. For example, Wu and Atkin (2018) found that people were more willing to express their opinions in anonymous comment sections. Woong Yun and Park (2011), on the other hand, found no difference in willingness to post a comment about abortion between participants who were anonymous and participants who were told to use their name. McDevitt et al. (2003) set up a chatroom experiment where participants were asked to chat about abortion. They found that minority opinion holders did speak up - only insofar as they participated in the general discussion about abortion - however, they did so without explicitly revealing their opinions about abortion.\n\nWhile the results of my study did not show a significant relationship between disclosure and social media usage, there were two notable exceptions. Republicans who use Gab tend to disclose more often than Republicans who do not. Among Democrats, those who use Reddit tend to disclose more often than Democrats who do not use Reddit, and those who use Facebook disclosed less often than those who did not use Facebook. It's unclear why these differences occur; there might be something about those platforms that either attracts people who are less apprehensive about sharing their opinions, or that encourages users to\n\nengage in contentious conversations. 18 More research is needed to investigate differences in self-censoring behavior and specific social media platforms.\n\nOverall, the findings of this study shed light on four main points. First, I was able to use a measure of self-censoring behavior by first surveying participants about their opinions and then comparing their survey responses to the content of their actual chat replies. This study complements existing selective disclosure research - which tends to revolve around surveys and vignettes (Cowan and Baldassarri 2018; Fox and Holt 2018; Kushin, Yamamoto, and Dalisay 2019) by allowing researchers to investigate when, and under what conditions, self-censorship actually occurs.\n\nSecond, I found evidence that political self-censorship amongst co-partisans is occurring in identity-specific contexts (evidenced only by the Democrats in my sample). However, why it occurs in some instances and not others, and among some groups but not others is a task worth undertaking in the future. Third, that participants were randomized into anonymous chats will have certainly affected their disclosure decision. We know from research that discussions in anonymous settings can induce one of two things: one's inhibitions may be lowered, and would thus lead to disclosure because of the safety-net that anonymity allows (and the decreased chance of social sanctioning), or second, the anonymous, impersonal nature of the conversations may lead some to feeling disinterested and disengaged in the conversation, thus leading to less disclosure. In this study, I did not have a non-anonymous chat condition, so I was unable to ascertain which of those two things may have occurred.\n\nFourth, due to the polarized nature of politics in the United States, I was forced to use two separate contentious issues for Democrats and Republicans to discuss. This makes it difficult to make cross-party comparisons. One way to address this issue is to conduct more studies like this one, where Democrats and Republicans discuss a wide array of within-party contentious issues. Only then can we get a well-rounded understanding of self-censorship and selective disclosure among co- and cross-partisans.\n\nIt is imperative that we understand both the causes and consequences of self-censorship. If individuals do not feel comfortable sharing their opinions due to pressures to conform or because it may be associated with a group they dislike, what consequences may that have? Would it push liberals over to the center or to the right, and vice-versa? Could it lead to feelings of political homelessness? Could these dynamics help explain the unexpected political surprises of Trump's 2016 election win, the UK's 'Brexit' referendum, or Youngkin's 2021 win in Virginia? There is recent evidence to suggest these dynamics may have led to the rise of far-right populist parties in Europe, for example. 19 Future research is needed to address these gaps.\n\n",
         "Recent surveys indicate most Americans are reluctant to share their political views on social media. This study examines how social identity and group composition shape self-censorship in a simulated social media setting. I recruited Democrats and Republicans (N=758) to complete a survey about their political views and randomized them into to chats to discuss a politically contentious issue with members of the other party or members from their own party. I find Democrats are more likely to disclose their opinions to Republicans than to fellow Democrats. Yet Republicans were no more likely to express their opinions to Democrats or Republicans. This research underscores the significance of political identity dynamics on the expression of minority views and uses a behavioral measure of self-censorship which may improve upon previous self-reported measures of self-censorship. My study thus contributes to ongoing debates with political sociology, social psychology, and the emerging field of computational social science.",
         ""
        ],
        [
         "17",
         "17",
         "## 1 Introduction\n\n\nHow income inequality affects people's life satisfaction has received considerable attention in recent years. Numerous studies in the fields of social psychology (Cheung and Lucas, 2016; Diener et al., 2013), sociology (Schneider, 2016; Schröder, 2018), economics (Clark et al., 2008; Senik, 2009), and political sciences (Piketty, 2022; Wirajing et al., 2023) have explored how income inequality affects people's subjective well-being. This research predominantly finds negative effects of income inequality on life satisfaction, indicating that as income gaps widen, general life satisfaction tends to diminish. These findings have fueled discussions about the societal costs of economic inequality and the need for policies that promote more equitable income distribution to enhance collective well-being (Piketty, 2022; Stiglitz, 2013; Wilkinson and Pickett, 2010).\n\nMost of these studies assume that rising inequality diminishes life satisfaction across all social strata. However, this assumption neglects the possibility that those at higher relative income levels may actually benefit from greater income disparities. For these individuals, wider income gaps can enhance their social standing and perceived sense of achievement, potentially leading to increased life satisfaction.\n\nThis paper aims to address this possibility by examining how people's relative income positions within their country's income distribution affect the relationship between income inequality and life satisfaction. This provides a nuanced understanding of the interplay between income inequality, relative income, and personal well-being and thus contributes to the broader literature by explaining why people of different social strata may not perceive income inequality as equally detrimental.\n\nThe unique methodological approach of this paper lies in its use of fieldwork material from the European Social Survey, which provided their interviewers with country-specific income brackets. These income brackets were calculated on each country's official statistics and thus allowed to accurately map respondents' incomes onto their national income distributions. This innovative use of data enables a more precise analysis of how relative income positions influence perceptions of life satisfaction within different economic contexts across Europe.\n\nThe results of multi-level analyses of Round 9 of the European Social Survey (21.040 respondents in 29 countries) reveal an interplay between income inequality\n\nand individual income position. Higher levels of income inequality generally decrease people's life satisfaction, but this effect is most pronounced among those in lower income brackets. Conversely, individuals in higher income positions tend to report greater life satisfaction, and this positive association is stronger in countries with higher income inequality. Moreover, men are more sensitive to changes in income inequality and their relative income position compared to women, indicating gender differences in how economic disparities impact well-being.\n\nThese findings suggest that future research on the effects of income inequality on life satisfaction should consider the varying experiences of different income groups. Understanding who benefits and who is disadvantaged in unequal societies, researchers can inform more targeted and effective economic and social policies that promote overall well-being.\n\n\n## 2 Theoretical background\n\n\n\n## 2.1 Income inequality and life satisfaction\n\n\nPioneering work by Morawetz and colleagues (1977) in two Israeli communities is often cited as the starting point of the literature on the relationship between income inequality and life satisfaction. They found that higher levels of income inequality within a community led to lower self-reported happiness among its members. Since then, numerous studies have attempted to replicate these findings using large-scale data either from one single country  or by using cross-country comparisons. 1 2\n\nHowever, not all studies found the expected negative effect of income inequality on life satisfaction. Some studies found that income inequality has a positive effect on well-being. Many of these positive effects were found in developing countries (Haller and Hadler, 2006; Kelley and Evans, 2017) and have often been attributed to the \"tunnel effect\" described by Hirschman and Rothschild (1973). Accordingly, rising inequality fuels expectations of future social mobility in societies undergoing\n\ntransformation and this positive future prospect increases people's life satisfaction. Other studies have found no significant relationship between inequality and life satisfaction (Deng and Schöb, 2023; Evans et al., 2019; Sommet and Elliot, 2022; Vezzoli et al., 2023). Although some of these null results may stem from an overcontrol bias due to the amount and type of control variables many of those studies employed. For example, many studies control for personal income or GDP, which might mediate the effect of income inequality. Yet, an insignificant direct effect (here of income inequality) while controlling for indirect effects of mediating variables may mask the actual effect and thus cannot be rigorously interpreted as null result (Huntington-Klein, 2022; Rohrer, 2018).\n\nNevertheless, the majority of studies found that higher levels of income inequality tend to decrease people's life satisfaction (Alesina et al., 2004; Ferrer-iCarbonell and Ramos, 2012; Hagerty, 2000; Oishi et al., 2011; Schneider, 2019). A prominent explanation for this negative relationship is inequity aversion, suggesting large income gaps violate perceived norms of fairness (Alesina et al., 2004; Bjørnskov et al., 2010; Senik, 2009). Furthermore, income inequality is thought to erode social capital and trust, exacerbate crime and political conflict, and weaken the quality of public institutions-all of which contribute to greater insecurity and anxiety, further lowering life satisfaction (Delhey and Dragolov, 2014; Ravazzini and Chávez-Juárez, 2018; Wilkinson and Pickett, 2010, 2009). Based on this body of evidence and as my study focuses on European countries, my first hypothesis is:\n\n- H1: With increasing levels of income inequality people's life satisfaction tends to decrease.\n\n\n## 2.2 Relative income position and life satisfaction\n\n\nThe key question of this study is whether people across all social strata perceive income inequality as equally detrimental, or whether people with higher relative incomes actually benefit from higher income inequality. To address this question, it is important to first understand how income relates to life satisfaction. The theoretical debate centers around two perspectives: the absolute income hypothesis and the relative income hypothesis (Ball and Chernova, 2008; Brady et al., 2023; Diener et al., 1993; Veenhoven, 1991).\n\nAdvocates  of the absolute income hypothesis, such as Veenhoven (1991), argue that higher income enables individual to meet their universal needs-such as food, housing, safety, and health-which in turn increases their well-being. Accordingly, people's life-satisfaction should increase with their absolute income regardless of others' income levels (Brady et al., 2023; Stevenson and Wolfers, 2013) However, research suggests that once basic needs are met, the relationship between absolute income and life satisfaction weakens considerably (Diener et al., 1999; Jebb et al., 2018; Kahneman and Deaton, 2010; Valet, 2023).\n\nEasterlin (1974) was among the first to advance the relative income hypothesis. Based on his findings rising income levels in a country did not lead to increased overall happiness. Thus, he concluded people primarily evaluate their well-being in comparison to others around them (Easterlin, 1995). This idea is echoed in theories of relative deprivation (D'Ambrosio and Frick, 2007; Runciman, 1966). Theories of relative deprivation assume people frequently compare their socio-economic status to a reference standard. If they perceive themselves below (above) the reference standard their well-being decreases (increases) due to their perception of relative deprivation (gratification). Thus, income becomes a positional good whose value depends on a person's income position within the income distribution (Jebb et al., 2018).\n\nMany empirical studies confirm this perspective, showing that people with higher relative incomes tend to report greater life satisfaction than those in lower income brackets (Amendola et al., 2019; Ball and Chernova, 2008; Brady et al., 2023; Katic and Ingram, 2018). However, these studies often rely on survey data in which both individual income position and income distribution are inferred from the same source. This approach might introduce biases, as individuals in the lower and upper tails of the income distribution are more likely to misreport their income (Kim and Tamborini, 2014) which in turn distorts estimates of a country's income brackets and income inequality (Valet et al., 2019). To address this issues, my study uses countryspecific income brackets based on official data. Nevertheless, and in line with the conclusion of many previous studies, I expect that people higher up in the income distribution of their country will report higher life satisfaction than those in the lower income brackets:\n\nH2: With increasing relative income positions people's life satisfaction tends to increase.\n\nThe next question is whether income inequality and relative income position interact, meaning that the effect of relative income on life satisfaction may be more pronounced in societies with more income inequality. If we link the arguments on the well-being effects of income inequality and relative income positions, it is evident that more income inequality leads to wider income brackets and therefore more pronounced differences in socio-economic-status. Consequently, people higher up in the income distribution should experience higher relative advantages in societies with more income inequality compared to societies with less income inequality.\n\nHowever, previous research yields mixed findings on this. Investigating data from the European Quality of Life Survey, Amendola and colleagues (2019) did not find asymmetric effects of inequality on life satisfaction between the rich and the poor. They conclude that increasing inequality decreases the life satisfaction of rich and poor people in the same manner (also see Schwarze and Härpfer, 2007; Ugur, 2021; Verme, 2011). Ravazzini and Chávez-Juárez (2018) also find negative effects of income inequality across all social strata, which are most pronounced among people at the top of the income distribution. They speculate this is due to dangers of downward mobility as richer people have more to lose in societies that are more unequal. Cheung and Lucas (2016) found that income inequality intensifies social comparison processes, which can heighten feelings of deprivation for those at the bottom of the income distribution (also see Schneider and Valet, 2017). Findings from Nettle and Dickins (2022) suggest that those at the top of the income distribution are less sensitive to rising inequality than those at the bottom. These findings are echoed by studies which found inequality disproportionately harms lower-income groups while those in higher income brackets are less affected by income inequality (Oishi et al., 2011; Schwarze and Härpfer, 2007). Moreover richer individuals experience less dissatisfaction from inequality (Lous and Graafland, 2022) and particularly in Europe gain greater life satisfaction from their relative economic success (Alesina et al., 2004; Katic and Ingram, 2018; Roth et al., 2017). These dynamics imply that income inequality magnifies the positive effect of relative income position, as it heightens social distinctions. Therefore, my third hypothesis is:\n\nH3: The positive effect of people's relative income position on life satisfaction tends to increase with the level of a country's income inequality.\n\n\n## 2.3 Gender differences in life satisfaction due to income inequality and relative income position\n\n\nThe relationship between income inequality, relative income position, and life satisfaction discussed in the previous sections may not affect all individuals equally. Specifically, a growing body of research suggests that men and women perceive and respond to income inequality and their relative economic standing differently. The social comparison processes described earlier-where individuals evaluate their socio-economic standing relative to others (Easterlin, 1974; Runciman, 1966)-can manifest differently for men and women. Traditional gender roles, reinforced by societal expectations, often place a greater emphasis on financial success and status for men, creating stronger economic pressures. Men are thus more likely to view income as a measure of personal achievement and social standing (Dutta and Foster, 2013; Valet et al., 2021). As a result, relative income position and income inequality may have a more pronounced effect on men's well-being, as their life satisfaction becomes more closely tied to their economic success compared to women.\n\nAt the same time, income inequality itself may shape gendered experiences differently. Some studies suggest that women are more sensitive to societal inequality because of greater inequality aversion, which might stem from their historically disadvantaged economic position and greater exposure to gendered economic disparities (Bjørnskov et al., 2008; Fehr et al., 2006). However, other research challenges this view, arguing that men's life satisfaction is more adversely affected by income inequality. For instance, Mayraz et al. (2009) observed that men respond more strongly to economic inequality, likely because societal norms equate men's success with their ability to achieve upward mobility and maintain financial stability. Evidence further suggests that women may experience the effects of income inequality less intensely due to different social comparison processes. Valet (2018) argues that women are less likely to detect income inequalities, as their social comparisons are often oriented towards other women.\n\nThese gendered dynamics are also relevant when considering the interaction between income inequality and relative income position. In more unequal societies, men at lower income positions may experience heightened feelings of deprivation due to intensified social comparison processes and a perceived failure to meet societal expectations of success. Conversely, men at higher income positions may derive\n\ngreater satisfaction in unequal societies, as their relative advantage is amplified. Women, however, may be less responsive to these interactions, as their well-being is less tightly linked to economic competition and relative income standing.\n\nTaken together, these findings suggest that men are more likely to experience the combined effects of income inequality and relative income position-whether as deprivation at the lower end of the income distribution or as gratification at the upper end-while women may be less affected due to differences in societal roles, comparison mechanisms, and well-being priorities. Based on this discussion, my fourth hypothesis is:\n\nH4: The effects of income inequality, income position, and their interaction on life satisfaction are more pronounced for men than for women.\n\n\n## 3 Data and Method\n\n\n\n## 3.1 Data\n\n\nTo test these hypotheses, I used edition 3.1 of the multilevel data from Round 9 of the European Social Survey (ESS9MDWe03.1). 3 The ESS is a multi-national survey collecting data on attitudes and behavior of people in Europe. Since 2002, the ESS is surveyed every other year and consists of a fixed core program and special rotating modules. The ESS data are cross sectional and not every country participated in each round. Country samples are representative of all people aged 15 and over who are residing in private households in their respective country.\n\nRound 9 data of the ESS are particularly suitable to test my hypotheses as these data include information on people's life satisfaction, their personal income as well as information on country specific income brackets, and information on country specific income inequality. Round 9 was collected in 29 European countries in the years 2018 and 2019.\n\nThe analyses were restricted to respondents who provided information on their personal income, their life satisfaction, and on the control variables (see section 3.2). After listwise deletion, the analytic sample covered 21,040 respondents from 29\n\ncountries. The average country sample size in the analyses was 726, ranging from 308 respondents in Cyprus to 1,228 respondents in the Czech Republic.\n\n\n## 3.2 Measurement\n\n\n\n## 3.2.1 Dependent variable\n\n\nLife satisfaction was measured with the question 'All things considered, how satisfied are you with your life as a whole nowadays?' Respondents could indicate their current life satisfaction on an 11-point scale with labeled endpoints ranging from 0 ('extremely dissatisfied') to 10 ('extremely satisfied'). People across Europe reported a mean life satisfaction of 7.40 (SD = 1.92). The lowest mean life satisfaction was reported from people in Bulgaria (Mean = 5.38; SD = 2.33) and the highest mean life satisfaction from people in Denmark (Mean = 8.62; SD = 1.18).\n\n\n## 3.2.2 Independent variables\n\n\nThe two focal independent variables were the country specific income inequality and people's individual income position in the income distribution of their respective country. Information on country specific income inequality is included in the Multilevel Data of the ESS. It is measured by the Gini-coefficient ranging from 0 (indicating perfect equality) to 1 (indicating maximal possible inequality). The Ginicoefficients were calculated by Eurostat for each country. To facilitate interpretation, the Gini was multiplied by 100. The mean Gini in the sample was 29.22, ranging from 20.9 in Slovakia to 39.6 in Bulgaria.\n\nDuring the fieldwork of the ESS, respondents could either state their actual income or the country specific income decile their personal income falls into. For this each ESS country staff calculated the lower and upper threshold of each income decile for their country based on official statistics. These thresholds were provided to the interviewers and shown to respondents during the query on their personal income. I used these country specific income decile thresholds to map all respondents who decided to report their income in their country specific income decile. On average respondents were in the 4.77 (SD = 2.48) income decile. The country with the lowest mean income position was France (Mean = 3.21; SD = 1.91), the country with the highest mean income position was the Czech Republic (Mean =7.82; SD = 1.36).\n\n\n## 3.2.3 Control variables\n\n\nTo avoid potential biases of spurious correlations or anteceding suppression, I carefully evaluated which variables must be controlled for in the analyses. I followed the recent literature according to which only variables that precede and influence both-the focal dependent and the respective focal independent variable must be controlled for (Huntington-Klein, 2022; Rohrer, 2018). Income inequality is a macro variable. Hence, we do not have to control for any individual-level variables to identify the effect of income inequality on people's life satisfaction (it is very unlikely that changes in characteristics of a single person changes the Gini of a country). The second focal independent variable-individual income position-, however, needs some closer inspection. We know from classic human capital literature that people's income increases with increasing education and work experience (Mincer, 1974). Moreover, women and foreigners, on average, earn less than men and citizens (Blau and Kahn, 2017; Guzi et al., 2021; Sauer et al., 2021). All these variables also have tangible effects on people's life satisfaction. Life satisfaction tends to increase with education (Becchetti et al., 2023). Women and citizens tend to report higher life satisfaction than men and foreigners (Ahn et al., 2016; Kirmanoğlu and Başlevent, 2014). Whereas life satisfaction often decreases as people get older-at least up to a certain age after which life satisfaction tends to increase again (Amendola et al., 2019). Therefore, I controlled for people's level of education (measured by 7 ISCED categories), their gender, their citizen status, and their age (also as a proxy for work experience). To allow for nonlinear age effects, I also included a squared term for age. Table 1 shows the summary statistics for all variables.\n\nTable 1: Summary statistics of variables used in the analyses across all countries\n\nData: ESS9MDWe03.1, own calculations\n\n\n## 3.3 Analytic approach\n\n\nFor the analyses, I used a multi-level estimation framework to account for the clustered data structure (people in countries). The intra-class correlation (ICC) for the empty model indicates that about 13.1 percent of the variation in life satisfaction can be attributed to the country level. Accordingly, observations are correlated at the country-level, which can be accounted for by mixed linear models. To test for the first and second hypothesis income inequality and people's income position were included subsequently in the model. To test for the third hypothesis, a cross-level interaction term of income inequality and income position was included in Model 4. I followed the advice of recent methods research (Heisig and Schaeffer, 2019) and included a random slope for the lower level variable (income position) of the cross level interaction. To investigate for the expected gender differences, I estimated separate models for men and women and tested for gender differences in a three-way interaction model. I used marginal effect plots to visualize the interactions and to ease their interpretation. All reported models were calculated using restricted maximum likelihood estimation.\n\n\n## 4 Results\n\n\n\n## 4.1 Descriptive results\n\n\nTable 2 shows the mean life satisfaction for each country (first column, left panel) and the country's level of income inequality measured by the Gini-coefficient (first column, right panel). The last line of Table 2 shows the grand mean ( 𝑋𝑋 � � 𝐺𝐺 � � ) , which equals the mean life satisfaction ( 𝐿𝐿𝐿𝐿 � 𝐺𝐺 � � � � ) / mean income inequality ( 𝐼𝐼𝐼𝐼 � 𝐺𝐺 � � � ) across all European countries. The right column of each panel respectively displays the difference in a country's mean life satisfaction from the grand mean (𝐿𝐿𝐿𝐿 - 𝐿𝐿𝐿𝐿 � � � ��� 𝐺𝐺 ) ��� and the difference in a country's income inequality from the grand mean (𝐼𝐼𝐼𝐼 -𝐼𝐼𝐼𝐼 � � ) 𝐺𝐺 � � .\n\nIn the first line, for example, we see the numbers for Austria. In Austria the mean life satisfaction (𝐿𝐿𝐿𝐿) ��� is 7.85. This is 0.45 (𝐿𝐿𝐿𝐿 - 𝐿𝐿𝐿𝐿 � � � ��� 𝐺𝐺 ) ��� above the mean life satisfaction in Europe ( 𝐿𝐿𝐿𝐿 � 𝐺𝐺 � � � � = 7.40). Austria's level of income inequality ( 𝐼𝐼𝐼𝐼) is 26.80. This is 2.42 (𝐼𝐼𝐼𝐼 -𝐼𝐼𝐼𝐼 � � ) 𝐺𝐺 � � below the mean income inequality in Europe ( 𝐼𝐼𝐼𝐼 � 𝐺𝐺 � � � = 29.22).\n\nIf we compare the columns with the differences for each country, we observe a pattern (with some exceptions) suggesting that higher mean life satisfaction (positive sign for 𝐿𝐿𝐿𝐿 - 𝐿𝐿𝐿𝐿 � � � ��� 𝐺𝐺 ) ��� is in many countries associated with lower income inequality (negative sign for 𝐼𝐼𝐼𝐼 -𝐼𝐼𝐼𝐼 � � 𝐺𝐺 � � ) and vice versa. For example, if we look at the countries with an average life satisfaction above 8.0 (Switzerland, Denmark, Finland, Iceland, and The Netherlands), we observe for four of these five countries lower income inequality compared to the European mean. The only exception is Switzerland for which we observe a slightly higher income inequality than the European mean. If we look at the two countries with the lowest life satisfaction (Bulgaria and Serbia), we detect that these two countries are among those with the highest income inequality (Bulgaria +10.38 and Serbia +6.38 relative to the mean income inequality in Europe). Yet, there are also some notable exceptions to this relationship of inequality and life satisfaction. For example, respondents in Hungary reported comparatively low average life satisfaction, while income inequality in Hungary is also below the European mean. Moreover, and despite their low inequality, the average life satisfaction in Slovakia and the Czech Republic is below the European mean. Mean life satisfaction in France is also quite low, despite its income inequality below the European mean. Yet, this might be explained by the fact that sampled respondents in\n\nFrance on average were in lower income brackets compared to other European countries (see section 3.2.2).\n\nTable 2: Life satisfaction and income inequality in European countries\n\n𝐺𝐺\n\nData: ESS9MDWe03.1, N=21.040, own calculations\n\n\n## 4.2 Multivariate Results\n\n\nTable 3 shows the results for the multilevel modelling of people's life satisfaction due to their country's income inequality and their own income position in their respective country. Model 1 shows the empty model which is mainly interesting for its inter-class-correlation (ICC). The ICC of 0.131 suggests that about 13.1 percent of the total variation in life satisfaction can be attributed to the country level.\n\nModel 2 includes the country's income inequality. The negative and significant effect for income inequality suggests that life satisfaction on average decreases as income inequality increases. This is in line with my first hypothesis. If we look at the\n\nICC in Model 2 and compare it to the ICC in Model 1, we observe a drop from 0.131 to 0.105. This means that country differences in income inequality explain about 20 percent  of the country variation in life satisfaction. 4\n\nModel 3 additionally includes people's income position in the fixed part and the control variables. The positive and significant effect of income position suggests that people's life satisfaction tends to increase as they move up in the income distribution in their respective country. This is in line with the second hypothesis. Moreover, we see that the effect of income inequality is smaller compared to Model 2. This, however, does not mean that income inequality does matter less as soon as we include income position. It means income position mediates a portion of the direct effect of income inequality.  If we look at the ICC of Model 3, we see a slight increase 5 compared to Model 2.\n\nFinally, Model 4 includes the interaction of income inequality and income position. The positive and significant interaction effect suggests that the negative effect of income inequality is not the same for everyone. As people move up in the income distribution of their country the negative effect of income inequality decreases and especially in countries with higher income inequality (also see Figure 1 for a graphical display of the interaction). This result is in line with the third hypothesis.\n\nIf we look at the ICC in Model 4, we see a considerable increase compared to the preceding models. This is due to the included random slope for income position and indicates that the relationship between people's income position and their life satisfaction varies considerably across countries.\n\nThe control variables (see Appendix Table A1) show positive effects for being female, being a citizen, and for higher education on life satisfaction. The effect of age is negative. Yet, the positive and significant effect of age-squared suggests the age effect is not linear. On average, life satisfaction decreases until people are around 55 years old  and then increases again. Although, it must be noted that these models 6 are not set up to identify the causal effects of the control variables. Therefore, the effects of the control variables are not very meaningful here.\n\nIf we look at the model fit measured by the Akaike-Information-Criterion (AIC) and the Bayesian-Information-Criterion (BIC), we see that model fit increases from Model 1 to 4 (AIC and BIC decrease as new variables are included).\n\nTable 3: Multilevel model of life satisfaction on income inequality, income position, and their interaction\n\nData: ESS9MDWe03.1; standard errors in parentheses; own calculations; full model with control variables and variance components in Appendix Table A1; + p &lt; 0.10, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\nThe interpretation of an interaction with two continuous variables is challenging. Therefore, Figure 1 plots the interaction of Model 4 in Table 3 for three crucial levels of income inequality. Figure 1 displays the linear predictions of income position (x-axis) on life satisfaction (y-axis). The black solid line represents a Gini of 30 (approximately the grand mean in Europe). The dashed grey line represents a Gini of 20 (approximately the lowest income inequality in our data) and the grey dotted line a Gini of 40 (approximately the highest income inequality in our data).\n\nIf we first look at the intercepts (predicted life satisfaction for the 1 st income decile), we see remarkable differences. In countries with low-income inequality (Gini = 20) the predicted average life satisfaction for people in the first income decile is 7.68 (se = 0.349, p &lt; 0.001). In the average European country (Gini = 30), the predicted life satisfaction is 6.81 (se = 0.148, p &lt; 0.001) and in countries with high income inequality 5.94 (se = 0.378, p &lt; 0.001). Hence, the intercept in life satisfaction\n\ndecreases by 0.867 if the Gini increases by 10 points. These differences in intercepts are statistically significant ( 𝜒𝜒 2 =6.79, p = 0.009).\n\nIf we look at the slopes, we see increasing life satisfaction in all inequality settings as people's income position increases. Yet, the slopes (the effects) are not the same across those three inequality settings. In the low inequality setting (Gini=20), life satisfaction on average increases by 0.069 (se = 0.026, p = 0.09) as people move up one income decile. In the medium inequality setting (Gini=30) the slope is 0.120 (se = 0.011, p &lt; 0.001), and in the high inequality setting (Gini=40) the slope is 0.172 (se = 0.029, p &lt; 0.001). This means, the effect of moving up one income decile on life satisfaction increases by 0.052 if the Gini increases by 10 points ( 𝜒𝜒 2 =4.33, p = 0.037).\n\nFigure 1: Interaction of income inequality and income position\n\n<!-- image -->\n\nTable 4 shows the Model 3 and Model 4 effects of Table 3 but separated for women and men. The left panel displays the results for women and the right panel displays the results for men. If we first look at the effects of income inequality and income position in Model 3, we see a negative and significant effect of income inequality on life satisfaction for women, and in comparison, a somewhat smaller and significant effect of income inequality for men. A higher income position leads to a\n\nsignificant higher life satisfaction for both. However, the effect of income position is remarkably larger for men than for women.\n\nIf we look at the interaction of income inequality and income position in Model 4, we see a positive but insignificant interaction effect for women and a larger positive and significant effect for men. This provides initial evidence to support the fourth hypothesis.\n\nTable 4: Multilevel model of life satisfaction on income inequality, income position, and their interaction estimated separately for women and men\n\nData: ESS9MDWe03.1; standard errors in parentheses; own calculations; full model with control variables and variance components in Appendix Table A2; + p &lt; 0.10, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\nHowever, group separated models do not allow to test if effects for men are indeed significantly higher than for women. To test for such gender effects, we need a full model that interacts the independent variables of interest and their interaction with gender. As three-way-interactions are hard to interpret, I plotted the results for men and women in Figure 2. The coefficients of the three-way-interaction model can be found in Table A3 in the Appendix.\n\nFigure 2 shows the linear predictions of income position (x-axis) on life satisfaction (y-axis) in the same way as Figure 1-but now differentiates the results for women (left panel) and for men (right panel). If we first look at the intercepts (predicted life satisfaction for people in the 1 st income decile), we see that intercepts differ due to a country's income inequality for both women and men. In low-income\n\ninequality countries (Gini = 20) the predicted life satisfaction for women in the first income decile is 7.67 and for men 7.73. The difference between those two intercepts of 0.06 is statistically insignificant ( 𝜒𝜒 2 =0.30, p = 0.585). For medium inequality countries (Gini = 30), the predicted life satisfaction for women in the lowest decile is 6.90 and for men 6.72. The difference between those two intercepts of 0.18 is statistically significant ( 𝜒𝜒 2 =16.18, p &lt; 0.001). For high inequality countries (Gini = 40), the predicted life satisfaction for women in the lowest income decile is 6.13 and for men it is 5.70. The difference between those two intercepts of 0.43 is statistically significant ( 𝜒𝜒 2 =11.48, p &lt; 0.001). Obviously, men in the lowest income decile are more affected by income inequality than women. Each 10-point Gini increase on average decreases the life satisfaction of men in the lowest decile by 1.02. This decrease is statistically significant ( 𝜒𝜒 2 =9.03, p = 0.003). Women are also affected but not as much as men. Each 10-point Gini increase decreases women's life satisfaction in the lowest income decile by 0.77 ( 𝜒𝜒 2 =5.25, p = 0.022). These gender differences in inequality effects on the intercepts are also statistically significant ( 𝜒𝜒 2 =4.79, p = 0.027).\n\nIf we look at the slopes in the two panels, we also detect differences in the effects of income position on women's and men's life satisfaction. In countries with lowincome inequality (Gini = 20), the effect of moving up one income decile is 0.079 for women and 0.051 for men. In low-income settings women seem to be more affected by their income position than men. While this is contrary to the expectation in hypothesis 4, the difference in these slopes of 0.028 is insignificant ( 𝜒𝜒 2 =1.57, p = 0.210). In countries with medium inequality (Gini = 30) the slope for women is 0.115 and for men 0.125. The larger effect of income position on life satisfaction for men is in line with the fourth hypothesis, yet the difference in these slopes of 0.010 is again statistically insignificant ( 𝜒𝜒 2 =1.18, p = 0.278). In countries with high income inequality (Gini = 40) the slope for women is 0.151 and 0.200 for men. This is again in line with Hypothesis 4 and the differences in these slopes of 0.048 is significant on the 10% level ( 𝜒𝜒 2 =3.28, p = 0.070).\n\nFigure 2: Interaction of income inequality and income position for women and men\n\n<!-- image -->\n\n\n## 5 Discussion and conclusion\n\n\nThis paper set out to investigate the relationship between income inequality and life satisfaction by considering how people's relative income positions interact with the level of income inequality in their respective countries. The unique approach of this study was that it mapped individual incomes onto the national income distribution to explore how life satisfaction varies among people with different income standings across Europe. Using multi-level modelling on data from the European Social Survey (ESS), this research offered a more nuanced perspective on how people's relative income positions, alongside overall income inequality, shape their well-being.\n\nThe findings largely support the hypotheses that the effects of income inequality on life satisfaction are not uniform across income groups. Consistent with Hypothesis 1, the study showed that higher levels of income inequality are generally associated with lower life satisfaction. Consistent with Hypothesis 2, people with higher relative incomes are more satisfied. The interaction of income inequality and relative income position revealed that the negative effect of income inequality on life satisfaction was predominantly observed among individuals in lower income brackets. Those in higher income positions reported greater life satisfaction and this effect was even stronger in countries with higher income inequality. In line with Hypothesis 3, this might suggest that individuals with higher relative incomes may derive a sense of\n\nsocial advantage or status from income disparities, which enhances their well-being. Moreover, the gender-specific results revealed that men are more sensitive to income inequality and their relative income position compared to women, although the differences were not significant across all models, providing only partial support for Hypothesis 4.\n\nDespite its contributions, this study has some limitations. One key issue is the observed bias in certain countries with respect to the reported incomes of respondent. For example, the sample of the Czech Republic disproportionately included individuals from higher income positions, while the French sample had an overrepresentation of people in lower income brackets. These sampling or nonresponse biases may have driven the observed effects of income inequality on life satisfaction within these countries. Additionally, the mixed results regarding gender differences suggest that further investigation is needed to understand how women and men may experience the impacts of income inequality differently. Another limitation relates to people's awareness of their country's income inequality. Literature suggests that individuals often lack accurate perceptions of the level of national income inequality (Norton and Ariely, 2011). Future research should address these limitations by ensuring more balanced sampling across income groups and employing methods that accurately capture individuals' awareness of income inequality. Longitudinal studies could also provide insights into how changes in income inequality and relative income positions over time affect life satisfaction. Furthermore, exploring the underlying psychological and social mechanisms that lead higher-income individuals to experience increased life satisfaction in more unequal societies could deepen our understanding of this complex relationship.\n\nIn conclusion, this study's focus on relative income complements existing research on why income inequality affects people's life satisfaction differently. By considering who benefits and who is disadvantaged in unequal societies, this approach enriches the discourse on economic inequality and well-being, providing valuable implications for policymakers and researchers aiming to promote societal well-being.\n\n",
         "This paper revisits the predominant view in the literature suggesting all people perceive income inequality as equally harmful. I argue that while income inequality tends to have negative consequences for the majority, it can be beneficial for those at the upper end of a country’s income distribution. Specifically, people in higher income deciles are likely to experience greater life satisfaction and especially in societies with higher levels of income inequality, where their relative advantage is more pronounced. To explore this, I analyze data from 29 European countries covered in Round 9 (2018) of the European Social Survey. Results employing multi-level modelling reveal an interplay between income inequality and individual income position. While higher income inequality is generally associated with lower life satisfaction, this effect is predominantly observed among people in the lower income brackets. Conversely, those in higher income positions tend to report greater life satisfaction, and this effect is magnified in countries with higher levels of income inequality. These findings suggest that income inequality has a differentiated impact, with the negative consequences largely affecting those at the bottom of the income ladder, while those at the top may benefit. Moreover, men compared to women are tentatively more affected in their life satisfaction by income inequality and their income position. To more accurately predict the relationship between income inequality and people’s life satisfaction, future research should consider the varying experiences of different income groups, particularly focusing on who benefits and who is disadvantaged in unequal societies.",
         ""
        ],
        [
         "18",
         "18",
         "## I THE PARAMETER OF DISTANCE BETWEEN FINITENESS AND INFINITY\n\n\nThe essential analogy of the relation of Hilbert mathematics and Gödel mathematics to that of non-Euclidean geometry and Euclidean geometry is introduced and widely utilized in the previous, first and second parts of the present paper. Another paper (Penchev 2023 March 13) elucidates why the analogy at issue is  really  essential:  by  the  mediation  of  pseudo-Riemannian  space  of Einstein's general relativity and the mapping of entangled qubit Hilbert spaces into it. Then, one can represent the variable of the degree of entanglement as that of superluminal velocity. It will be now interpreted as the parameter of the 'distance between finiteness and infinity'.\n\nOne can notice that the locality of subluminal speeds, furthermore inherent for physics at all until now since it has obeyed the postulate of relativity for not exceeding the speed of light in a vacuum 1 , can be reinterpreted to be infinitesimally small to the superluminal velocities. Then, one has and may use two descriptions of the same: however, the one inherent for physics, where the bound of the speed of light in a vacuum divides more or less artificially and conventionally two intervals of a single finite variable , but the other one is meant by mathematics since Newton and Leibniz's age so that the physical locality of the former subluminal is granted to be infinitesimally small and only its derivatives are able to be finite .\n\nOne  can  utilizes  at  least  two  different  'Rosetta  stones'  for  translating  the  two  languages between  each  other,  each  of  which  very  instructive,  but  in  a  proper  way:  the  one  absolutely unknown until now, the other one known as Robinson's nonstandard analysis (but not as a 'Rosetta stone') for the translation at issue. Indeed, the relativistic rule of how one adds the velocities (e.g. notated as 𝑣𝑣 1 and 𝑣𝑣 2 ) of reference frames moving to each other by the relative speed 𝑣𝑣 0 (i.e.: 𝑣𝑣 2 = 𝑣𝑣 1 +𝑣𝑣 0 1 +𝑣𝑣 1 𝑣𝑣 0 / 𝑐𝑐 2 )  implies for them to be non-Archimedean quantities in relation to the constant 𝑐𝑐 (the speed of light in a vacuum) just as the actually infinitesimally small differentials in Leibniz's or rather in Robinson's manner to any finite quantity . 2\n\nActually, if the axiom is equivalently reformulated to the operation of addition rather than by its original formulation by multiplication (that: ∀𝑎𝑎 𝑏𝑏 ∈ 𝑅𝑅 ∧ 𝑎𝑎 , &lt; 𝑏𝑏 , ∃𝑛𝑛 ∈ 𝑁𝑁 : 𝑛𝑛𝑎𝑎 &gt; 𝑏𝑏 ), the above rule implies for ∀𝑣𝑣 1 and 𝑐𝑐 to  be  non-Archimedean quantities since: ∀𝑣𝑣 1 ∧ 𝑣𝑣 1 &lt; 𝑐𝑐 , ∄𝑛𝑛 ∈ 𝑁𝑁 : 𝑛𝑛𝑣𝑣 1 &gt; 𝑐𝑐 . Then, all subluminal speeds obey inherently the limit of locality, i.e., the speed of light in a vacuum dividing  them  from  all  superluminal  speeds  being  Archimedean  ones.  A  still  more  precise formulation is that all subluminal speeds are non-Archimedean quantities only to all superluminal velocities rather than to each other, by the way, just as all differentials after Robinson (and more or less, after Leibniz) to all finite quantities.\n\nSo, the bound of light in a vacuum can be reinterpreted purely mathematically as distinguishing all Archimedean  from  all  non-Archimedean  quantities  (meaning  that  the  latter  are  non-\n\nArchimedean  only  to  the  former,  but  not  to  each  other),  or  even  more  loosely:  as  a  physical constant able to distinguish unambiguously both dual or complementary members of any pair of axiomatic systems differing from each other by a single postulate so that the one includes it, and the other one means idempotently its logical negation. Thus (and particularly), it is able to embody the bound of all local Leibnizian differentials to all 'normal' finite quantities since the former ones confess the non-Archimedean 'belief' unlike the latter. So, the 'Rosetta stone' of Robinson's nonstandard analysis translates between subluminal and superluminal velocities by means of the Archimedes axiom being valid to all the latter, and invalid to all the former in relation to latter (but not to each other just as in the case of differentials in a proper sense).\n\nThe other Rosetta stone, both equivalent and alternative to nonstandard analysis, utilizes the Dirac  δ -function  being  consistent  to  the  standard  infinitesimal  quantities,  i.e.,  after  Cauchy's 'standard analysis' rather than after Robinson's 'nonstandard' one. So, one can mean it as a usual probability  density  distribution  however  defined  on  an  infinitesimally  small  area  as  to  all subliminal  velocities  being  just  the  measure  of  that  fussiness,  though  an  infinitesimally  small fussiness measured by a corresponding infinitesimally small reference unit so that the result of that measurement can be finite just as after Cauchy not involving any non-Archimedean quantities being redundant if that is the case.\n\nSo, one means the Dirac δ -function to be reinterpreted as a 'normal' (that is 'non-generalized') function or a probability density distribution however defined on an infinitesimally small area and thus differing from any 'normal' probability density distribution (the characteristic function of which is a certain wave function in the mathematical formalism of quantum mechanics) only by the fact that the scope of its function argument variable is infinitesimally small (so that that the scope of its values is infinitesimally great 3 ).\n\nThen one can immediately  notice  that  the  corresponding  wave  function  of  the  probability density distribution whether being infinitesimal or finite (i.e. that mean usually) is the same, but the two cases can be anyway distinguished from each other, granting to belong to the two dual, but identical Hilbert spaces whether the separable complex one of quantum mechanics or the qubit one of quantum information. In other words, that Hilbert space corresponding to subliminal speeds (thus in terms of relativity) means the quantity of position, and its dual, but identical twin refers to the  quantity  of  speed,  and  properly  to  superluminal  speeds,  eventually  renormalized  to  be equivalent to subliminal ones for being consistent with relativity.\n\nAs a conclusion, the utilization of the above reinterpretation of the Dirac function as a relevant 'Rosetta  stone'  for  the  translation  at  issue  implies  the  formalism  of  quantum  mechanics  and information  able  to  ignore  the  distinction  of  superluminal  and  subliminal  velocities  therefore suggests a uniform description for both, unifying them by means of a more general principle of 'quantum relativity'  introduced in other papers (e.g. Penchev 2023 March 13; 2021 June 8). 4\n\nThis means: if one should describe the transition through the light barrier, the language of energy  conservation  (e.g.,  as  in  Pauli's  particle  paradigm  or  the  Standard  model)  generates nonsense thus being irrelevant. Nonetheless, the language of quantum information conservation generalizing the former as a particular case among the latter, relevant also to all 'dark', entangled and more or less coherent states, allows for a quite reasonable description of all physical processes transcending the light barrier in either direction, being an inherent subject of quantum information meaning entanglement. Even more, it may conjecture that general relativity describes the same, but in still one, already third language of locality by substituting the superluminal dimension by another second subluminal dimension resulting in the curvature of pseudo-Riemannian space (in detail in: Penchev 2023 March 13 ).\n\nSo, if one has two 'Rosetta stones' able to translate the same text into two different translations into  two  divergent  languages,  a  derivative  third  'Rosetta  stone'  is  available,  although  being implicit initially: and just it is the subject of the present section tending to introduce the parameter of  the  distance  between  finiteness and infinity in various  contexts in order to  facilitate its use further.  One  can  notice  that  each  of  both  'Rosetta  stones'  above  translates  a  certain  physical quantity such as velocity into two different mathematical languages though the one of them, that of Hilbert spaces, is utilized by a fundamental experimental (thus being physical) science such as quantum mechanics.\n\nThen,  one  may  bracket  (in  a  Husserlian  manner)  physical  reality  meant  in  the  input  text referring  to  the  quantity  of  speed,  whether  'revolutionarily'  and  nonlocally  superluminal  or 'classically' and locally subluminal, in order to build the derivative Rosetta stone able to supply a relevant translation between two languages both mathematical: the one being that of nonstandard analysis, and the other of the qubit Hilbert space. One can immediately reveal that the third and derivative Rosetta stone already exists, suggested by the paper of Alain Connes (1995). However, the objective of the present paper is rather philosophical or both philosophical and mathematical (in fact, linking it to the foundations of mathematics), relating the newly introduced third Rosetta stone to the initial input text of physical reality and generalizing it into reality at all, i.e., the reality meant by philosophy, for example to be 'ontological'.\n\nSo,  the  one  output  mathematical  text  'translating'  the  same  input  physical  text  describes Leibnizian  differentials  as  non-Archimedean  quantities  (to  the  usual  finite  and  Arcimedean quantities, but not to each other), on the one hand, and usual finite Archimedean quantities, on the other hand, thus also representable as two dual axiomatics differing from each other by the two idempotent  logical  alternatives  of  the  same  axiom,  that  of  Archimedes  (in  the  case,  but  also generalizable as above).\n\nThe other output, also mathematical is another translation of the same input texts referring to the unification of locality and nonlocality both distinguished and linked by the limit of the light speed in a vacuum, now in the mathematical language of quantum mechanics and especially, into its 'dialect' of quantum information, i.e. in terms of the qubit Hilbert space. Then, both local and nonlocal quantities are represented uniformly as the same kind of qubit values (i.e., as quantum information), however  incommensurable  simultaneously being belonging to the dual or complementary identical branches of the same qubit Hilbert space.\n\nIn other words, Bohr's complementarity as well as wave-particle duality both being inherent for quantum mechanics are now reinterpreted by the opposition of locality and nonlocality in a way also relevant to relativity (whether special or general). Then, measurement (as it is defined in classical quantum mechanics) being only local determines which of both 'identical twins' of the same separable complex Hilbert space is 'alleged' to be local by the preliminary preparation for a certain quantum measurement; that is: which of both conjugate quantum quantities is meant to be measured.\n\nHowever, the third 'Rosetta stone' targeted to translate between two thoroughly mathematical texts should 'bracket' the above physical interpretation (however, only initially intending then to restore  it  even  philosophically  and  ontologically  following  the  talweg  of  the  present  paper). Though, the language of Leibnizian differentials means literally the pair of infinitesimally small and finite quantities, Robinson's nonstandard analysis (1966) demonstrates that it is isomorphic to the pair of finite and infinitesimally great quantities by virtue of the lemma of ultrafilters and the axiom of choice in the final analysis, since the former is a weaker version of the latter.\n\nAs the 'distance between finiteness and infinity' in the present paper is meant just by the pair of  finite  and  infinitesimally  great  quantities  (as  to  the  terms  of  nonstandard  analysis),  though coinciding  mathematically  with  the  description  of  the  pair  of  infinitesimally  small  and  finite quantities. So, the distance at issue is an infinitesimally great quantity of nonstandard analysis, however represented by a qubit value of quantum information after utilizing the third 'Rosetta stone' or as a certain wave function corresponding unambiguously to a certain probability (density or not) distribution as to the terms of the separable complex Hilbert space or classical quantum mechanics.\n\nThen  and  following  the  essential  analogy  or  reinterpretation  in  the  concepts  of  pseudoRiemannian space (justified in detail in another paper: Penchev 2022 February 4 ), one can speak of 'concave', 'convex', or 'flat' mathematical ontologies according to the 'positive', negative or zero distance of finiteness to infinity: accordingly. They correspond to three different schools for the foundations of mathematics: intuitionistic, 'dialectical' or paraconsistent, and 'classical' or 'Gödelian' (i.e., accepting his dichotomy about the relation of arithmetic to set theory: 'either incompleteness or inconsistency').\n\nIn other words, they can be distinguished between each other by the relation of the law of excluded  middle  (or  that  of  noncontradiction  sometimes  called  also  sometimes  the  'law  of contradiction') to the opposition of finiteness and infinity. Both laws are valid in propositional logic.  It  may  be  anyway  shared  by  the  three  schools  though  they  historically  generated  quite different kinds of attitude to classical propositional logic granted to be thoroughly valid only by the 'classical' (or 'Gödelian') school.\n\nIntuitionism suspends it only in relation to the special case of the opposition of finiteness to infinity,  or  more  exactly,  even  only  the  law  of  excluded  middle,  not  touching  directly  that  of noncontradiction since no mathematical entity can be finite and infinite simultaneously. On the contrary, the dialectical or paraconsistent approach to the foundations of mathematics tends to replace  propositional  logic  following  the  Hegelian  philosophical  tradition  though  the  opinions about which exactly the new 'zero-order' logic might be and are various, furthermore exchanging directly the law of noncontradiction and admitting consistent propositions for which it is not valid: and thus 'dialectical entities' to which they are relevant.\n\nThe present paper by introducing the distance between finiteness and infinity is closest to the intuitionist idea but generalizing it: propositional logic is conserved to be universally valid as the relevant zero-order logics for all mathematics, however the parameter at issue is involved so that its positive values are to be related to intuitionistic mathematics, the zero value to Gödelianism, and    negative  values  as  to  'dialectical  school'  granting  an  area  of  overlapping  finiteness  and infinity, in which the law of noncontradiction is not valid, but only to them remaining true in all other cases. In other words, the innovation touches only a special numerical variable introduced to describe quantitatively the relation of finiteness (arithmetic) and infinity (set theory) rather than the 'throne' of propositional logic.\n\nFurthermore,  one  can  immediately  notice  that  the  distinction  of  the  class  of  ontologies  of positive distances to that of negative distances is rather conventional by virtue of the duality or equivalency of the laws of contradiction and excluded middle in propositional logic. There is a nonzero area of 'no man's land' in the former cases which can be interpreted not worse to be 'shared'  as  to  the  latter  cases,  to  which  only  the  case  of  a  zero  area  therefore  excluding  any 'territorial disputes between the countries of finiteness and infinity' can be opposed.\n\nThe main idea of the present paper consists in the conjecture that the eventually disputable area of 'no man's land' supplied by the statute of 'shared management'  should be identified with all 5 the physical world, i.e the universe as a particular case of Hilbert mathematics generalized to the usual understanding of it, reducing it to the 'zero' or 'flat' case of Gödelian mathematics in turn isomorphic to Gödel mathematics. The physical world can be absolutely opposed only in relation to Gödel mathematics and following the episteme of Cartesianism. On the contrary, it may be interpreted to be a particular case in the framework of Hilbert mathematics, therefore arising 'ex nihilo' by itself, i.e., by virtue of mathematical laws 6 .\n\nOnly if one tends to project Hilbert mathematics on the screen of the 'wall of Plato's cave', as a relevant metaphor of Gödel mathematics, the usual (in fact, mythical) picture of the 'Bing Bang' would  appear.  Our  worldview  is  crucially  incomplete  for  granting  the  dogma  of  Gödel mathematics, therefore remaining the 'dark phase' of the universe fundamentally incognizable by\n\nthe identification of all the universe with its 'light phase' being only visible on the 'wall' at issue. Mathematics and physics are the same in the dark phase of the universe, at the same time being fundamentally inaccessible to both Cartesianism and Gödel mathematics in their unity.\n\n\n## II THREE KINDS OF HILBERT MATHEMATICS ACCORDING TO THE DISTANCE OF FINITENESS AND INFINITY\n\n\nSpeaking quite loosely, one might state that the physical world is the particular case of any nonzero 'curvature' of mathematics or the mathematical world; or that the universe appears if the general (and thus comprising it) mathematical world is divided into overlapping ('entangled') parts such as 'finiteness' studied by arithmetic and 'infinity' for set theory.\n\nA necessary condition is the reinterpretation of the Gödel incompleteness statement (1931) from a theorem deducible from the axioms of arithmetic, set theory, and propositional logic into an independent axiom as this is demonstrated in detail in the first part of the paper. The analogy to the Fifth postulate of Euclid is essential rather than only superficial following the same first part or another paper (Penchev 2022 October 21; 2023 March 13) considering an entanglement theory of quantum  gravitation   by  the 7 mapping  between  Einstein's  general  relativity 8 and  the superluminal  domain  as  what  entanglement  is  interpreted  by  the  mediation  of  quantum information.\n\nThat  reinterpretation  of  the  Gödel  incompleteness  statement  (1931)  can  be  visualized  by realizing  a  bit  of  information  as  two  oppositions  rather  than  as  only  one  following  the  usual prejudice to it. Those two oppositions are: (1) that of the two equally probable alternatives of a bit of information, to which the prejudice at issue restricts its understanding; (2) a preliminary choice between the state before choice and that after choice meant by (1). So, (2) is a necessary condition of (1).\n\nThen and analogically, the Gödel incompleteness statement (1931) can be reinterpreted as an axiom since the opposition of finiteness by arithmetic and infinity by set theory is presupposed by their opposition in advance versus the state before the same opposition, or in 'Eden' and before the  'original  sin  to  be  consumed'  (i.e.,  before  the  'apple'  of  the  opposition  of  finiteness  and infinity to have been 'eaten' by Cantor's set theory). The second part of the paper (Penchev 2023\n\nJanuary 3) demonstrates that Russell's logicism to the foundation of mathematics, following the ancient precedent of Aristotle's ontological revisionism to Plato's doubling of all 'things' by their 'ideas', can be identified as that 'Eden' before Cantor's 'actual infinity'.\n\nThe subject of the present, third part of the paper means, figuratively speaking, to describe 'Paradise' as it has been 'lost' and after the 'Fall', as if from the 'viewpoint of Adam and Eve already living  on  Earth',  no  more  'in  Eden'.  Abandoning  the  Bible  metaphor,  this  means  the description of the naive or native state in mathematics before Cantor's actual infinity from the contemporary worldview of mathematics by the explicit opposition of finiteness (arithmetic) and infinity (set theory). Then, the 'zero intersection of finiteness and infinity', in fact presupposed in advance as an axiom and only ostensibly proved after that in the Gödel incompleteness paper (1931), is only an option along with that of intuitionistic or dialectical mathematics as they are introduced and distinguished above.\n\nThe case of the nonzero intersection of the two alternatives of a bit of information (as the Planck  constant  needs  physically,  and  this  will  be  justified  in  detail  in  the  next  section)  is equivalent, which can be granted as the two dual counterparts of a qubit of quantum information. Following the same approach, quantum information is analogically interpreted as originating from classical information. In other words, the initial (primary) choice or opposition is that between quantum information and classical information after and only after which the secondary choice or opposition between the two alternatives of a bit of information is already possible.\n\nSpeaking again figuratively, 'information in Eden' is quantum information, and 'information on  Earth  and  after  the  Fall'  is  classical  information.  Furthermore,  quantum  information  (i.e. 'heavenly', 'divine' information) is immediately the physical quantity of action by virtue of the Planck constant unlike classical information which can be transformed into physical action only by the mediation of humans. This is an interpretation of the Bible 'Word' being in the beginning by Goethe's Faust stating for the 'dead in the beginning' in a way merging both so that 'In the beginning was the Word and the Word was the Deed' as if after John's Gospel and Goethe's Faust simultaneously or only after the former if 'God' is substituted by the 'Deed': 'In the beginning was the Word, and the Word was with the Deed, and the Word was the Deed' instead of the original:  'In the beginning was the Word, and the Word was with God, and the Word was God'.\n\nThe relation of Hilbert mathematics to Gödel mathematics can be interpreted in two ways. In the  one  of  them,  they  are  opposed  to  each  other  according  to  the  logical  status  of  the  Gödel incompleteness statement (1931): either an axiom in the former or a theorem in the latter. In the other approach, Gödel mathematics is a particular case of Hilbert mathematics according to the zero value of the parameter of the distance between finiteness and infinity. One can compare with the relation of Euclidean and non-Euclidean geometries. Logically, they can be opposed to each other by the Fifth postulate where the former grants it, and the latter accepts its negation. However, Euclidean geometry can be also considered to be a special, zero particular case among all nonEuclidean geometries after Riemann's parameter of space curvature has been introduced.\n\nIf one follows literally the analogy with the relation of Euclidean geometry to its non-Euclidean counterpart(s),  Hilbert  mathematics  is  to  be  opposed  to  Gödel  mathematics  according  to  one metamathematical axiom (or 'meta-axiom') about whether the Gödel incompleteness statement (1931) is an axiom or a theorem correspondingly. In fact, that meta-axiom is a certain interpretation of the class of axioms (or eventually, meta-axioms as in the case at issue) among which can be also included that about a bit of information (either one opposition or two oppositions) or that of the nonstandard bijection (either a bijection or not).\n\nThe three kinds of Hilbert mathematics (namely, the 'hyperbolic' intuitionist mathematics, the 'spherical'  'dialectical'  mathematics,  and  the  'straight'  'Gödelian'  mathematics)  can  be distinguished only by the parameter of the distance of finiteness and infinity. Furthermore, the former two ones can be unified as 'curved' cases versus the third one of zero curvature. The essential  analogy  to  pseudo-Riemannian  space  as  the  fundamental  mathematical  formalism  of general  relativity  is  mentioned  above  and  justified  in  the  first  and  second  part  of  the  paper 9 . However, it can be also continued further following the approach of the unification of locality and nonlocality by pseudo-Riemannian space and thus by the gravitational theory of general relativity (Penchev 2023 March 13).\n\nThen, the 'straight' 'Gödelian' mathematics (being isomorphic to Gödel mathematics) can be situated 'on the light cone' (i.e. to be associated with the newly introduced 'light ether' of special or general relativity) now reinterpreted to be a new absolute 'reference frame' (though neither special nor general relativity allow for any reference frame to be linked to it, besides in some generalized sense) as the exact bound between locality and nonlocality and between finiteness and infinity correspondingly. The special local mathematics and the nonlocal hyperbolic or spherical mathematics can be unified following the approach of general relativity by pseudo-Riemannian space and thus both being interpreted only locally though in a rather ontological or metamathematical sense.\n\nThen, gravity can be reinterpreted ontologically or meta-mathematically as well. It is already fundamental by generating all the physical world only in the framework of mathematics, i.e. as a certain  class  of  mathematical  structures  not  belonging  to  the  'flat'  Gödelian  mathematics  (or respectively, to Gödel mathematics), and consequently within a kind of neo-Pythagoreanism 10 . An essential analogy to pseudo-Riemannian space utilized by general relativity to describe gravity is relevant.\n\n\n## III DIALECTICAL MATHEMATICS, OR HOW THE DIALECTICAL CONTRADICTION OF FINITENESS AND INFINITY IS THE PHYSICAL QUANTITY OF ACTION\n\n\nSo,  Hilbert  mathematics  (unlike  Gödel  mathematics)  postulates  that  the  physical  world originates  from  mathematics  being  a  particular  mathematical  structure  determining  a  class  of possible physical worlds, among which our universe is featured (and thus chosen) by certain values of the three fundamental physical constants: namely, the speed of light in a vacuum, the Planck\n\nconstant, and the gravitational constant. Their exact values as to our universe are not a subject of Hilbert  mathematics.  Anyway,  the  three  constants  determine  unambiguously  the  relation  of locality and nonlocality regardless of their certain values as the only mathematical justification (and thus synonymically, 'source', 'reason', or 'cause') of the physical world.\n\nThe speed of light in a vacuum is the exact bound of locality and nonlocality. Thus, it can be linked to the absolute reference frame or the immobility attached to the classical concept of the 'ether', now modified to be that of electromagnetic field. Indeed, the classical 'ether' meant an imaginary 'zero' speed which cannot be defined in any way after special or general relativity since it refers differently to various reference frames in relative motions to each other. There does not exist any sharable property of them able to serve for the definition of the classical 'ether'.\n\nSpeaking rather loosely, one might say that the classical ether cannot be rigorously defined to be immovable: any zero speed cannot be zero to all reference frames. On the contrary, the boundary between locality and nonlocality, as the speed of light in a vacuum is interpreted, is the same to all reference  frames  and  thus  allows  for  the  newly  introduced  'light  ether'  to  be  the  necessary universal property shareable by all reference frames without any exception: by all inertial or noninertial reference frames of special or general relativity as by all discrete or external reference frames necessary for quantum relativity (e.g., defined in Penchev 2021 June 8) and the generalized relativity able to describe the area of nonlocality consistently to that of locality.\n\nOnce  any  certain  value  is  attached  to  the  boundary  of  locality  and  nonlocality,  any  finite curvature unifying both cases of positive, 'hyperbolic' or 'intuitionistic' and negative, 'spherical' or  'dialectical' curvature features the particular case of the physical world generated as if 'ex nihilo' (at least in a physical sense 11 )  only by virtue of mathematical laws and necessity. That finite curvature implies quantum information, entanglement, all the 'dark phase of the universe' (in which mathematics and physics are also 'entangled', speaking rather figuratively), on the one hand, and a finite boundary of the minimal possible physical action (which is specified by the Planck constant in our universe), on the other hand, furthermore being shared by both 'dark and light phases of the universe'.\n\nThe  light  phase  of  the  universe  can  be  distinguished  from  its  dark  counterpart  by  energy conservation, locality, unitarity, etc. 12 , and by all featuring physics until now in the final analysis since physics has always been identified with the physics of the light phase of the universe. Then, what is nonlocal is anyway represented locally by means of Einstein's general relativity. Then, the gravitational constant determines how both reference units are to be related as a ratio to each other for nonlocality to be able to be mapped locally as the corresponding variable curvature in any point of  pseudo-Riemannian  space  furthermore  according  to  the  certain  value  of  gravitational  field acting on it.\n\nOne can summarize more or less loosely that the physical world can be generated from Hilbert mathematics by virtue of any finite non-zero curvature, regardless of being negative or positive, from the relation of locality and nonlocality as to the physical viewpoint or by the underlain it\n\nmathematical relation of finiteness and infinity by the mediation of that of infinitesimal quantities (whether infinitesimally small or infinitesimally great) to finite ones. On the contrary, the pure case of Gödelian mathematics in the framework of Hilbert mathematics is 'flat' or featured by 'zero curvature'. It is also isomorphic to Gödel mathematics as contemporary mathematics until now or in the framework of the organization of cognition in Modernity.\n\nThe concept of curvature is rather mathematical and related to the class of vector spaces, to which pseudo-Riemannian space utilized by general relativity or the separable complex Hilbert space of quantum mechanics belong in particular. Any finite nonzero curvature corresponds to a certain mismatch of the two dual spaces 13 versus the case of their exact coincidence if the curvature at issue is zero. Since gravity correlates with pseudo-Riemannian space after Einstein's general relativity  one  can  speak  of  it  in  any  case  of  curvature  defined  on  a  certain  vector  space  as originating from the mismatch of its two dual counterparts and always tending to remove their discrepancy, to reset the corresponding curvature into zero, or in terms of Hilbert mathematics: to reduce any of both general cases of non-Gödelian mathematics to Gödelian one, i.e., to cancel the physical world in the final analysis, transforming it to be mathematical in the narrow sense of Gödel mathematics.\n\nIf one utilizes the metaphor of 'love' for 'gravity' since both can be thought as 'forces of attraction' (at least figuratively), the above generalized and mathematical understanding of gravity can be likened to Freud's 'death drive', i.e., destroying the physical existence by annihilating its inherent and definitive contradiction. Nonetheless, gravity or 'love' can be figuratively interpreted as the opposite force of creation in relation to the physical world generating it 'ex nihilo' in virtue of mathematical laws and necessity (after the present consideration), realizing both as if in the manner of Newton's 'third principle': as the identification of a pair of forces directed oppositely, surely rather as a figure of speech than in a rigorous mathematical meaning.\n\nAnyway  the  case  of  'hyperbolic'  intuitionistic  mathematics  can  be  opposed  to  that  of 'spheroidal'  dialectical  mathematics  in  the  framework  of  Hilbert  mathematics  in  a  sense.  For example, the Planck constant can be interpreted in a rather intuitionistic way as 'no man's area' compromising the entire light cone and separating locality and nonlocality so that direct conflict can be avoided by the limit of the minimal, physically possible action. Nonetheless, the quantity of  action  itself,  therefore  exceeding  the  threshold  at  issue  can  be  relaxed  as  a  still  unresolved contradiction once it has overcome that crucial 'doorstep' in the manner of Hegel's ontological 'dialectical logic' generating also a physical or 'procedural' period of time, during which the 'litigation' of both sides can be decided by an ultimate sentence in favor of the 'plaintiff' or the\n\n'defendant' in the contradiction at issue or by any agreement of them 14 . The juridical metaphor can be continued as to energy conservation as the immutability of the 'claim' in the course of the 'judicial process' as a necessary condition for its consideration and decision in the final analysis in any of the enumerated ways. Then, the Planck constant is the natural low limit of the 'interest in the litigation', after which one can 'lay claim'.\n\n\n## IV INFORMATION  AND  QUANTUM  INFORMATION  INTRODUCED  ON  THE GROUND OF THE FIELD OF ALL RATIONAL NUMBERS AND SET THEORY WITHOUT THE AXIOM OF CHOICE\n\n\nBefore continuing to the unification of the dimensionless quantity of quantum information and the dimensionful quantity of physical action by the fundamental Planck constant, information and its kinds of classical (or 'finite') information and quantum (or 'infinite') information are to be defined set-theoretically, i.e. in the foundations of mathematics rather than usually, as a rather technical property of messages for communication. though eventually interpreted as widely as Norbert  Wiener's  cybernetics  does.  In  other  words,  a  more  fundamental  understanding  of information than that already available in cybernetics is necessary for the objective and objectivity of investigating the unity of physics and mathematics featuring the 'dark phase of the universe'.\n\nThat fundamental and mathematical introduction of information and quantum information is relevant to the intention of Hilbert mathematics to overcome the restriction of Gödel mathematics and  particularly  the  Gödel  dichotomy  about  the  relation  of  arithmetic  and  set  theory  ('either incompleteness or contradiction') by an information bijection embedded in the definition of a bit of information (called also 'nonstandard bijection' because of its special property for the straight and inverse mapping to be dual or complementary to each other).\n\nThe  property  at  issue  can  be  traced  back  even  to  the  general  idea  about  the  conservative generalization of any proposition to its logical negation avoiding any contradiction, but at the cost of some relevant generalization of the law of noncontradiction or that of excluded middle, however now restricted exceptionally only to the relation of finiteness and infinity (particularly relating to the Gödel dichotomy)  or involving the parameter of the distance between them a way recollecting Riemann's  space  curvature  to  the  class  of  all  non-Euclidean  geometries  in  order  to  comprise Euclidean geometry as a special case of zero curvature.\n\nThe  key  idea  for  avoiding  contradiction  between  arithmetic  and  set  theory  consists  in  the derivative  inference  of  Peano  arithmetic  from  the  field  of  all  rational  numbers  (in  fact  as  an sufficient exemplification of any field after the theorem corresponding to the axiom of choice in the usual approach) rather than vice versa. The field of all rational numbers can be exhaustively defined  by  two  linked  Abelian  groups  obeying  a  single  distributive  law  and  transformed immediately  into  Boolean  algebra  (i.e.  homomorphic  to  propositional  logic  as  the  universally shared zero-order logic of mathematics at all) only by adding the second distributive law. In other words, The field of all rational numbers can be simply defined by means of removing the one\n\ndistributive law from Boolean algebra or respectively the dual counterpart of the field of all rational numbers complementing it to propositional logic.\n\nDue  to  their  divergent  historical  origin,  propositional  logic  and  arithmetic  are  standardly alleged to be quite different and independent in default. In fact, the present approach elucidates that they are 'close relatives' algebraically, ever siblings, together with set theory allowing for the following less or more metaphorical 'genealogical motto': 'arithmetic is the half of propositional logic', which in turn is 'the zero-order twin of set theory', being the homomorphic class of all possible consistent first-order logics or mathematical theories. Arithmetic, logic and set theory is the  'ruling  dynasty  of  all  mathematical  theories':  their  'blood  ties'  are  demonstrated  by  their 'common  origin' from information and quantum information if one approaches them algebraically,  by  the  mediation  of  the  field  of  all  rational  numbers.  In  turn,  information  and quantum information can be interpreted to be 'siblings' of the quantity of action and the physical world at all 15 .  Then, the dark phase of the universe is the common 'parent', from which both mathematics and physics originate.\n\nThe present section will represent the above idea only sketched by the 'genealogical' metaphor in a more rigorous way relevant to the foundation of mathematics so that the next section will be able to reinterpret Noether's theorems (1918) in the new context of Hilbert mathematics.\n\nOne  can  consider  the  field  of  all  rational  numbers  consisting  of  two  linked  commutative groups:  additive  and  multiplicative,  each  of  which  possesses  its  own  unit  element,  denoted correspondingly by '0' and '1'. Then, one can construct Peano arithmetic of all natural numbers 𝑁𝑁 on  the  ground  of  the  field  of  rational  numbers  by  introducing  the  unary  function  successor ' 𝑛𝑛𝑛𝑛𝑛𝑛𝑛𝑛 𝑁𝑁 = 𝑁𝑁 + 1 '  therefore  combining the operation of the additive group ' + '  with  the  unit element element of the multiplicative group, ' 1 ': thus essentially involving both groups of the rational field for the definition of arithmetic. Then, any bijection of the set of all natural numbers and any other infinite set can be interpreted as a well-ordering of the latter set without the axiom of choice to be included and thus valid also in any axiomatic system in which neither the axiom of choice neither the well-ordering theorem participate.\n\nFurthermore, one can consider the additive group of all integers, all of which belong to the rational field. All integers are an infinite set and it can be well-ordered utilizing any bijection with the set of all natural numbers as above (i.e. without needing the axiom of choice). Both additive semigroups of the two subsets of all positive integers and all negative integers are naturally wellordered in two ways anti-isometric to each other. One can examine the natural bijection ' ℵ ' of the set of all natural numbers ' 𝑁𝑁 ' and the set of all pairs, the two members of which are 'namesake' or rather 'numbersake' and belong to the set of all positive integers and the set of all negative integers correspondingly:\n\n<!-- formula-not-decoded -->\n\nAny  element  of  ' ℵ ',  such  as  a  ' 𝑛𝑛 ↔ -𝑛𝑛 ( , + 𝑛𝑛 ) ',  defines  a  'bit  of  information',  and  the mapping of any finite set (or particularly, finite strings, i.e. finite well-ordered sets or respectively vectors if those sets can be identified as elements of any vector space) onto some finite subset of ' ℵ '  is  the  quantity  of  information  unambiguously  assignable  to  the  former  set  (respectively, 'string', or 'vector').\n\nThen, one can extend the concept of information to infinite sets, which is notated as 'quantum information' 16 only  by  the  substitution  of  all  natural  numbers  (i.e.  in  Peano  arithmetic,  here inferred as a structure, derivative from the field of all rational numbers to which the axiom of induction is added) with the set of all natural numbers (i.e. in set  theory, in which the axiom of induction is replaced by its logical negation, what the axiom of infinity is: e.g. in Penchev 2022 October 21 17 ); that of all positive integers by the set of all positive integers; that of all negative integers by the set of all negative integers. Those substitutions can be accordingly notated as:\n\n<!-- formula-not-decoded -->\n\n<!-- formula-not-decoded -->\n\n.\n\nThe  introduction  of  the  concepts  of  information  and  quantum  information  allows  for preventing the Gödel dichotomy of the relation of arithmetic to set theory in the following rigorous meaning. Though  it is still valid to the three substitutions above, ' 𝑁𝑁 → { 𝑁𝑁 } ; ( -𝐼𝐼 ) → {( -𝐼𝐼 )}  (+ ) ; 𝐼𝐼 → {(+ )} 𝐼𝐼 ', the derivative substitution ' ℵ → { 𝑁𝑁 } ' overcomes that 'either incompleteness or contradiction', which can be notated just as ' ℵ ↔ { 𝑁𝑁 } . In other words, classical information being inherently finite is able to be neither incomplete nor contradictory to the set of all natural numbers, even nor to quantum information, i.e. to the quantity of classical information in relation to the set of all natural numbers,\n\nThis means that the concept of information is able to bridge finiteness and infinity as well as physics  and  mathematics,  surprisingly  even  the  Cartesian  'body'  and  'mind'  after  a  more philosophical reflection.  Speaking loosely,  information  and  quantum information are the same though the former is inherently finite, and the latter is fundamentally infinite. As it happens, one can conjecture the converse statement, namely that information can be defined by the unification of finiteness and infinity, for example, after the fact that the unification of finiteness and infinity represents only a bit of information so that the one alternative of it is 'finiteness', and the other is 'infinity'.\n\nThe way of information not to be incomplete to the set of all natural numbers can be sketched briefly  so.  One  can  assign  either  'true'  or  'false'  to  all  resolvable  statements  featured  by  a corresponding finite Gödel number. Nonetheless, one may attach the finite ordinal number of a bit of  information  being  both  'true'  and  'false'  to  any  Gödel  insoluble  statement.  So,  the  Gödel\n\nnumber is a natural number as to all soluble statements, but the finite ordinal number (i.e., a natural number as well) of a bit of information as to all insoluble statements.\n\nFurthermore,  one  can  elucidate  the  mutual  equivalence  of  the  introduction  of  whether  the nonstandard bijection  or  information  where  the  Cartesian  product  of  all  natural  numbers  with themselves is represented explicitly in the former case, and implicitly, by the 'diagonal of the Cartesian product' in the latter case. However, the Carteseian product of all natural numbers with themselves is equated to all natural numbers in both cases. One can essentially illustrate the fact that information and quantum information are the same by identifying the two diagonals of the Cartesian product, where quantum information is anti-isometric to information, or notated more or less loosely, by the symbol of infinity ' ∞ ' as to arithmetic or to all natural numbers, but without involving the set of all natural numbers, ' { 𝑁𝑁 } ':\n\n<!-- formula-not-decoded -->\n\nSo, both tools of the nonstandard bijection and information involved already in the foundation of mathematics are able to build the conceptual ground for the intended unification of finiteness and infinity or respectively overcoming the Gödel dichotomy about the relation of arithmetic and set theory, furthermore  relevant  to the opposition  of Gödel  mathematics  versus  Hilbert mathematics, which is the main subject of the present paper. One is to distinguish the solution by the unification of finiteness and infinity (meant here) from the ontological and intensional decision of the same problem traceable back to Aristotle or embodied in the modern approach of logicism to the foundations of mathematics as in Whitehead and Russell's 'Principia mathematica' 18 .\n\nSpeaking  figuratively,  Aristotle's  ontological  decision  just  as  logicism's  solution  to  the foundation of mathematics tend to return back to the state of 'Paradise Lost', i.e., before 'the original sin to have been consumed', before 'the apple to have been eaten' whether by Plato's opposition of things versus ideas in the former case or by Cantor's set theory contrasting explicitly finiteness to infinity by the express concept of 'actual infinity'. In other words, logicism prevents the choice of either 'finiteness' or 'infinity' putting a stop to the choice itself by giving itself up.\n\nHusserl's 'epoché' to reality can be interpreted as a philosophical generalization in relation to the  more  special  problem  about  the  foundation  of  mathematics,  which  is  meant  by  logicism immediately, therefore restoring in a hidden form the ancient ontological solution of Aristotle. For emphasizing the similarity of Husserlian approach, one can introduce an analogical concept of 'epoché to infinity' to feature the main idea of logicism though in an unexpected way contradicting common sense's prejudice (Penchev 2023 January 3) and even to illustrate it by the 'lost solution' of Fermat's last theorem claimed by himself (Penchev 2021 March 9) therefore corresponding to the state of logicism's 'Paradise Lost' in turn tending to cancel the 'original sin' of Cantor's actual infinity by its intensional and logical unification with finiteness.\n\nThe distinction of the approach of the present paper from the idea of ontology or logicism is necessary for its realization to be an alternative to the foundations of mathematics, on the one hand,\n\nand the unification of information and physical action, on the other hand. It is also embedded in the project of Hilbert arithmetic (e.g., Penchev 2021 August 21), after which infinity is interpreted by  doubling  finiteness  (or  philosophically  and  theologically,  'finitude'):  that  is  as  a  second finiteness gapped from the former to be independent of it. The same doubling of finiteness or Peano arithmetic can be traced in both information introduced in set-theoretical manner as above or in the nonstandard bijection.\n\nAdopting the nonstandard bijection in set theory, the fundamental philosophical idea of duality (relative to complementarity in quantum mechanics) underlies the foundation of mathematics. It can be expressed in the new context as generalizing the bijection as to quality in a way consistent to  propositional  logic  unlike  the  approaches  involving  any  'non-classical  logic'  and  traceable philosophically  still  even  to  Hegel's  dialectical  logic.  The  nonstandard  bijection  can  be  also interpreted  to  introduce  infinity  implicitly,  e.g.,  after  Dedekind's  definition  of  infinity  by  the bijection of a set (claimed to be infinite) with its true subset. Then the nonzero complement of the true subset to the set at issue can be defined to be dual to the former subset.\n\nIn other words, the non-excluded middle of the dual subset as above is a special and sufficient property to define the concept of 'actual infinity', slightly paraphrasing the idea of intuitionism: not only the rule of excluded middle is irrelevant to infinite sets, but furthermore the invalidity of the excluded middle is sufficient for determining any set to be infinite, or by its nonzero dual counterpart implied if a bijection is nonstandard. The advantage of the nonstandard bijection to actual  infinity  consists  just  in  the  explicit  reference  to  the  difference  between  finiteness  and infinity, on the one hand, and then identifying that complement of finite to infinity as a second finiteness, but dual to the former one.\n\nAs to physical action, it originates from that 'doubling of finiteness' by itself and once again 'by itself', now by its dual counterpart. In other words, the definition of the nonstandard bijection implies  the  quantity  of  physical  action  as  equivalent  to  information,  on  the  one  hand,  and  to mathematics, on the other hand, even to arithmetic in the meaning in which the definition of the nonstandard bijection means the reducibility of mathematics to it.\n\nIndeed, if the nonstandard bijection is defined as to Hilbert arithmetic in previous papers (e.g. Penchev 22 October 21; 2021 March 9) as ' ( 𝑃𝑃 + ⊗𝑃𝑃 ↔𝑃𝑃 0 ) ↔𝑃𝑃 ' , the physical action can be associated with the product of any two elements, i.e. natural numbers, each of which belongs to the one of the two dual anti-isometric arithmetics (notated as ' 𝑃𝑃 + , 𝑃𝑃 -'). Then, the Planck constant can be interpreted as the fundamental 'curvature' of the Cartesian product ' 𝑃𝑃 + ⊗𝑃𝑃 ' so that its corresponding elements, i.e., relevant to the definition of information, are neither orthogonal nor infinitesimally orthogonal to each other since the Planck constant is the finite minimal possible projection on the one onto the other.\n\nAs  far  as  the  curvature  of  the  Cartesian  product  ' 𝑃𝑃 + ⊗𝑃𝑃 '  in  turn  can  be  realized  as 'entanglement', the physical equivalent of physical action to non-physical mathematical structures is due to entanglement. The 'dark', both physical and mathematical phase of the universe is a necessary condition for its 'proper' and only physical phase identified to be all physics until now to  which  mathematics  is  correspondingly  and  inherently  Gödel  mathematics,  a  position  of mathematics arising naturally from the Cartesian constitution of cognition in Modernity. Noether's theorems (1918) can be deduced from the same observation, in detail in the next section.\n\n\n## V ACTION AFTER EMMY NOETHER'S THEOREM (1918), NOW REINTERPRETED IN DIALECTICAL MATHEMATICS\n\n\nThe dimension of the 'distance between finiteness and infinity' (which can be also interpreted quite  loosely  as  the  'distance  between  physics  and  mathematics'  and  even  as  that  between 'subject' and 'object' philosophically) is quantum information mathematically, and quantity of action physically (what is the dimension of the Planck constant particularly). Thus, the physical quantity of action is fundamental by virtue of the fact that the physically dimensionless 'quantum information' is equated just to 'action' due to the dimension of the Planck constant.\n\nFurthermore, this turns out to be the equating link between physics and mathematics eventually regulated by the most fundamental law of conservation 19 including to the most general case of the 'dark phase of the universe' where energy conservation is not more valid since it can be related (even definitively) only to its 'light phase' restricted to about 4-5% of the entire mass and energy of the universe according to all contemporary astronomical measurements of them. So, the light phase of the universe where time and energy can be discernibly distinguished between each other is rather an exception, a markedly particular case, though not only all physics but even all natural science until now has been limited within its framework alone.\n\nIf one reflects the same restriction philosophically, it is due to the necessity of repeatability and empirical or experimental verifiability featuring natural science without any exception and thus physics as an essential part of it. Any empirical observation, any experiment and even any thought experiment (e.g., Einstein's 'Gedankenexperiment') obey it and thus they are interpreted to be local and causal. Indeed, just Einstein noticed that quantum mechanics admits 'experimental nonlocality' seeming to be a 'fallacy in definition' if the adjective 'experimental' is a synonym of 'local' as the repeatability and empirical or experimental verifiability are imposed to be a rule without any exception as to natural science 20 .  Nonlocality would imply what he denounced as 'spooky actions at a distance' essentially linked to his other very picturesque metaphor: that about 'God playing dice', thus rejecting the requirements of repeatability advocated by him 21 .\n\nEven much more, he together with Podolsky and Rosen (1935) suggested a thought experiment in his manner to demonstrate in a rigorous and quantitative way (rather than by metaphors) that quantum mechanics implies nonlocality, and thus if one accepts the principle of repeatability and experimental  verifiability  (since  the  latter  can  be  only  local  after  natural  science  in  his  age),\n\nquantum mechanics is inherently incomplete because of the absence of those additional restrictions of locality as natural science needs in the three authors' opinion.\n\nOn  the  contrary,  the  2022  Nobel  Prize  for  entanglement  and  quantum  information  (e.g. Penchev  2023  March  13)  introduces  quantum  correlations  to  be  recognized  as  an  absolutely credible  scientific  fact  therefore  admitting  exceptions  or  rather  generalizing  the  principle  of repeatability and local verifiability in natural science. Indeed, repeatability can be conserved if it is related to probability (density or not) distributions rather than to single events or experiments. Locality cannot be saved in any way, though: at least unless one accepts that nonlocality can be equivalently mapped  locally  by  Einstein's  general  relativity or by  the mediation  of  an entanglement theory of quantum gravity 22 .\n\nThe  same  generalization  of  the  principle  of  natural  science  about  repeatability  and  local verifiability can be illustrated by an eventual deduction of quantum-information conservation (thus as a generalization of energy conservation) by means of the first theorem of Emmy Noether (1918). One  can  assume  the  most  general 23 case  where  what  is  conserved  (or  literally  in  Noether's formulation:  the integral invariant to the Lie group  of  transformations)  is a physically dimensionless quantity (such as quantum information), and the Lie group of all transformations (what is that structure meant literally in Noether's formulation) of action itself is the meant set of corresponding physical changes.\n\nSo formulated, the most general case corresponds also to the wide approach underlying her paper,  namely  the  fundamental  physical  problem  of  any  conservation  laws  to  be  interpreted thoroughly and absolutely as an abstract and pure mathematical problem. Which is the relation of the integral invariant after variations to those variations themselves if they constitute a Lie 24 group? Then, one can continue Noether's idea even more abstractly (and partly rather trivially) to any group  (eventually  even  only  groupoid  in  both  algebra  and  category  theory)  and  the  structure invariant to all group, thus touching the well-ordering (more precisely, two anti-isometric wellorderings) implied by any group in definition and not needing the axiom of choice.\n\nAs  to  the  physical  interpretation  of  the  above  'most  general  formulation',  one  considers physical changes (or mathematically, their group) 'without time': as a slogan, 'changes without time', or as common sense would probably more like, 'changes before time'. As to time itself, the expression  'without  or  before  time'  means  the  two  directions  of  time  to  be  available simultaneously, or in a coherent superposition, for example visualizable by 'Schrödinger's cat': either certain result whether 'dead' or 'alive' corresponds to 'changes after time'. Energy as what is conserved also correlates only with 'changes after time' since it needs time.\n\nOn the contrary, quantum-information conservation means what is conserved in a coherent state, to which energy conservation is inapplicable even only by virtue of the fact that energy (as well  as  time)  cannot  be  yet  defined  as  being  an  inseparable  whole.  Nonetheless,  quantum information conservation continues to be valid after energy conservation or speaking figuratively, after  the  mythical  'Big  Bang'  intentionally  as  far  back  in  time  as  possible  so  that  energy conservation  is  universally,  omnipresently  and  omnitemporality  valid  (but  only  ostensibly,  in humankind's belief: seemingly scientific, really religious).\n\nThen and interpreting back, the dark phase of the universe by its light phase 25 , one may say rather loosely that 'after the Big Bang', the opposite direction of time (as if also available in a coherent state) has been transformed into energy, or generalizing: all pairs of dual and conjugate physical quantities can be distributed either into the one direction of time, or into the other, though idempotently, i.e., conventionally as to which member of the pair in relation to which direction to be.\n\nOne may further notice that the 'destruction' or 'deconstruction' 26 of  the  dual or dynamic quantities (to their cinematic counterparts) to the alleged origin from the neglected (unchosen or discriminate) direction of time follows even yet mathematically: from the substitution of the wellordering due to the axiom of choice with the pair of two dual or anti-isometric well-orderings presupposed by any group structure 27 .  One  can  further  say  that  the  idea  of  Noether's  theorem consists  of:  (1)  decomposing  any  group  into  two  semigroups;  (2)  the  substitution  of  either semigroup with an equivalent invariant (conservation law, physically); (3) confirming the same invariant to the dual semigroup if both originate from the same group; (4) linking the invariant at issue and the initial group as logically equivalent.\n\nThe invariant can be exemplified by the function successor (a concept literally borrowed from Peano arithmetic), which can be defined to any group. That is: as the unary operation originating by the additive group operation and the unit element of the multiplicative group so that two dual well-orderings appear both starting from the unit element but being idempotently anti-isometric to\n\neach other. Then, the algebraic sense of the idea of Noether's theorems 28 seems to be trivial and originates even from the definition of 'group' in the final analysis.\n\nIn fact, Noether's paper does not mention at all, even once the physical quantity of action. However, that physical interpretation though implicit is immediate as to classical physics since the article formulates the invariants by Lagrangians in turn able to describe any motion in classical mechanics, in which 'invariant variation' corresponds to the principle of least action, from which energy conservation is deducible. However, if one discusses the abstract group generalization (or an interpretation) of Noether's theorems, what corresponds to variations, or rather to the invariant inferable from those variations obeying furthermore some analogue of the principle of least action, needs  some  relevant  elucidation  in  other  to  be  corroborated  the  fundamentality  also  of  that algebraic counterpart of the physical quantity of action supposedly by the mediation of information and quantum information.\n\nIf one considers the two semigroups, respectively the two anti-isometric well-orderings both starting from the zero element of the additive group (eventually being 'curved' or parametrized to each other as in the second theorem), the principle of least action would correspond to the case of a 'square' since its area is least among all 'rectangles', the less side of which is the same, which in turn implies for the two semigroups to be exactly anti-isometric to each other, i.e. their reference units to be the same though opposite to each other. On the contrary if they are 'curved' to each other, or the one is parametrized to the other, the area of the square at issue cannot be zero, but some finite value, for example, such as the Planck constant as to our universe.\n\nFurthermore, one can distinguish the rather trivial mathematical sense of Noether's theorems from their proper and essential sense (once they have been reduced algebraically as above). The former consists in the consideration of the two anti-isometric semigroups in two alternative ways therefore  avoiding  the  direct  logical  conflict  due  to  their  mutual  anti-isometry.  The  one  is conserved literally, i.e., as a semigroup, but the other is 'paraphrased' by the 'conservation' of its unit element since it is the same as in the other semigroup and thus no logical contradiction can appear. Summarizing that rather trivial mathematical sense, it consists in the representation of any group  by  either  of  its  two  well-ordered  and  anti-isometric  semigroups,  sharing  only  the  zero element of the additive group at issue.\n\nThe relevant essential physical sense of the only algebraic consideration of Noether's theorems is due to the fact that the inherent well-ordering of time means the representation of the group in terms  of  either  of  its  semigroups  as  only  physically  relevant  and  meaningful  since  time  is irreversible  and  the  dual  semigroup  is  removed  from  any  physical  interpretation  as  nonsense, nonetheless being absolutely necessary for mathematical proofs and conclusions. Thus, action is\n\nfeatured to be the most fundamental physical quantity after Noether's theorems (1918) since it allows  the  consistent  unification  of  both  physical,  temporal  and  mathematical,  atemporal description: in fact, a unification being unavoidable for the description of the 'dark phase of the universe' (in more  detail in Section VIII ) and  the most  general  'quantum  information conservation', being the subject of Section IX .\n\nSo,  Noether's  theorems  (1918)  are  fundamental  for  the  idea  that  the  physical  world  is  a particular case in the framework of Hilbert mathematics: namely, that of any nonzero distance between  finiteness and infinity under the additional convention (elucidated above) that intuitionistic mathematics 29 can be reduced to dialectical mathematics. Speaking loosely, one may say  that  the  physical  dimension  of  action  appears  as  a  purely  mathematical  corollary  by  the consistent option for any group to be equivalently represented by the pair of a well-ordering (such as that implied by the one semigroup) and a certain conservation.\n\nThe logical inferability of the physical world from only mathematical premises results also in the  direct  link  of  the  group  of  action  (a  physical  quantity)  and  the  conservation  of  quantum information  (a  physically  dimensionless  quantity  able  to  be  equally  well  interpreted  both physically and mathematically). Unlike its particular case of energy conservation connecting two physical quantities (energy and time) and valid only to the light phase of the universe, during which mathematics  and  physics  can  be  absolutely  gapped  from  each  other,  quantum  information conservation means  the way  in which the physical worlds appears omnipresently and omnitemporally from quantum information, which is 'nothing' physically, i.e. as if 'ex nihilo', but strictly observing the most fundamental law of its conservation 30 .\n\nThe mythical 'Big Bang' is only an illusory projection of that permanent violation of energy conservation,  which  generates  the  physical  world  always  and  everywhere  by  virtue  of  the mathematical necessity subjected to Hilbert mathematics. The 'advantage' of the 'Bing Bang' conjecture 31 is that the violation of energy conservation is collected at a single special and singular point of space-time: that at the beginning of spacetime and the universe so that energy conservation is alleged to be universally valid at any other point. This means that the Big Bang is due to the prejudice for energy conservation to be universally valid, in fact absolutely false.\n\n\n## VI  HILBERT  MATHEMATICS  BY  NOETHER'S  THEOREMS,  OR  NO  PHYSICAL CONSERVATION IN GÖDEL MATHEMATICS\n\n\nMeaning the conclusions of the last section, one can reinterpret back the relation of Hilbert mathematics to Gödel mathematics now starting from Noether's theorems and the variability of a parameter,  which  is  the  Planck  constant  in  our  universe  (rather  than  a  rather  mathematical parameter of the distance between finiteness and infinity). One can illustrate the approach by the problem about the value of the curvature in great enough domains of the universe or about the magnitude of the gravitational constant.\n\nIf  general  relativity  is  a  relevant  theory  of  gravity,  as  contemporary  physics  suggests,  the curvature of immense areas of the universe and the value of the gravitational constant are linked both mathematically and physically since gravity can be also interpreted to be a physical corollary from the curvature of pseudo-Riemannian space. Analogically, if the idea about the mathematical origin  of  the  physical  world  is  accepted  as  a  kind  of  the  'curvature  of  mathematics'  (and represented by the variable parameter of the distance between finiteness and infinity) resulting in the existence of the physical world, the Planck constant corresponds to it.\n\nSo, the existence of the physical world itself refutes the suggestion that the 'flat' Gödelian mathematics is the 'real mathematics' of the world analogically to the way in which gravity or the gravitational constant after general relativity reject the hypothesis that Euclidean geometry is the 'real geometry of the world'. Though the expression the 'real mathematical structure of the world' (whatever that structure be: whether 'geometry' or 'mathematics', or any other first-order logic studied by mathematics) seems to be metaphorical in the Cartesian organization of cognition or from the viewpoint of Gödel mathematics relevant to it, Hilbert mathematics accepts the same phrase literally.\n\nIndeed (and following the Cartesian 'slang'), the link between mathematics and reality can be only mediated by any physical or belonging to natural science theory, which uses one mathematical model or another, and only it can be tested experimentally whether it corresponds to reality or not rather than the corresponding mathematical model directly. So, Einstein's general relativity can be really tested experimentally, a pseudo-Riemannian space to be or not the 'real geometry of the world' is only in a metaphorical sense by virtue of the fact that general relativity utilizes just it. That is the case also of any structure enumerated to belong to Gödel mathematics since it definitely needs a human arbiter, gifted by the divine 'ability of free will' to decide for a natural science theory to utilize one mathematical model or not, who 'would be erased, like a face drawn in sand at the edge of the sea' 32 by Hilbert mathematics, though.\n\nHowever,  the  analogical  expression  about  the  'real  mathematics  of  the  world'  is  not metaphorical  as  to  Hilbert  mathematics  since  it  identifies  the  physical  world  with  a  class  of mathematical structures featured by any nonzero finite value of the 'parameter of the distance between  finiteness  and  infinity',  and  resulting  into  a  minimal  possible  magnitude  of  physical action, which is the Planck constant in our universe. So the 'problem about the real mathematics of the world' generally means the choice between Gödel mathematics and Hilbert mathematics,\n\non the one hand, and the choice of a certain Hilbert mathematics corresponding to the Planck constant among the entire class of Hilbert mathematics, on the other hand.\n\nSo,  if  the  physical  action  is  always  zero  as  in  Gödelian  mathematics,  to  which  Godel mathematics is identical in the meaning elucidated above, in the framework Hilbert mathematics, all  physical  quantities  are  trivially  conserved  being  identically  zero.  The  physical  laws  of conservation meant by Noether's theorems are essential to Hilbert mathematics only as to any nonGödelian mathematics and thus to the certain mathematics being the 'real mathematics of our universe' and featured by the Planck constant.\n\nThe most general law of conservation, that is the conservation of quantum information includes as also valid the particular case of energy conservation, but its essential physical sense to regulate the creation of physical world can be better visualized in the complementing case where energy conservation is not valid: consequently out of the scope of all contemporary physics and classical quantum mechanics sharing the universality of Pauli's 'particle paradigm' and the Standard model relevant  to  it.  Figuratively,  it  means  the  state  'before'  the  mythical  'Big  Bang'  and  only mathematical laws rule the creation of the physical world occurring everywhere and always and resulting  in  the  visible  universe  and  its  expansion  rather  than  due  to  the  alleged  'Big  Bang' ostensibly having taken place about 14 billion years ago.\n\nIn other words, this is the state where energy and time are not yet distinguishable from each other, but this is not the imaginary singular point at or within the Big Bang. This is the omnipresent and omnitemporal 'dark phase of the universe', from which the known visible and light, local phase  arises  everywhere  and  always  as  if  'ex  nihilo'.  There  exists  the  increasing  quantity  of physical action corresponding to the universal conservation of a purely mathematical quantity such as quantum information or respectively the qubit Hilbert space: it conserves only because it cannot but be inherently complete.\n\nSo,  the  dark  phase  of  the  universe  is  necessarily  'caused'  by  a  mathematical  reason:  thus 'hypotheses non fingo' just as Newton said about gravitation, but now to the creation of the world (for which Newton needed the hypothesis of God, anyway). Then, the light phase of the universe arises from its dark phase again only by virtue of the mathematical necessity due to the inherent duality of the qubit Hilbert space. Even the 'haven' of the Big Bang which might shelter God is not more necessary for science, and thus no place at all for God in physics 33 . The conclusion is:\n\nThe  physical  world  appears  necessarily  and  purely  mathematically  in  any  non-Gödelian mathematics that is without any physical cause, especially without any supernatural one such as 'God'.\n\n\n## VII LOCALITY AND NONLOCALITY IN BOTH PHYSICS AND MATHEMATICS\n\n\nNoether's theorems (1918) can be literally related to the 'Lagrangian viewpoint' to action since they are formulated to Lagrangians. Nonetheless, the above, purely algebraic interpretation means the Hamiltonian one since kinematic and dynamics variables are opposed to each other as independent of each other and even separated in two dual and anti-isometric semigroups, after which all dynamic variables can be interpreted physically as the description 'backwards in time' in a way consistent with kinematic spacetime being 'forwards in time'. Of course, the absolute separability  of  the  two  semigroups  from  each  other  originates  from  the  light  and  local 'chauvinism' of physics until now totally neglecting and even not suspecting the dark and nonlocal phase of the universe: and thus, being quite conventional.\n\nApplying the same absolute separability of the one Lie semigroup from its dual counterpart of conservation after the latter is interpreted to be already that of quantum information rather than that  of  energy,  one  should  interpret  quantum  information  to  be  kinematic,  the  'Fourrier counterpart' of spacetime after it is identified to be Minkowski space in special relativity, i.e after the formal substitution of the variable physically interpretable as 'time' by that of 'frequency' or in terms of Bohr's viewpoint to quantum mechanics: by the replacement of the description in terms of the macroscopic 'apparatus' by its equivalent counterpart in terms of the investigated quantum entity.\n\nSpeaking  loosely,  quantum  information  conservation  means  the  dual  statement  of  the invariance  of  spacetime  distance  after  Lorentz  transformations  physically  interpretable  as  the direct  conversion  of  'time'  into  'space'  or  vice  versa  therefore  also  rejecting  the  absolute separability  of  space  and  time  featuring  classical  mechanics  and  physics,  in  which  Lorentz invariance is not valid. Then, one can look at general relativity also otherwise: as able to describe all  intermediate  states  in  which  Lorentz  invariance  appears  gradually  or  mathematically  said, smoothly by the corresponding limitation of the admissible infinite velocity of classical mechanics to the bound of the speed of light in a vacuum featuring special relativity as an initial postulate. This means that general relativity describes gravitation as the direct transformation between space and time under the condition of the invariance of spacetime distance as regulating how space and time may transform into each other however mapped only on the 'wall of Plato's cave': that of locality.\n\nThen,  quantum  information  conservation  regulates  the  correlating  transformation  of  the counterpart of what is out of Plato's 'cave' and represented as 'shadows' on the 'wall' at issue only visible by the 'chained and pinned down people'. That 'wall' is the screen of locality and experimental absolutely repeatable verifiability required by any classical natural science claiming to be objective and shared also by special and general relativity, but not by quantum mechanics, on which Einstein paid attention sarcastically, by the pejorative epithet 'spooky' or the sardonic metaphor of 'God playing dice'.\n\nOne can trace the origin of the absolute separability of the kinematic and dynamic semigroups from each other back: also still into the corresponding Gödelian or Gödel mathematics, in which kinematic is gapped from dynamics just as mathematics from physics or the material world by itself. On other words, its postulate is that the two semigroups do not origin from any single group and thus cannot be unified by sharing the same element so that to be the least in the one and the greatest  in  the  other  therefore  supplying  any  element  of  both  semigroups  with  its  inverse counterpart in the other semigroup and necessary for their joint structure to be a group.\n\nThen, the Planck constant of the minimal possible action reflects the identity of the unit of the multiplicative  group  also  available  as  the  same  unit  of  both  successor  functions  though  antiisometric to each other so that the unit of the one Peano arithmetic can be multiplied by the unit of its dual anti-isometric twin: so one obtains again the unit of the Planck constant possessing the physical dimension of action.\n\nOn the contrary, the product of those two units is zero in Gödel mathematics in definition, or speaking otherwise, the two semigroups are 'orthogonal' to each other so that the corresponding Gödelian mathematics is the single and special 'flat' case of Hilbert mathematics not generating any physical world by itself. Now, one can translate the Hamiltonian viewpoint inherent for the algebraic interpretation into the proper Lagrangian language of Noether's theorems, after which the opposition of locality and nonlocality, distinguishing particularly classical quantum mechanics from quantum information mechanics, will be also translated into a 'Lagrangian language' by means of Noether's theorems and quantum information conservation.\n\nIf one uses 'Lagrangian' and 'Hamiltonian' like 'English' or 'Bulgarian', i.e. as languages, the following formal mapping  can  describe the 'translation' at issue. All infinitesimal neighborhoods are considered as the class of equivalence of localities and opposed to a single globality as two independent variables after passing from 'Lagrangian' into 'Hamiltonian' (as 'languages'): respectively vice versa. Just the latter is what the 'expression' by Noether's theorem needs.\n\nThen, and also meaning the sketched above algebraic approach, one can reformulate the field of all rational numbers from its proper 'Hamiltonian' (language), after which the additive and multiplicative groups are nor subordinated, but independent of each other just like the two kinds of variables in 'native Hamiltonian', into an 'alien kind of Langangian' where the one group (either of both) is alleged to be 'local' and opposed to the other as being 'global'. In other words, any unit of the global Peano arithmetic ostensibly contains a local Peano arithmetic furthermore identifiable to be the same 'within' any global unit. Since any global unit including a local Peano arithmetic is isomorphic to a qubit, the Lagrangian translation of the field of all rational numbers turns out to be the qubit Hilbert space provable to be complete in virtue of the theorems of the absence of hidden variables in quantum mechanics 34 (though literally referring to its counterpart: the separable complex Hilbert space).\n\nThus, Hilbert arithmetic being the dual twin of the qubit Hilbert space can be interpreted to restore the initial 'original  in Hamiltonian  (language)'  to  its  'translation  in  Lagrangian (language)' by the qubit Hilbert space. So, one may say that the completeness of both qubit Hilbert space and Hilbert arithmetic relies on the same completeness: that of the field all rational numbers and resulting into two dual anti-isometric Peano arithmetic rather than into a single one as after\n\nthe  classical  approach  of  Peano  arithmetic  and  set  theory  inherently  suffering  from  the  Gödel dichotomy  (the  Gödel  dichotomy    is  a  'genetic  pathology'  of  the  classical  approach  to  the foundations of mathematics and shared, though in different 'symptomatologies', by the entire class of theories belonging to Gödel mathematics).\n\nFollowing the same metaphor, one might say that the mathematical origin of the physical world belongs to the 'genetic mutation' of Hilbert mathematics, in which the 'pathology' is not more a pathology,  but  a  new  and  very  useful  evolutionary  advantage  and  thus  normal  for  the  new 'species' 35 .  In  a  maybe  too  abstract  sense,  Hegel's  idea  of  dialectic  logic  means  the  same transformation  of  a  'pathology'  (the  violation  of  the  law  of  noncontradiction,  respectively, 'excluded middle') into a norm.\n\nThen, and speaking Lagrangian, one can distinguish a fussy (or accordingly, probabilistic) area of  'glocality',  belonging  whether  to  both  locality  and  globality  (as  which  nonlocality  can  be absolutely identified) or to the middle between them. What is quantum information out of that vague domain is the quantity of physical action obeying the Planck constant as to our universe. Quantum information conservation is able to describe uniformly both locality and globality, on the one hand, and glocality, on the other hand, and unlike energy conservation: which is valid only to the  physical  world  of  glocality,  but  being  meaningless  or  even  nonsense  as  to  the  proper mathematical world.\n\nOn the contrary, quantum information conservation is the only reason for the existence of the physical  world  by  virtue  of  the  nonzero  interaction  of  glocality  rather  than  'caused'  by  the mythical 'Big Bang' trying to explain the physical world as if 'by itself', but obeying energy conservation. Indeed, all in the physical world observes energy conservation, but not the physical world as a whole due to quantum information conservation 'causing' for the physical world to appear 'ex nihilo' omnipresently and omnitemporally.\n\nThe completeness of the separable complex Hilbert space being without any possible hidden variables,  then  transformed  equivalently  into  the  qubit  Hilbert  space,  is  the  mathematical counterpart of quantum information conservation, in turn and by itself (in the sense of Noether's first theorem) generating the permanently increasing amount of physical action and visible as the expanding universe. Its source is not the 'Big Bang' (in fact, an ostensibly scientific reading of the Creation in the Bible), but the completeness of the qubit Hilbert space in the final analysis, from which the expanding universe cannot but appear only by virtue of the mathematical necessity articulated in Noether's theorem 36 .\n\nVIII THE DARK PHASE OF THE UNIVERSE, IN WHICH PHYSICS AND MATHEMATICS ARE 'ENTANGLED'\n\nFollowing the approach of the last section, the dark and light phases of the universe are opposed as  locality  and  nonlocality  (globality 37 )  in  both  physical  and  mathematical  meaning,  therefore linking mathematics and physics in an inseparable whole, which can be called 'entangled' more or less metaphorically for scientific common sense, but in fact, quite literally from the viewpoint of the present paper.\n\nThe terms of the 'dark phase' versus the 'light phase' of the universe  suggests a smooth transition  between  the  infinitesimal  (in  mathematics)  opposition  of  locality  versus  nonlocality (both in physics) furthermore gapped by the speed of light in a vacuum so that the former is also literally the light phase being elucidated and visible unlike the prevailing and invisible nonlocal phase revealed only recently by its 'dark mass' and 'dark energy' 38 .\n\nThe term 'phase' is chosen also hinting at a 'twilight area' of entanglement between them furthermore interpretable also in a proper mathematical sense after Hilbert mathematics as any finite  nonzero  distance  between  finiteness  and  infinity  and  implying  a  probabilistic  transition between them illustratable for example by Einstein's sardonic metaphor of 'God playing dice', the allegorical sense of which is now illuminated so: infinity (for 'God') by means of probability (for 'playing dice') is transformed into finiteness (for each individual 'roll of the dice' what any single measurement of a quantum quantity is).\n\nCertainly, only that 'twilight area' is able to generate the fundamental physical quantity of action  (as  this  is  discussed  above)  following  an  only  mathematical  way,  meant  in  Noether's theorems  historically  for  the  first  time  and  rather  in  the  context  of  classical  mechanics  and expressed in 'Lagrangian' (language). Following them in a crucially generalized sense as in the present  sense,  one  is  to  to  unify  thoroughly  the  light  and  dark  phases  by  the  ostensibly  only intermediate twilight region between them: or following the same 'light metaphor', one might say that  'darkness'  is  'condensed  twilight',  and  accordingly,  'lightness'  is  'diluted  twilight' proclaiming  that  all  the  universe  is  in  the  twilight  entangled  phase  only  conventionally distinguishable into its dark phase versus its light phase.\n\nGödel mathematics accepts that barely human convention after the Cartesian gap featuring Modernity  so  (too)  seriously  that  it  even  dares  not  articulate  it,  thus  transforming  it  into  a 'subconscious' and therefore irresistible imperative which any theory claiming to be mathematical is ought to obey. One can compare with the fifth postulate of Euclid (by the by, called by himself 'postulate', i.e., 'convention'  rather than 'axiom',  i.e. 'obviousness'): being expressly articulated,  it  culminated  into  non-Euclidean  geometry,  Riemann's  'space  curvature',  and\n\nEinstein's general relativity in the final analysis. On the contrary, if Euclid had not articulated obeying  some  unconscious  and  unconditional  command  (as  in  fact  Gödel  mathematics  really does), all those did not take place maybe. Fortunately, that was not the case at least as to Euclid therefore aiding mathematics to overcome even the imperative of the Gödel dichotomy nowadays.\n\nThen, the universal twilight and entangled phase of the universe is able  therefore to unify physics and mathematics in an inseparable whole restricting energy conservation to be always valid only to the 'light physics' obeying the principle of absolute repeatability of any experiment. One can illustrate this by the case of the Fleischmann and Pons (1989) claims of cold fusion that caused a sensation and was subsequently denied due to the impossibility of reproducing 39 . On the contrary, one can admit it if the requirement of the obligatory reproducibility of any experimental result is not granted, as physics including 'dark phenomena' is forced to do, after which Einstein should 'rather be a cobbler, or even an employee in a gaming house', in his own words (Einstein 1926), of course only as a joke now.\n\nThe metaphor of the universe as a computer (in fact much more than a metaphor since the universe is really a quantum computer and thus the metaphor is reduced to the visualization of a quantum computer as a computer such as any of ours) can represent the light phase of the universe as its 'screen', and its dark phase as the 'hardware' hidden, invisible (and 'dark' in a sense)  in the  'box  of  the  computer'  and  processing  intangible  'data'  by  an  also  intangible  'algorithm' embedded in its 'software'. Indeed, the intangible data and algorithm processing are nonlocal being identically reproducible at any other spacetime point supplied by a relevant 'iron'. On the contrary, the computer as a material body is always local 40 .\n\nSo one can generalize the intangible nonlocal 'omnipresent and omnitemporal' 'ware' of the metaphorical 'computer' as mathematics, and its material and local 'ware' as physics. Of course, both  are  absolutely  separated  from  each  other  in  any  contemporary  real  computer,  by  the  by, divided thoroughly even it its mathematical model as a Turing machine: the tape and the four or five  possible  elementary  operation,  which  it  can  fulfill,  on  the  one  hand,  versus  the  variable algorithm and data, on the other hand.\n\nAnyway, one can at least imagine a future computer able to optimize relevantly its hardware for the problem that it resolves now, or vice versa: its software to fit maximally to its current hardware. This sounds utterly fantastic as to all contemporary computers, but not at all as to a quantum computer where the bound between its hardware and software is conventional, fussy and variable  at  the  discretion  of  even  the  user.  The  mutual  transformation  of  'hardware'  and 'software' of a quantum computer can well represent the complement of energy conservation (corresponding to the gap between hardware and software featuring any real computer) to quantum information conservation able to regulate the transformation at issue by natural laws.\n\nQuantum information necessary to describe both entanglement and quantum computer links simultaneously hardware and software since both are qubits: indeed, complementary to each other in classical quantum mechanics, but entangled in general as to the theory of quantum information. The eventually entangled software and hardware are mutually transformable at the same time and very well represent the way in which physics and mathematics are 'entangled' in the dark phase of the universe obeying only quantum information conservation, but not energy conservation.\n\nHilbert arithmetic (discussed in detail in a series of other papers: e.g. Penchev 2021 August 24 ) is not only a complete foundation of mathematics, bit also an instrument initially designed to describe mutual transformation of mathematics and physics since it exits in two dual copies: (1) as Hilbert arithmetic in a narrow sense consisting of two dual anti-isometric Peano arithmetics directly derivative from the field of all rational numbers, as this is inferred above; (2) the qubit Hilbert  space  interpretable  as  the  version  of  the  field  of  all  rational  numbers  rewritten  in 'Lagrangian' (language) and demonstrated above as well.\n\nThen,  one  has  two  alternative  ways  for  the  transition  between  its  dual  branches  and  thus between mathematics and physics. The one means any arithmetic unit as the corresponding empty qubit, i.e., the class of equivalence of all values of any certain qubits. The other translates between the  descriptions  of  the  same  field  of  all  rational  numbers  in  both  languages:  (1)  the  proper 'Hamiltonian' (language), from which the two dual Peano arithmetics of Hilbert arithmetic in a narrow sense are immediately inferable; (2) the newly introduced 'Lagrangian' (language), in which the 'expression' of the field of all rational numbers is the qubit Hilbert space.\n\nIf one equites secondarily the two approaches above as the same bridge between mathematics and physics, very interesting and instructive conclusions are possible, and first of all, the transition between: (1) a class of equivalence as a whole such as a set, and the same class as a collection of all its representatives such as all elements of the sets (furthermore able to be considered as  the homomorphism of the class of all first-order logics to propositional logic, meant by set theory, and propositional  logic  if  it  is  the  shared  single  'zero-order'  logic  both  being  the  same  Boolean algebra 41 ); (2) the two equivalent descriptions of the field of all rational numbers in 'Hamiltonian' and 'Lagrangian' (languages), and quantum measurement as the translation between them. An immediate  corollary,  perhaps  shocking  scientific  common  sense  enslaved  to  the  notion  of absolutely  separated  physics  and  mathematics,  is  the  option  for  physical  (in  fact,  quantum\n\nmechanical)  experiments  about  the  foundations  of  mathematics  just  as  the  aforementioned problem, which the real mathematics of our universe is, is not more a metaphor.\n\n\n## IX  QUANTUM  INFORMATION  CONSERVATION:  THE  ENERGY  OF  THE  'BIG BANG' ACCESSIBLE TO HUMANKIND?\n\n\nQuantum  information  conservation,  its  inference,  corollaries,  relations,  and  fundamental meaning for philosophy rather than only to physics and mathematics and their unity are mentioned above and discussed in detail in a series of other papers (e.g. Penchev 2020 October 5). The narrow subject in the same context in the present section is the reinterpretation of the colossal energy of the 'Big Bang' alleged ostensibly to generate all the universe and cause its expansion.\n\nThe main conclusion from quantum information conservation is: no Big Bang at all! There has not ever been the Big Bang: it is only a serial product of the rich human imagination tending to fill with it in the immense cognitive gaps, i.e., due to humankind's ignorance though seemingly being science. In other words, the 'Big Bang' only replaced 'God's Creation' in the Bible, not rather more justified than the latter.\n\nScience opposing religion to emancipate from it proclaimed and continuous to herald a new belief:  the  universal  and  absolute  materiality  of  the  world  cognizable  only  experimentally  or empirically by natural science obeying the repeatability and reproducibility by anyone anywhere and always as far as the conditions are described and copied exactly (ostensibly also being always possible).  Even  classical  quantum  mechanics  was  forced  to  generalize  the  latter  dogma  of scientificity,  since  the  result  of  any  single  quantum  measurement  is  fundamentally  random therefore substituting it by the reproducibility of the probability (density or not) distribution of a long enough series of the results of the same experiment.\n\nNonetheless, classical quantum mechanics does not touch the former dogma of scientificity and even reconfirmed it by Pauli's 'particle paradigm' of energy conservation culminating into the Standard model that managed to describe the 17 most fundamental elementary 'particles', orthodoxically and literally following the 'testament of the ancestors'. However, gravitation of Einstein's general relativity, entanglement and quantum information, and crucially, 'dark matter' and 'dark energy' were Kelvin's 'small clouds' (at that, three or more rather than the two original ones) remained on the horizon of the Standard model 'Brave New World'.\n\nSo, all anomalies not corresponding to that 'Brave New World' due to not obeying energy conservation  were  deported  in  a  special  'concentration  camp'  called  the  'Big  Bang'  in  the beginning of the universe, after which all the rest obeyed unequivocally energy conservation as all ideal residents of the Brave New World of the Standard model were obliged.  However, the 2022 Nobel Prize for entanglement and quantum information opened the gates of the terrible camp and the released prisoners moved all over the Brave New World everywhere disseminating the 'crime' of not  obeying  energy  conservation,  anyway  observing  the  weaker  quantum  information conservation.\n\nNot speaking eloquently and metaphorically, quantum information conservation implies the substitution of the mythical Big Bang by an omnipresent and omnitemporal medium of 'creation ex nihilo' due to the completeness of the qubit Hilbert space in the final analysis and known a long time  ago  as  the  theorems  of  the  absence  of  hidden  variables  in  quantum  mechanics  (Kochen, Specker 1967; Neumann 1932). The 'light' and local phase originates gradually and smoothly from  its  'dark'  phase  everywhere  and  always  therefore  constituting  a  medium  really.  So,  the creation 'ex nihilo' is already accessible to humankind in principle, following the natural laws of that: those natural laws only are to be studied and then implemented in relevant technical devices.\n\nSo, an analogue of Einstein's famous ' 𝐸𝐸 = 𝑚𝑚𝑐𝑐 2 ' seems to be forthcoming therefore hunting for a much greater counterpart of the 'A- &amp; H-bomb', to which the formula at issue is an emblem. It should be a corollary from the entanglement theory of quantum gravity just as the former formula follows more or less directly from special relativity. Since that theory at issue is not yet created though its contours can already be outlined, one might conjecture about its eventual future exact content:\n\nIt  refers  to  the  quantity  of  action  rather  than  to  energy.  That  action  is  due  to  the  nonlocal interaction of the universe, but restricted to its local domain i.e. within the light cone. It should not depend on time or mass (energy), since, figuratively speaking, it means the state 'before the Big Bang' 42 , though now distributed as a medium at any point of spacetime, and thus before dividing spacetime from energy-momentum, before dividing space from time, or particularly, energy from time. All those quantities distinguished separately are irrelevant to that previous state. It can be described only by the quantities of action and information whether quantum or not and the three most fundamental constants: the speed of light in a vacuum, the gravitational constant, and the Planck constant.\n\nIt seems to be quite inaccessible to humankind, at least at first glance, as far all experience is empirical  and  experimental  within  spacetime,  or  figuratively  speaking,  'after  the  Big  Bang' though now distributed in a continuous medium, all over the spacetime. There exists an initial paradox  about  the  utilization  of  that  action,  possibly  monstrous  according  to  its  magnitude, recollecting Baron Munchausen's efforts to pull himself out of the swamp by his hair. 'God' being transcendent might assist just as anybody else if he or she stays on the solid shore of the swamp might really pull Baron Munchausen out.\n\nIndeed, that action is the action of the 'Creation', a privilege reserved for 'God' rather for humankind at least until now. One might visualize that action of the creation, as a huge amount of energy as if infusing in the light cone each unit of time, in fact, to create it, i.e. to distinguish and separate by the bound of the speed of light in a vacuum from the real and nonlocal domain of\n\nMinkowski space, under condition that the infusing energy for each unit of time originates from that area of nonlocality.\n\nThose 'efforts of Baron Munchausen' are now embodied in the greater and greater energies of the  larger  and  larger  hadron  colliders  such  as  that  at  CERN  nowadays.  This  pathway  is meaningless,  a  'dead  end'  just  as  Baron  Munchausen's  pulls  himself  out  since  any  energy, however vast it be, is 'after the Big Bang' being just energy. The relevant approach to the creation seems to be rather that of information or rather quantum information, i.e., probabilistic and relied on  quantum  correlations  in  the  final  analysis  since  quantum  information  refers  to  action immediately not needing energy or time and able to mean inherently the state 'before the Big Bang' including as a 'medium'.\n\nSo, not too expensive experiments for entanglement and quantum information awarded by the 2022 Nobel Prize for physics (unlike more than the too expensive Large Hadron Collider and its eventual successors) are the only possible real approach of science to 'God's Creation' relied on the  transformation  of  'pure  information'  into  physical  action  observing  quantum  information conservation  rather  than  greater  and  greater  energies  of  colliders  thus  observing  energy conservation. The creation needs creativity: that of the new dimension of quantum information rather than the dull persistence of ever greater energies by means of ever more costly accelerators.\n\n\n## X  INSTEAD  OF  CONCLUSION:  A  NEW  LOOK  AT  INFORMATION,  QUANTUM INFORMATION, ACTION, ENERGY, TIME, AND TEMPERATURE\n\n\nThe idea about the physical world originating from Hilbert mathematics as a particular case in its  framework by virtue of mathematical laws and their necessity is the main viewpoint of the present  paper.  It  implies  particularly  a  different  understanding  of  basic  physical  quantities developing  further  the  approach  of  classical  quantum  mechanics  where  they  are  defined  by Hermitian operators. Involving them, only what is the change of a physical quantity is substituted in comparison with classical mechanics where it is a finite (experimentally) or also infinitesimal (theoretically)  quantity.  In  other  words,  the  change  of  a  single  value  in  classical  mechanics  is generalized to the change of a probability (density or not) distribution so that a Hermitiam operator obeying unitarity and energy conservation corresponds to the change of any quantity in classical quantum mechanics.\n\nThe physically dimensionful reference units determining which certain physical quantity is meant are the same in both cases, and they are absolutely gapped from the physically dimensionless measured  results  whether  finite  numbers  or  due  to  Hermitian  operators.  So,  physics  and mathematics continue to be reliably divided in classical quantum mechanics as well. However, the viewpoint  of  Hilbert  mathematics,  allowing  for  the  violation  of  energy  conservation  in  the framework of quantum information conservation, admits dimensionless mathematical quantities to generate dimensionful physical quantities however only by the mediation of action and thus accompanied  by  its  corresponding  conjugate  counterpart  complementing  it  to  the  quantity  of action.\n\nThen if one grants, for example conventionally, that the conjugate is constant, the change of dimensionless  quantum information may generate the  change of energy  or  any  other  physical quantity embodying the aforementioned 'creation ex nihilo' as far as quantum information being physically dimensionless can be interpreted to be 'nothing'. The change of quantum information at issue can be due to the change of the conjugate counterpart in turn, certainly under the condition of quantum energy conservation.\n\nThus, one can admit that energy can be directly transformed in time or vice versa as well as mutual  transformations  of  any  pair  of  conjugates.  Quantum  information  conservation,  though admits mutual transformation of physical quantities and thus violation of energy conservation, restricts  it  only  to  the  pair  of  conjugate  quantities,  though.  So,  one  can  allow  for  e.g.  time  to transform into energy, but its transformation in space distance seems to be problematic therefore needing  some  elucidation  since  Lorentz  invariance,  respectively  the  invariance  of  spacetime distance,  acknowledges  it.  Indeed,  quantum  information  conservation  can  be  considered  to  be conjugate to Lorentz invariance (or to that of spacetime distance) as above.\n\nSo,  one  can  distinguish  two  fundamentally  kinds  of  mutual  transformations  of  physical qualities, i.e. different physical dimensions: (1) only local and which general relativity have started to discuss a long time ago e.g. as the violation of energy conservation for the option for energy to be directly altered in momentum in its framework, and even still in special relativity for Lorentz invariance and the newly introduced there space-like time; (2) between locality and nonlocality (globality),  i.e.  between  conjugate  quantities 43 granted  to  be  complementary  to  each  other  in classical quantum mechanics now turning out to be mutually transformable after entanglement as long as they obey quantum information conservation.\n\nSo one can say, that the locally admissible mutual transformations of physical quantities obey 'action conservation' as an only local counterpart of quantum information conservation, though action  conservation  cannot  be  valid  nonlocally  (globally)  where  only  quantum  information conservation regulating the quantitative link of locality and nonlocality is only valid. Nonetheless, there exists no obstacle for the transformation of time into energy under quantum information conservation,  i.e.  nonlocally,  and  then  into  momentum,  i.e.  only  locally  and  under  action conservation being locally valid, though the two transformations are complementary to each other and thus cannot be accomplished simultaneously.\n\nThere is a special quantity in physics, more precisely in thermodynamics 44 : that is temperature, which can assist for a generalized thermodynamic approach to quantum mechanics after it has overcome the restriction of classical quantum mechanics after the theory quantum information investigating the transition between locality and nonlocality due to entanglement. Any quantum entity unlike that in classical mechanics is both 'particle' and 'wave', the duality of which can be now interpreted as a unification of locality (and mechanics for 'particle') and nonlocality (and Gibbs thermodynamics for 'wave'), which means that it can be granted to consists of its possible states  and  their  probability  distributions  whether  density  or  not.  So,  the  Gibbs  quantity  of temperature is relevant to it where the corresponding entropy is that of its states.\n\nEven more, quantum 'temperature' can be analogically introduced to any quantity rather than only to energy, after which the definition of physical quantity in classical quantum mechanics can be interpreted as any change of the corresponding 'temperature' featuring the quantity at issue. The peculiarity of that 'temperature' consists in the fact that it is a relation (which is a ratio in the simplest case) between an exact value of any quantity according to its local 'embodiment' and the corresponding probability (density) distribution of its conjugate counterpart. If the same approach is applied back to temperature usually defined by energy and entropy, this means the probability density  distribution  and  its  operator,  Hermitian  or  not:  both  inadmissible  in  classical  quantum mechanics due to implying the violation of energy conservation.\n\nSo, statistical thermodynamic, especially in its Einstein's version or interpretation 45 allowing for the mechanical consideration of the thermodynamic system as a whole rather than only that of its statistical units such as 'atoms' or 'molecules' after the Boltzmann approach, can be realized as a 'quantum mechanics' under the only additional conduction for the limit of the Planck constant action: as well as vice versa, Then, the transition between locality and nonlocality being inherent for quantum information, but representable differently in relativity (by the bound of the speed of light in a vacuum weather in a zero or nonzero gravitational field), can be once again realized by means of thermodynamics, explicitly in Einstein's  version  of  it  only  complementing  it  by  the Planck constant.\n\nThe  sketched  approach  to  physical  quantities  aims  to  demonstrate  their  inferability  of mathematics alone (as long as it is generalized to Hilbert mathematics as above) after granting the certain values of the three most fundamental physical constants (namely gravitational, Planck, and that of the light speed in a vacuum) featuring unambiguously our universe, only interpreting them mathematically, by the relations of locality and nonlocality. The speed of light in a vacuum is the exact  boundary  between  them;  the  Planck  constant  is  their  minimally  possible  overlapping implying  further  their  probabilistic  fussiness  and  mutual  diffusion;  the  gravitational  constant means the relation of the reference units of locality and nonlocality.\n\nAll the three constants can be related equally well to the dark and light phases of the universe and thus, to quantum information conservation relevant to both phases unlike energy conservation valid only to the later. The compose physical dimensions of those three fundamental constants, seeming strange and artificial as they are defined by the distinctions of all physical quantities in the light and local phase, can be easily explained by the converging of: (1) space and time (as to the light constant); (2) any two conjugate quantities into the quantity of action (as to the Planck constant);  (3)  the  former  two  inseparabilities  in  the  most  fundamental  fusion  of  all  physical quantities to be only mathematical in the final analysis (as to the gravitational constant allowing for the Planck units of time, space, and mass to be unambiguously determined by those three most fundamental physical constants).\n\nOne can add to them, the absolute zero temperature: the bound of '0°K' (or approximately -273.15  °C),  sometim es  identified  as  the  'third  principle  of  thermodynamics'.  It  can  be reinterpreted  in  the  context  marked  in  the  present  section  as  the  maximally  possible  entropy\n\n(conventionally and traditionally defined by temperature as a ratio of energy to entropy, but one can generalize it  to  any quantity  by  means  of  the  former  three  constants).  In  other  words,  the absolute  zero  means  the  minimally  possible  information  or  quantum  information 46 therefore directly  corresponding  to  the  Planck  constant  after  quantum  information  conservation,  in  fact historically initially inferred as an ad hoc convention for the solution of the blackbody radiation problem.\n\n",
         "The paper discusses Hilbert mathematics, a kind of Pythagorean mathematics, to which the physical world is a particular case. The parameter of the “distance between finiteness and infinity” is crucial. Any nonzero finite value of it features the particular case in the frameworks of Hilbert mathematics where the physical world appears “ex nihilo” by virtue of an only mathematical necessity or quantum information conservation physically. One does not need the mythical Big Bang which serves to concentrate all the violations of energy conservation in a “safe”, maximally remote point in the alleged “beginning of the universe”. On the contrary, an omnipresent and omnitemporal medium obeying quantum information conservation rather than energy conservation permanently generates action and thus the physical world. The utilization of that creation “ex nihilo” is accessible to humankind, at least theoretically, as long as one observes the physical laws, which admit it in their new generalization",
         ""
        ],
        [
         "19",
         "19",
         "## 1. Introduction\n\n\nChange towards sustainability (Fischer-Kowalski and Haberl, 2007; Leach et al., 2012; Schot and Kanger, 2018; Scoones et al., 2020) is now more urgent than ever to maintain a habitable and healthy environment for human and non-human life (Folke et al., 2021). Governance and politics are inherently implicated in any effort to foster such a change, irrespective of the focal system  (e.g.,  socio-technical,  social-ecological)  or  disciplinary  stance  (e.g.,  transitions, transformations, pathways) (Patterson et al., 2017). Existing governance configurations can create conditions ripe for change (Olsson et al., 2006; Kemp et al., 2007; Chaffin et al., 2016; Plummer et al., 2020), or may need to be transformed to enable those conditions to emerge (Meadowcroft,  2007;  Rijke  et  al.,  2013;  Schlüter  et  al.,  2021).  However,  despite  critical research  around  the  capacity  of  governance  to  foster  change  towards  sustainability,  the understanding of such a role remains underdeveloped in the literature (Berkes, 2007; MuñozErickson  et  al.,  2016;  Patterson  et  al.,  2017;  Kellner,  2021;  Orach  and  Schlüter,  2021; Muiderman et al., 2022; Rocha et al., 2022). In this article, we contribute to fill that general gap  with  a  focus  on  social-ecological  systems  (SES)  traps,  the  situation  where  social  and ecological feedbacks mutually reinforce each other to maintain or push the system toward an undesirable  state  (Holling  et  al.,  2002;  Carpenter  and  Brock,  2008).  Through  a  case  of  an entrapped SES, we explore how greater pluralism, which has been found to be instrumental for ensuring the preservation of ecological functions critical for sustainability (Gavin et al., 2015; Pascual and Howe, 2018), may help steer governance towards more desirable trajectories.\n\n\n## 1.1. Social-ecological systems traps and main research aims\n\n\nSES  traps  emerge  due  to  the  persistence  of  self-reinforcing  dynamics  among  social  and ecological systems maintained through strong feedback loops, producing negative outcomes at system level (Cumming, 2017). We are particularly interested in the interrelationship between the rigidity trap (Enqvist et al., 2016; Stedman, 2016) and the lock-in trap (Allison and Hobbs, 2004). Rigidity traps are characterized by the recurrent application of command-and-control approaches  (e.g.,  Holling  and  Meffe,  1996)  for  resource  and  ecosystem  management. Command-and-control  leads  to:  (1)  diminished  SES  resilience  to  shocks,  (2)  increased socioeconomic dependence on fewer resources, and (3) the erosion of a system's potential to adapt to change (Gunderson et al., 1995; Holling and Meffe, 1996; Cox, 2016). In a lock-in trap,  continued  degradation  of  the  resource  base  turns  into  a  syndrome  consisting  of  low capacity for change,  high connectedness among structural variables, and a near-total removal of natural capital (Allison and Hobbs, 2004). This degradation results in low resource yields, economic returns, social welfare, critical ecological functions and overall potential to escape undesirable situations (Allison and Hobbs, 2004). Rigidity traps, therefore, can be seen as more\n\ndesirable, having higher potential for change, though if pushed enough against certain social or biophysical thresholds, they can enter a self-reinforcing dynamic leading to a (less desirable) lock-in trap (based on Gunderson et al., 2017; Reyers et al., 2018; Dornelles et al., 2020). In the past decade, the explanatory focus of SES traps research has changed from deficiencies in human adaptive capacity to analyzing the influence of historical, institutional, discursive and/or power factors  regarding  the  emergence  and  persistence  of  traps  (e.g.,  Enqvist  et  al.,  2016; Laborde et al., 2016; Baker et al., 2018; Graziano et al., 2019).\n\nIn this paper, we demonstrate a novel approach that integrates those factors inherent in the above traps by blending different institutional analysis paradigms. We build on existing case study research carried out in the Doñana region, an estuary-delta SES (Guadalquivir estuary, SW Spain). The Doñana SES is characterized by a rigidity trap, including among other features: pervasive  command-and-control  approaches  to  water  resources  management  and  wetland conservation; high degradation of key SES functions but some degree of well-preserved natural capital; lack of demonstrated learning from management failures and environmental crises; and strong path dependence (Méndez et al. 2012, 2019, 2022). The Doñana case study research ('Doñana') aims to understand and explain the evolution of the governance configuration at the core of the rigidity trap, relying on an adaptive inference protocol (based on Holling and Allen 2002; see details in Méndez et al. 2019). Following previous research insights, our more specific aims here were:\n\n- -To understand and explain how a situation of limited pluralism emerged in governance and was perpetuated, leading to an undesirable rigidity trap.\n- -To explore how 'latent pluralism' could foster change towards sustainability 0F 1 .\n\nNext, we will explain our focus on limited and latent pluralism within the scope of values pluralism. The findings of our analyses will elucidate patterns in governance and its influencing discursive-institutional mechanisms and will provide insights into how latent pluralism may be nurtured to trigger change towards sustainability in SES.\n\n\n## 1.2. Pluralism of values and methodological pluralism\n\n\nDespite well-developed knowledge about the meso-level (e.g., aggregated rules) and microlevel (e.g., strategic interactions among actors) mechanisms orientating Doñana's current path towards a rigidity trap (see e.g., Méndez et al. 2019, 2022), we still lack understanding about the process of 'rigidification' in Doñana. Without understanding how this process occurred, we are ill-prepared to avoid lock-in traps or advise on change towards more sustainable states. In understanding this historical process, we are particularly interested in values pluralism. We also conceptualize our novel approach as constituting methodological pluralism.\n\nConcerning the plurality of values, the Doñana SES rigidity trap emerged historically, among other  factors,  from  recurrent  and  increasing  levels  of  top-down  command-and-control  as  a dominant approach to water resource use and wetland conservation. Here, we explore whether and  how  that  phenomenon  precluded  alternative  paradigms  and  values,  and  so  resulted  in 'limited  pluralism'  in  governance  settings.  Limited  pluralism  is  defined  as  a  top-down authoritarian tendency to control and curtail participation, without fully suppressing it (based on Owen and Bindman, 2017). Paradoxically, as we show below, Doñana is also characterized by 'latent pluralism'. Latent pluralism refers to the 'pluralism' of potential possibilities, of the different ways values and knowledge could influence decision-making if they were to develop in the future under the right conditions (based on Szalai 2005). Here, we explore whether and how the pluralism latent in Doñana could be expanded to disrupt the rigidity trap and foster change towards sustainability. We do this in the discussion by reflecting on current literature about how to orient policy to advance transformative change (Ghosh et al., 2021). As pluralism of both values and knowledge has been found to be instrumental for promoting sustainability in SES (Lang et al., 2012; Gavin et al., 2015; Pascual and Howe, 2018; Avriel-Avni and Dick, 2019; Wyborn et al., 2019), we employ this concept as our main focus throughout the article. Pluralism is also capable of producing more  ambitious visions of the future in which SES tensions are seen as opportunities for change, rather than merely as technical problems to be solved  through  managerial  governance  (Gillard  et  al.,  2016).  For  example,  the  diverse frameworks employed by actors to make sense of change processes can be used to figure out compromises and propose workable solutions (Feola, 2015).\n\nRegarding methodological pluralism, i.e., plurality of methods or frameworks, we delve into some concepts from previous research and reflect on them at an ontological level, rather than adding new analytic or framework layers like in previous iterations. In this way, we seek to operate  at  a  higher  level  of  analysis  and  further  refine  understanding  and  explanations  of discursive-institutional  dynamics  in  limiting  pluralism  and  rigidifying  governance  in  the Doñana SES.\n\n\n## 1.3. An example within the case study: a hydraulic megaproject\n\n\nTo undertake our illustrative exercise, we use a hydraulic megaproject launched in 2000 to improve  the  maritime  access  to  Seville's  inland  port  (IMAP  megaproject)  through  the Guadalquivir estuary. The shallow dredging of the estuary to allow for light-ship navigation and  maritime  trading  remained  a  relatively  uncontested  planning  measure  until  2000.  The IMAP megaproject proposed deeper dredging, regardless of the negative impacts identified on estuary  and  wetland  ecosystems  and  local  socioeconomic  sectors.  This  brought  about  civil contestation  and  discord  among  the  main  actors  involved  (Vargas  and  Paneque,  2015). Although some measures were implemented, the megaproject faced constant challenges from the outset and was finally cancelled by the Spanish Supreme Court in 2019. Important lessons can be drawn from this failed megaproject. The IMAP megaproject posed a high risk of creating negative effects difficult to reverse at system level, thus increasing the likelihood of a lock-in trap. Despite deep-dredging being canceled, the megaproject uncovered the inherent failure of\n\nthe main governance actors involved to coordinate to achieve more sustainable outcomes in the region.\n\nThe  article  is  organized  as  follows.  Section  2  describes  the  methodological  pluralism underlying the development of our novel approach. The approach itself is presented in section 3. Section 4 describes how we operationalized our approach to analyze the IMAP megaproject. Section 5 combines results and discussion, and section 6 offers our concluding remarks.\n\n\n## 2. The pluralist harmonizing movement in institutional analysis\n\n\nInstitutional  analysis  is  a  key  tool  for  public  policy  process  research,  encompassing  a  rich diversity of theoretical frameworks and logics. Policy research analyzes complex interactions involving public policy with a focus on change and stasis over time involving individual and collective  action  (Schlager  and  Weible,  2013).  Two  decades  ago,  Campbell  and  Pedersen (2001)  called  for  a  'second  movement'  towards  'a  more  constructive  dialogue  among [institutional  analysis]  paradigms'.  By  paradigms,  they  referred  to  the  application  of  neoinstitutionalist  strands  of  political  science  to  the  study  of  'institutions'  and  'discourses'  in policy  studies.  Although  based  on  different  theories  and  logics,  blending  these  strands  can provide a more robust and exhaustive approach to tackling pressing problems (sensu Howlett et al., 2016). In this article we respond to Campbell and Pedersen's call by applying a blend of neo-institutionalist strands to enhance understanding and explanatory power of SES studies (see similar efforts in e.g., Boettcher and Kim, 2022; Haller, 2019; Lubell, 2015; O'Riordan and Jordan, 1999; Ostrom, 2010; Vatn and Vedeld, 2012; Young et al., 2008). For Hotimsky et  al.  (2006),  different  neo-institutionalist  strands  provide  a  balance  in  SES  research  and governance that would not otherwise be achieved. Therefore, a consolidation exercise is crucial to  increase  our  comprehension  of  the  diverse  dimensions  of  SES  interactions.  Here  we contribute to bridging this gap by combining different neo-institutionalist strands through a replicable  analytical  approach.  By  working  at  an  ontological  level,  we  critically  analyze institutions and discourses and their relationships with human behavior, decisions and actions in the SES context (sensu Hotimsky et al., 2006). Our approach primarily builds on Schmidt's proposal for methodological pluralism (2008; 2010) by combining neo-institutional approaches for both theoretical- and solution-oriented purposes.\n\n\n## 3. A neo-institutionalist approach\n\n\nOur approach uses concepts from three neo-institutionalist strands: rational-choice, historical, and discursive. We summarize and compare differences among their theories and logics to identify potential areas of overlap or interaction below.\n\n\n## 3.1. Comparing three neo-institutionalist approaches\n\n\nRational  choice  institutionalism  (RI)  assumes  that  actors  are  fully  rational,  self-interested agents  seeking  to  maximize  their  own  utility.  These  agents  pursue  their  self-interest  by expressing preferences and goals in the institutional context, which is conceived as a structure\n\ncomposed of external incentives and disincentives (Schmidt, 2008; Hall and Taylor, 1996; Shepsle,  1989).  Having  evolved  from  neoclassical  economics,  RI  considers  institutions  as entities  that  provide  rationally  motivated  actors  with  a  degree  of  certainty  about  others' behavior in transactions (e.g., negotiations, information acquisition, enforcement rules) or the provision of public goods (e.g., knowledge, flood control, transport networks) (North, 1990; Ostrom,  1990).  Actors  employ  information  rationally  and  their  behavior  is  not  driven  by impersonal historical forces, but by strategic calculations or internalized rules (Shepsle, 1989).\n\nHistorical institutionalism (HI) relies heavily on three ideas (termed 'logics', as articulated by Schmidt  2008):  path  dependence,  contingency  (the  seeming  unpredictability  of  historical events and sequences that resulted in current institutional structures), and a 'logic of historical trajectory'.  For  HI,  institutions  are  sets  of  regularized  practices  with  rules  or  norms  that structure action and outcomes, thus viewing power asymmetries as historical dynamics (Hall and Thelen, 2006). Variations in political, governance or institutional settings shape actors' capacities for action, policy making, and institution building (Thelen, 1999). Despite actors operating  within  a  given  social,  psychological  or  cultural  structures  that  conditions  their behavior, they are also seen as having the ability to interpret situations and make choices within a given structure (Hall and Taylor, 1996). Institutions are seen as shaping actors' behavior, rather than as a rational product of actors' decisions (as in RI above) (Bell, 2002). Since HI focuses on path dependence, rationality is present 'only insofar as institutions are the intended consequences  of  actors'  choices',  so  using  HI  as  a  theory  lends  itself  to  mechanistic explanations or historical determinism (versus RI's economic determinism) (Schmidt, 2008).\n\nBoth  RI  and  HI  have  difficulties  explaining  the  causes  of  crises,  institutional  change,  and human agency, and both require adding elements from other analytic approaches to produce successful explanations (Schmidt, 2008). Institutions act as constraints, whether as incentives structuring action (RI) or paths shaping action (HI), thus both of these approaches conform strongly to a rule-following logic (Schmidt, 2008). This begs the question: how do we explain institutional  change  if  everyone  follows  rules?  The  discursive  strand  helps  explain  how institutional change occurs by focusing on the relationships between institutions (rules) and discourses (ideas) (Schmidt, 2008).\n\nDiscursive institutionalism (DI) synthesizes several theoretical concepts concerned with the communicative and coordinative processes of discourse argumentation (Schmidt, 2008). DI gives explanatory power to discourse, defined here as encompassing 'not only the substantive content of ideas but also the interactive processes by which ideas are conveyed' (Schmidt, 2008). Discourses are used by actors when generating, deliberating, and/or legitimizing ideas as part of political or policy processes, all of which are influenced by their institutional context (i.e., rules, legislation, norms) (Schmidt, 2008). However, for DI, institutions are 'carriers of ideas' (Williams, 2019). This interpretation is what makes for a more dynamic approach to institutional  change/stasis,  because  here  the  actors'  interests  are  seen  as  subjective  (versus objective as in RI), but they are also seen as real and observable empirical entities (Schmidt, 2008). The focus on the interactive communication processes involved in discourse is what differentiates DI from the other approaches. DI thus goes beyond the other strands' use of ideas,\n\nbelieving that ideas can largely explain institutional dynamics (Schmidt, 2010). The discoursefocused approach of DI (vs the rational actor focus of RI and HI) operates on the assumption that interactions largely determine political, policy and institutional change/stasis dynamics. Inspired by this approach, we conducted the illustrative exercise of this study guided by the concept of 'discourse inertia' (Williams, 2019), due to its plasticity to combine insights and logics from different neo-institutionalist approaches.\n\n\n## 3.2. Discourse inertia\n\n\nDiscourse inertia is defined as 'the persistent promotion and dominance of a perception of reality' through the 'continuous reproduction of certain storylines and elements of a discourse' (Williams 2019). According to Williams (2019), dominant or hegemonic discourses are often institutionalized, and are often fraught with inertia due to path-dependent tendencies (as in HI) and powerful entrenched interests (as in RI). However, despite those tendencies, dominant discourses are also dynamic, for they must constantly be conveyed, reinforced, and defended. This can lead to certain narratives to be taken for granted, self-reinforced, and thus prone to continuity  as  they  become  entrenched  within  institutions,  policy  and  political  practices. Discourse inertia can help us to understand the persistence of certain institutions or policy pathways,  despite  evidence  of  their  ineffectiveness  or  the  existence  of  more  suitable alternatives.  Finally,  discourse  inertia  may  aid  reflection  on  reasons  for  the  persistence  of dominant discourses and resistance to change. This has been visualized by the term 'discursiveinstitutional spiral', which illustrates how actors' ideas, discourses and institutions interact and co-evolve (Fig. 1, Williams, 2019).\n\nFig.  1.  Discursive-institutional  spiral  (modified  from  den  Besten  et  al.,  2014;  Williams,  2019).  Spiral  art: https://www.csaimages.com/ (Not for commercial use).\n\n<!-- image -->\n\n\n## 4. Methods\n\n\nTo  operationalize  our  illustrative  exercise,  we  performed  a  thematic  analysis  and  then reanalyzed  Doñana's  historical  pattern,  as  we  describe  below  (see  Fig.  2  for  a  detailed workflow).\n\n\n## 4.1. Task 1: thematic analysis\n\n\nIn task 1 we performed a thematic analysis of the IMAP megaproject to analyze commandand-control  traits  in  Doñana  in  the  present-day.  We  collected  data  from  online  newspaper articles about the IMAP megaproject and triangulated these data with existing studies of the IMAP megaproject that used a variety of sources, such as planning documents and research articles (Méndez et al. 2022). The objective was to match evidence from the newspaper articles against a series of categories from command-and-control theory (synthesized from Cox, 2016), through  deductive  thematic  analysis  (Nowell  et  al.  2017).  We  used  these  categories  as 'sensitizing' concepts (Kauffman and Wiering, 2021) to filter content and identify the most relevant  information  reflecting  the  command-and-control  categories.  We  also  developed  a historical profile of the IMAP megaproject (2000-2019) tracing key events using secondary sources.\n\n\n## 4.2. Task 2: reanalysis of Doñana's historical pattern\n\n\nTask 2 was carried out through two sub-tasks. First, we produced a synthesis of results from previous research iterations of the Doñana case (henceforward ' Doñana's historical pattern', Task 2.1). This task used resilience concepts such as traps theory to contextualize the IMAP megaproject  in  its  broader  SES  context.  Then  we  reanalyzed Doñana's  historical  pattern, reflecting on results obtained through the thematic analysis of the IMAP megaproject (task 1). Relying on the concept of discourse inertia and informed by the discursive-institutional spiral , our aims were to trace the historical persistence of command-and-control governance and to reflect on discursive-institutional dynamics that played out. We compared those dynamics to theoretical insights and logics from our neo-institutionalist approach (Section 3). Combining tasks 1 and 2 allowed us to assess contemporary rigidity in Doñana focusing on the IMAP megaproject and the historical processes of rigid entrapment (Fig. 2).\n\nFig. 2. Workflow of operationalization methods.\n\n<!-- image -->\n\n\n## 5. Results and discussion\n\n\nIn  this  section,  we  briefly  describe  the  IMAP  megaproject  historical  profile  (task  1)  and contextualize the megaproject within Doñana's historical patterns (task 2.1; see full thematic analysis results in Appendix 1; see full synthesis pattern in Appendix 2). We show how Doñana\n\nis characterized by a wealth of alternative viewpoints, which we characterize here as 'latent pluralism' (section 5.2.1).  Then,  we  expound upon how and why novel ideas quickly lose momentum in Doñana, resulting in limited pluralism and missed opportunities to foster change. Finally, we offer our reanalysis of Doñana's historical pattern (task 2.2, sections 5.2.2-5.2.4), concluding with a discussion of how pluralism could be expanded and mainstreamed in Doñana (section 5.3).\n\n\n## 5.1. Contextualizing the IMAP megaproject\n\n\nAt present, the inland Port of Seville and the Guadalquivir estuary's navigable canal (90 km) are both managed by the Seville Port Authority (see geographical location in Fig. 3).\n\nFig. 3. Geographical location of the Doñana's SES and Guadalquivir estuary. Modified from Méndez et al. (2019), under a Creative Commons CC BY-NC 4.0 International License.\n\n<!-- image -->\n\nThe IMAP megaproject was announced in 2000 as part of the Port Authority's 2020 Strategic Plan (see historical profile in Fig. 4).\n\nFig. 4. Historical profile of the IMAP megaproject (based on our thematic analysis and key secondary sources, e.g., Donadei, 2020; Sancho-Royo and Del Moral, 2015; Vargas, 2014; Vargas and Paneque, 2015).\n\nThe megaproject rested on the assumption that making the port more accessible and improving its connection to the Trans-European Transport Network, thus increasing freight traffic from (deep-draft)  high-tonnage  ships,  would  be  key  for  local  and  provincial  socioeconomic development (e.g., generation of thousands of jobs, increasing cruise tourism) (Vargas and Paneque, 2015, Donadei, 2020). The megaproject's main measures included (1) deep dredging of the estuary's navigable canal to increase its depth (from 6.5 to 8 m on average) and width (from 60 to 90 m on average), (2) the construction of a higher-capacity lock (named Sea Gate), (3) deep dredging maintenance for 20 years, and (4) auxiliary infrastructure. Since 1985, the Port Authority has performed maintenance shallow dredging for light-ship traffic on a regular basis (García and Marín, 2006).\n\nOur thematic analysis of the IMAP megaproject (Appendix 1) shows ubiquitous commandand-control traits in Doñana's governance configuration for water resources use and wetland conservation. These traits were inferred across the six categories synthesized from Cox (2016), although  with  different  degrees  of  actualization  in  reality.  According  to  previous  research, Doñana's  rigid  governance  configuration  evolved  historically  through  a  path-dependent dynamic and the persistence of a command-and-control governance approach. At the system level, this path-dependent historical pattern led to the emergence of a rigidity trap, which is the current state in the Doñana SES today (see description and definitions in Fig. 5). In this context, the IMAP megaproject can be characterized as a disturbance that might have been the trigger that pushed the region toward a lock-in trap (Fig. 5). Recent scholarship shows that short-lived anthropogenic disturbances might induce collapse into irreversible SES functions or states, suppressing  the  potential  of  change  toward  more  favorable  situations  (Haider  et  al.,  2018; Phelan et al., 2013; Standish et al., 2014).\n\nFig. 5. Doñana's current stability landscape.\n\n<!-- image -->\n\n\n## 5.2. Doñana's historical pattern reanalyzed\n\n\n\n## 5.2.1. Alternative views: latent pluralism in Doñana\n\n\nOur thematic analysis shows the presence of diverse paradigms and views  proposed by various actors as alternatives to deep dredging and associated development in the estuary and broader Doñana SES. One example of an alternative to the command-and-control paradigm that gave rise  to  the  IMAP  megaproject  is  the  protection-for-conservation  model,  to  which  direct  or indirect reference was made in most articles we reviewed. The ecological restoration of the estuary was also put forward as an option in the context of the Spanish Supreme Court's ruling (Fig. 4), suggested as a countermeasure after the cancelation of deep dredging. References were also  made  to  sustainable  development,  which  influenced  narratives  in  the  region  since  the 1990s. Some alternative views were backward-looking, promoting a return to an idealized form of 'equilibrium that broke in the 20th century.' This refers to enhanced navigability through meander cuts, the modification of the marshlands and floodplains for agricultural development and the pollution of the estuary (see e.g., ED\\_050 in Appendix 1). Clean renewable energy was also put forward as an alternative to gas storage in the region; for example, by using the Estuary Scientific  Commission  to  generate  knowledge 'about  cumulative  impacts  to  dispel  doubts about the complex risks' entailed by these type of projects (EPRESS\\_041). As these examples illustrate, 'working with nature' is another alternative paradigm that came up repeatedly in our analysis.\n\nVast  experience  and  know-how  has  been  accumulated  over  recent  decades  in  Doñana, particularly  through  numerous  participatory  and  transdisciplinary  initiatives  that  have  been carried out, resulting in a wealth of latent pluralism (e.g., the sustainable development plans put  forward  in  the  1990s;  Castells  et  al.,  1992).  Efforts  to  promote  transdisciplinarity  and enhance stakeholder engagement continued throughout the late 1990s and the 2000s, such as the hydro-ecological restoration projects launched as a response to Los Frailes' mining accident (Doñana  2005  and  Guadiamar  Green  Corridor)  (see  e.g.,  García  and  Marín,  2006).  These projects were relatively successful at coupling research with policy through action research (Escalera, 2003; Méndez et al., 2012) and collaborative adaptive management (Santamaría et al., 2006). Research underpinning these projects focused on a wide range of topics, such as: the study of cultural and ecosystem services (García-Llorente et al., 2011), the conservationvs-development paradigm in and around the protected areas (Martín-López et al. 2011), the institutional arrangements in place (Gómez-Baggethun  and  Kelemen  2008), and the contribution of traditional ecological knowledge to community resilience (Gómez-Baggethun et  al.  2012).  In  parallel  to  such  research  efforts,  the  Doñana  Long-term  Socio-Ecological research  (LTSER)  platform  was  established  in  2007  as  part  of  efforts  to  formalize  lasting infrastructures for integrated ecosystem research at the European level (Díaz-Delgado 2016). These efforts have evolved during the last decade and the insights, know-how and experience gained  are  currently  informing  a  major  European  effort  to  build  integrated,  continental infrastructure for social-ecological research (this project is known as 'eLTER RI'). Doñana's participation  in  this  project  constitutes  evidence  of  latent  pluralism  Doñana,  as  it  is  being\n\nshowcased  as  one  among  several  flagship  cases  where  components  of  long-term  socialecological,  transdisciplinary  research  are  present-albeit  still  in  need  of  an  overarching strategy to ensure its relevance and further promotion into policy and practice (Holzer et al., 2019). How and why has this latent pluralism been limited in Doñana and which are the risks entailed by that limitation? What can we learn from the IMAP megaproject?\n\n\n## 5.2.2. Was deep dredging irrational behavior? Yes and no - and 'history matters'\n\n\nFrom  the  perspective  of  rational  choice  institutionalism,  which  considers  institutions  as incentive/disincentive structures, the Port Authority and coalition of supportive actors, enabled by  the  Water  Authority,  behaved  rationally  between  2000-2010.  They  considered  expert knowledge supporting the IMAP project's purported socioeconomic benefits as relevant and valid,  despite  the  fact  that  this  knowledge  was  discredited  or  considered  incomplete  by opposing  actors.  The  Port  Authority  and  supportive  actors  acted  strategically  and  in  selfinterest, disregarding  the  potential  reduction  of  overall  socioeconomic  welfare  or  the suppression of SES functions. According to this perspective, the key problem between 20002010 was of formal regulatory nature: the 2003 megaproject's EIA was incomplete and was amended  ex  post  by  a  CSIC  study  (Fig.  4).  This  study  showed  the  estuary  to  be  in  poor environmental  condition  due  to  high  organic  matter  content  and  turbidity,  biochemical pollution  and  high  biogeochemical  alteration,  and  as  a  non-stratified  water  body  limiting biodiversity, with reduced habitat and potential for fishing activities (CSIC, 2010). Two key conclusions from the study were that: 1) cumulative impacts from the IMAP megaproject may have worsened the situation, both environmentally and socioeconomically, and 2) resource optimization for all  sectors  was  not  possible,  especially  in  dry  years  in  the  current  climate change scenario (CSIC, 2010). If this was the case, then why did the Port Authority persist seemingly irrationally - to implement deep dredging after the CSIC study? To explain this illogical behavior, we draw on insights gained through the Doñana's historical pattern.\n\nThe development of irrigation and rice agriculture in Doñana (past-1980) appears unexpected, if assessed as rational behavior. At the outset of the development process (1920s-1940s), local actors seemed to behave irrationally; rice and irrigation agriculture was an unsuitable economic choice to maximize earnings in a harsh saline environment-at least not without heavy public investment to dam and impolder the area (Appendix 2). Three factors can make this choice seem more rational:\n\nA) The discourse, which we refer to as 'political-level hydraulic mission discourse' in section 5.2.4,  embedded in institutions (e.g., legislation, regulations, incentives), in which actors speak about mobilizing top-down resources and that will yield ever higher economic profit to local actors.\n\nB) Local organizational (e.g., companies) and individual actors operating on the ground were responsive to the discursive and institutional signals and, backed by public funding and after several agronomic  experimental  failures, successfully implemented  irrigation  and  rice agriculture against unfavorable environmental conditions.\n\nC) Coalition of local and international actors engaged in a protection-for-conservation race for preserving the last remnants of terrestrial, coastal and wetland ecosystems, acting in a reactive way to the proposed agricultural development.\n\nThe actions of actors from factors B and C clashed and inadvertently contributed to rigidifying governance, leading the Doñana SES towards its current rigidity trap. The whole process was path-dependent because there were at least two alternative paths as described above (for detail see Méndez et al., 2019). At the time of creation of Doñana National Park in 1969, these two alternative paths both had a significant chance of happening. The sustainability trajectory was (and still is) linked to a better and coordinated integration with nature, and the lock-in trap was (and  still  is)  linked  to  failure  to  preserve  key  ecological  functions  due  to  hydraulic  and agricultural  modifications  (see  Allison  and  Hobbs,  2004).  The  takeaway  from  Doñana's historical  pattern  is  that  these  alternatives  are  both  still  possible  today,  but  that  large interventions such as the IMAP megaproject pose a high risk of pushing Doñana into a lock-in trap, thus hindering change processes towards sustainability (Fig. 5).\n\n\n## 5.2.3. The rigidifying power of clashing discourses\n\n\nAccording to our thematic analysis, the IMAP megaproject was dominated by (1) an economic development  discourse  underpinned  by  modernization  and  neoliberal  ideas,  and  (2)  a protection-for-conservation discourse. Over the course of the megaproject, the Port Authority advocated the economic development discourse, legitimized through a mandate by State Ports (the umbrella state body for all Spanish port authorities) to develop infrastructures and promote maritime trading activities. Based on contested and discredited economic assessments, the Port Authority  overstated  the  IMAP  megaproject's  potential  for  high  returns  on  investment (Sancho-Royo and Del Moral, 2014; Sancho-Royo and Del Moral, 2015; Vargas and Paneque, 2015) and ultimately built the Sea Gate using public funds (Fig. 4).\n\nPrior to the 2010 CSIC study and a decisive action of the Spanish Supreme Court to cancel the project,  the  IMAP  megaproject  had  been  hampered  by  the  protection-for-conservation discourse, used by the conservation nonprofit organization WWF and the quasi-governmental Doñana  Participation  Council.  At  critical  points,  both  organizations  were  supported  by regional,  national,  and  international  organizations  or  governments  (Fig.  4).  The  Doñana Participation Council played a key role as moderator of environmental governance conflicts in the  region,  amending  the  defective  EIA,  and  paving  the  way  for  the  Estuary  Scientific Commission  and  the  CSIC  study  (Fig.  4).  WWF  was  (and  is)  a  leading  conservation organization in Doñana; importantly, they made formal appeals to national and international legislative bodies over the incorporation of deep dredging as a measure in water planning (Fig. 4; see also 'lock-in factors in Appendix 1).\n\nThe  economic  development  and  the  protection-for-conservation discourses were  both embedded in the values, beliefs and cultural attributes of different groups of local actors. The struggle between supporters and opponents of the IMAP megaproject was dynamic in terms of legal interactions and power/knowledge conflicts. The situation resulted in a tug-of-war with\n\nno clear winner, which, in turn, meant a step back to a stable but fragile situation among actors and a deadlock regarding the future of the estuary. We might conclude that both supportive and opposing actors fit the rational model -- they all behaved rationally and strategically to achieve their own  objectives  while  responding  to  their  respective  economic  development  and protection-for-conservation  rule  settings.  However,  this  clashing  of  discourses  and  rational behavior  still  does  not  fully  explain  the  persistence  of  the  plan  for  deep  dredging,  nor  the inability of actors to break the deadlock after the CSIC study was released. Why didn't a new counter-narrative emerge from the supportive actors? Why did it take legal power to cancel deep dredging? We argue that factors A (the dominant discourse in Doñana), B (the successful implementation  of  irrigation  agriculture  in  unfavorable  conditions)  and  C  (the  coalition advocating  for conservation and  opposing  agricultural development)  complement  this explanation  underlying  the  deadlock  situation.  Beneath  all  of  this  history,  it  was  the discourses-the ideas and how they played out in institutions, plans, and on the ground-that shaped  Doñana's  discursive-institutional  spiral,  to  which  we  now  turn  to  explain  the rigidification process of governance in Doñana  (Fig. 6).\n\n\n## 5.2.4. Doñana's discursive-institutional spiral\n\n\nThe Guadalquivir estuary deadlock situation is based on the hydraulic mission discourse in Doñana.  Prevalent  worldwide,  the  hydraulic  mission  discourse  is  based  on  narratives  and actions of 'hydrocracies' (Williams, 2019), elite groups of policy and decision makers who consider water resource development a state duty to be implemented through technical and institutional efficiency-despite evidence of negative effects on the environment and society (see e.g., Molle et al., 2009; Verhoeven, 2019).\n\nIn  Spain  the  hydraulic  mission  discourse  (factor  A  above)  is  deeply  embedded  in  water planning and has steered geographical transformation since before the 18th century (Fig. 6). It mobilizes large public investments in hydraulic infrastructure and irrigation agriculture, based on a narrative of modernization and returns on investments to augment national wealth. With little  concern  for  hydrological  and  ecological  conditions,  the  discourse  operates  using  the paradigm of nature as an object to be dominated and shaped by humans (Saurí and Del Moral, 2001; Swyngedouw, 2015; Vargas and Paneque, 2015).\n\nThe  hydraulic  mission  discourse  was  promoted  by  key  figures  in  'regenerationism',  an intellectual movement seeking to rationalize Spain's decline as a global political and economic power  at  the  end  of  the  19th  century  (Font  and  Subirats,  2010;  Swyngedouw  1999).  The hydraulic  mission  discourse  gathered  momentum  at  the  beginning  of  the  20th  century  and became more deeply embedded at multiple levels (institutional, planning, local) during the 1930s-1940s (Fig. 6). In the Guadalquivir estuary and Doñana region, the hydraulic mission discourse started in the 1920s with irrigation and rice agriculture experiments, incentivized by policy and legislation. These rules and laws persisted through the 1930s-1970s, giving rise to a  massive  hydraulic  infrastructure,  funded  by  the  state  through  the  Guadalquivir  River Authority. This took place in synergy with a legislative and planning framework that promoted the colonization of large 'unproductive' areas (Fig. 6).\n\nFig. 6. Application of the discursive-institutional spiral to the Doñana case (based on empirical evidence from Appendix 2).\n\n<!-- image -->\n\nThe discourse  inertia of  the  hydraulic  mission  discourse  can  be  inferred  from  Doñana's historical  pattern.  Such  discourse  was  codified  in  rules  and  embedded  in  actors'  thinking, constraining the possibilities of what could be viewed as rational actions. This in turn limited the possibilities for change. The economic development discourse is impervious to alternative pathways based in different paradigms because it is deeply imbued with the ideas, narratives and  perception  of  reality  imposed  by  the  hydraulic  mission  discourse  (Fig.  6).  The  IMAP megaproject would not likely have been undertaken without the hydraulic mission discourse to persistently  structure  the  cognition,  perception  of  reality  and,  hence,  the  rationality  of  the supportive actors. This project also required the River Authority's passive attitude, neglect of governance duties and lack of compliance with environmental policy guidelines and planning regulations.\n\nThrough this alignment of events and factors, the hydraulic mission discourse continued to influence Doñana's recent history, reinforcing path dependence. This is evidenced in particular by:  (1)  a  high  pay-off  for  further  investment  in  the  deep  dredging  measure,  due  to  public funding and construction of the Sea Gate; (2) expectation of higher efficiency and returns from the enhancement and increased use of the estuary's navigable canal (moving from shallow dredging and light ship traffic to deep dredging and heavy traffic); (3) increasing prevalence of the  navigable  canal  operation,  i.e.,  adaptive  expectations  (based  on  North,  1990).  The assumptions made by the hydraulic mission discourse can thus be used predict the economic policy options and outcomes available in Doñana for certain powerful actors; options that did not (and do not) seem to be the most 'rational choices' at system level. These options could have been realized if it wasn't for the constant opposition from groups operating under the protection-for-conservation discourse.\n\nNot surprisingly,  the  protection-for-conservation  discourse  in  Doñana  is  subordinate  to  the command-and-control  approach  and  the  hydraulic  paradigm  (Fig.  6).  The  protection-forconservation  institutions  and  organizational  structures  were  co-opted  by  engineering  corps through  top-down  command-and-control,  although  not  without  opposition  from  some  proconservation engineers (see Appendix 2). Meanwhile, the 'hydrocracy' continued throughout this  period,  promoting  intensive  modifications  for  irrigation  and  rice  agriculture,  heavily transforming  the  natural  physical  features  that  regulated  the  hydrological  regime  of  the protected wetlands (Fig. 6).\n\nAgriculture and protected-area developments, driven by two opposing discourses, reduced the original estuary's floodplain marshland-wetland by ~80%. This created a hard geographical and operational boundary limiting the remaining semi-pristine nature of the inland Doñana SES (Fig. 3). The IMAP megaproject and its contentious deep dredging measure, justified through the hydraulic mission discourse, has essentially created another rigid boundary on the eastern side of the Doñana SES (Fig. 3). A different set of menaces and systemic risks might therefore materialize in the absence of key governance actors such as the Doñana Participation Council and  WWF, who act as guardians of the remaining natural capital. The  IMAP megaproject jeopardized the fragile governance stability currently existing in the region, triggering a highly\n\nconflictive  situation  pointing  to  lose-lose  prospects  for  the  actors  involved,  despite  their powerful discourses.\n\nStrikingly, discourse inertia can be found in the last strides of the IMAP megaproject. In 2017, after the first backlash from the Spanish Supreme Court (Fig. 4), the Port Authority shifted to a narrative promoting scientific knowledge production about the environmental sustainability of the estuary as a 'permanent and priority goal' (president of the Port Authority, PUB\\_003, Appendix 1). However, in the same communication, the Port Authority advocated some type of  dredging  measure  based  on 'better  techniques  and  better  integration' .  Today,  the  new strategy of the Port Authority aims 'for the optimization of navigation in the Guadalquivir [estuary]' (ibidem),  while  simultaneously 'working with nature' .  Since  the  Port  Authority stated that 'the sentence of the Supreme Court do not disrupt our plans for the port' (Diario de Sevilla, 2019), it is yet to be seen whether this new strategy will materialize to protect the integrity of the estuary, or whether just the working-with-nature paradigm will be co-opted again.\n\n\n## 5.3. Escaping the rigidity trap: expanding latent pluralism\n\n\nOur analysis of Doñana's rigid discursive-institutional spiral shows that discourse inertia is the mechanism  responsible  for  Doñana's  gradual  curtailment  of  pluralism,  resulting  in  rigid entrapment of the  SES.  How  can  this  mechanism  be  disrupted  to  escape  the  rigidity  trap? Specifically, how can latent pluralism be expanded to foster change towards sustainability? We answer by drawing from the sustainability transitions literature, specifically from recent efforts to make this body of theory more suitable for evaluation purposes (Ghosh et al., 2021; MolasGallart et al., 2021). Below, we focus on the initial steps of a potential process of change.\n\nBroadly speaking, spaces for governance experimentation need to be created to nurture latent pluralism.  Participation  by  a  range  of  engaged  actors  is  needed,  from  across  the  political spectrum  and  many  walks  of  life,  creating  enough  diversity  to  create  conditions  ripe  for minimizing polarization and decision paralysis (Hull, 2009). Such diversity encourages a wide variety of viewpoints, grounded in different knowledge sources. To successfully inform and shape  planning  policy  and  decision  making,  these  experimentation  spaces  also  need  to  be process  orientated  rather  than  technical  results  orientated.  These  spaces  must  be  protected ('shielded',  Ghosh  et  al.,  2021).  Examples  of  protecting  these  participatory  spaces  might include: aligning policy/decision makers and other actors through mutually agreed environmental  goals  and  ways  forward  that  cut  across  diverse  governance  levels  and  SES spatiotemporal scales ('deepen shielding'; Ghosh et al., 2021); voluntary agreements between actors with similar conceptualizations of nature conservation (e.g., Nature-Based Solutions, Nature  as  other,  human/non-human  relations);  or  new  regulations  to  enhance  pluralism  in formal  environmental  decision  making  (e.g.,  land-use  planning,  Environmental  Impact Assessment) (based on  Raven et al.,  2010;  Smith  et  al.,  2014;  Spash  2022).  'Learning' is another critical component to be considered in these spaces and must encompass both firstorder learning (e.g., changes in routines or protocols based on new monitoring information) and  second-order  learning  (e.g.,  changes  in  core  values  and  beliefs  or  different  ways  of\n\napproaching problems based on existing or new transdisciplinary knowledge) (Ghosh et al., 2021).  In  the  long  term,  second-order  learning  based  on  confronting  core  assumptions  and biases from actors may be more transformative, due to it challenging well-established rules (Van Poeck et al., 2020). 'Deepening of learning' (Ghosh et al., 2021) can happen if actors engage in processes where their thinking can be stretched in collaborative spaces that enhance reflexivity  and  mutual  trust  (Raven  et  al.  2019).  These  processes  can  ultimately  result  in 'deepening of networks'  drawing together actors with different power identities regarding , resources  and  decisions  (Ghosh  et  al.,  2021).  This  can  happen  via  interventions  that  are moderated  by  intermediaries  who  facilitate  mutual  connections  and  reconcile  narratives (Kivimaa  et  al.,  2019;  Smith  and  Raven,  2012).  Finally,  the  actors'  expectations  must  be navigated to prevent disappointment and minimize ambiguity. This can be achieved by creating collaborative, inclusive visions, which can lead to more robust, shared expectations (Ghosh et al., 2021). We argue that these initial steps-involving broadening participation and deepening learning and networking-would contribute to setting a new governance baseline more apt to nurture changes towards sustainability in Doñana that would be widely accepted. If that new governance baseline was achieved, conditions would be ripe for expanding and mainstreaming latent  pluralism.  This  could  happen  by  'replicating'  innovative  governance  experiments  to resolve issues or working at broader scales to 'institutionalize' such experiments through new regulations and the development of new cultural meanings ('upscaling') about the critical role of water resources for human and non-human well-being (Ghosh et al., 2021).\n\nThis whole process must start with a crack that breaks the dominant hydraulic discourse and command-and-control paradigm -- which presently influence institutions and discourse and, in turn,  give  rise  to  a  governance  configuration  unfit  to  advance  SES  sustainability.  Greater reflexivity must be promoted in governance; the transformative potential of pluralism can be hindered by the stance, still common among scientists, to behave as if they are neutral parties rather than as engaged in a mission-driven activity (Crouzat et al., 2018). Joint learning and the creation  of  a  common  vision  for  change  can  be  a  precondition  to  overcome  these  type  of challenges (Chaffin et al., 2016). At the same time, we must recognize that most perspectives (if not all) are not ideologically neutral. In the absence of equitable power structures to resolve disputes about how nature should be valued and shaped, certain perspectives dominate policy and  decision  making,  pushing  change  processes  to  unfavorable  conditions  and  trajectories (Garrett et al., 2021; Jacobs et al., 2020; Leonardsson et al., 2021).\n\n\n## 6. Conclusions\n\n\nGovernance plays a crucial role in fostering and steering change towards sustainability. Values pluralism constitutes a key ingredient for increasing the likelihood of robust and viable change processes.  Our  case  study  shows  that  a  tight  relationship  has  historically  existed  between institutional  structures  and  dominant  discourses  in  Doñana.  Current  ecosystem  and  water resources  governance  is  characterized  by  a  deeply  entrenched  contest  between  economicdevelopment and protection-for-conservation discourses, imbued with hydraulic mission ideas and  ways  of  thinking.  At  present,  Doñana's  governance  configuration  prevents  the  further deterioration of water resources and ecosystems through actions taken as part of a rich legal\n\nlegacy,  reactive  judicial  rulings,  integrated  knowledge  co-production,  and  local  nature safeguards and watchful international actors. These features are instrumental in averting the systemic  risks  posed  by  high-impact  interventions  promoted  by  elite  actors  with  narrow interests who have historically been disinclined to work towards broad socioeconomic welfare.\n\nOur  study  identified  several  mechanisms  (e.g.,  rationality  restricted  by  discourses,  path dependence mechanisms, discourse inertia) by which values pluralism can be systematically inhibited. Tightly interwoven dominant discourses and institutions can be impervious to new paradigms  and  knowledge  even  if  they  reach  the  agenda  at  high  level.  Novel  ideas  and narratives can be rapidly cancelled out by dominant discourses. This might reflect underlying coordination failures among governance actors to integrate new discourses into planning and policy.  Such  failures  can  be  compounded  when  multiple,  powerful  fronts  (legal,  planning, economic, conservation) act at odds with each other, risking inaction. Also, when critical issues such as modernizing irrigation, enhancing navigability, and protecting nature all tend to be issues high on the political agenda, attempts to steer the discourse in a new direction can result in a deadlock that hinders new policy directions.\n\nFinally, we have shown how latent pluralism might be expanded and mainstreamed to escape undesirable SES traps by reflecting on state-of-the-art concepts that can be leveraged toward sustainability  transformations.  Governance  experimentation  should  be  nurtured  through  the engagement of diverse actors and the protection of innovations set in motion by new networks emerging  from  these  spaces.  Firstand  second-order  learning, accounting  for power asymmetries,  and  mitigating  actor  expectations  are  key  ingredients  that  contribute  to reorienting  discourse  and  changing  governance-making  these  transformed  discourses  and governance  configurations  more  likely  to  advance  sustainability  initiatives  that  are  widely accepted by multiple actors. The main limitation of the research presented here stems from its single-case study design, which restricts its generalization to other cases of SES traps. Another limitation  stems  from  the  lack  of  integration  of  an  analysis  of  power,  a  key  factor  to understanding outcomes in SES traps (Boonstra, 2016)-although power has been considered elsewhere (Méndez et al., 2022). Future research should conduct comparative case studies to understand the influence of contextual factors such as different histories, cultures, and power dynamics. This work must also consider the potential social inequalities associated with deep processes of change that, in turn, will be affected by complex and uncertain social-ecological dynamics and major impacts resulting from global environmental and climate change.\n\n\n## 2.1. Nature of the problem\n\n\nDeep dredging appeared in numerous instances portrayed alongside other developments at basin and sea level  (e.g.,  metalliferous  mining,  underground  gas  storage,  maritime  crude  oil  transport,  groundwater extraction), as posing environmental hazards, nature conservation threats and intricate conflicts in the social realm (EPRESS\\_039; EPRESS\\_041). At regional level, water and some agricultural uses are affected by illegal activities and conversion of uses, due to inaction by competent authorities to implement approved plans,  concomitant  with  passivity  from  legal  authorities  to  penalize  illegal  water  and  agricultural  uses (EM\\_004;  EPRESS\\_126).  These  threats,  conflicts  and  illegalities  are  amplified  through  a  classical discourse conveying the economic development vs nature conservation divide, often representing Doñana as a precious place of universal value, in critical condition and under 'attack' (EPRESS\\_126; EM\\_004). Arguments  made  by  the  Port  Authority  and  key  actors  from  its  supportive  coalition  ('Sevilla  por  su Puerto'), show how deep dredging was seen as a panacea to bring about socioeconomic progress:\n\n- -'The future of the port is [deep] dredging, in optimal conditions for the environment.' Unattributed comment (EPRESS\\_019). By 'environment', supporters of the project normally referred to estuarine and protected  wetland  ecosystems,  and  to  downstream  irrigation  agriculture,  a  sector  quite  against  deep dredging due to the hypothetical increase in salinity of estuarine waters (EPRESS\\_019, PUB\\_003).\n- -'Dredging or dying', 'it is absolutely essential to ensure navigability in the river [to allow for] modern ships [and be] competitive', '[if not] we will jeopardize a fundamental pillar for employment and logistic activity in Seville, because logistics and transport are the key to the future', '[the role of] politicians and administration is to help. The only thing lacking is the project for the protection of the riverbanks. They must say how to implement every projected measure.' President of Sevillian Employers Confederation (EPRESS\\_019).\n\n\n## 2.2. Centralized authority and local disempowerment\n\n\nDeep dredging was envisaged merely a territorial conflict underpinned by a complex political puzzle of alliances and confrontations (EM\\_31), evidencing the existence of multiple centers of concentrated power divided for and against deep dredging. The potential failure of deep dredging was portrayed as another hindrance to the long-term historical endeavor to make the Guadalquivir estuary navigable in competition with more accessible seaports (e.g., Cadiz's port), within a broader landscape of failing urban engineering projects preventing Seville to 'stand out in the Spanish [economic] landscape' at present (DS\\_015). Our main inference regarding local disempowerment from several articles focusing on deep dredging (often in the context of other developments in the region) was not so much about how disempowerment was brought about  during  the  lifecycle  of  the  IMAP  megaproject  (and  other  major  developments)  (EPRESS\\_126; ED\\_063).  Disempowerment  was  evident,  otherwise,  from  the  lack  of  clear  and  institutionalized mechanisms for stakeholder and public participation. It was also noticeable the almost lack of reference to public participation from key international organisms during the megaproject lifecycle such as UNESCO, evidencing the low position of that issue in the political and diplomatic agenda.\n\n\n## 2.3. Analytical simplification\n\n\nAnalytical simplification could be inferred directly from the arguments of members of the Port Authority or its supportive actor coalition (see above). Also, it could be indirectly inferred from the tendency in the region to subject large development projects (e.g., metalliferous mining, underground gas storage) to more sophisticated and integrated technical, scientific assessments of cumulative impacts after mandatory but incomplete Environmental (or Strategic) Impact Assessment, often as a reaction to formal complaints from nature guardians (e.g., WWF, Doñana Participation Council) (EPRESS\\_113; ED\\_063; see also Vargas and Paneque, 2015). Analytical simplification was also exemplified in the propensity of the Port Authority and supportive  actors  to  propose  technical  fixes  as  panaceas  to  resolve  the  problems  created  by  the  deep dredging engineering solution (see 'Lock-in factors' below). The turn towards 'optimization' of the Port Authority in 2017 (see section 5.2.4 in main text) was also exemplary, for it indirectly recognized the need to consider richer knowledge inputs a priori, even if it was by commissioning ad-hoc studies to continue justifying a purportedly harmless intervention in the resource system to maximize outputs. And overarching all  this  was  the  argument  of  the  Spanish  Supreme  Court  (see  'Lock-in  factors'  below),  a  reproach  to malpractice upon considering deep dredging as a 'complementary measure' unfettered from mandatory assessments of ecological impacts.\n\n\n## 2.4. Capitalization and control\n\n\nThe introduction of substantial physical capitalization and mechanization to exercise control over the target water resource system, thus effectuating the analytical simplifications, was indirectly inferred from the expectations on high returns on investments from actors supporting the IMAP megaproject and directly\n\nfrom the megaproject's costs (DS\\_026). The IMAP megaproject was considered key for socioeconomic development at city and provincial level, based on the arguments that it would suppose the generation of 15000-17000 jobs and the increasing of cruise tourism (ibidem) and, as mentioned above, 'higher profit margins' for the Port's companies. The alleged benefits of the IMAP megaproject have been convincingly argued as unreliable, based on old forecasts no longer valid (Sancho-Royo and Del Moral, 2014; SanchoRoyo and Del Moral, 2015; Vargas and Paneque, 2015). Other key arguments in favor of the megaproject were the improvement of navigability in the estuary allowing for its connection to the Trans-European Transport Network, as well as the direct access to the European Regional Development Fund for financing the  megaproject's  development  costs  (€250  million  approx.).  Indeed,  the  fund  partially  covered  the construction of the Sea Gate (€63 million from a total of €163 million) and was expected to cover 80% of deep dredging costs (€37.7 million, plus €31.1 for waste management) (ibidem; see also Diario de Sevilla, 2013; El Confidencial, 2015; Vargas, 2012; Vargas and Paneque, 2015).\n\n\n## 2.5. Lack of fit due to social-ecological suppression\n\n\nInferences about this category were about the disregard by the IMAP megaproject supportive actors for key socioeconomic and ecological functions in the Doñana SES, which could have been suppressed if deep dredging would have been implemented. Since this was not the case, we contextualized our inferences within key insights from other sources informing the risk of large-scale interventions in the estuary (see Méndez et al. 2021). Concern for large environmental and socioeconomic impacts were latent in multiple articles (ED\\_068; EM\\_052).\n\n\n## 2.6. Lock-in factors\n\n\nFrom  data  rich  articles,  it  stood  out  the  argumentation  of  the  Spanish  Supreme  Court  to  justify  the cancellation of deep dredging, a Kafkaesque process that lasted four years and indicates lock-in among actors. In 2015, despite the modifications of the IMAP megaproject by the Port Authority to comply with the  environmental  requirements  of  the  2003  EIS  and  CSIC  study,  the  European  Commission  issued  a statement on the project's potential infringement of the EU Habitats Directive (EM\\_052). The same year, in response to an appeal from WWF, the Spanish Supreme Court ruled the removal of deep dredging as a 'complementary'  measure  from  the  2013  Water  Plan,  prepared  by  the  Guadalquivir  River  Authority (ibidem). That qualification turned deep dredging a binding measure but freed from justifying compliance with water quality standards (ibidem). The megaproject's supportive actor coalition reacted to the Court's ruling by considering the qualification of 'complementary' as a 'procedural defect' , rectifiable during the next planning phase starting in 2016 (ibidem). The Court's ruling was directed at the Spanish government, not at the Guadalquivir River Authority (water planning authority), nor at the Port Authority (promoter of the megaproject), both of which are state bodies. Defended by the State's Attorney, the Spanish government adduced that deep dredging was 'mere [planning] forecast' without providing proper justification, thus downplaying the potential consequences of the measure (ibidem). What perhaps was a 'procedural defect' was the lack of justification for a harmful measure like deep dredging in the Water Plans, something that was required by both the Water Framework Directive and the Spanish Water Planning Regulation (Royal Decree  907/2007).  In  addition  to  water  planning,  there  were  procedural  defects  also  along  the  IMAP megaproject EIA process and our evidence indicated that this seemed to constitute a ubiquitous pattern for other major developments in the region (e.g., underground gas storage, metalliferous mining, groundwater exploitation) (EV\\_EI\\_023). The Port Authority and its supportive actor coalition seemed to firmly believe that it was possible to fully balance out the negative environmental and socioeconomic impacts of deep dredging through further engineering and technical fixes. Standing out in this regard is the general argument of 'fixing the estuary' to  allow  for  deeper  dredging,  including proposals  such  as  the protection of  the riverbanks from the erosion caused by future ship wakes of higher-tonnage vessels, through measures that are normally implemented in emergency situations (e.g., 'geotubes' ) (EP\\_036; EM\\_051)\n\nTable A1.2. Random subset of articles used for our illustrative extracts of results.\n\n",
         "Processes of change towards sustainability are urgently needed to ensure that humans continue to live within safe biophysical limits. Governance and politics are inherently implicated in any effort to foster successful change processes. Pluralism has been argued as a key ingredient for increasing the likelihood of robust and viable processes of change. Here, we explore pluralism vis-a-vis resource and ecosystem governance from a social-ecological systems (SES) perspective, considering both plurality of values and methodological pluralism. We focus on (1) understanding situations of limited pluralism and factors contributing to it being perpetuated, and (2) exploring how “latent pluralism” could be drawn out to foster change towards sustainability. Our particular interest lies in understanding the role of discursive-institutional dynamics—discourses and how they play out via institutions—underlying governance. To these ends, we synthesize and build on existing case study research in the Doñana region (Guadalquivir estuary, SW Spain), an estuary-delta SES characterized by a rigidity trap, a situation of inflexibility that makes the SES more vulnerable. Using the illustrative example of a failed hydraulic megaproject, we use a novel analytical approach blending institutional analysis with discursive-institutional dynamics. We show how tight relationships between institutional structures and dominant discourses in the Doñana region, underpinned by a hegemonic hydraulic-mission discourse, played a prominent role in curtailing pluralism in Doñana's governance contexts over time. We also show how latent pluralism exists in the region, and reflect upon current ideas and discourses that might help loosen existing governance stalemates and foster change towards sustainability.",
         ""
        ],
        [
         "20",
         "20",
         "## 1. Introduction\n\n\nPosting preprints is an open science practice that helps to make scholarly publishing faster and more transparent. Preprint servers enable research papers to be shared openly prior to peer review (Hu et al., 2015). The adoption of preprinting has increased massively over the past three decades (Xie et al., 2021). Posting papers on a preprint server nowadays is a common practice in several disciplines, such as physics and mathematics (Brown, 2001; Larivière et al., 2014; Puebla et al., 2021). In other disciplines preprinting is less common (Kaiser, 2017), and in some disciplines it is hardly done at all.\n\nThe level of adoption of preprinting varies around the world. In the life sciences, for instance, Abdill et al. (2020) showed that the US and UK contribute a disproportionally large number of preprints to bioRxiv compared to other countries.\n\nThis could be due to a variety of reasons, such as differences between countries in the level of awareness of preprinting or in the implementation of open science policies. The specific features of the scholarly publishing system in countries such as China (Hyland, 2023; Ren, 2013; Wang et al., 2021) are also likely to play a role. Nevertheless, in recent years, there seems to be an increasing interest in preprinting in many parts of the world, as shown for instance by the emergence of regional preprint servers such as AfricArXiv, ChinaXiv, Jxiv and SciELO Preprints (Chaleplioglou &amp; Koulouris, 2023).\n\nPreprinting may offer several benefits to authors, readers and potentially also to other stakeholders, such as reviewers and editors. It enables immediate publication of research papers and may help to avoid duplicate work and to prevent other researchers from pursuing unproductive research directions (Puebla et al., 2021). Preprinting also allows authors to receive fast feedback on their work (Malički et al., 2021; Rzayeva et al., 2023), to claim priority for their work (Ginsparg, 2016; Vale &amp; Hyman, 2016) and to get 'scoop protection' (Pulverer, 2016). In addition, as permanent citable records, preprints can be used as proof of productivity, especially for early-career researchers and researchers who do not intend to publish their work in journals (Malički et al., 2021; Vale, 2015; Kim et al., 2020). Preprints also offer a way to attract early attention from readers and editors (Barrett, 2018; Barsh et al., 2016). This may help authors to make their work more visible, which may also increase the number of citations their work receives (Fraser et al., 2020; Fu &amp; Hughey, 2019).\n\nHowever, there are also challenges that may slow down the adoption of preprinting. Common concerns about preprinting include scooping risks, low reliability and credibility, premature media coverage, geographical disparities in adoption and incompatibility with journal policies (Blatch-Jones et al., 2023; Fraser et al., 2022; Ng et al., 2023; Puebla et al., 2021; Sever et al., 2019; Smart, 2022). Journal policies for posting and citing preprints vary across disciplines. Klebel et al. (2020) found that 91% of the journals in the life sciences and earth sciences allow preprinting, while this is the case for only 45% of the journals in the humanities. In a survey carried out by ASAPbio (2020), it was observed that concerns about preprinting were stronger among respondents who had never posted a preprint than among those who did have experience with preprinting.\n\nOur goal in this paper is to develop a systematic understanding of researchers' adoption of and attitudes toward preprinting. We present the results of a global online survey of authors of research papers asking them about their familiarity with preprinting and their experience with reading and posting preprints. Survey participants were also asked to share their views on benefits of preprinting, concerns about preprinting and ways in which preprinting can be promoted.\n\nWe address the following research questions in this paper:\n\n- 1. What is the level of adoption of preprinting and how does this differ across countries/regions and research areas?\n- 2. What do researchers in different countries/regions and different research areas see as benefits of preprinting and what are their concerns about preprinting?\n- 3. What do researchers in different countries/regions and different research areas see as ways to encourage preprinting?\n\n\n## 2. Methods\n\n\n\n## 2.1 Survey overview\n\n\nTo learn about researchers' adoption of and attitudes toward preprinting, we performed an online survey of corresponding authors of papers published in 2021 and early 2022 and indexed in the Web of Science database. The survey was carried out using the Qualtrics software. Respondents were asked to answer ten questions about their adoption of and attitudes toward preprinting. The survey also included five demographic questions. The questions in the survey were grouped into three parts:\n\n- ● Adoption of preprinting. Questions about familiarity with preprinting, ways of learning about preprinting, experience with reading preprints, experience with posting preprints and willingness to post preprints in the future.\n- ● Attitudes toward preprinting. Questions about benefits of preprinting, concerns about preprinting and ways to encourage preprinting.\n- ● Demographic questions. Questions about respondents' gender, country/region in which their organization is based, number of years of research experience, career stage and research area.\n\nThe survey questions were partly inspired by earlier surveys on preprinting (ASAPbio, 2020; Fraser et al., 2022; Sever et al., 2019; Soderberg et al., 2020).\n\nThe survey form and the raw survey data are available in Zenodo (Ni &amp; Waltman, 2023). The survey was carried out in English, except for the survey that was sent to researchers in China, which was made available both in English and in Chinese. Ethical approval to carry out the survey was granted by the Ethics Review Committee of the Social Sciences at the Faculty of Social and Behavioural Sciences of Leiden University. We consulted the Checklist for Reporting Results of Internet E-Surveys (CHERRIES) to report the survey results (Eysenbach, 2004).\n\n\n## 2.2 Survey data collection\n\n\nOur study was initially designed as a study of preprinting practices in specific parts of the world, but we ultimately decided to broaden our scope and to take a global perspective. Given the initial design of our study, data was collected separately for different parts of the world. We ran our survey first for researchers in China, then for researchers in the US and Europe, and finally for researchers in the rest of the world ('other'). Researchers invited to participate in the survey were selected as follows:\n\n- 1. All papers published in 2021 and early 2022 and indexed in the Web of Science database were selected. We made use of the in-house version of the Web of Science database available at CWTS, Leiden University, updated until week 13 in 2022. The database includes four Web of Science citation indices: the Science Citation Index Expanded, the Social Sciences Citation Index, the Arts &amp; Humanities Citation Index, and the Conference Proceedings Citation Index. We considered papers of all document types.\n- 2. For the selected papers, corresponding authors with an affiliation in a particular country/region (i.e., China, US, Europe, other) were identified and the email addresses of these authors were selected.\n- 3. The selected email addresses were deduplicated.\n- 4. A random sample of the deduplicated email addresses was taken and an\n\ninvitation to participate in our survey was sent to these addresses.\n\nIn the first question in the survey, respondents were asked to indicate their familiarity with preprinting. Respondents who answered that they were not familiar with preprinting at all (N=283) skipped the remaining questions about preprinting and went directly to the demographic questions at the end of the survey.\n\nWe sent the survey invitations in batches between November 2022 and March 2023. The survey was fully anonymous. For each country/region, we first sent a small number of invitations to test the survey process. We then sent another 30,000 invitations. Table 1 reports for each country/region the number of invitations that were sent and the number of responses that were received. Only completed responses are considered in our analysis of the survey results. In total, we received 3,506 completed responses to our survey. There were large differences between countries/regions in the response rate. The response rate was highest for researchers in Europe (4.7%) and lowest for researchers in China (1.2%).\n\nTable 1. Summary of survey data collection\n\n\n## 2.3 Survey participants\n\n\nFig. 1 provides an overview of the demographics of the survey participants. More details can be found in Table A1 in the appendix. 66% of the survey participants identified as man and 29% as woman. 5% chose \"prefer not to say\" or \"prefer to self-describe\". More than half of the survey participants reported having at least 15 years of research experience, revealing a strong overrepresentation of senior researchers among the participants. Only 2% of the participants had fewer than 3 years of research experience. Full professors accounted for the largest proportion of survey participants (29%), followed by associate professors (21%) and assistant professors (15%). Survey participants were active in research areas across the sciences, social sciences and humanities. They were requested to choose their research area from a list of 13 predefined areas. Survey participants that felt they did not fit in any of these 13 areas could choose 'other'. Because the number of survey participants in some of the 13 areas was quite small, we decided to merge some areas, reducing the number of areas to 9. In the presentation of the survey results in the next section, participants in the 'other' category are excluded when results are reported by research area. In total, survey responses were received from 114 countries/regions.\n\nFig. 1. Demographics of survey participants (N=3506)\n\n<!-- image -->\n\n\n## 3. Results\n\n\n\n## 3.1 Adoption of preprinting\n\n\n\n## Familiarity with preprinting\n\n\nSurvey participants were asked to report their familiarity with preprinting. Fig. 2 shows the familiarity with preprinting by country/region and research area. The differences between research areas are substantial. The highest familiarity with preprinting across all countries/regions can be found in physics and astronomy as well as mathematics and computer science. For example, around 85% of the US respondents in these areas reported to be 'very familiar' or 'extremely familiar' with preprinting. There are also large differences between countries/regions. In most research areas, the familiarity with preprinting is highest in the US, followed by Europe, and lowest in China.\n\nFig. 2. Familiarity with preprinting\n\n<!-- image -->\n\nWithin Europe, there are substantial differences between countries in the familiarity with preprinting. Overall, 45% of the European survey participants reported to be 'very familiar' or 'extremely familiar' with preprinting. Focusing on the ten European countries with the largest number of respondents, respondents from Germany (52%), the UK (51%), Switzerland (49%), Spain (48%), the Netherlands (47%), and France (47%) turn out to be more likely to be 'very familiar' or 'extremely familiar' with preprinting than respondents from Sweden (38%), Italy (36%), Norway (34%), and Poland (30%).\n\nOf the survey participants from the rest of the world, overall 38% reported to be 'very familiar' or 'extremely familiar' with preprinting. A breakdown by the seven geographical regions distinguished by the World Bank shows that this percentage is higher for respondents from Europe and Central Asia (46%; mainly respondents from Russia and Turkey), North America (43%; mainly respondents from Canada), South Asia (42%), and Sub-Saharan Africa (41%) and lower for respondents from East Asia and Pacific (33%), Middle East and North Africa (33%), and Latin America and Caribbean (32%).\n\nReading preprints is the most important way to learn about preprinting (Fig. 3). In each country/region, more than half of the survey participants reported that they had learned about preprinting by reading preprints. Learning about preprinting through formal training is uncommon. It was mentioned by only 4% of the respondents. Interestingly, results for China differ substantially from the rest of the world. 58% of the respondents in China reported they had learned about preprinting when submitting a paper to a journal. This percentage is much lower for respondents in other countries/regions. Compared to other countries/regions, far fewer respondents in China had learned about preprinting from a colleague (17%).\n\nFig. 3. How do researchers learn about preprinting?\n\n<!-- image -->\n\n\n## Experience with reading preprints\n\n\nWe also asked survey participants how often they read preprints (Fig. 4). Overall, the frequency of reading preprints is quite similar across countries/regions. Regardless of the country/region, more than half of the respondents in physics and astronomy reported that they read preprints at least a few times per week. Reading preprints is also quite common in mathematics and computer science. It is much less common in other research areas.\n\n<!-- image -->\n\n\n## Experience with posting preprints\n\n\nIn terms of posting preprints, physics and astronomy as well as mathematics and computer science show the highest adoption of preprinting (Fig. 5), in line with the familiarity with preprinting in these areas (Fig. 2). In physics and astronomy, 72% of the respondents in the US reported that they had posted all or most of their papers on a preprint server, and 64%, 67% and 56% of the respondents in Europe, China and the rest of the world reported the same. Interestingly, the situation in mathematics and computer science varies strongly between countries/regions. 67% of the US respondents and 53% of the European respondents reported that they had preprinted all or most of their papers, while this is the case for only 15% and 32% of the respondents in, respectively, China and the rest of the world.\n\n<!-- image -->\n\nSurvey participants who reported that they had posted papers on preprint servers were asked which preprint servers they had used and at what stage they had posted preprints (Fig. 6). In terms of preprint servers, arXiv was mentioned most frequently by respondents (39%), particularly in Europe, followed by bioRxiv (24%), which turns out to be especially popular in the US. ChinaXiv, a preprint server based in China, was mentioned almost exclusively by respondents in this country. Additionally, a relatively high percentage of respondents in China reported the use of Research Square (16%) or SSRN (15%). Presumably, most papers are posted on these commercial preprint servers when authors submit a paper to a Springer Nature or Elsevier journal. OSF Preprints, a multidisciplinary preprint server, PsyArXiv, a preprint server for psychological sciences, and SocArXiv, a preprint server for social sciences, were mentioned more often by respondents in the US and Europe than by their colleagues in China and the rest of the world. Based on the free-text responses in the 'other' category, 4% and 3% of all respondents with preprinting experience reported having used medRxiv and ResearchGate, respectively. While ResearchGate is sometimes seen as a preprint server (e.g., https://asapbio.org/preprint-servers), it can best be characterized as an academic social networking platform. Sharing of research papers is one of the functions it provides.\n\nIn terms of the stage at which preprints are posted, many survey participants responded that they had posted their work on a preprint server before submitting it to a journal (25%) or when submitting it to a journal (31%). 15% of the participants had posted their work as a preprint after it had been accepted by a journal. Such preprints are sometimes referred to as postprints.\n\nFig. 6. Preprint servers and stage of posting preprints\n\n<!-- image -->\n\n\n## Willingness to post preprints\n\n\nSurvey participants were also asked to report their willingness to post preprints in the future (Fig. 7). The willingness to post preprints is strongest in physics and astronomy. The percentage of respondents that expect to post most or all of their future papers on a preprint server varies between 59% and 78% for different countries/regions. In mathematics and computer science, on the other hand, there are large differences between countries/regions. 78% of the US respondents and 54% of the European respondents expect to preprint most or all of their future papers, while this is the case for only 14% of the respondents in China. Respondents in the medical and health sciences expressed the lowest willingness to post preprints. Less than 10% of the respondents in this area plan to preprint most or all of their future papers. Apparently, the COVID-19 pandemic has not led to a major shift in attitudes toward preprinting in the medical and health sciences.\n\nFig. 7. Willingness to post preprints in the future\n\n<!-- image -->\n\nInterestingly, while the US has a relatively high percentage of respondents that expect to preprint most or all of their future papers (24% across all research areas), it also has the highest percentage of respondents that do not plan to preprint any of their future papers (39%). This percentage is substantially lower in Europe (30%) and China (30%). Hence, attitudes toward preprinting seem more polarized in the US than in other countries/regions.\n\n## Association with gender and level of experience\n\nWe used ordered-logit regression to analyze how different aspects of the adoption of preprinting are associated with respondents' gender and their number of years of research experience, in addition to their country/region and their field. The results are reported in the coefficient plots presented in Fig. A1 in the appendix.\n\nThe coefficient plots reveal that, other things equal, men on average show a higher adoption of preprinting than women. In addition, researchers with fewer years of research experience on average have more experience with reading preprints and are more willing to post preprints.\n\n\n## 3.2 Attitudes toward preprinting\n\n\n\n## Benefits of preprinting\n\n\nFig. 8 shows the attitudes of survey participants toward nine statements about potential benefits of preprinting. The research areas distinguished in Subsection 3.1 have been grouped into three broad fields: physical sciences and engineering (PS&amp;E), life and health sciences (L&amp;HS), and social sciences and humanities (SS&amp;H). The benefits of preprinting tend to get most recognition in the physical sciences and engineering, but disciplinary differences are relatively small. The attitudes of respondents in different countries/regions are also fairly similar. Being free to read is seen as the most beneficial feature of preprints. Approximately half of the respondents\n\nregarded this as very beneficial. Nearly 40% of the respondents considered the increase in the speed of research communication to be very beneficial. Free posting, getting additional exposure and establishing priority are also seen as significant benefits of preprinting. In comparison, only about one-fifth of the respondents stated that preprints are very beneficial in enabling authors to receive early feedback, to receive more citations, to share results that do not fit in journals and to demonstrate progress in the context of evaluation for grants or jobs.\n\nFig. 8. Attitudes toward benefits of preprinting\n\n<!-- image -->\n\nNotes: Survey participants were asked about their attitudes toward nine benefits of preprinting. The choices included 'not at all beneficial', 'somewhat beneficial', 'very beneficial' and 'do not know'. The figure shows the percentage of 'very beneficial' responses. PS&amp;E, L&amp;HS and SS&amp;H refer to physical sciences and engineering (N=1245), life and health sciences (N=1270), and social sciences and humanities (N=794) respectively.\n\n\n## Concerns about preprinting\n\n\nWhen asked about concerns about preprinting, survey participants in different countries/regions and different fields responded differently (Fig. 9). Low reliability and credibility of preprints, sharing results before peer review and premature media coverage of preprints are the most important concerns. These concerns were raised in particular by respondents in the life and health sciences, with US respondents being most concerned. For example, 53% of the US respondents in the life and health sciences indicated that they are very concerned about premature media coverage. Interestingly, respondents in the life and health sciences in China were more concerned about the risk of preprint authors getting scooped and the lack of recognition for posting preprints, with respectively 35% and 30% of the respondents indicating being very concerned about this. These percentages are much lower for respondents in other countries/regions, and also for Chinese respondents in other fields. Only a small share of all respondents expressed strong concerns about harmful comments on preprints and information overload.\n\nFig. 9. Attitudes toward concerns about preprinting\n\n<!-- image -->\n\nNotes: Survey participants were asked about their attitudes toward eleven concerns about preprinting. The choices included 'not at all concerning', 'somewhat concerning', 'very concerning' and 'do not know'. The figure shows the percentage of 'very concerning' responses. PS&amp;E, L&amp;HS and SS&amp;H refer to physical sciences and engineering (N=1245), life and health sciences (N=1270), and social sciences and humanities (N=794) respectively.\n\nParadoxically, while some respondents see preprinting as a tool that researchers can use (or misuse) to scoop others, there are also respondents who fear that preprinting may increase the risk of being scooped. However, by facilitating early registration of timestamped versions of research papers, preprinting enables researchers to make priority claims, which offers protection against being scooped. Some respondents do not seem to be aware of this, which suggests a need to develop a better understanding of preprinting in relation to the issue of scooping.\n\nFree-text responses confirm some of the concerns about preprinting described above and also reveal additional concerns. The 303 valid responses were coded by one of us, resulting in the identification of a broad range of concerns. Important concerns include:\n\n- ● Quality of preprints (N=59). A major concern relates to low-quality preprints. Some respondents witnessed a surge of low-quality preprints during the COVID-19 pandemic (e.g., 'As COVID demonstrated, without peer review, much rubbish is published' , man from Macau, China working as full professor in the social and behavioral sciences). Without quality assurance by peer reviewers, respondents worried about the credibility of scientific work (e.g., 'They are not peer-reviewed and can undermine the credibility of peer-reviewed science' , man from the US working as practitioner in the earth sciences).\n- ● Multiple versions of the same paper (N=34). This concern is about the risk of confusion caused by having multiple versions of the same paper (e.g., 'Confusion between the status of the preprint and the final peer-reviewed article' , woman from Canada working as full professor in earth sciences;\n\n- 'The possibilities for confusion with the 'final' version' , woman from Ireland working as academic developer in education).\n- ● Citation of preprints (N=24). Another concern relates to the citability of preprints. Respondents felt uncertain about citing preprints in their papers (e.g., 'I feel a little bit reluctant to cite a preprint of a study in my current research. The reviewers might question that' , man from China working as assistant professor in the social and behavioral sciences). Respondents were not sure how to cite preprints and how to distinguish them from peer-reviewed papers (e.g., 'It gets confusing when there is a pre-print and peer-reviewed version of a paper and dilutes citations' , man from the US working as associate professor in the medical and health sciences).\n- ● Accusation of self-plagiarism (N=7). Respondents expressed their worry that reviewers and journals may consider a journal submission to be self-plagiarized if the paper has already been posted on a preprint server (e.g., 'I had this problem that after publishing as a pre-print, journals that submitted my paper had reported plagiarism!!!!' , man from Iran working as assistant professor in the medical and health sciences; 'Reviewers often do not know about preprints and reject articles for plagiarism (personal experience)' , woman from Italy working as full professor in chemistry).\n\n\n## Encouraging preprinting\n\n\nTo encourage preprinting, survey participants emphasized the importance of integrating preprinting in journal submission workflows (Fig. 10). For most combinations of a country/region and a field, about one-third of the respondents considered this integration very important. Likewise, providing recognition to researchers for preprinting their work is an important way to encourage preprinting, especially in China and in the social sciences and humanities. Recognition was regarded as very important by 45% of the Chinese respondents in the social sciences and humanities. Approximately a quarter of the respondents stated that encouraging or mandating preprinting by research funders, research institutions and journals is very important.\n\nFig. 10. Attitudes toward different ways to encourage preprinting\n\n<!-- image -->\n\nNotes: Survey participants were asked about their attitudes toward seven ways to encourage preprinting. The choices included 'not important at all', 'somewhat important', 'very important' and 'do not know'. The figure shows the percentage of 'very important' responses. PS&amp;E, L&amp;HS and SS&amp;H refer to physical sciences and engineering (N=1245), life and health sciences (N=1270), and social sciences and humanities (N=794) respectively.\n\nFree-text responses varied widely. Of the 382 valid responses, almost half (N=174) expressed that the respondent does not want to encourage preprinting or even opposes preprinting, usually because of the lack of peer review and the low credibility of preprints (e.g., '... I don't think that preprinting before peer-review should be encouraged. I think the risks of media/lay people sharing misinformation are too high and that we should aim to amend the peer review process' , woman from the US working as postdoctoral researcher in the life sciences). Many respondents indicated that better support for preprinting from journals (N=49) is one of the most effective ways to promote preprinting (e.g., ' Consistent policy of journals regarding preprints ' , woman from Germany working as PhD candidate in the social and behavioral sciences; 'Optional preprinting as journal submission process' , man from an unknown country/region working as full professor in physics and astronomy; ' Journal policies need to change ' , genderqueer respondent from the US working as assistant professor in the social and behavioral sciences). In addition, recognition of preprints (N=15) was identified as an important way to encourage preprinting (e.g., ' Forcing recruitment commissions in federal-founded research institutions to count preprints as a publication ... ' , man from France working as postdoctoral researcher in the social and behavioral sciences; ' Recognizing preprints (or working papers that are not just lines on the CV but actually circulable) would encourage the practice ' , man from the US working as assistant professor in the social and behavioral sciences).\n\n## Association with gender and level of experience\n\nWe used ordered-logit regression to analyze how the attitudes of respondents are associated with their gender and their number of years of research experience, in addition to their country/region and their field. The results are reported in the coefficient plots presented in Figs. A2, A3, and A4 in the appendix. Results are shown for the four most important benefits of preprinting, the four most important concerns\n\nabout preprinting and the two most important ways to encourage preprinting.\n\nThe coefficient plots reveal that, other things equal, men on average are less concerned about preprinting than women and tend to be more focused on the benefits of preprinting. To encourage preprinting, researchers with fewer years of research experience on average put more emphasis on the importance of integrating preprinting in journal submission workflows and providing recognition for posting preprints.\n\n\n## 4. Discussion and conclusion\n\n\nWe conducted a survey to investigate researchers' adoption of preprinting and their views on benefits of preprinting, concerns about preprinting and ways in which preprinting can be promoted. We focused in particular on analyzing differences between countries/regions and research areas.\n\n\n## 4.1 Main findings\n\n\nCompared to China and the rest of the world, the US and Europe lead the way in the adoption of preprinting. While reading preprints is more or less equally common in different countries/regions, survey participants in the US and Europe reported a higher familiarity with preprinting and a stronger commitment to posting preprints than their colleagues in China and the rest of the world.\n\nThere are large differences between research areas in the adoption of preprinting. Our survey results show that the adoption of preprinting is strongest in physics and astronomy, followed by mathematics and computer science. It is much weaker in other research areas. Many researchers in these other areas are at least somewhat familiar with preprinting and they occasionally read a preprint, but posting preprints is less common for them.\n\nSurvey participants perceived the free accessibility of preprints for readers as the most important benefit of preprinting. Speeding up research communication was seen as another major benefit. Respondents identified being free to post, getting additional exposure and establishing priority as other significant benefits of preprinting.\n\nSurvey participants in different countries/regions and different fields show substantial differences in their concerns about preprinting. Low reliability and credibility of preprints, sharing results before peer review and premature media coverage of preprints are the most important concerns, raised in particular by respondents in the life and health sciences and especially by US respondents. Compared to respondents in other countries/regions and other fields, respondents in China in the life and health sciences expressed strong concerns about the lack of recognition for posting preprints and the risk that researchers who post preprints may get scooped.\n\nIntegrating preprinting in journal submission workflows was identified as the most important way to promote preprinting. Providing recognition to researchers for preprinting their work is another important way in which preprinting can be encouraged, emphasized in particular by respondents in China and respondents in the social sciences and humanities.\n\n\n## 4.2 Recommendations\n\n\nOur survey results show that researchers have mixed opinions on preprinting. Some are strong proponents of preprinting. Others are generally supportive, but have practical concerns, for instance about the lack of integration in journal workflows or the lack of recognition for preprinting. There are also researchers that have more fundamental concerns, for instance because they fear that sharing results before peer review may be harmful.\n\nPreprinting is an important element in the broader open science agenda that is currently receiving considerable attention in many countries, both from researchers and from science policy makers. Widespread adoption of preprinting would be a major step in the transition to more open ways of doing science. However, to promote preprinting, the concerns that researchers have need to be taken seriously. To address these concerns and to encourage researchers to preprint their work, we make the following recommendations based on the results of our survey:\n\n- 1. Integrating preprinting in journal submission workflows. The importance of integration of preprinting in journal submission workflows is emphasized by researchers in all countries/regions and all fields. This integration is therefore likely to offer a powerful mechanism to promote preprinting, and in some cases it may even enable journals to mandate preprinting.\n- 2. Developing new approaches for quality assurance and peer review of preprints. Some of the negative attitudes toward preprinting stem from concerns about the reliability and credibility of preprints, as preprints typically have not been peer-reviewed. However, preprinting also enables innovative new approaches to quality assurance and peer review (Avissar-Whiting et al., 2023; Polka et al., 2023). To address concerns about the reliability and credibility of preprints, investments in these new quality assurance approaches should be made.\n- 3. Providing recognition to researchers for preprinting their work. Research institutions and research funders should recognize and reward researchers for preprinting their work. This is especially important for early-career researchers.\n- 4. Providing guidance to researchers on citation practices and copyright issues in relation to preprinting. Citing preprints should be normalized, with clear guidance on appropriate citation practices (Berg et al., 2016). In addition, it should be made clear to researchers that they own the copyright of their papers, at least as long as they do not hand it over to a journal. Journals should clearly inform authors about their policy with respect to preprinting (Klebel et al., 2020).\n\n\n## 4.3 Limitations\n\n\nAn important limitation of our study is that our survey results may overestimate the level of support for preprinting. Researchers who are familiar with preprinting and have a positive attitude toward it may have been more likely to complete our survey. We received seven emails from researchers informing us that they decided not to participate in the survey because of their lack of knowledge of preprinting. Another limitation is that senior researchers with extensive research experience are overrepresented among our survey respondents. Survey invitations were sent to\n\ncorresponding authors of papers, resulting in an overrepresentation of senior researchers.\n\nWhile our primary focus has been on regional and disciplinary differences regarding preprinting, future studies could explore differences between early-career researchers and more senior researchers. A deeper analysis of differences between countries or organizations with different infrastructures, policies, and research cultures would also be of major interest.\n\n",
         "Open science is receiving widespread attention globally, and preprinting offers an important way to implement open science practices in scholarly publishing. To develop a systematic understanding of researchers’ adoption of and attitudes toward preprinting, we conducted a survey of authors of research papers published in 2021 and early 2022. Our survey results show that the US and Europe lead the way in the adoption of preprinting. US and European respondents reported a higher familiarity with and a stronger commitment to preprinting than their colleagues elsewhere in the world. The adoption of preprinting is much stronger in physics and astronomy as well as mathematics and computer science than in other research areas. Respondents identified free accessibility of preprints and acceleration of research communication as the most important benefits of preprinting. Low reliability and credibility of preprints, sharing results before peer review and premature media coverage are the most significant concerns about preprinting, emphasized in particular by respondents in the life and health sciences. According to respondents, the most crucial strategies to encourage preprinting are integrating preprinting into journal submission workflows and providing recognition for posting preprints.",
         ""
        ],
        [
         "21",
         "21",
         "## INTRODUCTION\n\n\nMany of the biggest questions faced by European society today are ones that are intrinsically social and cross-border.  How can we develop an economy that is ecologically sustainable? How can we reduce inequalities and improve the opportunities of all members of society? How can we ensure that technological shifts in how we communicate bring us closer together and not push us further apart?\n\nBecause of these questions and many more, it is an exciting time to be a social scientist. New data, methods, tools and computational resources are opening up new lines of enquiry every day. But with  these  innovations  come  challenges  on  how  to  apply  new  methods  rigorously,  to  judge  new data  forms  ethically,  and  to  ensure  the  sustainability  of  our  tools  and  computational  resources. Because of the immediacy of these opportunities and the scale of these challenges, it is more vital than ever that we see greater investment in European Social Science Infrastructure.\n\nSocial Science Infrastructure will allow us to make use of the opportunities of new data, methods, and tools whilst also rising collectively to the challenges that they pose. Scale and interoperability are  needed  to  achieve  this,  and  efforts  that  are  concentrated  at  the  national  level  or  in  specific domains  will  not  be  sufficient.  These  challenges  stretch  across  European  Society  and  permeate every domain of social science. We must invest in a better understanding of human society before it's too late.\n\nTo  achieve  this  it  is  vital  that  we  develop  a  strategy  that  reflects  how  much  we  have  already achieved, how we can build on these successes, and how we can better align the investments in European  Social  Science  Infrastructure  with  the  needs  of  the  scientific  community.  In  this  white paper  we  set  out  what  such  a  strategy  could  look  like  and  bring  these  together  in 7  clear recommendations for the future development of European Social Science Infrastructure.\n\nThese  recommendations are  guided  by  widely  held  commitments  to  open  science  as  well  as  the FAIR  and  FACT  principles.  We  also  recognize  that  there  are  many  exceptional  elements  in  the European landscape, including the European Open Science Cloud and Social Science and Humanities Open Cluster. In drafting these recommendations, we seek to build on these successes, to enhance and complement their existing sizeable impact.\n\nThis white paper is not an endpoint. Instead, we hope it is the start of a broader discussion on what European  Social  Science  needs  in  order  to  meet  these  grand  societal  challenges.  We  appreciate engagement and feedback of all forms.\n\n<!-- image -->\n\n\n## RECOMMENDATION #1: CREATE A PAN-EUROPEAN PANEL SURVEY\n\n\nA  pan-European  probability-based  online  panel  should  be  created  that  covers  all  countries,  is conducted monthly, enables modularity, and includes the integration of other platforms for nonsurvey-based experiments and data donation.\n\nThe panel should be available to researchers through a) an open, excellence-based grant system, and b) a paid basis of access to generate revenues.\n\nThe  panel  would  also  provide  access  on  a  paid  basis  to  the  European  Commission  and  national governments  to  supplement  the  functionality  of  Eurobarometer  and  offer  higher  scientific standards.\n\nThe panel would be designed in the same form as current national online panels such as the GESIS Panel, ELIPSS Panel, and LISS panel which have already demonstrated the high level of demand for such  data  collection  facilities.  For  the  offline  population,  specific  support  would  be  provided  to enable their participation as is the case in the UKLHS, CRONOS, and many other online surveys.\n\nThe  panel  could  also  serve  as  the  basis  for  or  complement  to  the  existing  European  Survey Infrastructures,  including  the  European  Social  Survey,  the  European  Values  Study,  GUIDE  and  the Generations  and  Gender  Programme.  It  would  be  based-off  a  centralized  system  operated  via  a single site, like the service provided by Centerdata in the implementation of the Survey of Health, Ageing, and Retirement in Europe.\n\nSuch an online panel would, for the first time, offer 'beam-time' to early career researchers looking to field their own survey items and experiments to a high-quality, pan-European panel. This would greatly democratize, accelerate innovation, and improve the openness of European Social Science.\n\nAll data collected in the panel would be open to verified researchers using a lightweight and simple access procedure.\n\nSuch a panel would revolutionize the field of Social Science and allow researchers to collect highquality data on pertinent social issues rapidly. This was exemplified during the pandemic when such panels  enabled  researchers  to  understand  life  during  lockdown  and  vital  issues  such  as  vaccine hesitancy.\n\nA European Online Panel would allow Social Scientists to keep their finger on the pulse of Europe.\n\n\n## RECOMMENDATION #2: ESTABLISH A EUROPEAN INTERNET OBSERVATORY\n\n\nMuch  of  the  data  infrastructure  in  Europe  at  the  moment  is  designed  to  support  data  directly collected  by  scientists  such  as  survey  data.  However,  the  social  sciences  have  been  radically transformed over the past 20 years by the increasing availability of social media data and digital trace data for the study of human behaviour.\n\nDespite this growth, the recent Twitter API shutdown has had dramatic consequences for existing research agendas and the social science community's dependence on these platforms collaborations has been exposed.\n\nEurope poses a unique competitive advantage provided for through GDPR and the Data Governance Act with which to respond to this. European Data Legislation ensures that all individuals must be able  to  access  a  digital  download  package  in  a  machine  readable  format  which  provides  a transparent,  legally  grounded,  and  scalable  way  for  data  to  be  collected  on  individuals  via  'data donation'.\n\nThe software, expertise and infrastructure needed to coordinate, harvest, and collate these data donation efforts are currently a vast unmet need of the social science community. The demands for this  infrastructure  are  evident  from  infrastructures  such  as  SoBigData  Europe  and  MeDem  which seek  to  combine  data  from  a  wide  variety  of  sources.  However,  these  projects  do  not  offer infrastructure for collecting and harmonizing this data directly.\n\nThis  trend  in  the  use  of  social  media  and  digital  trace  data  is  reflected  in  significant  large  scale investments  at  the  national  level  such  as  the  Leibniz  Associationsupport  for  the  creation  of  the Digital Behavioural Data Pillar at GESIS and the ESRC investment in Smart Data Research UK. These groundbreaking  national  initiatives  need  to  be  better  coordinated  and  integrated  with  existing infrastructures and to engage with the social media platforms that are the source of this data.\n\nJust as cross-national surveys have been developed to examine social questions at the European level, it is vital for a digital Europe to have a European Level research facility. We refer to this facility as  the  European  Internet  Observatory  in  reference  to  the  National  Internet  Observatory  in  the United States which uses a data donation framework to monitor the online behaviour of thousands of volunteers.\n\nWe  propose  that  a  similar  facility  be  developed  for  Europe,  and  specifically  one  that  seeks  to integrate digital trace data across borders and align data sources so that research can focus on the European dimension to these questions in compliance with GDPR. A single facility is vital in this area as  trust  is  vital  to  the  concept  of  data  donation,  and  visible,  established,  and  clearly  signposted facilities  make  this  process  more  transparent  and  trustworthy.  We  would  also  strongly  urge  that such a facility be closely aligned with existing and future survey infrastructures so that digital trace data  can  be  collected  in  these  infrastructures,  connected  to  high-quality  survey  data,  and  the broader impact of online life be better understood.\n\n<!-- image -->\n\nCOMPUTATION\n\nPAGES 6-7\n\n\n## RECOMMENDATION #3: INVEST IN AN INTERNATIONAL DATA ACCESS NETWORK\n\n\nSocial scientists regularly encounter computational constraints, especially when dealing with large scale and complex datasets. However, the primary challenge for social scientists is not in sourcing computational resources but ensuring that these computational resources comply with the security standards of existing national and European Legislation.\n\nThis  has  led  to  the  wide  scale  development  of  'Trusted  Research  Environments'  (TREs).  These environments  allow  researchers  to  conduct  their  analysis  on  a  virtual  machine  which  can  be resourced with a very large amount of computational power as well as the required data and tools.\n\nIn the life sciences, the personal data in question is clinical data provided by hospitals, other health care practitioners, and public health data providers. In the social sciences there is a greater reliance on the use of TREs is in combination with administrative data and generally provided via a National Statistical Office.\n\nThis  means  that  the  social  science  infrastructure  for  TREs  is  almost  exclusively  developed  at  the national level,  and  there  is  currently  very  limited  standardization  in  the  implementation  of  these TREs  across  National  Statistical  Offices.  The  largest  initiative  in  this  area  comes  from  the International  Data  Access  Network  (IDAN).  However,  this  is  sustained  directly  by  just  five  data providers and does not have a framework for interoperable TREs that align with EOSC initiatives such as Entrust.\n\nWe  recommend  that  IDAN  be  radically  scaled  up  and  to  provide  TREs  that  are  recognized  as trustworthy  by  a  large  number  of  member  states.  This  could  include  providing  infrastructure  for commercial and non-governmental organizations willing to provide secure research access to data they possess. This would not only increase the access to data for researchers but would also enable cross-national research with such data. Eurostat already provides a framework for the harmonization  of  administrative  data,  but  this  could  be  expanded  and  better  supported  by  a network of TREs with a specific focus on supporting research.\n\nInvestments in IDAN would have two crucial benefits for the European Research Area. Firstly, they would enrich the existing ERICs and complement survey data collection investments. It is currently possible to link SHARE data to administrative data in eight countries, but it is currently impossible to analyse this data across the eight countries simultaneously. This does not have to be the case.\n\nSecondly,  TREs  are  pervasive  in  the  North  and  West  of  Europe  with  the  UK,  Sweden,  Norway, Finland, Denmark, and the Netherlands being the leaders in this field. However, this infrastructure is flexible and transferable. National Statistical Offices in the South and East of Europe could utilize this  network  without  the  high  initial  investments  in  infrastructure.  The  creation  of  a  robust  and flexible TRE network would therefore represent a radical transfer of resources from the North and West to the South and East and enrich the whole of the European Research Area.\n\n<!-- image -->\n\n\n## RECOMMENDATION #4: CREATE PROFESSORIAL CHAIRS TO SUPPORT FAIR\n\n\nSince the FAIR data principles were set out in 2016 (Wilkinson et al., 2016), there has been a large amount of activity and investment in ensuring that data across the sciences is FAIR and machineactionable. The social sciences are no different.\n\nThe  European  Social  Sciences  are  exceptionally  lucky  as  CESSDA,  the  European  consortium  of national data archives, provides a natural home for the implementation of FAIR within the field. This has not been the case in many other fields, and this is reflected in CESSDA's flagship role in many European  FAIR  Initiatives.  CESSDA  leads  the  SSHOC-EU  community  and  helps  to  address  FAIR implementation  issues  specific  to  social  science  data  providers  and  as  the  necessary  expertise across its network to drive this change.\n\nHowever, as with many other fields of research the key challenge in the social sciences is engaging the research community in the FAIRification of existing vocabularies and ontologies so that they can be  used  to  enrich  and  link  data  from  across  the  domain.  As  a  matter  of  fact,  many  of  these vocabularies and ontologies are widespread in the field in the form of codebooks and classifications. Yet  they  lack  machine-readable  representations  and  proper  identifiers  for  terms.  Therefore  a disconnect remains between FAIR infrastructure and the community of data providers and scientists that are actively conducting research. To fill this gap, leaders in the field need to be supported in coordinating and enacting the FAIRifciation of their field.\n\nCESSDA  has  set  itself  the  goal  of  developing  its  strategic  partnerships  with  the  Social  Science Research  Community  by  2027  but  the  commitment  from  the  Research  Community  itself  is  more ambiguous  and  within  the  research  ecosystem  itself,  FAIR  remains  an  unfunded  mandate  for scientists collecting or analyzing data. The recruitment of data stewards in this area only goes some way  to  solving  this  issue  as  these  positions  are  often  classified  as  support  rather  than  scientific positions.\n\nTo  correct  the  imbalance  and  asymmetry  in  the  commitments  to  FAIR  implementation  we recommend  that  scientific  associations  and  universities  support  and  encourage  the  creation  of Chairs that are dedicated to leading FAIR implementation for specific domains.\n\nThese  FAIR  Leaders  would  be  responsible  for  ensuring  that  their  field  not  only  generates  new knowledge but also does so in a way that is FAIR and machine-actionable. By establishing only a few laureates  across  Europe,  the  profile  for  FAIR  implementation  work  in  the  scientific  community would  be  greatly  elevated  and  would  reaffirm  that  a  commitment  to  FAIR  is  a  commitment  to science.\n\nThese Chairs would allow their host institutions to take a leading role in the strategic partnerships that CESSDA seeks and help make FAIR a reality for the domain.\n\n<!-- image -->\n\nSOFTAWARE\n\nPAGES 10-11\n\n\n## RECOMMENDATION #5: CREATE A NETWORK OF EXCELLENCE FOR SOCIAL SCIENCE SOFTWARE\n\n\nThe explosion and diversification in the data available to social scientists only represent part of the challenge faced by researchers today. As well as ever-changing and evolving data, the tools used to analyze that data and the models that are generated from that analysis are also ever-changing, and currently, the Social Science community is relatively underdeveloped in coordinating and managing these rapid changes.\n\nThe maintenance of crucial R, Python, or Julia packages, upon which a whole sub-field can rely, is often entirely left to the goodwill of the original developer. There is little support and coordination for this work and in time this will erode the replicability and standardization within the field at a time when continuity is crucial. Even in instances when a tool or model is heavily supported from an institutional  perspective,  the  broader  alignment  and  integration  across  the  community  is  not actively promoted and it is left to the resources of individual institutions to support vital elements of social science infrastructure. A crucial example of this is EUROMOD.\n\nEUROMOD is a model of tax and benefit systems of the European Member States that can be used to produce policy simulations and help policy-makers better understand the impacts of fiscal policy. It is, however, sustained by the Joint Research Center of the European Commission. It is a powerful tool for the research community, but the development of features that would be of benefit to the wider research community, such as a Python or R package, remain out of the purview of EUROMOD given that these developments are not a priority for the JRC.\n\nThere are many similar examples, and most codebases in the social sciences have access to far fewer resources  than  EUROMOD.  For  example,  the  Comparative  Panel  File  is  an  open-source  codebase that harmonizes the Longitudinal Panel Studies from across the globe. It is a wonderful idea and resource,  but  it  will  need  to  be  maintained,  developed,  extended,  and  integrated  within  wider initiatives  as  they  develop.  Part  of  the  challenge  here  is  that  these  tools  and  models  are  often developed by scientists who are not equipped with the training and capacities to build sustainable software  that  is  relatively  future-proof.  Many  of  the  first  developers  of  such  tools  are  also  now heading towards retirement and there is a sustainability crisis developing for many of these tools.\n\nTo address these challenges we propose a network of excellence for the development, deployment, and  maintenance  of  research  software  in  the  social  sciences.  There  is  already  an  International Research Software Engineers community that coordinates efforts across domains. We argue that a specific network is needed, however, that is explicitly focused on the challenges faced by the social sciences.  Specifically,  this  network  should  1)  attempt  to  coordinate  efforts  in  the  development, maintenance, and archiving of software and tools in the social sciences, 2) Train PIs of projects that generate software and tools in Software Development Skill sets, 3) Act as a host of last resort as the first  great  generation  of  software  developers  in  the  social  sciences  heads  towards  retirement. Europe has a large amount of pre-existing expertise in this area at places such as GESIS, the UKDA, FORS,  and  SoBigData  Europe.  These  efforts  should  be  brought  together  in  this  network  of excellence.\n\n<!-- image -->\n\nEXPERTISE\n\nPAGES 12-13\n\n\n## RECOMMENDATION #6: ESTABLISH AN EU-WIDE CSS GRADUATE SCHOOL\n\n\nThe speed of developments with regard to data, methods, and tools available to social scientists can be  both  intimidating  and  exhilarating  for  young  scholars  starting  to  conduct  their  first  research projects.  However,  the  biggest  constraint  on  the  uptake  and  utilization  of  these  opportunities  is training and access to the right knowledge resources.\n\nYoung  scholars  today  not  only  need  to  familiarize  themselves  with  sociological,  economic,  or sociological  theory  they  also  have  to  absorb  a  fast-changing  range  of  advanced  methods  such  as machine learning, neural networks, and natural language processing. This has always been one of the exciting challenges of a career in science but these new methods increasingly require scholars to develop skill sets in areas that draw  heavily from other departments, such as software development, complex data management, data governance, or computational resource management.\n\nThese skill sets are hard to access and develop amongst young social scientists, and they are largely left to their own devices when it comes to translating and applying these. Even the most advanced computational social science faculties in Europe struggle to provide sufficient training and expertise in the eclectic and diverse range of methods that are required in modern social research.\n\nEurope does, however, have a rich Erasmian tradition that can help address this by supporting the mobility of young social science scholars and providing the opportunities to access the expertise and  training  required.  The  European  Consortium  of  Sociological  Research  and  the  European Consortium  for  Political  Research  already  offer  graduate  courses  on  advanced  topics,  and  the European  Doctoral  School  of  Demography  provides  first  year  PhD  Students  with  the  eclectic technical  skills  needed  to  conduct  cutting-edge  demographic  research.  There  are  also  a  range  of excellent  methods  for  summer  schools  and  trainings  such  as  the  Essex  Summer  School,  UPF, Ljubljana, and the Summer Institute for Computational Social Science.\n\nThere are however significant gaps in training, specifically in skills that will help develop the field more  broadly.  These  include  basic  skills  in  FAIR  data  management,  project  management  and development,  science  communication,  advocacy,  and  legal  and  ethical  dimensions  of  research. Infrastructures such as CESSDA and SoBigData have made efforts in this area but broader support and coordination is needed.\n\nWe propose to strengthen and extend these current initiatives through the creation of a European Computational  Social  Science  Graduate  School.  This  Graduate  School  would  aim  to  provide  fully accessible courses that provide ECTS accredited training by leaders in their respective fields. These courses could be integrated with and extended from existing offerings but with a view to provide greater interdisciplinarity, clearer accreditation, and greater capacity. The European Doctoral School for Demography provides a model for how this could be developed and implemented.\n\n<!-- image -->\n\nGOVERNANCE\n\nPAGES 14-15\n\n\n## RECOMMENDATION #7: BUILD A FEDERATED EUROPEAN INFRASTRUCTURE CONSORTIUM FOR SOCIAL SCIENCE\n\n\nThe fault line that runs through the previous challenges is the relationship between research and research  infrastructure.  With  all  research  infrastructures,  it  is  vital  that  they  lead  the  research community by implementing new technologies, enabling new methods, and providing access to new data. Ultimately however, research infrastructures must be responsive and accountable to the field which they serve.\n\nCurrently within the European Framework, this connection is often lost. FAIR investments are made only  in  infrastructure  and  so  the  research  initiatives  are  lacking.  Large-scale  data  collections  are created and then isolated from the research community they were designed to serve. New tools and methods are enabled, but a lack of coordination with Universities and training centers mean that the  research  community  is  ill-equipped  to  exploit  them.  These  investments  are  of  exceptional valuable but far more could be gained from them with greater coordination and alignment across the social sciences.\n\nThis issue is in large part due to the design of ERICs themselves, as funding agencies and ministries constitute the board of these organizations and are rarely best placed themselves to judge whether an  infrastructure  is  meeting  the  needs  of  scientists.  This  is  generally  why  funding  agencies  send funding applications out for peer review rather than evaluating them themselves. In ERICs however, funding agencies are ultimately responsible for evaluating performance.  This represents a considerable  asymmetry  in  scientific  knowledge  between  the  team  running  the  ERIC  and  those evaluating  the  performance  and  the  scientific  aims  of  the  ERIC  are  therefore  largely  set  by  the executing team.\n\nWe  propose  to  fix  this  misalignment  through  the  creation  of  a  Federation  of  European  Social Science  Infrastructures.  This  Federation  will  be  constituted  by  two  sets  of  organizations.  On  one side it will include infrastructures or service providers and specifically the Social Science ERICs and ESFRI members: ESS, SHARE, CESSDA, GGP, GUIDE, SoBigData Europe and any future social science infrastructures within the ESFRI framework. On the other side, there would be field organizations and specifically any European wide organization with more than 2,000 paying members from at least 20  countries.  Examples  of  such  organizations  include  but  are  not  limited  to  the  European Consortium  for  Political  Research,  European  Consortium  for  Sociological  Research,  the  European Association for Population Research, the European Economic Association, the European Federation of Psychologists Association, the European  Survey  Research  Association  and  the  European Communication Research and Education Association.\n\nThese field organizations would pay a small membership fee to be part of the Federation and in return would be able to nominate a member of a small Federal Council. This Federal Council would then be responsible for the evaluation and coordination of European Social Science Infrastructure in Europe, ensuring that Research Infrastructure serves the needs of scientists and leads to ground breaking research. This would alleviate the burden on national funding agencies of evaluating ERICs and would make the investments in European Social Science Infrastructure accountable to the field.\n\n",
         "Building on the achievements of recent years and envisioning a stronger alignment between the needs of the research community, we offer 7 clear recommendations for developments in Data, Computation, FAIR, Tools, Expertise, and Governance. Greater investments in European Social Science Infrastructure will make use of the opportunities of new data, methods and tools whilst also rising collectively to the challenges that they pose, harnessing the power of this ongoing data revolution. The challenges we face, such as climate change, ethical AI, misinformation, and population ageing, all have an international character. This white paper has been prepared by Tom Emery, Kasia Karpinska, Angelica Maineri and Lucas van der Meer and is open to comments, contributions, and co-authorship. We are aiming to collate the infrastructural needs of the European Social Science community in a coherent plan. If we have made errors, omissions, or misrepresented these needs the we would be very happy to correct this. All comments and contributions can be sent to tom@odissei-data.nl and will be very gratefully received.",
         ""
        ],
        [
         "22",
         "22",
         "## 1. Introduction\n\n\nPopulation forecasts at the intraurban levels are widely used by local governments for future spatial planning, including housing, service provision, infrastructure, and policy developments. They are also useful for businesses to assess the size of potential markets, influencing investment decisions. For example, population forecasts assist local governments and housing developers to anticipate future dwelling demand. They are also useful to strategize the optimal locations for hospitals and schools, and  design  roads  and  public  transport  infrastructure.  Additionally,  population  forecasts  can  be included as input data in models to estimate future consumption of natural resources, including water and energy, and environmental impacts, such as waste production or pollution. Population forecasts have many important uses at the intraurban level, though they are typically constrained to national and regional scales. Small area population forecasts remain problematic despite efforts to improve existing approaches and develop new ones (see Wilson et al., 2022).  Thus, there is a discrepancy between the importance of population forecasts at the intraurban level and the applicability of stateof-the-art forecast methods at this territorial scale.\n\nMost population forecast methods are developed for broad geographic units, which have benefited from more research (Booth, 2006; Mazzuco &amp; Keilman, 2020). For instance, the cohort component model is often unsuitable at the intraurban level (Wilson et al., 2022). It requires detailed data on population, fertility, mortality and migration with temporal and spatial granularity, which are usually not  available  below  the  regional  level.  Additionally,  residential  mobility  must  be  considered  as another component of population change, which is more complex and volatile than other demographic components. It responds to various of factors which are difficult to predict, such as urbanisation, housing  developments,  and  gentrification  (Mulder,  2002;  Ding  et  al.,  2016).  Small  area  forecast methods have undergone little development, particularly in the Global South, since most population forecasts for small areas were undertaken in the Global North. Thus, there is a modest size in the literature  on the topic and the need for more research to produce small area population forecasts (Wilson et al., 2022), especially at the intraurban level in developing countries.\n\nIn  this  paper,  we  use  annual  data  from  the  WorldPop  Open  Population  Repository  and  ARIMA models to forecast population by age-group in the municipalities of Greater Mexico City, the seventh largest metropolitan area in the Global South. ARIMA models have been widely used as a forecast technique, but rarely applied to population forecast at the intraurban levels, despite showing low error levels and short confidence intervals when input data have consistent linear or exponential trends (González-Leonardo et al., 2023 &amp; 2024), such as population trends over time. To date, only two case studies for Australia (Athukorala et al., 2010) and the United States (Walters &amp; Cai, 2009)  have produced population forecasts with ARIMA in small areas. We aim to prove the suitability of ARIMA models to forecast population at the intraurban level. To do so, we evaluate forecast errors of ARIMA by forecasting the period 2011-2020 using 2000-10 data as an input, and compare these estimates with actual counts for the same years. We test forecast errors for the total population and populations by age-groups 0-14, 15-39, 40-64 and 65+ in Greater Mexico City, and for the total population and populations by the same age-groups in the 76 municipalities of Greater Mexico City. Specifically, we aim to address the following research questions:\n\n1) How accurate are ARIMA models to forecast population in Greater Mexico City?\n\n- - We expect small errors when forecasting the total population, which may increase over time. We also hypothesize small errors in population forecasts by age-groups.\n\n- 2) How accurate are ARIMA models to forecast population in the municipalities of Greater Mexico City?\n- - We anticipate small errors when forecasting the total population in most municipalities, but higher errors in population forecasts by age-group, which may probably increase over the forecast period.\n\nThe rest of the paper is structured as follows: we next present a brief literature review on methods to produce small area population forecasts; we explain the data and methods used for this study; we present the results, first, including forecast errors for the total population and populations by agegroup in Greater Mexico City and, second, for the total population and populations by age-group in the municipalities of Greater Mexico City, selecting specific results for the largest 20 municipalities; finally, we discuss our results and potential implication.\n\n\n## 2. Literature review\n\n\nPopulation forecasting approaches for small areas remain underdeveloped despite recent efforts. For example, we can find studies where various methods are implemented to forecast population in small areas:  extrapolative  models  (e.g.,  Walters  &amp;  Cai,  2008;  Smith  et  al.,  2013);  simplified  cohortcomponent approaches (e.g., Baker et al., 2017 &amp; 2021; Hauer, 2019); model averaging (Goodwin, 2009; Thomasen, 2015); incorporation of sociodemographic variables and spatial relationships (e.g., Chi, 2009; Voss, 2011); housing-led population projections (e.g., Hauer et al., 2015; Swanson &amp; Tayman, 2021); downscaling approaches (e.g., Boke-Olén et al., 2017; Breidenbach et al., 2019); microsimulation  (e.g.,  Ballas  et  al.,  2005;  Marois  &amp;  Bélanger,  2014);  machine  learning  (e.g., Grossman et al., 2023; Newsham et la., 2024); estimating and projecting small area component input data (e.g., Simpson &amp; Snowling, 2011; de Beer, 2012). In most of these methods, however, forecast accuracy and uncertainty levels were not explored, since authors did not perform a  retrospective forecast to assess accuracy, and approaches were often deterministic which do not typically provide uncertainty. Forecasts in small areas tend to present higher errors than those from forecasts at regional and  national  levels,  which  usually  increase  when  population  size  decrease  and  over  the  forecast horizon (Rayer, 2008; Wilson &amp; Rowe, 2011, Wilson et al., 2018).\n\nExtrapolative models usually consist in linear or exponential extrapolations and are generally applied to forecast population totals. They are based on past trends, require minimum input data and simple calculations.  They  tend  to  be  more  accurate  than  other  methods  in  short-  and  medium-horizons (Wilson et al., 2023). Smith et al. (2013) and Wilson et al. (2015) produced retrospective small area forecasts for population totals over 10 years using several extrapolative models, and compared these estimates to actual counts in Australia, New Zealand, England and Wales. The author found mean errors between 4.6% and 22.1%. Time-series models, including ARIMA, are a type of extrapolative models. Athukorala et al. (2010) used ARIMA models to forecast the total population in small areas within the Australian state of Queensland, although the author did not provide any measure of forecast errors. Walters &amp; Cai (2008) evaluated the accuracy of linear, exponential and ARIMA model using retrospective forecasts of 5, 10 and 20 years for local areas in the USA´s state of Virginia. The authors found errors of 1.6% in a 5-year horizon, 5.1% in a 10-years horizon, and 13.9% in a 20-years horizon.\n\nThe simplified cohort-component method, known as the Hamilton-Perry model, allows to project population by cohort using a cohort change ratio, and do not require input data on fertility, mortality and migration  (Hamilton &amp; Perry,  1962). Most  application  of  this  method  were  used  to  forecast population in small areas across the United States (e.g., Baker et al., 2017 &amp; 2021; Hauer, 2019).\n\nBaker et al. (2021) tested the Hamilton-Perry model for US municipalities in a retrospective forecast by age and sex for the period 2000-10. The authors found mean forecast errors about 20% for the total population, and between 20.1% and 43.4% in forecasts by age and sex. There are some variants of the simplified cohort component model. For instance, Wilson (2016) evaluated several models to forecast the total population and populations by age for small areas across Australia, including the standard  Hamilton-Perry  model  and  a  version  constrained  to  total  population  forecasts  from  an extrapolative model. The former returned a mean error of 9.0% for the total population in a 10 yearshorizon, and the latter gave an error of 6%. The constrained version produced slightly better forecasts by age than the unconstrained one, between 5% and 15% depending on the age group, with the highest values  generally  among  children  and  young  adults.  Surprisingly,  the  constrained  model  returned higher error in old ages, totalling 15%, while the Hamilton-Perry model did not.\n\nModel averaging consists in combining output from different forecast models. This approach tends to reduce errors, since it incorporates a wide amount of information from various models, and errors in different directions from individual models compensate each other (Rayer, 2008; Goodwin, 2009; Rayer and Wang, 2020). For example, Rayer (2008) produced retrospective forecasts for the total population of counties across the United States using five methods. They found that the average of these methods displayed the lowest errors, with values over 9-10% in a 10-years horizon. Reinhold &amp; Thomasen (2015) combined different model to carried out a 10-years retrospective forecast in small areas across the German region of Lower Saxony. The authors concluded that the average of the models returns slightly lower errors than individual models. A similar result was found by Wilson (2015) in forecasts for small areas across Australia, New Zealand, England and Wales.\n\nA  few  population  forecasts  in  small  areas  include sociodemographic  variables  and  spatial relationships. Chi (2009) incorporated demographic and socioeconomic variables, and information on land development, transport accessibility and local amenities into a regression model to forecast population  totals  in  a  civil  division  of  Wisconsin,  whose  results  were  compared  to  linear  and extrapolative models. The authors concluded that the former did not outperform the latter. Chi &amp; Voss (2011) tested regression models with spatial lags of population change, social, economic and environmental  variables  in  the  same  minor  division  of  Wisconsin.  The  authors  found  that  these variables did not produce lower errors than extrapolative models. Baker (2014) incorporated spatial weights into a simplified cohort component model. The weighted model retuned a mean error of 5.2% for a retrospective 1990-2000 forecast of New Mexico municipalities, while the unweighted model produced an error of 11.0%.\n\nHousing-led  population  projections  estimate  total  populations  as  the  number  of  household  units multiplied by the rate of occupied housing by usual residents, multiplied by average household size, plus the number of people in institutions. The future number of housing development over a 5-10years  horizon  is  known  with  a  low  degree  of  certainty  Thus,  housing-led  population  projections provide accurate forecasts, although they do not produce estimation by age, only for population totals (Swanson &amp; Tayman, 2021; Wilson et al., 2022). The housing-unit model is often combined with other models. For example, Baker et al. (2008) used a logistic curve to model the household's growth, Hauer et al. (2015) combined it with a linear/exponential model for population forecasting in small areas of the United States, and Dittgen &amp; Dutreuilh (2005) used housing-led projections together with the cohort component method to forecast population in Paris.\n\nForecasts from downscaling approaches come from national forecasts which are disaggregated into small areas. Thus, they are based on macro-scale scenarios. Studies on downscaling used different methods. For example, Breidenbach et al. (2019) applied a cohort-component model to produce population forecasts  by age  and  sex  for  grids  of  1  km   across  Germany,  assuming  country  level 2\n\nmortality rates for all grids, grid-specific fertility rates, zero internal migration, and net international migration distributed according to population size in each grid. Boke-Olén et al. (2017) used data on roads, water, and distance to urban centres to disaggregate IIASA´s population projections at country level  and  create  gridded  population  forecasts  for  Africa.  Kanaroglou  et  al.  (2009)  combined  a multiregional  cohort-component  model  and  a  spatial  multinomial  logit  model,  disaggregating migration data at the small area level by using characteristics of migrant and destinations, such as migrant's age, number of schools, and distance to city centres. Many downscaling models have not undergone accuracy assessments (Wilson et al., 2022).\n\nSmall area microsimulation works at the individual levels, and outputs are aggregated. They are data remanding and include rich output details. Ballas et al. (2005) used a microsimulation model for the Irish  local  economy  to  create  population  forecasts  for  small  areas  across  Ireland.  In  the  model, mortality rates are based on age, sex, and location, and fertility dependents on age, marital status, and location. Internal migration is obtained by randomly sampling from censuses based on age, sex and county, and international migration is excluded from the model. The mean forecast error for the total populations was 6.4% in a 5-year horizon. Marois and Bélanger (2014) applied a micro simulation model to forecast the populations of the municipalities within the Montreal Metropolitan Area in Canada.  The  authors  used  conditional  logistic  regressions  to  distribute  internal  and  international migrants by municipalities, based on population size, population composition, distance to the city centre, geographic location, and the potential of development. The model returned a mean error of 3.4% for total population forecasts in a 5-years horizon.\n\nArtificial  intelligence  (AI)  has  demonstrated  successful  results  in  many  fields.  In  the  context  of population  forecasts,  their  application  is  incipient  with  a  small  community  seeking  on  the  most effective ways to leverage on the advantages of these models. So far, application of AI has resulted in mixed evidence (Wilson et al., 2022). Some research shows that AI may outperform traditional methods. In others, the opposite applies. For example, Makridakis et al. (2018) assessed the accuracy of  different  machine  learning  methods,  including  Long  Short-Term  Memory  (LSTM)  models, Bayesian  Neural  Networks,  and  Regression  Trees,  against  traditional  model,  such  as  ARIMA, exponential methods, and model averaging, to forecast population in small areas. They concluded that traditional methods were more accurate and had lower computational requirements. Forecasting populations  across  small  areas  in  Australia,  Grossman  et  al.,  (2023)  found  that  LSTM  models outperform traditional methods in some cases but not in others, with mean errors of 5.0-5.8% in a 5years  horizon,  and  9.5-11.8%  in  a  10-years  horizon for machine  learning  methods.  Riiman  et  al. (2019) tested LSTM models to forecast the total population of Alabama counties in a 10-year horizon and compared outputs with forecasts from the cohort-component method. LSTM models produced a mean error of 16.7% when they were trained for all counties, while the cohort-component method returned an error of 6.5%. However, LSTM models produced a mean error of 6.3% when they were trained for specific counties. Newsham et al. (2024) tested the accuracy of LSTM models to forecast population across small areas in Europe for a 1-year horizon and got a mean error of 1.3%. Newsham et  al.  (2024)  argues  that  as  we  understand  the  complexities  of  AI  algorithms,  we  will  be  able  to develop and leverage on their multiple advantages to address issues that traditional approaches cannot effectively handle. These include issues, such as handling complex non-linear relationships, capturing long-term  dependencies,  automatic  and  scaling  models  for  multiple  areas  (potentially  global  or regional models), and integrating various types of information, such as text and imagery.\n\nFinally, other way to produce population forecast for small areas consist of estimating and projecting small area component input data. The main challenge of this approach is obtaining reliable data at small area levels and dealing with small counts, mainly in sparely populated units. Thus, many studies which applied this method often used assumptions from larger areas (e.g., mortality and fertility from national or regional levels), standard schedules of migration or data smooths (Simpson &amp; Snowling,\n\n2011; de Beer, 2012; Anson, 2018). There are several methods to estimate demographic component in small areas, including Bayesian statistics which can incorporate various data sources to forecast demographic components within a statistical framework. Schmertmann et al. (2013) created fertility estimates  for  small  areas  in  Brazil  using  Bayesian  methods.  Alexander  et  al.  (2017)  produced mortality estimates for subnational areas in the United States. Leknes &amp; Løkken (2020) used Bayesian statistics to estimate mortality rates, fertility, internal migration and emigration in small areas across Norway. An advantage of Bayesian statistics is that models produce uncertainty measure. However, forecast errors have not been tested by comparing retrospective forecasts to observed data. Forecast methods need to undergo historical validation to test their accuracy (Wilson et al., 2022).\n\n\n## 3. Data\n\n\nPopulation  forecasting  requires  long  and  uninterrupted  time-series  of  input  data.  These  data  are usually problematic for small areas due to the infrequency of data collection in traditional sources, small counts and boundary changes (Wilson et al, 2022). To overcome these challenges, we used annual population estimates from the WorldPop Open Population Repository (https://hub.worldpop.org/geodata/listing?id=65). WolrdPop produce population count estimates by sex and five-year age groups for 100 m 2 georeferenced cells between the years 2000 and 2020. To produce this information, WorldPop disaggregates census data into intercensal estimates and gridded cells using a set of geospatial variables derived from remotely sensed data (Stevens et al., 2015). WorldPop  provides  this  information  for  each  country  in  the  world.  WorldPop  estimates  are particularly useful in countries where there is no annual register data at the small area level, including most developing countries.\n\nWe made use of datasets for Mexico by aggregating population counts from 100 m 2  cells into the municipalities of Mexico using a spatial join. We place an explicit focus on the 76 municipalities of Greater Mexico City (Figure 1). These municipalities include 16 spatial units in Mexico City, 59 in the State of Mexico, and 1 spatial unit in the State of Hidalgo. Large populations and regular trends over time are needed to produce consistent forecasts. Since we work with small areas, populations of five-years  age  groups  were  often  not  large  enough  and  get  regular  trends  over  time.  Thus,  we aggregated  the  five-years  age  groups  into  four  broad  age-groups:  0-14  (children),  15-39  (young adults), 40-64 (middle-aged populations), and 65+ (the elderly).\n\nFigure 1. Conversion from WorldPop population grids into municipalities of Greater Mexico City\n\n<!-- image -->\n\n\n## 4. Methods\n\n\nWe used ARIMA models, a type of extrapolative forecasting method, and input data from 2000 to 2010 to produce annual retrospective forecasts for the period 2010-20 by age-group and sex within Greater  Mexico  City.  We  compared  these  estimates  with  actual  counts  for  the  same  period  and calculated the absolute percentage error between our forecasts and observed data. First, we produced specific forecasts for the total population in the México City Metropolitan Area, and populations by age-group. Then, we produced municipality-specific forecasts of population totals, and municipalityspecific population forecasts by age-group.\n\nARIMA models include three components: an autoregressive (AR), a moving average (MA), and an integrated (I) component. These elements capture the long-term, stochastic and short-term trends of a time-series, respectively. The AR and MA components control for temporal autocorrelation in a time-series from two mechanisms. The first mechanism assumes that a variable ( Y ) at time t ( Yt ) is explained by its past values ( Yt-1 , Yt-2 , ⋯ , Yt-p ). The second mechanism considers Yt as a function of current and past moving averages of error terms ( ut-1 + ut-2+ ⋯ +ut-q ), and current deviations from the mean depends on previous deviations. A general ARMA ( p, q ) model takes the form of:\n\n<!-- formula-not-decoded -->\n\np and q denote the order of the autoregressive and moving average components, respectively. Fitting a time series in a model containing AR and MA parameters requires the data to be weakly stationary. Weakly stationary is characterized by constant mean and variance of Yt over time, and the covariance of Yt to be time-invariant. It means that the covariate only depends on the lag between current and past values, and not the actual time at which the covariance is computed (Hyndman &amp; Athanasopoulos 2018). However, weak stationarity data in time-series is rare. They must be integrated ( ), and time I series must be differentiated to be stationarity. Therefore, its statistical properties (mean, variance, and  autocorrelation)  are  constant  over  time.  Equation  (1)  can  be  modified  to  represent  a  general ARIMA ( p, d, q ) model:\n\n<!-- formula-not-decoded -->\n\nwhere: yt = Yt - Yt-1 for a first order differencing model, and d denotes the degree of first differencing.\n\nWe used the specification ARIMA ( 0, 2, 0 )-Random Walk with Drift because it was identified as the best fit for 92.5% of observed 2000-2010 trends based on a combination of model selecting tools. Specifically, we used unit root tests to assess for stationarity and the Akaike Information Criterion to determine the appropriate order of autoregressive, moving average, and differencing terms. Models were estimated using maximum likelihood. Results include 95% confidence intervals (CIs) of the forecasts. Our analysis is conducted in RStudio, using the packages tseries, forecast , and astsa .\n\nAs above, we evaluated the accuracy of ARIMA by comparing the absolute percentage error between retrospective  2011-20  forecasts  and  observed  population  counts  for  the  same  period.  In  the  first subsection of the results, we present forecast errors for the total population and populations by agegroup in Greater Mexico City using line plots. In the second section, we display forecast errors for population totals and populations by age-groups in the 76 municipalities of Greater Mexico City using a combination of box and violin plots. Then, we show specific forecast errors for population totals and populations by age-group in the largest 20 municipalities of Greater Mexico City.\n\n\n## 5. Results\n\n\n\n## Assessing the accuracy or ARIMA population forecasts for Greater Mexico City\n\n\nFigure 2 presents 2011-20 ARIMA forecast errors for the total population in Greater Mexico City (Panel A), and a comparison between observed and forecasted counts (Panel B). ARIMA models return low error levels over the forecasted horizon, from &gt;-0.1% in 2011 to -3.1% in 2020. There is almost no change between forecasted and observed populations during the first years of the period. In 2020, ARIMA forecasts 22.1 million inhabitants and actual figures were about 22.7 million, being within the upper CI of ARIMA. Thus, forecasts slightly underestimate population growth in Greater Mexico City. This may be explained by the fact that actual population growth in 2011-20 was greater than  that  of  the  period  2000-10,  which  was  used  by  ARIMA  as  an  input  to  produce  population forecasts in 2011-20.\n\nFigure 3 displays population forecast errors by age-group in Greater Mexico City (Panel A), and a comparison between observed and forecast populations (Panel B). Forecast errors are very low among age-groups 0-14 and 15-39. In the former, errors are close to 0 over the forecast horizon, except in 2019 and 2020, when values reach -1.2% and -2.1%, respectively. Panel B displays the decreasing trend of observed population counts in this age-group and its eventual stability from 2017, while ARIMA, based on historical data, forecasts a constant decline until 2020. This explains why ARIMA slightly underestimates population growth and errors increase in the last years of the forecast. In the age-group 15-39, forecast errors are almost 0 during the first half of the period. They increase to 2.0% in 2016 and remain at this level until 2020. Panel B shows that a slight break in the trend of observed counts in 2015 causes the overestimation of population growth and the aforementioned increase of forecast errors. ARIMA models return slightly larger forecast errors for the age-group 40-64, reaching to -5.0% from 2016 to 2020, while forecasts perform better in 2011-15. In Panel B, we see that the observed  population  growth  decelerated  from  2016,  explaining  the  underestimation  of  ARIMA forecasts and the increasing errors from this year.\n\nForecasts produced by ARIMA are less accurate for the age-group 65+. They perform relatively well in the initial forecast period, with errors below -4.5%, but then the accuracy progressively decreases, with errors reaching -21.2% in 2020. Panel B shows that actual population counts increase at a greater rate from 2014, causing ARIMA models to underestimate population growth and producing higher forecast errors. It suggests that ARIMA models are powerful when rates of population change are linear or unchanged, but present limitations to predict unexpected changes in population trends. Yet, observed counts are within the CIs of ARIMA, as for another age-groups.\n\nFigure  2.  Forecast  errors  2011-20  for  the  total  population  in  Greater  Mexico  City,  and  population forecast vs observed population\n\n<!-- image -->\n\nFigure 3. Forecast errors 2011-20 for population by age groups in Greater Mexico City, and population forecast vs observed population\n\n<!-- image -->\n\n\n## Assessing the accuracy or ARIMA population forecasts for the municipalities of Greater Mexico City\n\n\nNext,  we  present  short-term  (1-year  horizon-2011)  and  medium-term  (10-years  horizon-2020) ARIMA forecast errors of population totals and age-group populations in the 76 municipalities of Greater Mexico City (Figure 4). Here, box plots represent the median, quartiles 1 and 3, maximum and minimum values, and outliers. The distribution of errors is displayed using violin plots. Negative values were converted to positive values to get a consist median, since the former could annul the latter.\n\nIn  the  short-term,  both  forecasts  for  population  totals  and  by  age-group  return  low  errors  at  the municipal level, with the median error below 0.1% in both cases. The quartile 3 and maximum errors also display low figures, although slightly higher when forecasting populations by age-group. Violin plots show that most errors are distributed close to the median, particularly in models for population totals.\n\nForecasts for population totals show considerably lower errors than those performed by age-group in the medium-term horizon, with median values of1.5% and 5.7%, respectively. The median of ARIMA models by age-group is reasonably strong considering a 10-year horizon. However, the quartile 3 is 17.2%,  the  maximum  error  reaches  33.2%  and  several  values  are  distributed  over  the  median, although the majority of errors are under the median. ARIMA models for population totals display a quartile 3 of 4.5%, a maximum error of 10.1%, and most values are distributed around the median.\n\nFigure  4.  Median  and  distribution  of  short-  and  medium-term  forecast  errors  (positive  values)  for population totals and populations by age-groups in the municipalities of Greater Mexico City\n\n<!-- image -->\n\nFigure  5  displays  forecast  errors  for  population  totals  in  the  20  largest  municipalities  of  Greater Mexico City, ordered by population size. Errors over the forecast horizon are almost 0 in 13 of 20 municipalities, including the 5 largest units. Nonetheless, while low errors are found among some of the largest municipalities, there is no correlation between population size and forecast accuracy in our case study. Although it is not included in the paper, we tested this relationship using a scatterplot. 3 municipalities also display a near 0% error during the full period, but a small increase in the last years, with errors below -1.5% in 2020. ARIMA models return higher and increasing errors in 4 municipalities, where population forecasts are underestimated, although 3 of them display low errors, below -6.0% in 2020. Only population forecasts in the municipality of Tecámac return high error levels, 13.0% in 2020. If we look at Figure S1 in the Supplementary materials (SM) which represents observed and forecasted populations, we identify that population growth in these 4 municipalities, especially  in  Tecámac,  was  very  high  in  2011-20,  and  higher  than  in  the  period  2000-10.  Thus, population forecasts are below actual counts, despite being within CIs of ARIMA models.\n\nFinally, errors of population forecasts by age-group in the 20 largest municipalities of Greater Mexico City are represented in Figure 6. Forecasts for age-groups 0-14 and 15-39 show low error levels, below 5.0% in the last years of the forecast horizon. ARIMA models often produce an overestimation of population growth. Population forecasts of the age-group 40-64 are also quite accurate. Most errors are between -5.0% and 5.0% in 2020, and only in a few cases errors go over -10.0% for the same year. The only exception is the municipality of Tecámac, where the forecast error reaches -29.5% in 2020.\n\nPopulation forecasts for the age-group 65+ are underestimated and produce higher and increasing error levels. Most municipalities show errors between -20.0% and -30.0% in 2020, and only in a few instances, 5 of 20 municipalities, error levels are from -10.0% to -20.0%. Figures S2 and S3 identify that actual population growth among the age-group 65+ is higher than that forecasted by ARIMA models.  This indicates that observed population growth was greater in 2011-20 than in 2000-10, and such  population  increase  in  2011-20  was  then  not  anticipated  by  ARIMA  models  which  rely  on historical  data  with  lower  growth  rates  from  the  previous  period.  Despite  the  underestimation  of population growth and high error levels for the oldest age-group, actual counts are within the CIs of ARIMA models, except in 3 of 20 municipalities where population growth was extremely high in 2011-20 among individuals over 65 years-old. All observed counts are within the CIs of ARIMA forecasts in age-groups 0-14, 15-39 and 40-64.\n\nFigure 5.  Forecast errors 2011-20 for the total population in the 20 largest municipalities of  Greater Mexico City\n\n<!-- image -->\n\nFigure 6.  Forecast errors 2011-20 for population by age group in the 20 largest municipalities of Greater Mexico City, 2011-20\n\n<!-- image -->\n\n\n## 6. Discussion and conclusion\n\n\nWe found that ARIMA models produced accurate forecasts in a 10-years horizon for population totals in the municipalities of Greater Mexico City, with a median error of 1.5%. This value outperforms accuracy  levels  from  studies  which  have  created  small  area  forecasts  for  population  totals  using various methods. Small area forecasts with extrapolative models returned mean errors from 4.5% to 22% in a 10-years-horizon (Walters &amp; Cai, 2008; Wilson et al., 2015), simplified-cohort component approaches between 5.0% and 20.0% (Wilson, 2016; Baker et al., 2021), averaging methods about\n\n10% (Rayer, 2008), models including sociodemographic variables and spatial lags from 5.0% to 11.0% (Baker, 2014), and machine learning methods between 6.5% and 16.5% (Riiman et al., 2019; Grossman, 2023). The accuracy of microsimulation models was tested in a 5-years horizon, returning mean errors of 3.4-6.4% (Ballas et al., 2005; Marois  &amp; Bélanger, 2014). To our knowledge, the accuracy of other methods to forecast population in small areas, such as downscaling approaches or Bayesian statistics, has been not explored using retrospective forecasts.\n\nOur results show that ARIMA population forecasts by age-group were less accurate than those for population totals. Yet, forecasts display a relatively small median error of 5.7% in a 10-years horizon. Forecasts for age-groups 0-14, 15-39 and 40-64 were more accurate, with error levels generally below 5.0%. Forecasts among the age-group 65+, however, showed higher errors, often over 20% in most municipalities of Greater Mexico City. Baker et al. (2021) found mean errors from 20.1% to 43.4% in  a  10-years  horizon  when  tested  the  simplified-cohort  component  model  to  produce  small  area forecasts by age, and Wilson (2016) reported errors between 5.0% and 15.0%.\n\nOur results contribute to a modest but growing body of literature on population forecasting methods in small areas, particularly to the lack of studies on population forecasting at the intraurban level in developing countries. Based on our use case, we conclude that ARIMA models produce smaller total population forecast errors than other methods tested for geographical areas across the Global North. Our findings are in line with existing literature suggesting that extrapolative models tend to be more accurate than other methods to forecast total population counts for small areas (Wilson et al., 2023). Additionally, ARIMA models need minimum input data and simple calculations. We also showed that ARIMA may return lower errors than other approaches to produce population forecasts by age in small area, except for the age-group 65+. However, there are few studies which tested the accuracy of  population  forecasts  by  age  in  small  areas  to  corroborate  this  hypothesis.  Additionally,  an advantage of ARIMA forecasts is that they include uncertainty levels, while commonly currently used population  forecasting  methods  do  not,  since  they  tend  to  be  deterministic  in  nature.  In  our retrospective forecasts, we demonstrate that actual counts are within the CIs of ARIMA model. Thus, ARIMA does not only produce forecasts with low errors, but also reliable measures of uncertainty.\n\nDespite the accuracy of ARIMA models, they have some limitations that should be acknowledged. The  main  criticism  is  that  they  solely  rely  on  historical  data  (Bijak,  2012;  Disney  et  al.  2015; González-Leonardo et al., 2024). ARIMA models are powerful when rates of population change are linear  or  unchanged  but  cannot  anticipate  unexpected  changes  in  demographic  components.  For example, those caused by a  sudden increase  of  population inflows.  It  partially  explains  why  our forecasts  underestimate  population  growth  in  some  municipalities,  including  Tecámac.  This municipality is among the lowest-income areas within suburbs of Mexico City (CONEVAL, 2014) and there are many available lands where housing developments have been built (Isunza-Vizuet, 2010). Therefore, a sizable number of low-income individuals have moved to Tecámac in search of affordable housing. As a result, the number of inhabitants increased to a greater extent in 2011-20 than in 2000-10, and the magnitude of this phenomenon was not anticipated by ARIMA models. To this end, we have demonstrated the low forecast error potential of ARIMA models when population change remains somewhat linear. Additionally, ARIMA cannot properly predict the ageing process of cohorts with different population size, as the simplified-cohort component model does. This is why our results underestimated the great increase among the age-group 65+, since ageing of larger cohorts over time was underestimated by ARIMA forecasts.\n\nWe evaluated the accuracy of ARIMA models in a 10-years horizon for the municipalities of Greater Mexico  City.  Future  work  could  expand  our  study  to  test  the  accuracy  of  ARIMA  to  forecast population in other metropolitan areas across the Global South in longer forecast horizons. Future\n\nstudies  could  also  directly  compare  the  accuracy  of  ARIMA  with  other  methods  for  the  same geographical area or combine ARIMA with a different method to forecast population. Our forecasts produce lower error levels for ARIMA in Greater Mexico City compared to forecasts from studies in other areas around the world, mostly in the Global North. However, it does not necessarily mean than ARIMA models perform well everywhere and that other methods of population forecasting would not outperform ARIMA in Greater Mexico City. Further research is needed on population forecasting methods in small areas.\n\n",
         "Population forecasts at the intraurban level are crucial for governments and businesses to implement spatial planning and identify potential markets. However, population forecasts are often produced at coarse scales, namely national and regional, and state of the art small area forecasting methods are scarce and adjusted to work on Global North countries. We aim to explore the accuracy of autoregressive integrated moving average (ARIMA) models to forecast population totals and age-group populations at the intraurban level for the municipalities of Greater Mexico City. We use WorldPop 2000-10 population estimates as input data and perform retrospective forecasts for 2011-20. Comparing our forecasts with actual population counts, we found that ARIMA models return a median error of 1.5% when forecasting population totals in a 10-year horizon, and 5.7% for population forecasts by age-group. The age-groups 0-14, 15-39 and 40-64 performed particularly well, with error levels below 5% in most municipalities, while the age-group 65+ displays higher errors, typically over 20%. We conclude that ARIMA models outperform accuracy levels of small area population forecasts from previous studies which use different methods across the Global North. Yet, ARIMA models have limitations. They are powerful when rates of population change are linear or unchanged but cannot predict sudden changes in demographic components or ageing processes in cohorts with different population size.",
         ""
        ],
        [
         "23",
         "23",
         "## INTRODUCTION\n\n\nThis  article  explores  the  manga  of  Santa  Inoue's Tokyo  Tribe-2 (1997-2005)  and Tatsuo  Satō's  anime  adaptation  (2006-07),  as  well  as  the  anime  of  Shin'ichirō Watanabe's Samurai Champloo (2004-05) as two different entry points for\n\nunderstanding the diffused hip hop culture in Japan, that is, by examining their fictitious street dance scenes that correspond to the contextualized 'real' world. As early as the 1980s, street dance (or breakdance to be exact) became a craze in Japan when Charlie Ahearn's Wild Style and Joel Silberg's Breakdance were released in 1983 and 1984 respectively. The release of Wild Style was 'the seminal moment for breakdancing in Japan', while Breakdance brought 'the first of several breakdancing booms', as early street dancers practised outdoors by mimicking the dance routines in films or videos (Condry 2001: 228-29). Although the Japanese focus on hip hop culture switched from dance to rap music later, hip hop dance and music are inseparable. Either way, their popularity at the time had no parallel with manga and anime - another subculture that quickly reflected popular trends in Japan - which had not yet extended its understanding to dialogue with this subculture that had developed against the backdrop of American racial or ethnic segregation.\n\nAlthough the cultural interplay between hip hop and Japanese manga or anime appears  naturally  in  the  music  video  of  Nicki  Minaj's  'Chun  Li'  (2018)  that appropriates Japanese anime's explosive effects, and American hip hop-themed anime The Boondocks (2005-06) created by Aaron McGruderl today, the two subcultures hip hop and Japanese manga or anime had sought for an 'adequate language' to dialogue with or understand each other at first sight. My article hence develops a framework for reading  cross-cultural  hip  hop-themed  manga  and  anime,  by  drawing  on  Charles Taylor's  concept  of  'a  language  of  perspicuous  contrast'  (1985)  and  Paul  Gilroy's (1993) observation of 'call and response'. This framework offers insight into a reading of the diffusion of hip hop into manga and anime as a process of double-sided cultural extension that is based on the interplay of multiple, endless 'cultural appropriation'. The  article  therefore  explores  how  Japanese  manga  and  anime  transcribed  hip  hop elements and paralleled the 'real' world with graphic representation, while the cultural expression of hip hop diffused into the narratives of manga and anime, and in return, triggered  the  activism  of  today's  Japanese  youth.  Examining  the  ongoing  social movements in Japan, my article unfolds into two main sections. First, to what extent does Tokyo Tribe-2 and its anime adaptation understand hip hop culture through their representation  of  dance  scenes  reflecting  the  Japanese  context.  Second,  how  does Samurai Champloo advance its understanding of the culture through its transcription of street dance elements today against the Japanese historical background.\n\n\n## EXPLORING STREET DANCE, MANGA AND ANIME\n\n\nStreet dance, together with the most important elements of hip hop culture, such as DJing, MCing (rap music) and graffiti, were originally developed in the United States mainly by African American youths in the 1970s. 1  While Latino, Caribbean American\n\nyouth  and  even  Asian-Americans  contributed  to  the  formation  of  hip  hop,  echoing Bakari Kitwana's term, African American youths are 'the hip hop generation' (2002. In Kitwana's definition, this culture still reflects one of the generation's world-views, which is that Blacks are 'continu[ing] to be discriminated against in often subtle and sometimes not so subtle ways' (2002: 13). The most explicit example is that '[m]ore so than any other racial or ethnic group, African Americans remain segregated from whites in housing' (2002: 13). In other words, hip hop culture developed through waves of the movement of Black groups fighting adversity, and grew out of the collection of cultural expressions that have given (non-)verbal utterances to their struggles.\n\nIncluding street dance, the cultural expressions of hip hop began to travel around the world in the 1980s. Following that, '[m]embers of different cultures [would] pick up styles and statements [of hip hop culture] […]' and 'recast [the] culture to give it meaning within their own context' (Nanda and Warms 2014: 296). Taking this crosscultural trail, street dance as one element in the 'package' of hip hop culture, rapidly diffused into East Asia in the mid-1980s. Since then, not only dancers but also members of different cultures around the world began to embrace this 'package' of culture, and diversified its cultural appearance and meanings with local elements - including those of Japan.\n\nManga and anime culture in Japan, for example, crossed over to hip hop culture and started to depict hip hop scenes beginning in the 1990s. Such cultural crossing has embodied  the  'interchange  between  Japanese  and  U.S.  youth  culture'  (Nanda  and Warms 2014: 296) or the 'black-Japanese cultural interaction' (Anderson 2007: 258). The birth of manga, in effect, was to provide 'cheap entertainment […] to temporarily escape from the harsh realities of life experienced after World War II' (Rees 2013: 81). Furthermore, through appropriating Japanese manga and anime, contemporary artists have been able to 'reinterpret this visual medium by constructing alternative realities, blurring the lines between realities and fantasy' (2013: 82). Hence, like hip hop culture, manga and anime also provide a space for their readers to escape from their struggles by mirroring their harsh social experiences.\n\nHowever, on depicting hip hop, Japanese manga and anime creators did not 'pick up' or 'translate' the American hip hop generation's struggles to overcome racial segregation or their impoverishment due to racial inequality. Instead, they transformed the  violent  American  gangster  scenes  into  a  surreal  world  that  represented  the atmosphere of Japan's hip hop scene. Santa Inoue's manga Tokyo Tribe-2 , for instance, has  represented  some  dance  scenes  in  the  Japanese  dance  clubs,  with  Japanese representations of violent gangsters. Yet, this work also faithfully reflects the contextual atmosphere that the hip hop practitioners experienced in Japan, where the club goers could enjoy the music but not 'dance' at all. Even so, Inoue's Tokyo Tribe-2 doubtlessly\n\nis a milestone of manga to the extent of its hip hop theme, because it reflects not only on the 'real world' atmosphere of Japan's hip hop scene but also on evolving trends in Japanese hip hop.\n\nNotwithstanding, manga researcher Kentarō Miwa drawing on manga specialist Fusanosuke Natsume warns that it is easy to fall into the trap of reading manga or anime as a 'transparent' medium that 'reflects the trend of a society or the general public like a mirror' (2014: 16). To gainsay Miwa's standpoint, Japanese cartoonist Miki Tori's (2019) speech on manga and anime offers a strong discourse how these are related to popular trends in Japan, and of which Japanese youths are fond of Tori (2019: 247-48). In this sense, it is interesting to trace the development of hip hop culture in Japan since the 1980s. However, the way in which manga and anime appropriated hip hop implied that they also 'appropriated' what hip hop addressed culturally, racially, ethnically and politically. The articulation of political or cultural issues in Japan underlying these hip hop scenes in Tokyo Tribe-2 is more than a representation or 'social reflection' of the hip hop trends in Japan only, as Tori contend. I argue that in adopting 'the perspective of social reflection', which Miwa (2014: 16) criticized, hip hop-themed manga or anime are characterized by drawing attention to social issues in the 'real' world within its fantasy scenes. Said otherwise, I regard manga and anime as 'transparent' media that parallel social issues between fantasy and the 'real' world.\n\nThis significant 'characteristic' of hip hop-themed anime can also be found in Shin'ichirō Watanabe's Samurai  Champloo . Slightly different from  the anime adaptation of Tokyo Tribe-2 , Samurai Champloo is an anime that has transcribed hip hop elements into the Tokugawa-Edo period's art scenes, with anachronism as well as anatopism - i.e. the temporal and geographical misplacement in the sense of twisting the Tokugawa-Edo  period's  historical  backgrounds  by  including  the  Ryukyuan protagonist  Mugen,  for  example.  What  is  different  from  the  'sans-dance-scene'  of Tokyo Tribe-2 is  that Samurai Champloo widely transcribed several styles of street dance into a samurai background.\n\nThis  setting  of Samurai  Champloo , however,  invites  criticism  for  being 'postmodern eclecticism' or 'cultural hybridity', while striking both the readers and the critics that 'Watanabe is up to something else' (Benzon 2008: 271). Indeed, critics such as  Anderson  (2007)  and  Condry  (2005)  both  commented  on Samurai  Champloo , arguing  that  Watanabe's  anachronistic  and  anatopistic mise  en  scènes are  obvious attempts to draw attention to the excluded minorities in Japan. Anderson pointed out that the cultural expression of hip hop which derived from suppression corresponds to the  'play'  of  supressed  chōnin  from  the  'pleasure  quarters',  who  produced  Ukiyo-e painting  in  the  Edo  period  (2007:  659). Samurai  Champloo ,  from  her  viewpoint, perfectly  embodied  the  Black-Japanese  cultural  interplay.  But  Anderson  did  not  go\n\nfurther by looking at the contemporary Japanese context. Condry, on the other hand, noted  that Samurai  Champloo has  '[drawn]  attention  to  discrimination  against minorities, such as Okinawans and Ainu' (2005: 53). Yet, Condry did not specify how the fantasy of Samurai Champloo triggered their audience or readers to pay attention to the 'contemporary' real world from which it takes reference. No matter how the critics viewed it, Samurai Champloo was a success in the Japanese diversification of hip hop culture. Thus, it is worthwhile to compare how it differed from Tokyo Tribe-2 and how the setting of Samurai Champloo advanced the representation of hip hop after Inoue's manga had set a milestone by doing so.\n\nIf  Inoue's Tokyo  Tribe-2 was  a  milestone  of  manga  in  Japan,  which  made manga's fictitious world appear hip hop, then Watanabe's anime Samurai Champloo advanced the possibility of Japanese manga and anime to diversify hip hop elements in order to foreground what hip hop has in effect fought against so far. However, from the arrival of hip hop until Inoue's representation of Japanese dance clubs and Watanabe's hip hop/street dance transcription, there was apparently a prolonged interval of decades until hip hop elements were represented by manga and anime after Japanese youths took  up  street  dance.  This  long  interval  resulted  from  the  'language'  that  the  two different cultures 'speak', which will be further discussed in this article through the examination  of  the  Japanese  social  context.  Yet,  even  though  manga  and  anime approaches in Tokyo Tribe-2 and Samurai Champloo succeeded in contributing to the Japanese understanding of hip hop culture, how the two distinct cultural expressions provided an 'adequate language' for 'cultural interplay' remains unclear in the existing manga and anime research or hip hop culture studies. This article hence aims to provide a framework to examine how Japanese manga and anime create an 'adequate language' for such cultural interplay with hip hop culture as follows.\n\n\n## THE LANGUAGE OF PERSPICUOUS CONTRAST: HIP HOP VS. JAPANESE MANGA/ANIME\n\n\nTo dissect how hip hop-themed manga and anime won great popularity from the fans of different background, Charles Taylor's idea of 'a language of perspicuous contrast' in  his  chapter  'Understanding  and  incorrigibility'  (1985)  can  be  useful.   Taylor  has 2 designed an 'interpretive approach' (or ' verstehen view') to avoid two common social science errors: assuming that we can approach an alien culture from a purely objective standpoint (1985: 123); or 'taking [the agent's] description with ultimate seriousness' but turning out to be 'incorrigible' (1985: 123). By contrast, Taylor argued that as we challenge 'their language of self-understanding, we may also challenge ours' (1985: 125). In this sense, when applying his principle of perspicuous contrast to the hip hopthemed  manga  or  anime,  Japanese  manga  and  anime  represent  hip  hop  culture.  In\n\nTaylor's words, it would be the result of 'an alteration in [their] self-understanding' (1985: 130) in relation to the Japanese transcription (or representation) of hip hop that might be 'distorted or inadequate in some respects' (1985: 125) at the beginning, while at  the  same  time  challenging  the  self-definitions  of  manga  or  anime.  But  notably Taylor's  argument  focuses  not  just  in  one  direction  but  is  an  extended  'two-way' understanding of both cultures when they encounter one another.\n\nTo this point, the diffusion of hip hop into manga and anime also  gains the possibilities of extending the self-understanding of hip hop culture. This refers to the 'call and response' structure - an African-diasporic cultural expression - as Paul Gilroy (1993) observed in his Black Atlantic . 3 To put it simply, 'call and response' structure enables the culture to synchronize its cultural expression with other cultural practices in  terms  of  the  alteration  of  its  self-understanding.  By  appropriating  the  cultural practices  of  Japanese  manga  and  anime,  hip  hop  cultural  expression  can  be  more extensive,  too.  Therefore,  the  meaning  of  hip  hop  would  be  extended,  whereas  the genres of manga and anime would have more possibilities to the extent they become hip hop-themed manga or anime.\n\n\n## TOKYO TRIBE-2 : THE FIRST HIP HOP REPRESENTATION\n\n\nTo name several hip hop-themed anime is not a difficult task. For example, there are Afro  Samurai (2007)  directed  by  Fuminori  Kizaki  and The  Boondocks (2005-06) created by Aaron McGruderl, both produced in the United States, as well as Tokyo Tribes (2006-07) and Samurai Champloo (2004-05) in Japan. Yet, the hip hop-themed manga is quite limited. Except for Inoue's Tokyo Tribe series that was originally printed in Shodensha's street fashion magazine Boon from November 1997 to May 2005 issues, it is hard to find any other manga, especially that date back to the 1990s.\n\nThis makes the Tokyo Tribe series a significant milestone for manga in the hip hop genre. As a 'b-boy manga' serial, Tokyo Tribe-2 (1997-2005) is significant because it had been adapted for anime, film and even musicals, all depicting the daily life of youths  in  the  fictitious  city  of  'Tōkyō',  including  its  elements  of  violence,  crime, murder, sex, love and friendship. The plot of Tokyo Tribe-2 is set after the five-year Shivuya riots, where several tribes - meaning gangs - are based in different areas of the relatively convivial Tōkyō, scenes of which duplicate real urbanscapes in Tokyo. Apart from the similarity of urbanscapes, what is significant about Inoue's Tokyo Tribe2 is that he enriched the readers' understanding of hip hop by adding 'magazine-like' columns at the end of each volume, which included interviews, introductions of hip hop street culture, song lists, topics or neta (materials) about rap music and so forth.\n\nAchieving similar levels of popularity as its original manga version, producer Tatsuo Satō's Tokyo Tribes 2 (2006-07) was animated with equal parts of violence and\n\nhip hop cultural elements. Several hip hop groups such as Kool G Rap &amp; Young Chris's 'The Extravaganza' and Japanese DJ Muro's 'So Cool' added the flavour of Japanese hip hop to the anime. Yet, hip hop music is not the only element that manga and anime appropriated  from  hip  hop  culture.  The  club  'dance'  scene  from  Episode  42  of  the manga and Episode 6 of the anime were also meant to reveal a space where the DJ and clubgoers practised 'call and response'. 4\n\nFigure 1: Kai plays music, while the clubgoers enjoy his performance. But they are not actually 'dancing'. This scene corresponds to Satō's anime adaptation in Episode 6. Source: Santa Inoue (1997-2005: 65).\n\n<!-- image -->\n\nThis 'antiphonic' club dance scene is controversial, however, as it opens with Iwa and other members from the Shinjuku Hands tribe attending a club event held by Musashino Saru tribe. When the members of Hands come into Club Jenna to attend Saru's party, the protagonist Kai is playing music with a turntable on the stage. Soon after, the corpse of a member of Hands tribe is sent to the club by the Wu-Ronz tribe. This provoked the Hands tribe to leave Jenna and seek revenge. The scene in the manga version focused more on the DJ playing music and the clubbers enjoying Kai's selection of hip hop. Nevertheless, apart from the same depiction in the anime version, the scene also shows the clubbers swaying to the rhythms of songs played by Kai.\n\nFigure 2: Instead of 'dancing', the clubgoer in yellow sways to the rhythms of songs played by Kai. Source: Tatsuo Satō (2006-07).\n\n<!-- image -->\n\nIn other words, despite it being called 'b-boy manga' (and thus 'b-boy anime'), Inoue's work and Satō's anime adaptation have hardly depicted street dance elements in their representation. Why did both manga and anime not include fictitious hip hop dance scenes such as those practised by street dancers in Yoyogi Park and Hokoten (a Tokyo pedestrian paradise) since the 1980s (see Condry 2001)? This question hence leads to the club scene controversy, although the club scene is the most likely fictitious space in both works for observing how hip hop music is related to the street dance culture in Japan. In fact, in both the manga Tokyo Tribe-2 and its anime adaptation, the ineffective 'call-and-response' dance scene is considered for reasons that contextualize the  Japanese  club  scenes  related  to  legal  problems  and  the  music  industry,  and  the Japanese manga kai's (comic world) insights into the popular cultural trends.\n\nFirst of all, the development of hip hop culture after its arrival in Japan is the crux. As a big fan of hip hop and a manga writer, Inoue claimed that no one but he could make manga and hip hop grounded in Japan (Wada 2017: n.p.), because he had seen how Japanese hip hop culture developed. Inoue's experience and knowledge of the culture testifies to his Tokyo Tribe-2 being the first solid representation of Japanese hip hop, not to mention the anime adaptation Tokyo Tribes . The depiction of the scene in Club Jenna must have been based on Inoue's personal experience in Japanese dance clubs. As Ian Condry, who has captured the environment of Japanese dance clubs and reviewed the development of Japanese hip hop culture, has pointed out, although 'rap albums have become more commercially successful', hip hop culture was introduced through 'breakdance' - a street dance genre - to Japan in the first place (2001: 227). However, it turned out that what Japanese clubs have provided hip hop practitioners with is not a 'genba' (actual site) for dancing to music, but rather, echoing  Condry (2001: 235-36), a site for 'professionalism in performance' or a gathering to exchange the latest information on the music industry.\n\nSecondly, dancing was strictly prohibited in the Japanese dance clubs under the Fueiho Law. More specifically, the clubs that provide drinks or foods and 'let the guests dance' were obliged to apply for a proper license, and to close at midnight or before 1 a.m., according to the Law (Isobe 2012b: 14). This law was promulgated in Japan in order  to  prevent  dancehalls  from  becoming  hotbeds  of  prostitution  since  the  Allied Occupation in 1948, and had applied to ballroom dance schools as well as dance clubs until October 2014, when the Cabinet approved a bill to amend it. What triggered this amendment was a petition by the citizens' group Let's Dance, which related to a 2010 incident in a club in Amemura, Osaka, where a college student died in a fistfight. After that, the Fueiho Law's policing of dance clubs became harsher than it had been (see Manabe 2015: 251-52). As a result, the citizens' group Let's Dance sided with several members of National Diet, lawyers, musicians, (street) dancers, and collected 176,000 signatures to lobby the Diet to amend the law. Despite the amendment, the regulation, as  a  means  of policing  dance  culture in Japan,  still restrained street dance culture's development in the club scenes, but it did boost the growth of the Japanese hip hop music industry.\n\nIn reality, dance clubgoers did dance. But this was not in contradiction to music critic Ryo Isobe labelling Japan as 'the country where you can't dance' (2012a: 4-5). Instead, '[the club owners] could not let [their guests] dance without a license' (Isobe 2012a: 5). It exposed a 'loophole' in the law, which is visible in the lyrics of Japanese rap  singer  Haruo  Chikada's  song  'Hoo!  Ei!  Ho!'  (1987);  a  punchline  meant  to  be pronounced like  Fueiho in Japanese (Isobe 2012b). Chikada's song thus provided a cynical view of the Fueiho Law and suggested that the Japanese authorities had turned\n\na blind eye to 'no-license' dance clubs; the lyrics of his song go, 'Just close the door, and you won't be found out/You won't be found out'. Many club owners actually risked running their clubs without a license by claiming that they 'let [the guests] listen to the music instead of letting [them] dance' (Isobe 2012b: 14). The Fueiho Law impacted everyone who was involved in club culture, but despite this (some) clubs exploited this loophole, and dancing could continue. However, Inoue's manga and anime story left the club scene 'policed' reflecting the reality of the restrictive Fueiho Law.\n\nFigure 3: The clubgoers admire Kai's performance by saying, '[h]aven't listened to the music Kai played', and 'I like this music!'. Source: Santa Inoue (1997-2005: 66).\n\n<!-- image -->\n\nIsobe (2012a, 2012b) has accused the policing of clubs under the Fueiho Law of restraining the development of dance culture, while Condry (2001) has observed that a  hip  hop  dance  club  is  a  'genba'  for  professional  information  exchange.  Their viewpoints explain why the emphasis on musical choices and the representation of hip hop culture through rap  music carried  more weight than the dance scenes in Tokyo Tribe-2 and  its  anime  adaptation.  And  such  representation  also  articulated  the  selfdescription of Japanese manga kai.\n\nTokyo Tribe-2 was produced in an atmosphere where many manga writers vied for supremacy in the Japanese comics world (manga kai). Inoue's production of the Tokyo Tribe series released in the 1990s was an unprecedented attempt to help manga meet hip hop culture at the crossroads. As critic Angela Drummond-Mathews posited, Inoue's Tokyo Tribe series 'features Japanese gang members who are wrapped up with hip hop culture' (2010: 75). Drummond-Mathews (2010: 74-75) also argued that Tokyo Tribe was a production of Japanese manga which absorbed American culture. But why had not Inoue come up with this idea to write a hip hop-themed manga earlier if the 'notorious'  American  culture  had  already  arrived  in  Japan  by  the  1980s?  There definitely  was  a  'prolonged  interval'  between  the  arrival  of  hip  hop  in  Japan  and manga's  representation  of  it.  Japanese  cartoonist  Miki  Tori's  talk  touching  on  the Japanese  manga  world  in  the  1980s  evidently  answered  this  question.  Tori  (2019) focused on the quarrel within the manga kai and how the trend of popular culture and subculture  were  represented  in  the  manga  kai  from  the  1970s  to  the  1980s.  This sequence of the quarrel within manga kai turned to a new trend in that some cartoonists 'dealt with the subculture [materials] but not with the real music, real fashion or real manga' (2019: 247-48). Regardless of its popularity, hip hop culture as a theme in manga was thus drawn into this combat to vie for supremacy in manga kai. Nonetheless, in the mid-1990s, the manga industry had reached its peak, and Japanese cartoonists again turned to catering to the readers' favour.\n\nAs a result of this change, Inoue grasped the taste of the readers and decided to create  a  hip  hop-themed  manga  to  promote  hip  hop  music  as  the  trackmakers  do, although he said he felt 'a bit reluctant' (Yoshihashi 2009: n.p.) in the beginning. His reluctance might have been related to his uncertainty about dealing with his hip hop culture  despite  his  career  as  a  manga  creator.  Taylor's  concept  of  'a  language  of perspicuous contrast' (1985) supports Inoue's conjecture. To write a hip hop-themed manga, Inoue first had to enhance the possibilities of manga spaces for understanding and representing hip hop culture. To do so, he added columns in Tokyo Tribe-2 and started writing manga from his knowledge and insights into Japanese hip hop culture. As mentioned earlier, these columns broke the established practice of manga and altered its understanding of hip hop culture. In addition to his representation of Japanese hip\n\nhop, based on his insights, he also provided possibilities for manga to extend its cultural expression to increasingly synchronize with that of hip hop culture. Although there was a 'prolonged interval' already, these approaches indeed made Inoue's Tokyo Tribe-2 successfully conspicuous and popular.\n\nThe various genre adaptations of Tokyo Tribe-2 , which are also popular, enabled opportunities to reread this manga text and to reconsider the specific dance club scene depicted by Inoue with the atmosphere of Japanese dance clubs in the 1990s and the policing of dance culture. Manga like Tokyo Tribe-2 might have drawn attention to violence and caused Japanese youths' rebellious and violent behaviour. 5  However, by rereading Tokyo Tribe-2 , the violence that Inoue tackled on purpose could be seen as more meaningful. Despite the lack of a street dance scene in Tokyo Tribe-2 ,  Inoue's depiction of the dance club Jenna is a metaphorical space that he created to express the 'reluctance' of what Japanese hip hop culture was confronting at the time. In this sense, his Tokyo Tribe-2 not only extended manga's self-understanding so as to understand hip hop culture, but also negotiated what the culture was struggling with in the 'real' world. Inoue's creation of Japanese hip hop-themed manga provided an understanding of hip hop cultural expression, which was thus an epic achievement. As a beneficial result of Inoue's manga, the musical adaptation Tokyo Tribe , for instance, has involved Japanese  street  dancers  such  as  Umebo  and  Go  Ueki  in  choreographing  the  dance routines - that is, explicit 'call and response' scenes. All through the rereading of this work, each of its adaptations reproduced an alteration of Japanese self-understanding and  enhanced  the  possibilities  for  cultural  exchange.  Hence, Tokyo  Tribe-2 that generated meaningful anime and other genres' adaptations was indeed a milestone in manga.\n\n\n## SAMURAI CHAMPLOO: HIP HOP TRANSCRIPTION\n\n\nA follow up to Inoue's contribution, Shin'ichirō Watanabe's Samurai Champloo anime television series (2004-05) has made a further contribution to representing Japan's hip hop culture, as it transcribed hip hop elements into a set mixed with a contemporary view of the world from  Japan's Tokugawa-Edo  or Traditional Period (1603-1867). According to Miki Tori, remaking manga into anime for a television drama or movie has been the trend since the 1980s (2019: 248-49). In the 1990s and the 2000s, the remakes accelerated, and Satō's anime adaptation of the hip hop tale Tokyo Tribes rode this wave. Meanwhile, Samurai Champloo first appeared as a hip hop-themed anime production and was adapted as a two-volume manga written by Masaru Gotsubo at its release in 2004.\n\nTo the audience's surprise, the characters in Samurai Champloo speak in the tones of today's Japanese youths or use loanwords in their dialogues, and they beatbox\n\nor  battle  each  other  in  the  Japanese  martial  arts  style  as  if  they  are  dancing.  These contemporary usages of Japanese language and hip hop elements are discoverable in every episode of Samurai Champloo . In Episode 8, for example, the characters use the youths'  Japanese  language  such  as  nanpa  (flirt)  as  well  as  loanwords  such  as  hanii (honey  in  terms  of  'sweetheart')  and  biggu  (big  in  terms  of  'important')  in  their conversation.  These  usages  are  Watanabe's  way  of  breaking  the  stereotype  of  the 'jidaigeki'  (samurai  drama)  whose  actors  speak  in  an  archaic  manner.  Besides,  the opening of the same episode begins with a beatbox performance of a samurai carrying his  sword  as  if  it  is  a  microphone.  And  throughout  the  anime  series,  the  samurai characters make hip hop music beats visible by doing dance moves. These seemingly unnecessary 'add-ons' - including the language use, the rap music and street dance elements - were apparently Watanabe's intended devices to transcribe hip hop elements into the Japanese understanding of them in Samurai Champloo .\n\nThese cross-cultural transcriptions in Watanabe's Samurai Champloo not only fascinated (and still fascinate) audiences but also attracted the attention of critics and scholars. As critic Rose Bridges commented, Samurai Champloo assembled four main elements of hip hop culture, such as using the Japanese hip hop soundtracks by Nujabes and DJ Tsutschie, 'graffiti art in the opening sequence', 'the fight choreography that resembles breakdancing', and scene  changing  'with  'record  scratch'  sound  effects' (2017:  11-12).  Bridges'  comment  accords  with  critic  Jiwon  Ahn's  (2013)  and  Ian Condry's (2005) interpretation of the term 'champloo' in the anime title. Condry noted that this term literally means 'Okinawan stew' which refers to 'cultural remixing' (2005: 53). Meanwhile, Ahn pointed out that the term is an Okinawan loanword in Japanese, meaning 'something mixed' or referring to 'a popular local dish ( champurū ) created from stir-frying all sorts of different ingredients' (2013: 365). That is, the term, on one hand,  indicates  that  hip  hop  elements  are  scattered  throughout  the  anime  through samurai appropriation and transcription of the Japanese culture (Bridges 2017: 12-13). On  the  other  hand,  this  term  'can  be  understood  as  signifying  the  show's  eclectic approach to representing time and space in its diegetic world' (Ahn 2013: 365). In this sense,  Watanabe's champloo schemata  -  namely,  anachronism  and  anatopism  as mentioned  in  my  introduction  -  avoided  cultural  misappropriation  and  enabled  the anime  to  diversify  the  appearance  of  hip  hop  culture  against  a  fictional,  Japanese historical background.\n\nLikewise, critic William L. Benzon argued that Samurai Champloo overstepped certain bounds by subverting postmodern interventions to Japanese culture and national identity (2008: 273-74), by pointing out that the anime is 'culturally eclectic' (2008: 271). But Benzon fell into the pitfall of defending 'national identity' introduced into the 'narrative through anachronistic gesture' (2008: 273). Benzon's argument raised the\n\nquestion:  Why  does  Watanabe's Samurai Champloo turn  out  a  successful  hip  hopthemed anime through the extended Japanese understanding of hip hop, although the backdrop of the traditional samurai world and that of hip hop culture are quite a contrast? This  question  can  be  answered  by  returning  to  Taylor's  'language  of  perspicuous contrast' (1985).\n\nBased on Taylor's theory, since hip hop cultural expression is outside the range of language available to Japanese graphic representations, the way in which manga and anime  represent  hip  hop  culture  is  to  neither  depict  the  culture  that  developed  in objective reality with their defined expression nor to merely reframe hip hop cultural expression as it is into their fictitious world. Instead, the alternative approach, as Taylor proposed,  is  to  develop  a  language  of  contrast  by  the  discovery  of  the  obvious differences between hip hop cultural practices and manga or anime interpretations of it. This alternative language requires an alteration of self-understanding in the first place so that it can extend the understanding of both cultures. Inoue's Tokyo Tribe-2 stopped short  at  the  first  step,  whereas  Watanabe, by  using  anachronistic  and  anatopistic schemata in Samurai Champloo , further advanced this alternative language for the two cultures.\n\nThere is no exact translation for hip hop elements in a Japanese cultural setting. Watanabe's schemata of using anatopism and anachronism in Samurai Champloo was his approach to transcribing hip hop culture into a fictitious, Japanese historical setting. These schemata seemed to hybridize two slightly distinct cultures into one Japanese narrative  by  objectivizing  hip  hop  culture.  But  that  was  not  Watanabe's  intention. Instead,  hip  hop  elements  and  the  Tokugawa  historical  background  in Samurai Champloo are  such  a  'perspicuous  contrast'.  Watanabe  framed  them  in  an  anime representation so as to transcribe hip hop culture into an alternative language and in so doing provided a fictitious space for the understanding of hip hop and anime culture.\n\nFigures 4 and 5 show typical examples from scenes in Samurai Champloo that illustrate the use of such alternative languages for hip hop and manga or anime.\n\nThese are the street dance scenes, that is, the physical/dance movements of hip hop that correspond to Japanese martial arts. The most explicit is from Episode 1, when the protagonists Mugen and Jin, a rōnin (masterless samurai), first meet in the teahouse where the heroine Fuu works, and when Mugen battles the Daikan's (local magistrate's) subordinates.  In  the  teahouse,  Mugen  attacks  Jin  for  mistaking  him  for  a  Yagyu swordplay master raised by the local magistrate, and they begin to battle with swords. While  they  are  fighting,  the  scene  runs  with  breakdance  music.  Mugen's  action  is skilfully depicted with a mixture of Japanese martial arts swordplay and his windmill breakdancing moves.\n\nFigure 4: The scene illustrates the battle between Mugen and Jin, where Mugen performs his swordplay-breakdance movements. Source: Shin'ichirō Watanabe (2004-05).\n\n<!-- image -->\n\nFigure  5:  Mugen  flips  over  and  performs  a  windmill  move.  Source:  Shin'ichirō  Watanabe (2004-05).\n\n<!-- image -->\n\nSuch windmill moves are also seen before the Daikan orders his subordinates to decapitate Mugen and Jin for their crime of accidentally killing the magistrate's son Shibui Tomonoshin. But as soon as the subordinates come towards him, Mugen flips over using windmill moves and kicks them away.\n\nThen, Jin cuts the rope tied to his wrist with a subordinate's sword and sets Mugen  free,  and  they  begin  to  battle.  The  following  scene  again  illustrates  the combination  of  breakdance  moves  and  Mugen's  swordplay  with  a  percussive  beat background music. Both the Mugen vs. Jin battle scene and the battle scene against the Daikan's  subordinates  are  framed  in  a  'call  and  response'  structure,  namely  they combine the inseparability  of  music  and  dance,  as  well  as  the  interactions  between swordplay and the physical movements of hip hop. As an alternative language, these scenes  clearly  demonstrate  how Samurai  Champloo has  successfully  altered  the understanding of breakdance.\n\nThis is not to say that breakdance is the only dance style that Watanabe intended to transcribe. Rather, his version of breakdance is only one of his understandings of street dance culture, which is related to the term 'hip hop dance' or 'street dance'. Street dance, as an umbrella term, may refer to the following two categories: (a) uprocking, hip hop dance (or breakdance, b-boying and b-girling) that emerged from the Bronx in New York City; and (b) the funk styles including popping, locking that came from the US West Coast (see Pabon 2006; Schloss 2009: 59-61).\n\nNotably,  these  dance  styles,  as  hip  hop  cultural  historian  and  activist  Jorge Pabon commented, are 'performed best with [their] appropriate musical influences' (2006: 25). But from his viewpoint, 'hip hop dance' would be a more suitable umbrella term to refer to  these  dance  forms.  Regardless  of  Pabon's  view,  Yoshito  Sekiguchi posits that the term 'street dance' emerged in the United States when the dance styles of the West Coast came to New York (quoted in Arikuni 2018: 44). 6  In the Japanese context, sutoriito dansu (street dance) turned out to be more common and well known after several dance booms (see OHJI 2001), because, as street dance scholar Akihiro Arikuni (2018: 46) pointed out, street dance appeared abundantly with its promotion on Japanese television from the 1990s and the internet from the 2000s. Watanabe's hip hop-themed Samurai Champloo was one example of its appearance on television. And this physical movement of hip hop was intended to transcribe not only 'breakdance', but also the various street dance styles well known around the world.\n\nAs such, street dance elements are widely used in Samurai Champloo .  Apart from Mugen's swordplay breakdance moves, he also exhibits breakdance moves in the opening  scene  of  some  episodes,  as  does  Fuu.  Furthermore,  Bunta  Ogura,  a  minor character playing a flunky, makes the wave move (a routine movement of popping) in Episode 8,  when  he  sees  Fuu  in  a  restaurant.  The  wave-move  scene  is  humorously represented,  albeit short, in the anime.  Either  way,  these  street  dance  scenes demonstrated by samurai manifest Watanabe's extensive understanding of the corporal expressions in hip hop culture.\n\nIn  other  words,  the  cultural  expressions  of  'breakdance'  differ  from  that  of swordplay, and they rarely share anything in common. However, Watanabe's rendition of street dance through Mugen's breakdancing swordplay manifests Taylor's 'language of perspicuous contrast'. The scene of Mugen's breakdancing swordplay distorts the understanding  of  both  cultures  to  a  certain  extent.  But  Mugen's  breakdance  moves emphasize  the  self-description  in  street  dance  culture  embedded  in  the  'call  and response'  structure,  while  the  transcription  of  dance  into  swordplay  is  a  process  of challenging  self-description  in  Japanese  martial  arts.  As  a  result,  this  scene  indeed illustrated  what  Taylor  further  delineated  in  his  theory:  the  alternative  language generated by one culture to understand another would challenge both cultures' selfdefinition and extend 'the language of human possibilities' (1985: 131). In this sense, progressing  from  Inoue's  representation  of  hip  hop  culture  in Tokyo  Tribe-2 to Watanabe's schemata of anatopistic or anachronistic samurai world is a method set up ingeniously  both  to  understand  the  self-definition  (cultural  expression)  of  hip  hop culture and to challenge the alteration of Japanese self-definition in anime, and vice versa.\n\nTo shift the focus from anime scenes to ongoing cultural issues around the world, what Watanabe's Samurai Champloo offers is more than an extended understanding of hip hop culture or an alternative language for intercultural exchange. As mentioned in the introduction, Condry (2005: 53) assumes that the setting of Samurai Champloo was designed to draw attention to racial or ethnic discrimination in Japan. Since hip hop was developed in a diasporic reality and always aligns itself with the oppressed, to what extent does hip hop-themed anime or manga intertwine with the 'real' world? To take this question into account, Condry's assumption can be more comprehensive, because what Watanabe intended to reveal is not only how hip hop's cultural practices can be appropriated by anime representation, but also by how its cultural expression articulates the diasporic realities and consciousness to fight social injustice.\n\nTake  for  example  Akitomo  'Aki'  Ri,  an  urban/street  dancer  or  hip  hop practitioner from Kobe, Japan, becoming involved with the 2020 Black Lives Matter protests.  Aki  wrote  on  his  Facebook  wall  after  he  took  part  in  the  Osaka  march protesting the George Floyd killing on 7 June 2020: 'As a promoter of the culture, I would like to fight  for  those  who  developed and are developing hip hop and street culture so as to secure their dignity and interests' (Ri 2020: n.p.). He also uploaded a selfie videoclip in which a signboard reads 'Yellow Pearl Supports Black Power!' Born into a fourth generation of Chinese residents in Japan, Aki has always been concerned about  social  injustice  that  includes  racial,  ethnic,  gender  discrimination  and  so  on. Meanwhile,  he  thinks  that  understanding  hip  hop  culture  and  adopting  a  'hip  hop attitude' can make social injustice right. Throughout his process of understanding hip\n\nhop culture, watching Samurai Champloo has been one way that Aki was cognizant of the culture.  From his example, it is evident that the anime not only transcribed hip hop 7 into an anachronistic and anatopistic representation but also provided an understanding of its cultural expression, one that suggests diasporic realities and consciousness.\n\n\n## CONCLUSION\n\n\nThis article articulates an understanding of the political aspects of street dance while at the same time exemplifying Taylor's concept of 'a language of perspicuous contrast'. If Inoue's Tokyo Tribe series was a milepost for manga that revealed the development of Japanese hip hop culture and the policing of (street/club) dance in the first hand, then Watanabe's  anime Samurai  Champloo advanced  the  meaning  and  possibility  of Japanese  manga  and  anime  with  their  diversified  hip  hop  elements.  Furthermore, Samurai Champloo has succeeded in synchronizing Japanese youth's street dance and hip hop interests with manga and anime. This has provided a better understanding of the cultural and sociopolitical expressions of hip hop.\n\nWith  Inoue's  and  Watanabe's  contributions,  hip  hop-themed  manga  has increased since the 2000s. For instance, Street Dance Classroom: Master with Manga (2017), written by Kyota Shibano, is a street-dance-themed manga that guides readers on how to do the dance moves. I consider Shibano's work a progressive example that warrants further investigation along the lines of the hip hop discussion presented in this article.\n\nMoreover,  hip  hop-themed  manga  or  anime  now  even  challenges  their  own possibilities, as can be seen from the example of the up-to-date manga series Shonen in the  Hood (2020-present)  by  graffiti  writer  SITE  (aka  Ghetto  Hollywood).  SITE's manga  tackles  social  issues  of  low  income  housing  estate,  drug  abuse  and  foreign residents in the satellite cities of Tokyo, against the background of 1996 Japanese hip hop culture with storylines that trace to his personal experience. From Tokyo Tribe-2 to Shonen in the Hood , hip hop-themed manga depicts the transition from rebellious and violent behaviour to tackling Japanese social issues and speaking up for social injustice.\n\nFinally, hip hop visual arts have also appropriated manga or anime materials through digital sampling. The music video for Nicki Minaj's 'Chun Li' (2018), directed by Steven Klein, for example, is controversial yet worthy of further consideration for the 'cultural appropriation' of Japanese anime materials in hip hop. This music video combines several Asian signifiers such as Japanese anime's explosive effects, a tattoo of Chinese characters and coolie hats along with others. Critic Andrew Chow opposed the  mixing  of  Asian  signifiers  because  it  'conflates  many  Asian  cultures  into  an Orientalist  mess'  (2018:  n.p.).  However,  Chow's  criticism  is  too  judgemental  and intolerant, if compared to Gilroy's insight into hip hop culture, i.e., the aesthetic rules\n\nthat  govern  the  culture  are  'premised  on  a  dialectic  of  rescuing  appropriation  and recombination' (1993: 103-04). In this regard, it is not surprising that the music video for 'Chun Li' took cutting and mixing Japanese anime materials with hip hop elements through  digital  sampling  for  granted.  Instead,  it  is  a  subsequent  refinement  of  the cultural practices that hip hop culture grew out of. This corresponds to the 'call and response' structure, where hip hop culture could dialogue with manga or anime with the condition that it alters its self-understanding to generate an alternative language. Hip  hop  culture  enriches  Japanese  manga  and  anime  and  creates  a  new  genre  of representation that parallels the 'real' world of (fictional) graphic narratives, which in part raises awareness of specific social issues.\n\n",
         "Street dance, one of the four most important elements of hip hop culture, was developed mainly by African American youths in the 1970s and imported to Japan in the 1980s. Since then, street dance has been diversified by local media such as manga/anime in Japan. This article therefore analyses how Japanese storytelling, exemplified by Shin’ichirō Watanabe’s anime Samurai Champloo (2004–05), Santa Inoue’s manga Tokyo Tribe-2 (1997–2005) and Tatsuo Satō’s anime adaptation Tokyo Tribes 2 (2006–07), has transcribed the hip hop elements into the Tokugawa-Edo period’s art scenes and fictitious ‘Tōkyō’, and provides a basis for understanding hip hop culture in Japan by drawing on Charles Taylor’s ‘language of perspicuous contrast’ (1985). Although manga and anime quickly reflected popular cultural trends in Japan, hip hop elements did not manifest as main material until Tokyo Tribe-2 was released. Thus, there was apparently a prolonged interval between the arrival of hip hop culture in Japan and its representation by manga/anime after Japanese youths’ first fancied street dance. Therefore, street dance culture could have been transformed within the Japanese cultural context. This article also analyses the representation/transcription of street dance and hip hop in manga/amine by contextualizing the Japanesesocialpolitical background to explain this prolonged interval.",
         ""
        ],
        [
         "24",
         "24",
         "## Introduction\n\n\nCoding complex concepts from text corpora is one of the primary tasks for both quantitative and qualitative social scientists. Although human coding remains the gold standard, computer-aided coding has been proven to be capable of efficiently conducting sophisticated text annotation (Nelson, Burk, Knudsen, &amp; McCall, 2021). For instance, in social movement studies, scholars have devoted considerable resources to building protest event databases by leveraging supervised machine learning techniques to distill protest information from largescale news articles and social media posts (H. Zhang &amp; Pan, 2019; Hanna, 2017). Recently, many scholars are applauding the potential that the swift advancement in generative artificial intelligence (AI)-particularly large language models (LLMs)-can transform how scholars conduct social research by automating the research pipeline including summarizing literature review, generating and testing hypotheses, and conducting data collection and analysis (Ziems et al., 2024; Messeri &amp; Crockett, 2024; Manning, Zhu, &amp; Horton, 2024; Bail, 2024). Yet, little research has been done to systematically examine its validity, reliability, transparency, and replicability in terms of coding complex concepts for social science research. Generative AI tools may carry great epistemic risks when social scientists treat them as knowledge-production partners (Messeri &amp; Crockett, 2024). To fill this gap, this study asks\n\nthe crucial question of whether or under what circumstances we, as social scientists, can trust the results from generative AI models. More specifically, what are the risks of using LLMs for coding in social science research and how we can better mitigate and communicate the risks associated with the implementation of LLMs? By doing so, we explore and propose a schema for incorporating LLMs into text annotation in social science research in a reliable and valid manner.\n\nComputer scientists have demonstrated the potential of generative AI to achieve high accuracy by benchmarking various large language models across a range of tasks, including multiple-choice questions (MMLU), reasoning (HellaSwag), coding (HumanEval benchmark), and mathematics (MATH benchmark). For instance, the benchmark dataset used for measuring multitask accuracy spans 57 tasks across STEM, humanities, social sciences, and more (Hendrycks et al., 2020). These evaluations offer the broader community a snapshot of how these LLMs perform in terms of knowledge acquisition and reasoning capabilities. For example, the average accuracy rates across benchmark datasets including MMLU, HellaSwag, HumanEval, BBHard, GSM-8K, and MATH are 79.45% for GPT-4, 80.08% for Gemini 1.5 Pro, and 84.83% for Claude 3 Opus 1 . In scientific contexts, generative AI has been lauded for its contributions to enhancing scientific discovery and objectivity, overcoming limitations related to scientists' time, attention, cognitive capacities, subjectivity, and bias (Messeri &amp; Crockett, 2024; Ziems et al., 2024; Manning et al., 2024). However, generative AI also poses challenges to scientific understanding due to potential epistemic risks such as data leakage, hallucinations, strong alignment with social norms, and issues with replicability, transparency, and interpretability.\n\nIn this paper, we utilize the field of social movement studies as an illustrative case to outline several risks of using generative AI, specifically OpenAI's GPT-4, for coding tasks, and we propose solutions to address some of the associated epistemic risks. We examine the typical tasks conducted by social movement scholars in creating protest databases from newspaper articles, such as determining the relevance of articles to protests and extracting crucial information including participant numbers, objectives, tactics, and involved social movement organizations. In the social movement literature, a frequently utilized benchmark dataset for analyzing protests in the United States is the Dynamics of Collective Action (DoCA) project (Earl, Martin, McCarthy, &amp; Soule, 2004; Hanna, 2017). This project annotated news articles from the New York Times covering the period 1960-1995 to construct a detailed event database containing information at both the article and event levels, such as the reporting year, article title, size of protests, claims, social movement organizations, locations, timing, and more 2 . As the DoCA dataset does not include the original NYT articles, we align the annotated NYT corpus (1987-2007) from the Linguistic Data Consortium (LDC) with the DoCA dataset and employ GPT-4 for coding various complex concepts. We conduct a series of experiments to evaluate the validity, reliability, transparency, and replicability of the outputs generated by GPT-4.\n\nWe compare the outputs of GPT-4 with the results of human coding as documented by the DoCA project. To summarize, the performance of LLMs decreased as the complexity of\n\ncoding tasks increases. GPT-4 performed pretty well in binary classification such as police presence, but relatively poor in mutilabel and multiclass classification. We also show that the reliability of the LLM ouputs varies across task complexity, with a relatively high level of reliability for simple task instead of complex ones. More importantly, we show that social scientists can use LLMs to output reasoning steps to increase the transparency in coding decision making processes.\n\nWe also stress that scholars need to be cautious when using LLMs as the primary coder. To achieve a high level of validity and reliability, scholars need to test the accuracy and stability of their prompts and find the optimal prompting strategy using a small development dataset and report the accuracy metrics by randomly selecting a small evaluation dataset with human evaluation after scaling the prompt to the whole dataset. Meanwhile, LLMs can serve as the secondary coding assistant by producing step-by-step reasoning results and potential classification for human coding.\n\nThere are several caveats when interpreting results. First, we only experimented zero-shot text classification with different prompting strategies. Scholars can further test additional strategies such as few-shot prompting or even fine-tuning their own LLMs. Second, with the rapid advancement of generative AI techniques, some of these limitations or risks might be mitigated in the near future. Third, we focus on the specific domain of social movement studies, and the performance of LLMs might vary across different domains. Finally, we only compared GPT-4 with LlaMa3-8B model but the latest release of Llama3.1-405B model has shown greater performance across different benchmarks.\n\n\n## The Adoption of LLMs for Text Annotation\n\n\nTransformer-based large language models such as BERT, RoBERTa, and Longformer with transfer learning have been the state-of-the-art techniques in natural language processing tasks for social scientists especially those with relatively limited training datasets (Vaswani et al., 2017; Devlin, Chang, Lee, &amp; Toutanova, 2018; Liu &amp; Salganik, 2019; Beltagy, Peters, &amp; Cohan, 2020; Do, Ollion, &amp; Shen, 2022; Wankm¨ller, 2022). u Since social scientists often lack critical resources to label large-scale training examples to build a model from scratch, transfer learning allows scholars to transfer knowledge learned in the pretraining stage from other data sources to the learning process on the task in the target domain. To put it simply, social scientists can borrow transform-based models pretrained on large-scale textual or multimodal data and fine-tune them for downstream tasks with a limited number of training examples. The common practice is to (1) choose an appropriate model like BERT pretrained on a massive dataset of Wikipedia and Google Books Corpus and (2) to finetune the classification layer with human annotated training examples for domain specific tasks (e.g., binary or multiclass classification). For instance, scholars have used pre-trained transformer-based models to study a variety of topics such as populism (Bonikowski, Luo, &amp; Stuhler, 2022), Sinophobia (Y. Zhang, Lin, Wang, &amp; Fan, 2023), and propaganda (Lu &amp; Pan, 2022). However, fine-tuning LLMs for domain-specific tasks requires certain knowledge of deep learning and programming which impedes its wide adoption in social sciences.\n\nThe recent advancement in generative AI has transformed the field of computational social\n\nscience, as scholars have begun to use LLMs to implement zero-shot or few-shots text classification without any prerequisite programming skills (Brown et al., 2020; Chae &amp; Davidson, 2023; Ziems et al., 2024; Do et al., 2022). Generative AI refers to algorithms capable of producing realistic text, images, audios, videos, and other human-like outputs in response to prompts (Bail, 2024). Large language models, such as OpenAI's ChatGPT and Meta's LLaMa series, are pretrained on extensive textual datasets. These models learn the probability distribution of words within the training data, enabling them to conduct out-of-sample prediction and generate text based on an input sequence of tokens or the prompt.\n\nScholars are still debating whether social scientists should fine-tune transformer-based large models for information retrieval with transfer learning or simply use generative AI tools such as ChatGPT for zero-shot or few-shot classification. Although limited research indicates that generative AI tools do not surpass the performance of top fine-tuned models in text classification, LLMs such as ChatGPT offer a unique advantage in zero-shot annotation, frequently generating explanations of higher quality than those provided by crowd workers (Chae and Davidson 2023; Ziems et al. 2023). A recent study also shows that ChatGPT even outperforms crowd workers for annotation tasks based on four samples of tweets and news articles, including 25 percentage points higher in zero-shot accuracy and thirty times cheaper than MTurk (Gilardi, Alizadeh, &amp; Kubli, 2023). Notably, LLMs are also widely used by crowd workers on MTurk to automate text annotation tasks, with a prevalence of approximately 30% (Veselovsky, Ribeiro, &amp; West, 2023).\n\n\n## The Framework of Text Annotation Workflow with Generative AI\n\n\nGiven the increasing use of LLMs for coding tasks, it is critical for social scientists to evaluate the workflows and standards governing these processes. We propose that LLMs can serve as two different roles in text annotation: as the primary coder with humans serving as evaluators for large-scale data, or as secondary assistants with humans as the final decisionmakers for small/medium-scale data. Figure 1 proposes the workflow of using LLMs for coding, focusing on these two major roles.\n\nFor social scientists, the role of LLMs in text annotation - whether as primary coders or secondary assistants - depends on several factors, including the scale of the data (e.g., large versus small), task complexity (e.g., binary versus multiclass classification), and error tolerance (e.g., required accuracy rate). If researchers are dealing with a large-scale dataset with low task complexity and relatively high error tolerance, LLMs can serve as the primary coder while humans take on the evaluation role. To enhance the quality of coding quality, first we need to develop a coherent and clear codebook where all the concepts to be measured are well-defined. Second, researchers need to build a development dataset by purposefully selecting 100 ∼ 200 cases to iteratively test various prompting strategies for identifying the optimal prompt. Third, with the optimal prompt we scale it up to the entire dataset to obtain the coding output. After that, researchers need to further construct a separate evaluation dataset by randomly selecting an additional 100 ∼ 200 cases to report performance\n\nmetrics. Thus, the whole process takes both prompt engineering and data preparation into consideration. Note that selecting the optimal prompt is crucial to achieving the desired output in this process, and testing different prompts relies on the high-quality human-labeled development dataset.\n\nThe development set and the evaluation set are an archetype that we adapted from machine learning. The development set, also known as the validation set, is used to fine-tune the model's hyper-parameters in supervised machine learning and to select the optimal model. Here it is used to test and determine the optimal prompt. The evaluation set, sometimes referred to as the testing set, is used to evaluate the performance of the model. Here it is also used to assess the performance of the optimal prompt. Both datasets are separately sampled from the larger dataset, ideally ensuring they are distinct from each other because we cannot guarantee whether LLMs will incorporate the development set into their training process when used as input. This way, we can potentially avoid any inflated performance. The size of these datasets is flexible and depends on time and budget constraints, although we recommend a minimum of 100 ∼ 200 cases for each. Both sets require human labeling and serve as the ground truth.\n\nHowever, if the annotation task is sophisticated, requiring strong reasoning capacity, the data scale is manageable within budget limits, and error tolerance is low, or the analytic approach is inductive, LLMs can serve as coding assistants. In this role, they help with text summarization and provide an initial round of reasoning for annotation. Similar to computerassisted coding, LLM-powered coding allows scholars to efficiently digest key information from textual or multimodal data (e.g., images, audio) and make the final coding decisions.\n\n\n## Prompt Engineering for Text Annotation Tasks\n\n\nGiven that the output of LLMs is highly dependent on the prompts developed by scholars for specific tasks, we further discuss common prompting strategies proposed by computer scientists and engineers. A prompt is a sequence of text input that directs LLMs to perform certain tasks, allowing scholars to bypass the fine-tuning of LLMs for downstream tasks. Prompt engineering is the process by which scholars refine these prompts to guide generative AI towards producing desirable outputs. Various strategies for prompt engineering have been developed, such as in-context learning, role-play prompting, chain-of-thought prompting, and tree-of-thought prompting, to optimize the effectiveness of LLMs.\n\nIn-context learning is a prompting strategy that provides LLMs with a few training examples to learn from analogy. Scholars create prompts by incorporating several examples as the demonstration context, enabling LLMs to discern hidden patterns in these examples to correctly perform downstream tasks. Notably, in-context learning does not update the LLMs' parameters, which significantly reduces computational costs and can be easily applied to social science problems (Dong et al., 2023). For instance, to classify whether a news article is related to a protest, movement scholars can include several protest-related articles as training examples when formulating the prompt.\n\nRole-play prompting is a novel strategy that assigns a specific role to the LLM, enabling it to\n\nFigure 1: The Workflow of Using LLM for Text Annotation. Note: the LLM icon was created using GPT-4o.\n\n<!-- image -->\n\nproduce outputs tailored to the LLM's identity and persona given by the researcher (Kong et al., 2024). For instance, researchers can assign the LLM the role of an expert movement scholar role who excels at extracting protest information from news articles.\n\nThe chain-of-thought (CoT) prompting strategy directs LLMs to generate the intermediate reasoning steps, improving their ability to perform complex reasoning (Wei et al., 2022). CoT allows LLMs to decompose multi-step problems into several intermediate steps, offering an interpretable window into the models' decision-making processes. CoT can be combined with in-context learning by providing several examples (few-shot CoT) and can also be triggered by simply adding let us think step by step at the end of the prompt (zero-shot CoT) (Wei et al., 2022; X. Wang et al., 2023; B. Wang et al., 2023).\n\nInstead of modeling the human thought process as a linear chain, the Tree-of-Thoughts (ToT) approach decomposes multi-step problems into a tree structure, where each thought represents an intermediate step in problem-solving (Yao et al., 2023; Long, 2023). This method allows language models to self-evaluate multiple intermediate thoughts through a deliberate reasoning process (Yao et al., 2023). Hulbert (2023) applies the ToT framework to guide LLMs in evaluating intermediate thoughts within a single prompt. For instance, the sample prompt used by Hulbert (2023) to trigger ToT is as follows: 'Imagine three different experts are answering this question. All experts will write down one step of their thinking, then share it with the group. Then all experts will proceed to the next step, and so on. If any expert realizes they're wrong at any point, they will leave. The question is...'\n\nNext we show several examples how we can adopt some of these common prompting strategies for coding tasks in social science research, particularly social movement studies.\n\n\n## Standard Zero-Shot Prompting with Role Play\n\n\nSystem: You are an excellent AI language model trained to extract protest information from news articles.\n\nUser:\n\nYou need to determine whether it discusses peace movement in the following ar- ticle:\n\nNo=0)\n\n&lt; fulltext &gt; . Please structure your response as follows: &lt; numeric answer (Yes=1; &gt;\n\nAssistant:\n\n1-9012028\n\n\n## Zero-Shot CoT Prompting with Role Play\n\n\nSystem: You are an excellent AI language model trained to extract protest information from news articles.\n\nUser: You need to determine whether it discusses peace movement in the following article: &lt; fulltext &gt; . Let us think step by step. Please structure your response as follows: &lt; numeric answer (Yes=1; No=0) &lt; Step-by-step reasoning &gt;&gt;\n\n## Assistant: 1;\n\nThe article mentions the arrest of eleven people, including antiwar activist Philip Berrigan, who were part of a demonstration against war. They scaled a fence at the White House and threw red ink into a fountain as a form of protest.\n\nThe demonstrators are described as being affiliated with an antiwar group, specifically named the D.C. Coalition Against the U.S. in the Middle East.\n\nThis indicates that the protest was related to a peace movement, as it involved a group actively opposing war in the Middle East.\n\n\n## Zero-Shot ToT Prompting with Role Play\n\n\nSystem: You are an excellent AI language model trained to extract protest information from news articles.\n\nUser: Imagine three different social movement experts are answering this question. All experts will write down one step of their thinking, then share it with the group. Then all experts will proceed to the next step, and so on. If any expert realizes they are wrong at any point, they will leave. The question is that You need to determine whether the following article discusses peace movement: &lt; fulltext &gt; . Please structure your response as follows: &lt; Step-by-step reasoning &gt;&lt; numeric answer (Yes=1; No=0) &gt;\n\n## Assistant:\n\nStep 1: Identify the main activity described in the article.\n\n- - Expert 1: The article describes a group of people, including a known antiwar activist, who were arrested for scaling a fence at the White House and throwing red ink into a fountain.\n- - Expert 2: The demonstrators are affiliated with an antiwar group, indicating their primary motive is related to opposing war.\n- - Expert 3: The act of throwing red ink to simulate blood suggests a symbolic protest against violence or war.\n\nStep 2: Determine the nature of the group involved in the activity.\n\n- - Expert 1: The group is identified as the D.C. Coalition Against the U.S. in the Middle East, which clearly positions itself against U.S. policies or actions in the Middle East.\n- - Expert 2: The involvement of Philip Berrigan, a notable antiwar activist, supports the interpretation that this is an antiwar protest.\n- - Expert 3: The name of the group and the nature of the protest both align with typical peace movement activities, which often involve symbolic actions to draw attention to the costs of war.\n\nStep 3: Assess if the described actions align with those typical of a peace movement.\n\n- - Expert 1: Peace movements often use dramatic, non-violent actions to make a political point, which is consistent with the described protest.\n- - Expert 2: The use of red ink as a symbol for blood is a strong visual metaphor against war violence, aligning with peace movement strategies.\n- - Expert 3: The target of the protest, the White House, is a strategic location for making a bold statement against national policies on war.\n\n## Conclusion:\n\n- - Expert 1: The article describes a protest by an antiwar group using symbolic non-violent action, typical of peace movements.\n- - Expert 2: The involvement of known peace activists and the nature of the demonstration clearly point to a peace movement.\n- - Expert 3: The overall context and details provided in the article align with the characteristics of a peace movement protest.\n\nNumeric Answer:1\n\n\n## Limitations of Using Generative AI for Text Annotation\n\n\nNext, we discuss the limitations of using generative AI for text annotation. It is important to note that we are not AI-Luddites; as the technology advances, we anticipate improvements that will mitigate these limitations and challenges, enabling more effective and ethical use of LLMs in social science research. We will use social movement studies as an illustrative example to demonstrate the potential epistemic risks in using generative AI for coding. We want to recognize that these epistemic risks are particularly critical when scholars use generative AI as the primary coder instead of secondary coding assistant. Drawing on studies examining the risks and limitations of LLMs, we discuss how to incorporate those considerations into the prompt development process to eliminate such risks.\n\n\n## Are Generative AI coding results valid?\n\n\nIntegrating generative AI into social science research, particularly for constructing protest event datasets in social movement studies, presents unique challenges. Movement scholars demand high accuracy due to the complexity and nuance of the protests involved. The primary concern among social scientists when adopting generative AI is whether it can match human-expert level precision in coding complex concepts, since these LLMs may suffer from hallucination and biases (Srinivasan &amp; Chander, 2021; Bail, 2024). Recent studies indicate that LLMs like ChatGPT and other similar technologies can outperform crowd workers in tasks such as text summarization (Gilardi et al., 2023). However, a notable gap remains in achieving expert-level accuracy for domain-specific tasks. We benchmark generative AI-produced results with the DoCA-LDC dataset to systematically assess whether LLMs can achieve expert-level accuracy. We consider different levels of task complexity for classification tasks, including binary (police presence), multi-class (protest size), and multilabel classifications (protest activities). For demonstration, we only use several common strategies including standard zero-short with role-play, zero-short CoT, and zero-shot ToT (see Appendix A for example prompts) by querying OpenAI-GPT4-turbo model using the matched DoCA-LDC dataset.\n\nTo demonstrate the potential variations in the relationship between prompting strategies and task complexity, we conducted experiments using the same prompt question, incorporating different triggers to initiate various strategies. In real settings, researchers should have a development set to test the performance of strategies and choose the optimal one. Table 1 presents the accuracy and F1 scores across a variety of text classification tasks. Police presence is a binary variable, indicating whether police involvement was mentioned at the event. Protest size is a categorical variable scaled from 1 to 6, where a score of 1 denotes a small group of 1-9 individuals, and a score of 6 corresponds to gatherings of 10,000 or more participants. The protest activity involves a multi-label classification problem where LLMs are tasked with identifying up to four activities from a predefined list, which includes bannering, candle-lighting, petitioning, holding signs, camping, sit-ins, physical attacks, looting, and more. For assessing the classification performance on protest activities, we adopt the subset accuracy . This metric is defined as the proportion of instances where all relevant protest codes listed in DoCA are completely encompassed within the predictions made by\n\nGPT-4. Consequently, a prediction is deemed accurate only if every protest activity code generated by GPT-4 for an article is inclusive of all corresponding codes in DoCA. We show that the coding performance of GPT-4 varies across different levels of task complexity and prompting strategies. Overall, GPT-4 performs pretty well in less complex tasks but not in those multiclass and multilabel classification tasks. Note that we only ran experiments using zero-shot prompts, and results might be different for other prompting strategies such as few-shot prompts.\n\n\n## Are Generative AI coding results reliable?\n\n\nAnother widely shared concern among scholars is the reliability of using LLMs in social science research. A critical question is whether Generative AI produces consistent results when using the same prompting strategy and parameter settings. Our proposed approach involves running the same prompt multiple times (at least 25) on a development dataset and calculating the intraclass correlation (ICC) to measure inter-rater consistency. Each run is treated as a separate rater. According to Koo and Li's guideline (2016), ICC values below 0.5 indicate poor reliability, values between 0.5 and 0.75 suggest moderate reliability, values between 0.75 and 0.9 indicate good reliability, and values above 0.90 indicate excellent reliability.\n\nTo demonstrate, we used the OpenAI GPT-4 model to classify a subset of the DoCA-LDC dataset, focusing on two specific tasks: police presence and protest size. To mimic a development set, we randomly selected 200 articles and queried the OpenAI API 25 times using the same prompt and parameter settings. Figure illustrates the trend of average accuracy across these 25 classifications. Overall, the accuracy scores fluctuate for both measures when repeated 25 times. We also use intraclass correlation to evaluate the inter-rater consistency (if we treat each run as a rater). The ICC score for police presence is 0.934 (95% CI : [0.921,0.946]), indicating excellent reliability. While the ICC score for protest size is 0.518 (95% CI :[0.463,0.577]), a moderate reliability which means the results are not very reliable. It is quite evident that results are more reliable or consistent when performing simple tasks than complex ones (i.e., binary versus categorical variable).\n\n\n## Are Generative AI coding results replicable?\n\n\nThe potential lack of replicability is another hurdle that lowers social scientists' enthusiasm to adopt LLMs in their research (Barrie, Palaiologou, &amp; T¨rnberg, 2024). o A recent work conducted by Barrie et al. (2024) shows that the prompt stability of outputs generally\n\nFigure 2: The Consistency of 25 Repeated Outcomes.\n\n<!-- image -->\n\ndecreases with increasing temperature due to the degradation in the quality of prompts. Datasets exhibiting the least prompt stability typically contain data that are either illsuited or have imprecisely defined outcome constructs. Thus, can other researchers replicate generative AI results using the same method and data? The answer is very complicated. The replicability depends on a variety of factors, including the specific prompt, parameter setting, specific type of model, etc.\n\nThe alchemy of prompt engineering. The performance of coding tasks is highly sensitive to prompt engineering. In this paper, we tested several common prompting strategies, including zero-shot with role play, CoT, and ToT. Our experiments show that LLM performance varies across different types of prompting strategies. We show that the simple zero-shot with role play performs pretty well across different tasks. But for binary classification, we show that the zero-shot CoT outperforms others, while for multiclass classification, zero-shot ToT works better. This is not to suggest that scholars need to use CoT or ToT in their research but to show that different prompting strategies may lead to different results.\n\nModel drifting. The rapid development in generative AI brings the unprecedented challenges to social scientists in tandem with opportunities. New advanced models offer scholars more power to handle multimodal data with better performance. However, this also brings uncertainty and replicability issues. For instance, OpenAI offers a series of different models, such as GPT-4, GPT-4o, and GPT-3.5, for scholars to handle different tasks with different pricing and speed. When some of those legacy models are not accessible to scholars, others cannot replicate their results due to model drifting.\n\nPersonalization and memory. The alignment of LLMs with human values and norms via reinforcement learning from human feedback was used to maintain the safety of LLMs, but the alignment norms were often dictated by fewer developers or researchers, leading to the exclusion or under-representation issues. To better reflect individual preferences, these proprietary models such as OpenAI GPT-4 models can be tailored to individuals via\n\nthe memory or personalization feature. Personalized LLMs can reduce cultural hegemony and improve usefulness, but also bring risks pertaining to privacy infringement and bias reinforcement (Kirk, Vidgen, R¨ttger, &amp; Hale, 2024). o Although personalization is the new frontier in LLM advancement, it poses particular challenges for social scientists regarding replicability. This is particular the case when researchers use these proprietary models to produce coding with memory enabled.\n\n\n## Are Generative AI text annotation results transparent?\n\n\nLLMs are like black-box, especially the proprietary models. Scholars have warned the danger of using proprietary LLMs in social science research in part due to the transparency issues (Bender, Gebru, McMillan-Major, &amp; Shmitchell, 2021; Ollion, Shen, Macanovic, &amp; Chatelain, 2024). One strategy for social scientists to improve the coding transparency is to ask LLMs to output the reasoning steps which might help us understand the potential logic. In so doing, human evaluators can take advantage of the outputs for cross-validation. The below is the example using zero-shot CoT to ask GPT-4 to determine whether the article discusses peace movement. GPT-4 reasons output the following steps:\n\n- 1. The article mentions the arrest of eleven people, including antiwar activist Philip Berrigan, who were part of a demonstration against war. They scaled a fence at the White House and threw red ink into a fountain as a form of protest.\n- 2. The demonstrators are described as being affiliated with an antiwar group, specifically named the D.C. Coalition Against the U.S. in the Middle East.\n- 3. This indicates that the protest was related to a peace movement, as it involved a group actively opposing war in the Middle East.\n\nThese steps detail how GPT-4 evaluates whether this article discusses a peace movement based on several key information. However, scholars should be cautious about the stepby-step reasoning results because of model hallucination. LLMs may just simply produce results conforming to the prompt instead of learning what LLMs have seen (B. Wang et al., 2023). Thus, we selected 100 news articles to ask GPT4 and LLaMa3 to use zero-shot CoT to output the step by step reasoning. We then manually examine whether these outputs are factually correct. Based on our human evaluation, GPT-4 correctly reasoned these 100 cases as we manually assessed the materials extracted from articles. However, we did find some errors for LlaMa outputs. Below are some examples:\n\n## Examples of Llama' Wrong Reasoning - The Inference Goes too Far\n\n## Example 1\n\n## Output: 1-Yes\n\nHere is my step-by-step reasoning:\n\n- * The article describes an event where David Duke takes the oath of office as a member of the Louisiana Legislature.\n- * The event took place in the House chamber, which suggests that it was held at the Louisiana State Capitol building or possibly another government building.\n- * Later in the article, it mentions 'lawmakers' and 'Representative C.D. Jones', who were present at the event and reacted to Mr. Duke's swearing-in.\n- * From this context, I infer that police officers would likely be present at such an event, especially considering the controversy surrounding David Duke's appointment.\n- * Therefore, I conclude that police were indeed present at the event mentioned in the news article, which is why my answer is 1-Yes.\n\nWhere the mistake lies: The news article does not mention the presence of police, but Llama infer from the context that usually police officers would likely be present at such an event.\n\n## Example 2\n\n## Output: 1-Yes;\n\nStep-by-step reasoning: The article mentions police only once, in the following sentence: 'Those departments that fail to do so will be required to show why they failed and to undergo an outside review of their recruiting procedures.' This suggests that there might have been a mention of police presence at the event, but it does not explicitly state the presence of police.\n\nWhere the mistake lies: The news article does not mention the presence of police, but Llama infer from an irrelevant statement.\n\n## Example 3\n\nOutput:\n\n1-Yes;\n\nStep by step reasoning:\n\nThe article mentions that the student editors have protested the rule by handing out their publications across campus, which could prompt the university to disband their groups. This implies that there may be some interaction or presence of police at this event.\n\nWhere the mistake lies: The news article does not mention the presence of police, but Llama infer from the context that police officers would likely be involved in such situation.\n\nAnother wide concern among social scientists when using LLMs for coding is on the confidence of model output. How confident is the Generative AI classification? When proprietary LLMs do not output the distribution of token probability, then it poses greater epistemic risks as scholars are not informed about the confidence of the results. OpenAI GPT-4 provides a feature that allows scholars to access the logprob parameter and calculate the probability. Note that log probability can provide researchers with important insight into the confidence of the model regarding each token it predicts. Here we use police presence as an example to show how we can obtain the token probability based on logprobs parameter. We use the\n\nbelow prompt with setting logprobs as True: You need to determine if it mentions police at the event in the following article: &lt; fulltext &gt; . Please structure your response (1-Yes; 0-No) as follows: &lt; numeric answer &gt; .\n\nFigure 3 shows the extracted predicted token probability (i.e., our classification result). The majority of these cases reported a value of over 95%. For the ease of presentation, we only report the 137 cases with a value less than 95%. These cases show a relatively low level of probability or confidence in terms of generating the predicted token. These cases oftentimes warrant further investigation.\n\nFigure 3: Histogram of Reported Probability for Police Presence\n\n<!-- image -->\n\n\n## The Future of Text Annotation with Generative AI\n\n\n## Ascertaining the role of LLMs for text annotation in social science research\n\nLLMs can serve as invaluable tools in social science research, functioning either as primary coders or as secondary coding assistants. These models are particularly beneficial for handling extensive texts that require significant effort for human coders to process. Scholars can use LLMs to perform intermediate steps such as generating text summarizations, which human coders can then assess for further analysis in downstream tasks. This application proves especially useful when the volume of text is substantial. To obtain detailed and reasoned coding results, researchers need to craft specific prompts, such as the Chain of Thought (CoT), to guide the LLMs effectively. In scenarios where high accuracy is paramount, the dataset is relatively small, and the budget allows for hiring additional research assistants, LLMs typically assume a secondary assistant role to support human coders in their decisionmaking processes. In scenarios where the error tolerance is relatively high, the dataset is large, and the coding task is not complicated, LLMs can function as primary coders. In other words, scholars fully depend on these models to complete coding tasks such as classification and regression problems. Of course, scholars can use LLMs as primary coders to generate labeled training datasets for fine-tuning their own large language models for largescale datasets. Given the divergence in the workflow, scholars need to ascertain the role of LLMs in their specific coding tasks.\n\n\n## Enhancing the quality of AI results with prompt engineering\n\n\nOur experiments indicate that the quality of generative AI coding outputs is highly sensitive to the specific prompts used. Consequently, scholars need to pay particular attention to prompt engineering-finding the optimal prompt for their specific coding tasks. For LLMs serving as secondary coding assistants, we recommend that researchers experiment with the chain-of-thought prompting strategy. This approach guides LLMs to produce step-by-step reasoning, providing scholars with detailed information for human evaluation and decisionmaking in coding tasks. For LLMs that serve as primary coders, it is crucial for scholars to create an development dataset to systematically test the performance of different prompting strategies. This testing phase ensures that the chosen prompt candidate is effective before its application to the entire dataset. We also propose that scholars can report on the log probability of predicted tokens and select the cases with low confidence to diagnose the potential issues leading to low accuracy. In this paper, we only showed several common prompt strategies including zero-shot, role play, chain of thought, and tree of thought. Other prompting strategies such as in-context learning with few examples and graph of thoughts. Notably, with sufficient budget, scholars can also fine-tune LLMs for specific downstream tasks with own training datasets.\n\n\n## Decomposing complex tasks into simple ones such as binary classification\n\n\nWe tested several common coding tasks in social science research, particularly in social movement studies. Our experiments show that GPT-4 performs better in simple binary classification task than multilable and multiclass classification tasks. As the task complexity increases, LLMs' performance worsens. We recommend that scholars should decompose complex coding tasks into simple ones. For instance, scholars can modify multilable or multiclass tasks into a series of binary classification.\n\n\n## Improving the interpretability by outputting the AI underlying reasoning and coding decision\n\n\nOne of the major concerns of using LLMs in social science coding is its black box nature that lacks interpretability. We propose that scholars can tailor prompts to guide LLMs to produce the underlying reasoning for human evaluation. Instead of outputting the final result, LLMs can create the step-by-step reasoning that explains their coding decision making processes. But scholars should be cautious when relying on generative AI as it may not reflect what it has learn from CoT and the underlying reasoning could be hallucination or simply conform to the guidance of the prompts (B. Wang et al., 2023). But our human evaluation of 100 cases show that the underlying reasoning is reliable in our case of coding police presence in protests. We did find that in some cases, LLMs are hallucinating as they might infer too far.\n\n\n## Increasing the replicability by making codes and outputs transparent\n\n\nTo improve the replicability of using generative AI social science research, we encourage scholars to deposit and share codes in public repository such as GitHub and SocArxiv, documenting the specific prompt, the specific model, and the specific parameter setting. If\n\npossible, we also call for scholars to share their outputs from LLMs. We acknowledge that scholars should anonymize/remove some of these input/output data that contain sensitive information (Li, Dohan, &amp; Abramson, 2021).\n\n\n## Prioritizing open-source models over proprietary LLMs for data security and responsible use\n\n\nSocial scientists should call for responsible and ethical use of generative AI in their own research. One of the primary concerns is related to sharing proprietary and sensitive data. Social scientists often engage with proprietary and sensitive data, such as the New York Times news articles, voter records, interview transcripts, and survey results. When individual researchers use proprietary LLMs from leading companies such as OpenAI and Google, they have to upload their data, which may cause potential data leakage and privacy violation. One common task of social movement scholars is to extract key protest information from news articles. Is it okay to upload these news articles to proprietary LLMs for classification tasks? One common practice is to ascertain the proprietary LLMs do not use your uploaded data for training their own models or share them with third parties. Other qualitative scholars may interview protesters on a series of sensitive questions and use generative AI to transcribe and analyze data but is it okay to share these data with LLMs? One common research protocol is to get permission from participants to use these generative AI tools to analyze their data.\n\nThe alternative to use proprietary LLMs is to prioritize open sourced LLMs in social science research, such as LLaMA family models. You can run these open source models with langchain, ollama, or huggingface transformers on your own computers or remote servers in a secure environment. In this study, we evaluated the performance of the Meta Llama3 model, specifically we experimented with the 4-bit quantized version known as Meta-Llama-3-8B, across the three tasks. We applied the same zero-shot prompt technique used for the GPT-4 model at a temperature of 0.2. We deployed the model in our local computer and employed the ollama interface. The completion times for each task were as follows: 1.6 hours for the binary task assessing police presence, 2.2 hours for the multiclass task determining the number of participants, and 5.5 hours for the multilabel task identifying protest activities. The results of Llama3 is shown in Table 2.\n\nTable 2: LLaMa3 Performance based on CoT.\n\n\n## Conclusion and Discussion\n\n\nGenerative AI has been applauded since it can improve social science research including automated text analysis (Ziems et al., 2024; Bail, 2024). But can we replace human coders\n\nwith LLMs in text analysis? Our findings indicate both promise and pitfalls. In this paper, we propose a framework to integrate LLMs in social science coding by assuming two roles: LLMs as secondary coding assistant and LLMs as primary coding decision-maker. When LLMs are the secondary coding assistants, human coders can use the information extracted by prompted LLMs to assist their decision making processes. The epistemic risk associated with this role is relatively low since LLMs perform pretty well in information retrieval and human coders make the final decision. However, when LLMs assume the primary coder role, scholars should be cautious of replacing human coders with LLMs as they tend to misportray marginalized groups as more like outgroup imitations instead of ingroup representations, flatten demographic groups with ignoring within-group heterogeneity, and essentialize identities with amplifying stereotypes (Dillion, Tandon, Gu, &amp; Gray, 2023). To better communicate the epistemic risks associated with using LLMs in social science coding, we propose several practice guidelines, including the before-prompt engineering and after-evaluation pipeline, the explainable coding by outputting underlying reasoning, improving transparency by sharing codes with specific prompts, model parameters, and returned outcomes, prioritizing open sourced LLMs for data security, and obtain permission for using proprietary LLMs to analyze sensitive data.\n\n",
         "Generative artificial intelligence (AI) or large language models (LLMs) have revolutionized computational social science, particularly in automated textual analysis. In this paper, we conduct a systematic evaluation of the promises and risks of using LLMs for diverse coding tasks in social movement studies. We propose a framework for social scientists to adopt LLMs to text annotation, either as the primary coding decision-maker or as a coding assistant. Additionally, we discuss the associated epistemic risks related to validity, reliability, replicability, and transparency. We conclude by offering several practical guidelines for using LLMs in coding tasks.",
         ""
        ],
        [
         "25",
         "25",
         "## 1. Morality in Children and Youth\n\n\nThe study of morality within children and youth is virtually absent in sociology. This is both surprising and, perhaps, not. It is surprising because sociologists have cared (off and on) about child and adolescent socialization (Lareau, 2003; Parsons, 1951), with a growing resurgence capped by a recent review article pushing for a revival (Guhin, Calacro and Miller-Idriss, 2021). Going back further, the notion of education as inextricably entwined with morality or moral socialization has a long-standing tradition in sociological theory (Cooley, 1902 [1964]; Dewey, 2007; Durkheim, 1925 [1973], Elias, 1978; Martineau, 1938). Thus, it would seem that the cultivation of morality would be as important as the cultivation of, say, class interests, intrinsic motivation, or schema. And yet, the mention of morality among children or adolescents, in theory or empirical research, is mostly invisible or implied (Corsaro and Eder, 1990), conflated with conceptual short-hand that presumably act as proxies of morality, like norms (Horne and Mollborn, 2020) or values (Guhin, Calarco and Miller-Idriss, 2021), or biased towards the sorts of “liberal” categories found in Haidt’s (2004) model like care or justice versus authority or what Shweder (2003) refers to as “ethics of community.” Equally vexing is the tendency to examine youth morality from adult perspectives, seeing their behavior and deviance—or, what is sometimes amplified as a/immorality—refracted through adult values rather than asking them, especially children, what they think and why they do or did what they do or did). In this sense, youth morality has been ceded to psychologists and neuroscientists (Decety and Wheatly, 2015; Eisenberg, 2000; Tomasello and Vaish, 2013).\n\nOn the other hand, this lack of engagement with youth morality is not as surprising as it may seem. Despite the theoretical and methodological stakes for studying youth (Pugh, 2014), some barriers include trepidation predicated on methodological and ethical dilemmas with studying youth, especially children (Eder and Corsaro, 1999); the explicit or tacit belief that youth, particularly children, lack moral accountability and agency (Frankel, 2012); the fear that studying socialization will paint a picture of passive creatures (Guhin, Calacro and Miller-Idriss, 2021); and, finally, a disagreement about what constitutes “moral” or “morality,” with various sociological answers settling either on the sociological psychologizing that Wrong (1962) critiqued as oversocializing, such as belongingness (Pugh, 2009), conformity to norms (Horne and Mollborn, 2020) or adjacent proxies of morality like politeness, manners, and caring for others (Britton, 2015). This is not to say what these scattered studies examine is not morality; rather, we argue that most sociologists have yet to import the general insights of the sociology of morality (Hitlin and Vaisey, 2013; Abend, 2008) into the unique developmental and sociocultural elements of children and youth.\n\nNonetheless – and despite the ambiguity and disagreement surrounding the definition of morality that surely runs like a thread throughout this volume – there seems to be much at stake in studying youth morality. That is, it is not territory worth ceding, as the fundamental basis of social interaction and organization require consideration of both the phylogenetic and ontogenetic roots of morality that consume bio-psycho research on youth and an understanding of the processes by which culturally-specific morality is added on to what is inherently human. Moreover, much is lost when sociology’s full methodological tool box goes unused.\n\nThe core theoretical insight we import from the bio-psycho sciences is that cooperation and the ability to coordinate our actions with significant others and strangers rests at the heart of youth morality. There is a phylogenetic, or evolved, component to this assertion in so far as domination and not cooperation characterizes our closest relative’s social organization (Abrutyn and Turner, 2022; Boehm, 2018), with naked aggression being 100 times more frequent in chimp communities vis-à-vis human communities (Wrangham, 2019). Thus, while humans are animals capable of great conflict and violence, research on child development points towards the phylogenetic and ontogenetic roots of morality in the innate cooperative behavior of infants and toddlers that is carried on, with social modification, in children and youth more generally. Thus, while the current trend in sociology, for understandable reasons, leans towards highlighting difference, inequality, and injustice, we miss the part where humans are wired for morality and the sociological study of how this morality is encouraged or discouraged over the most formative years of human development. And, without this part, it is difficult to make methodological decisions, let alone interpret our data, with regard to how early and later socialization affects the innate moral actions of children.\n\nBefore we can dig into this perspective and its implications for sociology, we begin by reviewing the classical literature on morality and, where possible, youth. This review is brief to avoid redundancy with other chapters in this volume and because classical sociology was only tangentially interested in children or youth more generally. From there, we explore the best candidates for a contemporary sociological study of youth morality, identifying some really important studies along the way, but also finding a general lack of systematic research that begs to be filled. The chapter then shifts to the bio-psycho literature and concludes by pointing sociologists to future directions that may benefit from a happy interdisciplinary marriage.\n\n\n## 2. The Classics Revisited\n\n\nAny essay on morality must begin with the classics (Hitlin and Vaisey, 2013; Abend, 2008), particularly Durkheim’s (1925 [1973]) Moral Education, where Durkheim sees education as inextricably linked to building a civic, moral society without religion in highly differentiated societies (Guhin, 2021); a point made much earlier by Martineau (1938). Across the Atlantic, however, a similar argument was being made by the nascent pragmatist movement in American sociology (Dewey, 2007), which translated into an intense interest in transforming theories of psychological development into theories of a social self and its socialization. Most famously, this interest emerged first with Cooley’s (1902 [1964]) assertion that human nature itself was a product of primary group socialization, which required not simply internalizing cognitive appraisals, but also core moral emotions like pride and shame. Mead (1934) also adopted this view, adding that the self is not completely developed without internalizing a generalized other, or an imagined other that reflects the community’s moral authority. In classic sociological fashion, morality was found outside of the individual, in the community’s beliefs and practices internalized through informal and formal socialization.\n\nFor better or worse, the assumption that morality is external to individuals presents a paradox. On the one hand, it echoes the problems Parsonian functionalism (Wrong, 1962) produces in which youth are passive vessels waiting for society to pour its latent cultural patterns. Youth then reproduce their parent’s class-based and/or racial interests and beliefs, and thus morality appears far more fixed and socially constructed (Calarco, 2018; Lareau, 2003; Bourdieu 1984). On the other hand, this sort of fixedness runs counter to many sociologists’ commitment to some sort of praxis, which would prefer to emphasize the malleability and relative nature of morality, such that youth could actively resist, negotiate, or modify morality. Ironically, neither position contradicted the other because the externality of morality invites any given sociologist to impose their own version of morality onto youth attitudes and behavior. Class interests, if they create inequity in opportunity or resources, are inherently immoral, from many sociological vantage points (Willis, 1977), whether reproduced unwittingly or actively. Lost in this is the Durkheimian side of sociology in which we interrogate what is actually moral about youth culture, interactions, attitudes, and behavior from their perspective and from direct observations that do not immediately put the cart before the horse.\n\nThis problem is especially pressing as the movement towards a subjective, critical account of youth obscures two very different aspects of youth morality. First, it makes it difficult to imagine youth as having moral agency or accountability or, worse; adults strip them of it in oversocializing them. Instead, what might be deemed moral, cooperative behavior may simply be interpreted through the typical suspicious sociological lens that it is, in fact, power and conflict (Lignier, 2021); interpretations, incidentally, that pits sociology against the substantial and mounting evidence to support the idea of a social ontogeny predicated on cooperation (e.g., Curry, Mullins and Whitehouse, 2019; Tomasello and Vaish, 2013). Second, social science that has taken seriously children (Corsaro and Eder, 1990; Pugh, 2009) and adolescent (Britton, 2015) culture reveals a significant amount of coordinating behavior and attitudes for the collective good, cooperation, and cohesion that echoes what we believe is core to youth morality, but which often is obscured by the conventional sociological conflict prism. Indeed, these studies unsurprisingly support the notion that youth display agency, autonomy, and creativity that, admittedly, is not totally free of adult interference but is far more distinct than we often give credit. In short, then, we are not arguing that research on youth that emphasizes distinctions borne of internal status hierarchies and competition (Coleman, 1961) or class-based differences that reproduce or intensify inequities (Lareau, 2003) are wrong or unnecessary, but that it is time to revisit the moral side of children and youth. But, before we present the current science of moral development, let us consider contemporary work in sociology that has close ties to the cooperative tradition in sociology.\n\n\n## 3. Contemporary Trends in the Sociology of Youth Morality\n\n\nAs noted above, the bulk of the sociological literature on youth morality is indirectly observed through the focus on norms, or “social rules about how to behave that result in negative sanctions when violated” (Mollborn, 2017, p.1). While norms are not synonymous with moral behavior—for instance, etiquette can be ought to moral directives or should conventions (Abrutyn and Carter, 2015), they are connected to morality in at least two ways. First, norms involve both judgments about what is “right” and “wrong” and perceptions of what others think is right and wrong (Horne and Mollborn, 2020); both important aspects of moral development and decision-making (Morris, Eisenberg and Houltberg, 2011). And second, normative behaviors, like moral behaviors, are inherently cooperative. Fundamentally, norms work to meet the collective need for social order and often serve as the basis for laws alongside moral values (Hechter and Horne 2009; Axelrod, 1986). Though this assumption undergirds a significant portion of microsociology, Goffman (1967:19ff., 1983) most eloquently described this in his discussion of the interaction or expressive order in which the “rules of conduct” arising from the obligations one has towards others and the expectations they have towards her and one’s commitment to obeying these rules are a “tacit agreement…to abide by the ground rules of social interaction.” That is, cooperation is predicated on the socialization of norms.\n\nFrom the earliest stages of life, children learn to coordinate their behaviors with those of their families, peers, teachers, and religious communities to ensure effective and efficient completion of day-to-day activities (e.g., Horne and Mollborn, 2020; Brint, Contreras and Matthews, 2001). As we discuss throughout this chapter, these types of coordinated efforts are central to moral behavior into adulthood. It is important to emphasize that norms are still cooperative even if, paradoxically, they can also reinforce social inequality, for example, by implying that some behaviors and groups of people are more socially desirable than others and thus worthy of social and material rewards. In such situations, a gap between what we might call “global” or 3rd person morality (judging such inequality as immoral) and “local” or 1st person morality can exist without much dissonance (Lukes, 2008), as local culture tends to feel more direct, embodied, and experienced and is more easily monitored and sanctioned, thereby generating greater conformity (Fine, 2010).\n\nYouth norms are particularly tricky to study because multiple, often conflicting, forces shape them. On the one hand, youth are subjected to tremendous pressure to conform to adult-imposed norms (which can be different from adults’ own behavior) and pay a high price for any violation. For instance, Mollborn’s (2017) found that teens can face long-term consequences to their interpersonal relationships and career opportunities when they violate adult-imposed sexual norms around virginity and pregnancy. Moreover, parents, teachers, and other adults can enforce norms through physical and material control, for example, by imposing restrictions on youth’s movements and activities, and by limiting the resources spent on their personal interests and desires.\n\nOn the other hand, youth create and enforce their own norms (e.g., Allison, 2009; Bauermeister et al., 2009; Best, 2006; Ilan, 2015; Corsaro, 1992; Coleman, 1961). For example, Corsaro’s (1992) research has highlighted how preschool children take part in a creative process of interpreting externally imposed norms and values, referred to as “interpretive reproduction,” a process ignored by earlier work on socialization (e.g., Parsons). And other research among California youth has shown how teens, and male teens, in particular, attempt to gain a sense of freedom and visibility from their parents and communities through risky driving behaviors (Best, 2006). But unlike the material and physical consequences of adult-to-child norm enforcement, peer-to-peer norm enforcement can take the form of social sanctions and exclusion not unlike how adults enforce norms on each other (Coleman, 1961). Ultimately, youth actively attempt to present themselves in ways that promote social approval from their peers and adults in their community (Juvonen and Cadigan, 2002). This tension is exacerbated by the fact that youth are constantly on social media and must simultaneously juggle multiple conflicting identities; they can no longer isolate these identities from each other as previous generations could, conforming to context-dependent norms (Smith-Lovin, 2007). Instead, their online behaviors are turned into public, permanent “exhibitions” (Davis, 2016, p. 14) of their moral beliefs, attitudes, behaviors, and political affiliations (Ekström and Shehata, 2018).\n\nOne might be wondering: what shapes these norms in the first place? While we are not equipped to answer this question fully, we argue that cooperation is key to moral norms.  Our perspective is in line with what has been referred to as the “consequentialist” approach to studying norms, which posits that norms are shaped by the benefits a person’s behavior confers onto other group members (Coleman, 1990; Heckathorn, 1988, 1989; Horne and Mollborn, 2020). Although other competing theories on norms exist – such as the relational approach -- the consequentialist approach is considered the most well-tested theory on norms (Horne and Mollborn, 2020). In Coleman’s (1961) ethnographic work on high schools in the greater Chicago area, for instance, he found that students preferred to be remembered as an “athletic star” rather than a “brilliant” student.  Coleman argued that this was due to the collective “glory” that athletes offer their peers, in contrast to the individual-level status gains that result from academic achievement.  The consequentialist approach to moral norms also fits with the extensive body of work on the evolutionary roots of morality, which we discuss below.\n\nDespite this body of work on youth norms, we argue that a clear research program focused on youth morality is still needed to gain a deeper understanding of morality's role in shaping social action and its roots, development, and socialization. The broad conceptual research of “norms” used in contemporary sociological research makes it difficult to distinguish what is moral from what is simply normative. Examining youth norms without making such distinctions leaves room for scholars to impose their own perspectives on what is moral, which they likely to derive from adult culture – in essence, acting as “moral philosophers in disguise” (Abend, 2008, p. 87). To address some of these conceptual issues, sociological research on youth morality would benefit from integrating insights from other disciplines, such as psychology, neuroscience, and evolutionary anthropology. In the following sections, we provide an overview of these literatures and how they can inform future research on youth morality.\n\n\n## 4. The Evolutionary Roots of Youth Morality\n\n\nIn this section, we provide an overview of the evolutional roots of moral development, drawing on research in psychology and neuroscience. Sociology has a long history of casting itself as supremely distinct from biology and psychology, but at what cost? We see several advantages to reviewing and integrating insights from these other fields, particularly on the subject of morality in children and youth. First, there are fundamental behaviors that are universal to neuro-typical humans. These behaviors provide further evidence that morality is universal to humans and – as infants begin to discern between prosocial and anti-social adults quite early – that there is something to the idea that children are moral beings. Second, it highlights some of the roots of sociological processes, like Mead’s classic taking the role of the other, placing it firmly on biological grounds, and shedding more light on how it works. Third, it offers potentially fruitful avenues for advancing the sociology of children and youth and for bringing the discipline into greater dialogue with other disciplines.\n\nAs previously noted, cooperation is a key aspect of moral behavior. Motivations for cooperative behavior span well beyond social conformity and norm following. We know that giving feels good. Aknin et al. (2015), for instance, have shown that the emotional rewards for generous and cooperative behaviors are universal, even if what counts as generous or cooperative varies across time and space. What is important here is that we can leverage this insight about cooperation as a fundamental moral act to better understand (a) what constitutes cooperative behavior across and between cultures, (b) how this motivation manifests itself, and (c) what happens when the motivation the cooperate comes into conflict with other motivations. In doing so, we start from a stronger empirical and epistemic perch as sociology moves forward in developing a more comprehensive theory of moral behavior.\n\n\n### 4.1 The Phylogenetic Roots of Cooperation and Morality\n\n\nBefore reviewing evidence that children are moral creatures, we begin by asking where does morality come from? Do our closest relatives, the great apes, demonstrate moral behaviors that could provide the foundations for human morality? To paraphrase famous primatologist Frans de Waal: the two pillars of morality are a sense of fairness and the capacity to empathize. To that end, humans share many qualities with their fellow apes. For instance, Brosnan and colleagues (2010) have demonstrated through experiments that chimps often do not tolerate inequity. For instance, in one study, some chimps occasionally rejected a grape (the preferred treat) when their buddy received a carrot instead. Chimps can discern buddies because they also reciprocate with those who have previously shared food with them. While they will share food with certain others, chimps do not live in cooperative communities, and these reciprocal relationships are tenuous at best, as chimps, like gorillas, live in communities forged from (moderate) dominance behaviors (Boehm, 2018). Nonetheless, they appear to have the capacity to calculate what is fair and unfair.\n\nThe other piece of morality is empathy. All mammals have mirror neurons, which are believed to be one of the key brain structures responsible for feeling and understanding the pain and suffering of those who belong to our group (Lents, 2016:69ff.). Gorillas and, especially chimps, are both highly attuned to the faces and emotions of others, allowing them to determine who belongs to their community and who does not (de Waal, 2019). Moreover, research has shown that chimps act “to benefit the other without any direct anticipation or planning for any kind of payback” (Tomasello and Vaish 2013, p. 236). In short, great apes have the biological wiring to be reciprocal (with some members of our group) and to pay close attention to the affect of others and, thereby, have the foundations of a moral nature.\n\nThat said, apes differ from humans across a spectrum of ways that have implications for human morality (Tomasello, 2019:5ff.). For one thing, experimental and naturalistic research confirms that humans act collectively with intention. The externalization of practices and beliefs in language and ritual is an intentional act of cooperatively remaking and representing the group. In contrast, chimps and gorillas do not seem to (a) intentionally form and pursue shared goals, (b) engage in a Meadian “conversation of gestures” in which both actors take each other’s roles and mutually constitute a situation, and (c) willingly divide rewards equitably.\n\nFrom an evolutionary perspective, cooperation makes a lot of sense. The human capacity for social and moral evaluation is rooted in systems that help us distinguish between friend and foe, which is required for the long-term functioning of cooperative systems (Hamlin, 2014). Moreover, helping kin, helping your group, reciprocity, sharing resources, and respecting some semblance of property all are adaptive cooperative traits that would have enhanced the survival of the groups whose members were more likely to display them (Curry, Mullins and Whitehouse, 2019). In short, as humans evolved physiologically and neurologically, their societies grew distinct, shedding the organizational dominance in favor of a cooperative, mutually reinforcing set of adaptations: language, tool making and use, big game hunting, and kinship (Abrutyn and Turner, 2022).\n\nTomasello and Vaish (2013) identify six ubiquitous cooperative behavioral traits that appear to make up humans' moral nature, which might serve as a basis for thinking about children and adolescent attitudes and behavior. First, unlike for other apes, food has long been procured collectively and cooperatively: from the big game hunting that simultaneously provided the necessary caloric bang that expanded our brains -- which allowed us to communicate more complexly, control our emotions during a hunt, and coordinate more efficient hunting -- to the first human settlements that owned property in common (Bowles and Gintis, 2011). Whether communal, private, or public, property is the second feature of morality. Regardless of the rules, it is cooperative. In communal situations, the land is cooperatively farmed, while in private propertied societies, rules are designed to respect who can access property and requires coordinating behavior to respect these rules. Third, in ape societies, mothers provide 100% of the childcare, whereas in human societies, mothers rarely provide more than 50-60% (Hrdy, 2009). Rather, fathers participate in various child-rearing activities, as do grandparents and other extended family members, and, in modernity, daycares and schools are also involved intimately in childcare. Fourth, apes communicate to tell each other what to do, while humans communicate for a panoply of reasons, including disseminating information, transmitting knowledge, and purely sociality. Fifth, politics tend to shape power and authority instead of strength and intimidation. Whether one likes politics or not, it is a form of cooperative, relational domination that involves internalizing the rules of a game and maintaining ceremonial rituals. Sixth, habits become conventions, customs, norms, and laws, embedded in structural and cultural spheres that endure beyond the life of any given incumbent. Our capacity to simultaneously externalize society in external representations and internalize it in schema or scripts (or whatever cultural mechanisms one favors) is morality. The universal behaviors surrounding cooperation and more relative norms and rules become a collective, enduring endeavor.\n\nIndeed, if there is a big takeaway point, it is that these six axes of cooperation are a good starting place for sociologists, especially those who take Tavory’s (2011) suggestion for studying moral action seriously. Each one provides an opportunity to ask what actions define actors as a kind of socially recognized person, that this recognized self is trans-situational or more aligned with a person-identity, and that either doing the action or breaking the rule elicits predictable emotions for the actor and others. In particular, we see property and politics as excellent starting points for a marriage between disciplines, but we will save a more detailed discussion for the implications section below. For now, combining the phylogenetic origins of morality with these uniquely human cooperative endeavors, we can think about the social ontogeny of morality.\n\n\n### 4.2 Moral Ontogeny\n\n\nA significant body of research has focused on understanding infant and child moral behavior, suggesting that even pre-verbal infants prefer cooperative and pro-social behavior. For instance, research by Hamlin and Wynn (2011) found that five-month-old infants uniformly prefer individuals who display pro-social behaviors, even when that behavior is directed towards anti-social others. However, older children develop more sophisticated moral judgments, preferring those who display pro-social behaviors towards other pro-social others instead of those who display pro-social behaviors towards anti-social others. Put simply, older children learned to prefer those who were nice to other nice people and did not like those who were nice to mean people. These children already displayed a predisposition towards punishment and retribution.\n\nSimilarly, other research finds that as early as 9-months old, infants are able to distinguish between pro-and anti-social behaviors (Decety, Steinbeis and Cowell, 2021). And while they pay more attention to anti-social actors, they are more interested in interacting again with those that acted pro-socially with them (Jensen, Vaish and Schmidt, 2014). Again, older children display more sophisticated judgments: their preferences for pro-social others have become contingent, to some degree, on the situation. By the time children are 9 to 14 months old, they will pick up objects that adults have dropped or ask to help when they perceive the adult as needing help (Decety, Steinbeis and Cowell, 2021). It is not surprising that, around this age, children begin to also purposefully engage in collaborative actions to form and realize joint goals (Warneken and Tomasello, 2009). By 13 months, they gain the ability to discern who belongs to their group and who does not. Hamlin (2013), for instance, found that 9-to-14-month infants display an in-group bias when judging others’ behavior: not only did they prefer those who treated similar others well, but they also preferred those who treated dissimilar others poorly. Despite this preference for anti-social others when directed towards out-group members, these children’s behaviors are cooperative without being prompted.\n\nChildren also prefer goal-directed behaviors. For example, other research by Hamlin, Hallinan, and Woodward (2008) found that when behaviors appear to be goal-directed, infants are more likely to imitate them. These findings highlight children’s agency in shaping their own socialization: they learn which behaviors are important (i.e., goal-directed ones) and focus on reproducing those. Indeed, infants will even attempt to engage partners when others are not necessary to achieve the goal, although they seem driven to cooperate with people they feel reciprocal relations with (Tomasello, 2019).\n\nMoreover, children are oriented towards fairness. In terms of fairness, by 12 to 15 months, kids display a sense about what is fair regarding the distribution of resources, with a sensitivity towards norms appearing around the latter end of that time scale (McAuliffe et al., 2017). However, as infants become toddlers, the social world begins to shape the expression of their moral ontogeny. Most importantly, as Mead’s developmental model predicts, as they shift from playing to games, the rules and norms external to their own ego become core to shaping the directionality and expression of their moral ontogeny. By three, for example, kids begin to enforce social norms (Rakoczy, Warneken and Tomasello, 2008). It is clear that they are aware that these norms extend beyond themselves, as play with friends shifts from parallel to cooperative or competitive forms of interaction. Norms are usually standards that are believed to be shared by others, enforced through group opinion, and applied to everyone. It is important to note that an understanding of norms is preceded by the ability to express moral judgments about others (Engelmann and Tomasello, 2017) as well as discern between good and bad reasons for decisions, rules, and so forth (Köymen and Tomasello, 2020).\n\nIn short, the research above illustrates how children naturally display prosocial preferences and behaviors. Children also develop a sense of in-group/out-group even before they learn to speak; thus, from a very young age, they have a notion of whom to direct cooperative behavior. Finally, infants and young children already have a strong sense of fairness, empathy, and reciprocity (Decety, Steinbeis and Cowell, 2021). By the time that child is eligible for more formal educational socialization in preschool, they are wired to cooperate and be moral creatures without prompting or explicit cues.\n\n\n## 5. Concluding thoughts\n\n\nAs we conclude, we identify three major axes along which sociology can and should develop. The first is a set of concerns related to the socialization of morality. The second returns to Tomasello and Vainish’s review of the literature on moral ontogeny in children and the emphasis on certain concepts, like property and politics, that are unique to human societies and, though often refracted through a lens of inequality and conflict, also reflect a cooperative species. Finally, the question of moral judgment and decision-making, rooted both in ontogeny and social phenomena like politics, remains surprisingly beyond the interest of sociologists when, in fact, it is a cornerstone to understanding youth culture. We briefly examine each of these to point towards potential future research directions in sociology.\n\n\n### 5.1 Socialization\n\n\nSetting aside the problems with Parsons and structural-functionalism, socialization was and should be a central focus of sociology. As Corsaro’s and Eder’s respective works on child and adolescent culture underscore, socialization is not unidirectional. In fact, socialization reflects cooperative efforts between adults and children, on the one hand, and between peers on the other (Corsaro and Eder, 1990; Eder and Corsaro, 1999; Eder, Evans and Stephen, 1995). Mead’s theory of development forcefully supports this assertion, positing that society does not exist “out there,” but rather exists only in the symbolic reality that makes cooperation at a level unseen in other species possible. Conflict, competition, status hierarchies, dominance, and even power are as relational as social solidarity built from shared joint-task responsibility or interaction rituals. Thereby, these behaviors rely just as much on language and cooperative efforts, even if we can take off our social scientific hat and argue, through a critical lens, about whether or not relationships are fair, equitable, and just. Thus, we agree with Guhin and colleagues (2021): socialization should return to the sociological lexicon because, without it, sociology has no real satisfying explanation for how and why human morality is amplified, extended, and transformed.\n\nWhat we are suggesting, however, is building on classic research on adult-child socialization processes and youth peer cultures to ask more pointed questions about youth morality. We also think that taking informal processes seriously is just as important as focusing on schools. For instance, Wolf and Tomasello’s (2020) work shows that humans are the only primate that bonds not just from reciprocal activities, like sharing meat, but through sharing experiences (see also, Woolley and Fishback, 2017; Marsh, Richardson and Schmidt, 2009). What is more cooperative (and therefore moral) than play? Even Mead recognized that the first steps into the larger world of self and mind required playing roles and, eventually, participating in games that signified one’s commitment to the situation itself as much as to one’s own success and pleasure. In addition to this suggestive path, we also see Pugh’s (2009) and Britton’s (2015) work as exemplars. They both start by asking and observing youth, rather than adults; they take the agentic capacities of children and teens seriously; and, implicitly or explicitly, recognize youth as morally accountable creatures. While we believe training our lens on cooperative efforts is central to the sociology of youth morality, efforts to understand the larger worlds of youth through proxies of or adjacent concepts to cooperation. Finally, we see two areas related to socialization as key: (moral) education and moral emotions.\n\nAs to the former, many have made the case regarding the inextricable connection between morality and education in classical sociology (Abend, 2008; Hitlin and Vaisey, 2013). And yet, as Baker’s (2020) recent paper examining morality in the sociology of education, sociologists have largely ignored the cultivation of morality, its expression by youth, and how to study it. This is largely because “stratification remains central” to contemporary education scholarship, which reflects less the moral agency and accountability of its subjects and, instead, the deep moral “commitment to justice [and] sense that these inequalities are morally and politically wrong and it is academics’ duty to understand these wrongs and address them” (Guhin, 2021, p. 912). And, when scholars do focus on schools and morality, it is often focused on either the norms around teen behavior (i.e., where these norms come from, the rates and consequences of deviation from them) or the cultivation of the types of values that square with sociologists’ moral commitments (e.g., the fundamental value of caring) (Horne and Mollborn, 2020; Haidt and Graham, 2007; Shweder, 2003). As such, we would push sociologists to expand their rather limited research questions to examine how schools facilitate and constrain the ontogenetic aspects of children’s morality, the processes by which being moral agents is encouraged or constrained, and, especially, how peer culture comes to mobilize morality in relation to adult culture and vis-à-vis social differentiation within a school; especially in terms of adolescent schooling.\n\nMuch of this topic is related to the second area of socialization that sociology might move into: the socialization of moral emotions. We know humans are hardwired to feel empathy and pride, guilt, and shame (Tracy, Robins and Tangney, 2007), but sociologists have largely ceded the study of how we learn to identify, label, and express or suppress these emotions (Eisenberg, 2000). For instance, we know guilt is a core moral emotion surrounding transgressing (socially constructed) norms and that it motivates actors to engage in the sorts of reparative rituals Goffman (1967:19ff.) discussed. However, sociologists have largely ignored how we are socialized to feel guilt instead of shame (Scheff, 1997), whether guilt varies according to sex, race, class, or any number of key axes of stratification, and how much of this variation is due to adult socialization versus peers. Like Ridgeway’s (2006) status beliefs theory, some traditions have begun to do some of the necessary work on this front, but it is nearly always focused on either adults or college-aged populations. Consequently, sociologists have very little understanding of how parents, schools, peers, and media shape the feeling and framing rules children and adolescents internalize surrounding moral emotions.\n\nThe very moral and political commitments sociologists make to fighting inequality might benefit from understanding what makes youth cooperative and affectually bond with youth who do not look the same, come from the same background, have the same tastes, interests, or preferences, and so forth. Affect is at the core of interpersonal bonding and broader collective cohesion, hence the stakes for studying moral emotions cannot be overstated.\n\n\n### 5.2 Property and politics\n\n\nAs is the case with socialization and education, the study of youth in relation to other areas of uniquely human cooperation, like property and politics, remains centered on stratification and power. In terms of property, this is understandable as private property and the rules, sanctions, and enforcement agents surrounding property rest at the core of a Marxian view of inequality both in theory and empirically, even among children (Stockstill, 2021). Can we imagine both a sociology of morality that can study preschoolers’ capacity to follow rules surrounding property and a sociology of morality that stays true to its moral and political commitments to reveal injustice and inequities wherever they may lie? We see these projects as not mutually opposed. In fact, these projects can explain how and why different rules shape different patterns of cooperation and, also, the limits to either pole of property relations (communal/libertarian). In pursuing these projects, sociologists could offer schools and communities empirically grounded policy suggestions for doing the work necessary to reduce the physiological, psychological, and social effects of inequality among youth.\n\nWhen we turn to politics, we see two obstacles. The first is the tendency to focus on either the asymmetrical power-differential between adults and youth (Guhin, Calarco and Miller-Idriss, 2021) or the effort of children to cultivate their own power over adults (Lignier, 2021). That is, the dark side of politics, power, and control, overshadow the fact that politics involves cooperative maneuvering rooted in relationships. The second tendency emerges from the first: forgetting that adult-youth culture and peer culture are political. Status hierarchies are not immutable. Whether adults like it or not, socialization is not mutually constitutive, and all collectives and situations within them are characterized by micropolitics and claim-making (Clark, 1990). We know very little about how this works even though sociologists are perhaps the best equipped to study this! Generally speaking, the study of child development in psychology relies on either parent reports (Eisenberg, 2000) or experiments (Tomasello and Vainsh, 2013), whereas some of these processes demand ethnographic observation and interviews with youth; methods squarely in the wheelhouse of sociologists!\n\n\n### Moral Judgment and Decision-Making\n\n\nFinally, we suggest sociologists take moral judgment, reasoning, and decision-making seriously; an pursuit which may feel increasingly out of reach given the popularity of dual-process models in cultural sociology—the more vibrant subfield currently studying social action—that have come to emphasize the deeply engrained aspects of cognitive schema as opposed to their elasticity, flexibility, and/or acquisition and modification (Vaisey, 2009; cf. Brett, 2022). Not only do these areas present essential questions about the relationship between beliefs and practices, but examining these areas is perhaps the most useful way to bring adolescents into the larger constellation of youth morality. That is, by age 13, moral reasoning is characterized by concerns about others’ social expectations and, over the course of adolescence, concerns shift towards the generalized other, so to speak, as rules, laws, and authority come into focus (Kohlberg, 1969). The promise of studying adolescents derives from two interrelated points (Morris, Eisenberg and Houltberg, 2011). First, the vast majority of developmental research focuses on negative behaviors, like aggression or, as delineated above, norms regarding sex. Second, a relative dearth of research on adolescent prosocial behavior (for examples, see Mortimer, 2012)—including eminently sociological interests like the moral emotions and moral identity of teens’ inclinations towards cooperation—offers a major set of opportunities.\n\nHere, once again, the return of socialization is welcomed. Past developmental research has demonstrated that parental morality predicts teen morality, particularly in families high in cohesion, adaptability, and communication (White and Matawie, 2004). Differences in volunteering behavior, for example, are shaped by parents’ behavior and their attitudes towards the civic sphere, but importantly, best friends matter as much, if not more so (Van Goethem et al. 2014). Because of the ethical challenges presented by neuroscientific research that would expose youth to simulated trauma (Pfeifer and Blakemore, 2012), sociologists seem well situated to ask questions and observe how attitudes and behaviors associated with volunteering—among other prosocial behavior—are in fact shaped by parents and other adults, as well as how peer groups and networks facilitate and constrain cooperative behavior in ways similar to more risky behavior like smoking or risky driving. This is particularly important as prosocial behavior has been associated with academic, socioemotional, and sociocognitive outcomes (Morris, Eisenberg and Houltberg, 2011).\n\nUltimately, sociology seems well-positioned to tease out the ontogenetic aspects of adolescent moral development from the environmental forces, as research has revealed that there are few gender differences in reasoning (both male and female equally reason based on care and justice), but there is some evidence girls are more prosocial in adolescence. As is the case with children, we believe the neglect of prosociality among all youth in the scant research of youth morality is a blind spot with real consequences. For instance, a much larger and more complex debate surrounding the use of social media, which does echo previous debates about traditional media, extends into morality, with some research finding a decline in adolescent morality correlated with television and internet usage (Fitzpatrick and Boers, 2021). Perhaps youth morality is weakened by the barriers to “normal” neural processing digitally mediated forms of interaction produce (Dickerson, Gerhardstein and Moser, 2017), and/or the feeling expressed by many people that these interactions are hollow and difficult to embrace (Tufecki and Brashears, 2014). After all, Collins (2004) argued two decades ago that the fundamental basis of moral solidarity—mutual arousal via co-presence and rhythmic bodily synchronization—is virtually impossible in virtual space. And yet, the ubiquity of social media use among youth remains an untapped frontier in sociological research, but like our neglect of the development of youth moral identity or the study of how youth moral emotions are encouraged or not based on various demographic and environmental factors appears to be a high reward, low risk territory to develop.\n\n",
         "In this chapter, we make the case that cooperation is at the center of moral behavior by presenting insights on youth morality from neuroscience, psychology, and evolutionary science. First, we discuss the gaps in the sociological literature concerning youth morality. Instead of studying youth morality explicitly, sociologists often use proxies for morality such as norms, values, and socialization that underplay both youth’s agency in shaping their moral worlds and their innate cooperative abilities. As such, we argue that sociologists’ neglect of youth morality obscures our understanding of the interaction between the socialized and the innate aspects of moral development and behavior. Next, we review existing bio-psychological research that points to the innate aspects of cooperation and why cooperation may have been evolutionarily adaptive. In looking at the moral behaviors of infants, we see that moral judgment, a preference for pro-social versus anti-social others, and the ability to coordinate action, precede norm following and norm enforcing behaviors. We conclude this chapter by discussing the exciting opportunities that could result from interdisciplinary work on the morality of youth, and present some ideas for future directions in the areas of socialization, property and politics, and moral judgment and decision-making.",
         ""
        ],
        [
         "26",
         "26",
         "## Introduction\n\n\nFor many, speaking Spanish is an intimate practice that signals community membership. However, the Spanish language is widely marginalized in US K-12 education, primarily due to its racialized association with Latinx 1 communities. Examples include negative stigmas about speaking Spanish, historic invocations of the Spanish language being used as justification for school segregation for Mexican students (Lozano 2018), and statewide 'English Only' policies that were understood to be targeting Spanish speaking students and communities (e.g., California Proposition 227). Additionally, bilingual language usage such as 'Spanglish' (mixing Spanish and English words in the same speaker turn) is often considered an inadequate form of linguistic fluency in US educational institutions despite being a vital form of in-group communication (Rosa 2018) . In contrast, institutional higher education in the US officially celebrate diversity of all kinds (including racialized language practices like Spanish), as indicated by the University of California's diversity statement 2 as well as many other analogous statements (Duchˆ ene 2020). Institutions actively recruit for linguistic and ethnoracial\n\ndiversity in part because it is recognized as a valuable but observable difference with respect to current makeup.\n\nThis tension regarding the varying value that institutions place on non-English language presents the opportunity to 1) examine how young people manage these competing norms, and 2) identify the mechanisms deployed by these institutions that elicit these practices (Gebre-Medhin, Giebel, Alvero, Domingue, Stevens, et al. 2022). We study these dynamics in the context of college admissions and measure the ways and extent that students incorporate Spanish into their admission essays. We model this process as a crucial element of an applicant's admission strategy and as an estimate of the impact of institutionalized language views in a key social process. Understanding how young people manage this important transition could generate useful insights for scholars of culture, language, evaluation, and other domains. It also has practical relevance, however, given the rising popularity of test-optional admissions after the COVID-19 pandemic . 3 The increased attention placed on admissions essays in the wake of the Supreme Court's decision to eliminate affirmative action has further heightened its relevance.\n\nAnswering these questions also creates opportunities for computational social science that injects perspectives grounded in sociolinguistics and cultural studies. Sociolinguists contribute to this literature (Nguyen, Do˘ru¨z, Ros´ e, and De Jong 2016; Grieve, Speelman, and Geeraerts 2011), but g o their primary inquiries typically lie with spoken language. While the potential for text data to uncover sociocultural trends and patterns of interest to sociologists is well established (van Loon 2022; Macanovic 2022; Mohr and Bogdanov 2013; Kozlowski, Taddy, and Evans 2019; Nelson 2021; Stoltz and Taylor 2021), there has been less uptake in adapting tools specifically for multilingual text 4 . This is partly due to computational challenges, especially for non-English and non Indo-European languages (Ho and Chan 2023), though machine translation tools do show promise (Mate, Seb˝k, o Wordliczek, Stolicki, and Feldmann 2023). It is therefore unsurprising that studies of text containing examples of translanguaging, generally defined as the deployment of linguistic features that reflect multiple named languages 5 (Otheguy, Garc´ ıa, and Reid 2015), are even less common (along with multilingual text analysis more generally). Understanding how popular tools can be used for analyzing translingual text (while also being mindful of potential forms of variation in Spanish by well known dimensions like class and ethnic identity) can create useful benchmarks for social scientists and computer scientists alike, especially by scoping their potential limitations and biases if and when they are used in evaluative settings (such as college admissions). Our paper accomplishes these goals by focusing specifically on the ways that applicants use this culturally grounded form of language as part of their admissions essays while outlining the strengths and weaknesses of using machine translation to uncover these patterns.\n\nTo study whether or not Spanish is strategically used in evaluative settings (in this case, selective college admissions) in the limbo of institutionalized value placed on that language, we leverage a dataset of 91,409 first-year undergraduate applications submitted by every Latinx identifying appli-\n\ncant from 2015-2016 and from a racially representative random sample of non-Latinx applicants from 2016-2017 to the University of California system. The applications contained their admissions essays (n = 276,768), self-reported household income (shortened to income hereafter), and specific Latinx ethnic identities, including the three primary census groups of Mexican, Cuban, and Puerto Rican, along with geographic groupings of Central American, South American, and European based on the 'Hispanic, Other' responses. The Google Translation API and OPUS-MT were used in conjunction with extensive hand checking and coding of data and statistical analyses. We show the degree that language, specifically Spanish, varies in usage by applicant ethnicity 6 and social class, and answers the following questions:\n\n- · To what extent are students including Spanish words and language in their admissions essays?\n- · Do patterns vary by social class and ethnicity as related findings might imply?\n\nThough not a primary research question, our paper also provides insights into the potential for machine translation tools to be used in computational and cultural sociology. We outline the unique affordances and limitations in the hopes that it will spur more engagement with multilingual practices reflected in written and spoken language and the potential for machine translation to join the suite of tools for computational social science.\n\n\n## College Admissions Essays\n\n\nAdmissions essays have been used for nearly a century in selective college admissions (Karabel 2005), yet have largely avoided the same public scrutiny as other information provided by applicants like test scores and transcript data. Nevertheless, they are a key site for applicants to share additional information about themselves to admissions officers (Stevens 2009; Hossler, Chung, Kwon, Lucido, Bowman, and Bastedo 2019; Beck and Godley 2023). Qualitative studies have found that many students do not have a clear sense of who their audience is, believe the goal is to show 'generic good writing,' to be 'interesting' and 'stand out,' and to avoid including written dialogue (Aukerman and Beach 2018; Early and DeCosta-Smith 2011). Likewise, a study of essays written for selective admissions in Britain also highlighted the notion of 'standing out' but noted that there was variation along social class lines; higher class students referenced high status social connections whereas lower class students more often referenced paid work (Jones 2013). Jones also found that class was a strong predictor of stylistic aspects of writing, such as average sentence length.\n\nBecause of the common association between Spanish and Latinx communities along with the salience of ethnoracial identity in college admissions, it is possible that Spanish will be used by many applicants as a way to present themselves. When considered alongside the aforementioned research, the use of Spanish might also vary by social background. Therefore, we hypothesize that the impact of linguistic discrimination faced by students might show up through disparate Spanish usage in their\n\nessay by both socioeconomic status and race, ethnicity, and/or nationality. However it is also the case that students might assume the application evaluators might make these strong associations between Latinx identity and Spanish and include it for any number of rationale. Other studies on college admissions have found that 'authenticity' is a prominent idea in the college admissions counseling space, making it plausible that students might assume 'authenticity' could be achieved through the use of Spanish (Huang 2023). Further, Latinx families, especially middle class families, have shown a tendency to promote cultural omnivorousness (Tatum and Browne 2019), and showing fluency in both English and Spanish could be an easy way to help demonstrate this ideal. Surfacing patterns of Spanish language usage in this context - which allows for editing and rewriting text - could yield important insights into dimensions of language usage not often observed in the literature that skews towards spoken language analysis. Currently, there is very little in the literature which focuses on written language.\n\nThe uniform structure of the format of the college admissions essay (i.e., identical prompts, word count limits, and deadline), lends itself well to macro analyses of the student's submitted college essays. Recent studies using methods from machine learning have found that computational representations of admissions essays are strong predictors of applicant income, educational pathway, gender, and SAT score (Arthurs and Alvero 2020; Alvero, Arthurs, Antonio, Domingue, GebreMedhin, Giebel, and Stevens 2020; Alvero, Pal, and Moussavian 2022; Giebel, Alvero, Gebre-Medhin, and Antonio 2022; Alvero, Giebel, Gebre-Medhin, Antonio, Stevens, and Domingue 2021; Berger and Toubia 2024; Lee, Thymes, Zhou, Joachims, and Kizilcec 2023). These correlational analyses were broad in their approach and did not investigate finer grained language patterns in the text, such as the use of Spanish. Other scholars have noted that race and ethnicity are central to student's experiences in ways that are reflected through personal statements, such as Black students describing experiences of anti-Black racism and trauma (Do Pham 2021; Waller-Bey 2020; Kirkland and Hansen 2011). We expand on these studies by focusing specifically on multilingualism and translanguaging. Given that race, language, and culturally grounded linguistic practices are all so intertwined, these findings could open up new challenges and insights into how people describe and define themselves in otherwise private moments of evaluation that challenge conventional beliefs. Showing how large groups of people from shared and different backgrounds specifically leverage stigmatized linguistic practices would suggest a cultural practice that goes outside the domain of selective college admissions and open up new questions about the complexities and intricacies of language evaluation, what people deem worthy of evaluation, and how people might adopt counterintuitive approaches.\n\n\n## Spanish in the US\n\n\nA rich body of scholarship has studied the social position, status, and usage of Spanish in the US and in education specifically. The panethnic category of Latinx was created partly due to shared\n\nSpanish language culture across many (but not all) Latin American immigrant enclaves in the US and its associated stigmatization (Mora 2014; Baca Zinn and Mirand´ e 2021). These associations between Spanish and Latinx identity have persisted, sometimes to the point of young Latinx people feeling pressure to be bilingual and the use of Spanish as a social boundary marker (Garcia 2020). An ethnographic study at different colleges and universities in California found that Spanish fluency was used as a social and cultural gatekeeping mechanism among Latinx undergraduates: Latinx students who did not speak Spanish reported feeling socially excluded by Latinx students who did speak Spanish (Reyes 2018). This contrast between negative social stigma towards Spanish and its maintenance as a strong identity marker among Latinx young people helps explain why theories of resistance and community derived social and cultural capital have often been invoked in this line of research (Yosso 2005; Cobas and Feagin 2008). Most of these studies of Spanish usage among Latinx people and communities consider language at the interpersonal level, whereas studying college admissions essays provides an opportunity to extend these studies to the context of communication between individual actors and organizations. The same is true for connecting and contrasting studies of spoken language with those of written language, the latter of which contains only a sparse literature.\n\nOther studies have examined intra-Latinx attitudes about Spanish maintenance. For example, studies on Central Americans in Southern California have found that the desire to speak Spanish in order to better communicate and fit in for non-Spanish speaking Indigenous individuals is in tension with the idea that speaking Spanish is a hindrance to socioeconomic advancement in the US (Canizales 2021a; Canizales 2021b; O'Connor and Canizales 2023). A study of Cuban-Americans in Miami found that middle and upper middle class families encouraged their children to speak Spanish to maintain their cultural heritage and identity, something that lower income Cuban-American families did not report as strongly (Lambert and Taylor 1996). Given the widely reported correlations between social class and college application patterns, we might expect to see variation along social class lines in terms of Spanish usage. However, all of these studies are focused on spoken language and often on interlocutors with close social proximity: parents and children, friends, students and teachers. Written language is often not available for this level of inspection, especially not with high stakes evaluation, a gap in the literature we address. Considering the contours between spoken and written language will become ever more important as social and cultural experiences become increasingly textualized (eg. social media).\n\nDespite Spanish being spoken by many people in California and elsewhere in the US (with 39% of residents identifying as Latinx (U.S. Census Bureau 2020), access to materials in Spanish from institutions, such as college application materials, is not easily available (Taylor 2020; Koenecke, Giannella, Willer, and Goel 2023). On the applicant side, less is known about how Spanish is used in evaluative contexts (e.g., college admissions or job interviews). Prior sociology often examines language repression and expression as binary, such as how often English or a language other than English is spoken (Stevens 1992; Linton 2004) to measure things like cultural assimilation in society\n\n(Tran 2010). Patterns in both evaluation and strategies from those being evaluated have been understudied, especially with respect to multilingualism and translanguaging. A study of applicant interviews at the University of Cambridge found that the applicant's language varieties were less predictive of successful interviews than how applicants managed the interview itself (Weston 2021). Conceptually similar studies investigating language, such as human-made classification of transgender voices in healthcare settings (Lagos 2019), highlight this paper's opportunity to connect sociological perspectives on language in organizational and evaluative settings with computational social science. We do so by specifically identifying the extent to which college applicants identify Spanish as part of a winning strategy in the game of selective college admissions.\n\nSociological studies and research on systems of evaluation, such as cultural matching for hiring decisions (Rivera 2012), typically opt for more holistic analyses rather than the kind of fine-grained work we describe here. For example, we know from (Rivera 2012) that hiring firms prefer applicants they feel are the best cultural matches. But what are the ways applicants convey this information using text and language beyond bullet points on a r´ esum´? e The impetus for studying language usage patterns in admissions essays has never been stronger, as many universities switched to testoptional admissions due to the COVID-19 pandemic but continuing to solicit personal statements from applicants. It is also unclear whether or not students would use Spanish so much as the ways they would use it.\n\nStudying Spanish usage patterns could show 1) how students are interpreting the personal statement (a genre most people encounter more than once in their lives), 2) beliefs held by students about whether or not universities view Spanish as a positive sociocultural asset, and 3) fundamental perceptions held by students about Spanish in relation to educational institutions. Put differently: are applicants using Spanish as linguistic capital, or are they self-censoring their Spanish (Bourdieu 1977) in this evaluative context? It is possible that students might adopt a linguistic strategy that makes them 'stand out' or 'mismatch' rather than 'fit in' and 'match' (Goldberg, Srivastava, Manian, Monroe, and Potts 2016; Rivera 2012) despite societal norms and language hierarchies enforced in other educational institutions (ie. primary and secondary schools in the US). These norms are also variably enforced, with the particular treatment of Mexican and Central American communities in California being a noteworthy example of linguistic punishment that other groups and contexts, such as Cuban-Americans in Miami, have not had to contend with (Linton 2004). Practically, such findings could help inform various educational stakeholders about the different strategies deployed in what is otherwise the blackbox process of holistic review.\n\n\n## Perspectives on Machine Translation\n\n\nComputational text analysis has become a popular methodological framework across the social sciences, including political science (Grimmer and Stewart 2013), sociology (Evans and Aceves 2016),\n\nand economics (Ash and Hansen 2023). Sociolinguists have also produced research in this domain, such as a widely cited study describing gender-based lexical variation in social media textual data (Bamman, Eisenstein, and Schnoebelen 2014). Despite the breadth of popularity, many studies from these respective disciplines focus on English language text and generally shy away from multilingual analysis. This is especially true for situations where non-expert translation, such as those used in political convenings, are unavailable (Rodriguez, Spirling, Stewart, and Wirsching 2023). For linguists and computer scientists, multilingualism and machine translation are more prominent topics both as a tool and an object of inquiry. Further, social institutions have already begun to adopt these machine translation tools in earnest, even when the results are not good or even damaging to certain dialect communities (Angermeyer 2017). It is therefore crucial to develop more understanding of their limitations, potential usage in computational research, and capacities to extend the current literature on translanguaging practices in text. In this section, we briefly review modern perspectives and methodological use cases for machine translation.\n\nBeyond the 'accuracy' or 'quality' of the act of translating from one language into another (which might be defined differently if you are a philosopher or a computer scientist and so on), translation has been a popular topic of study in many different disciplines for some time. Implicit in these studies, though, is the point that despite their limitations, these tools have been adopted into different organizational practices in earnest. For example, uptake from legal and medical organizations have been found to be problematic and exacerbate social inequalities (Vieira, O'Hagan, and O'Sullivan 2021). Sociological inquiries also find similar problems, such as the ways they inscribe hegemonic values and influence entailing political and socioeconomic realities (Olohan 2019). Even the data these tools are trained on have problems with respect to lack of representation for certain dialectal forms and varieties (Koenecke, Nam, Lake, Nudell, Quartey, Mengesha, Toups, Rickford, Jurafsky, and Goel 2020). These studies suggest that critical and careful incorporation of machine translation tools is necessary to fully scope out its strengths and limitations. This is especially true as the popularity of computational text analysis grows in the social sciences.\n\nResearch in the area of translanguaging found that computational tools can be up to 98% accurate when identifying a given word's language between Dutch and Turkish (Nguyen and Do˘ru¨z 2013). g o A similar study comparing English and Vietnamese found that Google Translate worked best at word-based language identification (Nguyen, Mayeux, and Yuan 2023) as well as in other languages (van der Veen 2023). Importantly, these and other studies often rely on human annotated data for ground truth. Although having these human interventions might not be tractable from a purely computational sense, the common use of human interventions and annotations points to a clear need for cautious use of machine translation as a research tool. Additionally, the fact that some of these errors come from dialectal variation also points to the importance of considering fundamental social dimensions in such an analysis, like ethnicity and class.\n\nPast studies have found issues with inequality and translation, creating systems where some\n\nforms of multilingualism become punished in various ways (Angermeyer 2022), including Spanish that deviates from the normative standard (i.e., Iberian Spanish). To try and remedy some of these limitations, we incorporate these theoretical considerations and add significant manual inspection as part of our study.\n\n\n## Framework\n\n\nOne of the foundational theories of the sociology of language is Basil Bernstein's elaborated vs. restricted code (Bernstein 1964; Bernstein 1971). In formulating the theory, he described observations where students from working class backgrounds were more likely to speak with a restricted code, meaning they assumed shared knowledge and insider status on a given topic from the listener and therefore did not need to elaborate or explain seemingly obvious details. Middle class students, on the other hand, were more likely to speak with what he called elaborated code, where description of a given topic was elaborated in such detail that anyone listening could understand regardless if they already did or not. The key insight was not that one practice was better than the other (a position we also take), but rather that the process of language socialization varies across different social dimensions (Garc´ ıa and Otheguy 2017). Spanish usage in the US has likewise tracked with social class and ethnicity, where communities in specific geographic areas have had their Spanish language practices either derogated or incorporated (akin to Bernstein's original concept of elaborated vs. restricted). If there are social patterns in Spanish usage in the context of college admissions, it would likely follow these trends. Regardless, it would be informative to analyze Spanish usage patterns by students across intersecting identities such as race, ethnicity, and class to gain insight into how students understand this cultural mismatch as they employ their languages in admissions essays in ways that might reflect restriction and elaboration.\n\nSchools, teachers, and evaluative systems in education (e.g., selective college admissions) are essential to language socialization in that they judge and rate the spoken and written language of students. Sociologists like Mich` ele Lamont have described this feedback loop between people and institutions as legitimation (Lamont 2012): the process by which institutions grant certain linguistic practices legitimacy and value through the act of evaluation. Through legitimation, certain language practices become more highly valued and normalized; these practices then become part of larger cultures. Sociolinguists have described similar processes of legitimation external to educational institutions, such as the strategic use of Mayan among bilingual Spanish-Mayan rappers in Mexico (Cru 2017). This and other studies of music demonstrate other contexts in which marginalized linguistic practices are assumed to be 'legitimizable' by their respective audiences. This is distinct in multiple ways. The institutions undergirding these processes are wildly different, and singers/songwriters have not had these practices be subject to specific laws which ban these forms of language (as is the case with Spanish and certain educational contexts). Further, the legitimation of college admissions\n\nwould implicate the institutions rather than a musical audience as part of this linguistic process and promote stronger levels of expectation and conformity (Schoon 2022). It is also important to note that institutional legitimation of Spanish has varied greatly by specific race and ethnicity, such as Cuban-Americans in Miami compared to Mexican and Central Americans in California for K-12 contexts.\n\nSocial science tends to rely on panethnic categories for analysis, a tendency that can belie important variation and tensions within the constituent subgroups. Within the panethnic category of Latinx, Mexican and Central American students in the southwest have long faced language discrimination and repression in schools (Mora 2014). Conversely, the first publicly funded bilingual school in the US, Coral Way Elementary school in Miami, FL, was meant to accommodate the influx of Cubans coming to Florida in the wake of the Cuban revolution. In many ways, the disparate treatment is racially motivated and can still be tied to back to anti-Blackness (Bonilla-Silva 2006; Benson and Clealand 2021). The cumulative effects of these differences linger: Arizona still has an 'English Only' educational policy in effect, whereas Miami has been described in a Duolingo user study as the only city in the United States where the most studied foreign language is English 7 , a signifier of who is afforded fluency in their native and/or non-English language. These provide structural contexts for how Spanish language usage fits in to broader patterns of variation in assimilation and acculturation (Lutz 2006), as well as why in Latinx communities geographically located in the western US, English language usage has long been associated with upward social mobility (Penalosa and McDonagh 1966). To account for this variation, we include ethnic subgroup analysis along with panethnic analysis. Doing so will generate deeper insights into cultural and linguistic variation in education and high stakes evaluation.\n\nA clear argument could be made as to why students would be hesitant to include language that could be labeled or interpreted through more negative lenses. However, other scholars have pointed toward the strong connection between identity, community, and linguistic practices in school and everyday life. The work of education and critical race scholar Yosso has been instrumental in expanding notions of cultural capital (Bourdieu 1987) to think more critically about race and racialized communities (Yosso 2005). Linguistic capital, described by Yosso as communication and style picked up in one or more languages through cultural traditions like storytelling and proverbs or sayings, is particularly apt here due to the emphasis on connecting language, culture, and identity in admissions essays. From this perspective, students who do include some form of Spanish in their essays are likely doing it with some degree of intentionality. Because our study does not include interview or survey data, we can only speculate as to why students would or would not include Spanish. However, we will be able to definitively show what applicants did and surface demographic patterns that might not necessarily emerge if we asked students what they were planning to do (Jerolmack and Khan 2014). Additionally, it would require a much larger research community to conduct interviews to the scale of the data presented in this paper.\n\nSociolinguistic frameworks could explain why applicants include Spanish words and phrases in their essays or not. Indexicality, the concept that language usage and variation therein communicates not just the literal words but also of other associated things (eg. 'smoke' indexes 'fire'), is particularly apt here (Jaffe 2016). Variation in indexicality might also emerge by varying degrees of performativity, such as students using Spanish words to simply describe themselves and their surroundings compared to students who use many Spanish words, phrases, and stories in their essays (Eckert 2019). In this way, language transmitted through personal statements becomes a site of strategic essentialism with respect to ethnoracial and linguistic identities (Spivak 2012). These distinctions, however, can only become salient if they are contrasted with non-Spanish (in this case, English words and phrases) in the same essay.\n\n\n## Analytic Strategy\n\n\nOur paper takes a highly inductive analytical approach. Since there are no comparable studies identifying and analyzing multilingualism in this type of evaluative setting, our paper has two primary goals: identification of Spanish usage in the essay, and analysis of the types of Spanish being used.\n\n\n## Data\n\n\nThe data come from every first year undergraduate application to the University of California from self-identified Latinx students (n = 44,434; approximately 27% of the entire application pool) submitted during the fall of 2015 and a racially representative random sample of students who applied in the fall of 2016 (n = 46,975; approximately 29% of the entire application pool). A caveat to working with this data is that we do not know who was accepted, rejected, nor enrolled due to privacy concerns. Rather, our focus is on better understanding whether or not students believe Spanish is worthy of legitimation through college admissions. Students who identified as Latinx in 2016 essays (checked by cross referencing other data not used in this paper) were filtered out.\n\nThe University of California uses a single application system. Students complete one application and then choose which of the constituent campuses will receive their materials. In 2015, students had to write two essays based on the same two prompts, and in 2016 students had to write four essays after choosing from eight distinct prompts (see Table S1). The essays asked applicants to describe various aspects of their background, identity, and life experiences. The essays were combined for analysis. Previous studies have found little variation among the essays over the years and formats (Gebre-Medhin, Giebel, Alvero, Domingue, Stevens, et al. 2022). Comparing the data in this way also allowed us to see if Latinx students in particular were using more Spanish than students who did not identify as Latinx. Students were given a max of 1,000 words for their essays in 2015 and 1,400 words in 2016. The average total word count was 924 words for the 2015 essays and 1,283 words for\n\nthe 2016 essays.\n\nThe application operationalizes Latinx identity through a system based on the United States Census (Mexican, Cuban, Puerto Rican, and 'Other'). Students selecting 'Other' had to writein their identity (e.g., 'Honduran'). We manually organized the Other responses into regional groups: Central America, South America, and Europe . Applicants who selected multiple categories 8 (eg. Cuban and Mexican) were counted for membership in each group rather than one. The small number of students (n = 60) who selected 'Other' and wrote in a country or region not captured in the aforementioned groups were excluded from ethnic specific analyses. There was also a generic 'Latino' category students could select; students only selecting this option were excluded from the ethnicity specific analyses. The specific ethnoracial identities (eg. Black, Asian, White) of the nonLatinx students were not available. Self-reported household income was also provided. Students reporting household incomes below $ 10,000 were suspected to have done so erroneously and excluded from analyses of income (Alvero, Giebel, Gebre-Medhin, Antonio, Stevens, and Domingue 2021). See Table 1 for summary statistics of the data.\n\nTable 1: Summary statistics of income and ethnicity.\n\n\n## Methods\n\n\nThe primary methodological challenge was to identify and label instances of Spanish usage in the admissions essays. To do this for the entire corpus, we developed a computational mixed methods approach that leveraged machine translation and data wrangling tools, our Spanish language fluency, and various other resources (e.g., online maps to check for place names). This approach extends the literature on computationally grounded theory (Nelson 2020), used widely in computational and cultural sociology, into machine translation methods. The first step was to label words as being either Spanish or not Spanish; we used only the Latinx corpus for this step. This process generated a dictionary of Spanish words that was used to label all of the words in all of the essays as either Spanish or not Spanish. After the words in the essays were tagged, we manually filtered out inadvertent, unintentional, and erroneous instances. Examples included words like 'bursitis' being\n\nlabeled as Spanish (due to the same spelling in English and Spanish) despite not being used in or around other Spanish words, and 'mija' (commonly used contraction of 'mi hija') being labeled as not Spanish despite numerous instances of it being included as part of a Spanish phrase. Once the essays were hand-checked, we used logistic regression to model how well income predicts the use of Spanish and negative binomial regression to model how well income predicts the amount of Spanish words being used in the essays. Income was selected because of its prominent relationship with essentially every element of the modern college application, including essays. While this allowed us to connect our work to many other studies, we also recognize the drawbacks of solely focusing on income and describe them in the limitations section. For the subsequent analyses of the variations in Spanish use, we focused on essays containing strings of Spanish with at least three consecutive words. These essays were the ones that contained the most complex examples of Spanish, gave us the most material to qualitatively analyze (as opposed to simpler single-word instances), and narrowed the data to allow for more focused analysis (including additional hand-checking and labeling). Future studies might develop tools to help streamline and simplify this approach.\n\n\n## Language Detection: Machine Translation and Human Reading\n\n\nTo create a dictionary of the Spanish words used in the essays, we focused on the essays written by Latinx students on the assumption that they would use more Spanish in their essays than the nonLatinx students. Additionally, because we understand admissions essays to be a place for students to speak on their personal experiences, we are prioritizing Latinx students in the dictionary construction on the assumption they are more likely than non-Latinx students to have a more personal connection to Spanish language use (e.g., through it being their native language for some applicants). To do this, we generated the vocabulary as the set of individual words that appear in a corpus (n = 81,495). The words 'me,' 'a,' and 'no' are high frequency words in English and Spanish that are orthographically equivalent and were removed from the vocabulary to reduce the amount of false positive labels in downstream coding and analysis. To label words as being either Spanish or not Spanish, we first used the Google language detection API to label each word in the vocabulary. Focusing on single words reduced the amount of computation needed for analysis and the cost of using the Google API (around $ 250.00).\n\nThis approach introduced two obstacles. Machine translation and language detection tools are not designed for single word translation or detection (though as previously noted they can do well in this kind of task) because many words across many languages are orthographically identical. Specific words and terms also favor specific dialects. As a simple example, Google Translate defines 'drinking straw' as 'pajita' , 9 the word most commonly used in Spain, as opposed to 'popote' which is used most often in Mexican Spanish (the kind of Spanish most of the students in our dataset would likely be familiar with). Given the highly subjective nature of human language along with the complexities of the task of translation, machine translation works better with additional human\n\nFigure 1: Conceptual diagram of how Spanish words were identified using AI and hand coding.\n\n<!-- image -->\n\ninput (Santy, Bali, Choudhury, Dandapat, Ganu, Shukla, Shah, and Seshadri 2021), especially when using single-word identification techniques due to resource limitations. Social science using machine translation also often analyzes text at the sentence level rather than entire documents (Bullock, Serigos, Toribio, and Wendorf 2018). In our preliminary examinations of the data, we realized that analyzing this data at the sentence level would miss many instances of students including Spanish words and phrases within the sentence, which would likely be labeled as English by the machine translation. For example, the sentence 'For breakfast, I always have pan con mantequilla.' is labeled as entirely English by the AI. The biases and values of the people who created these language technologies mixed with language ideologies about what is considered to be Spanish (Paffey 2014) could also influence machine translation. For these reasons we repeated the same process by handcoding each word in the vocabulary. This decision also mirrors the common practice in computer science research of creating benchmarks to compare similar outcomes, findings, and methodologies. Simply, future studies using machine translation tools could have a reference point for how many discrepancies they might expect to see (though this would probably vary by language) if AI is used. Our methodological decisions were therefore motivated by both social science and computer science disciplinary frameworks. A full diagram of this process is described in Figure 1.\n\nOver the span of several months, we went through each of the 81,495 words and labeled them as either plausibly Spanish or not Spanish. Plausibility was defined to be whether a word on its own\n\ncould be understood as Spanish, as part of a multi-word phrase in Spanish, or a word that could be considered part of a Spanish user's repertoire (e.g., indigenous place names in Latin America). This part of the work was not intended to be final, as many words and phrases in Spanish would be impossible to identify alone (e.g., 'santa' on its own could be part of 'santa claus' or 'santa clara'); we describe additional hand-checking to account for this below. There are also many words, names, and terms common in parts of the Spanish speaking world that might not be seen as Spanish (or, problematically, not part of any language (Rosa 2016)). Many words were easily identifiable as being plausibly Spanish or part of Spanish multi-word constructions and phrases. However, there were also many edge cases that spurred the development of clear inclusion/exclusion rules. See the supplementary materials for a description of the rules and examples of what was labeled as plausibly Spanish. The largest group of Spanish derived words that were excluded were place names, specifically Spanish place names in the US and the names of Hispanopohone countries); we provide the full list of these words in the supplementary materials. This process culminated in a dictionary of Spanish containing 7,064 words labeled by the AI (4,494 words) and the author team (2,570 words). This means that close to 10% of all the words used at least once by UC applicants in our dataset are derived from Spanish. Once this procedure was done, we hand checked 80% of the essays that had a Spanish word to check for errors and affirm our results. More details of this process are also described in the supplementary materials.\n\n\n## Statistical Analyses\n\n\nTo model the relationships between income, ethnicity, and the Spanish used in the essays, we used several statistical tools. To model how well income predicts whether a student uses Spanish in their essays or not, we used logistic regression. The results are reported as odds ratios, where values below one signal negative correlations, and values above one signal positive correlations between the independent and dependent variables. To model how well income predicts the number of Spanish words used in the essays, we used negative binomial regression. Initially, a Poisson regression was used but suffered from overdispersion relative to the negative binomial approach (Allison and Waterman 2002). The statistical models are used to get a sense of Spanish usage with respect to a key dimension of the college admissions debates in the social sciences: household income. Finally, we used frequency ratios (Alvero, Arthurs, Antonio, Domingue, Gebre-Medhin, Giebel, and Stevens 2020) to compare how frequently different groups of students used sayings and conversation excerpts in their essays:\n\n<!-- formula-not-decoded -->\n\nwhere C ( { x, z } , y ) is the number of essays that used sayings or conversation excerpts ( x ) among all of essays in that group ( ) containing strings of three or more words ( i y ) divided by the number\n\nof essays without sayings or conversation excerpts ( z ) among all essays containing strings of three or more words ( y ) in the same group ( ). i Frequency ratios are also used in Naive Bayes classifiers as predictors (Kim, Han, Rim, and Myaeng 2006). The reciprocal frequency ratios are also calculated and compared.\n\n\n## Identifying Student Translations In Situ\n\n\nIn our final analysis, we combine neural machine translation with hand-checking to identify instances of students providing their own translations for the Spanish words and phrases they included in their essays. This analysis will show how many students are essentially doubling the amount of words they are using on Spanish since Spanish and English have roughly similar lexical structures.\n\nWe use the OPUS-MT, a machine translation model developed by researchers at the University of Helsinki that builds on the Marian Neural Machine Translation framework (Tiedemann and Thottingal 2020) 10 . This allowed us to save costs (compared to Google Translate) and help point out that there are many machine translation tools to consider using when working with multilingual text. We use OPUS-MT to generate English translations for the strings of Spanish containing three or more words, and then check which essays contain these translations near the Spanish strings (which we verify manually).\n\n\n## Results\n\n\nThe Spanish dictionary was updated after hand-checking 80% of the essays to reflect any additions or deletions. This final dictionary was used to identify the Spanish words used in the non-Latinx corpus (a simpler hand-checking approach was also used to catch errors). After all of the essays were checked and filtered, the number of Spanish words for each essay was tabulated. Before hand checking, 65% of the essays submitted by Latinx identifying applicants contained at least one word of Spanish, primarily through references to place names in California. In our entire dataset, 33% of the Latinx students and 15% of the non-Latinx students used at least one Spanish word in their essays. Among essays using any Spanish, approximately half contained two or fewer words, regardless of ethnicity (see Figure 2). There was a notable discrepancy between the maximum number of words: one Latinx student used 94 words whereas among the non-Latinx students the high was 33. The shape of the distribution resembles other rank-probability word distributions widely observed in text analysis and natural language processing, such as the Yule-Simon and Zipf distributions (Voloshynovska 2011), hinting that the use of Spanish and amount of Spanish used might have a non-random, probabilistic structure. Figure S2 in the supplementary materials contains a log-log plot and a line of best fit of the same data to further demonstrate this statistical structure (though more data would likely be necessary to determine which distribution best fits).\n\nFigure 2: Spanish words per essay among students using at least one Spanish word. Note the different y-axes for the the Latinx applicants (top, red) and non-Latinx applicants (bottom, blue).\n\n<!-- image -->\n\nAfter noting that approximately 50% of the essays using any Spanish contained either one or two words, we developed a heuristic to organize the essays by the types of Spanish being used by applicants: code-switching for strings of one or two words (e.g., 'mija', 'mi hija'; 'my daughter') and longer strings containing three or more consecutive Spanish words (e.g., 'ella es mi hija'; 'she is my daughter'). This heuristic was informed by the theoretical framework and used to capture more elaborated (Bernstein 1964) deployments of Spanish, such as conversations and sayings similar to linguistic capital as defined by Yosso, as opposed to more restricted switching. The code-switches included instances where an applicant would use a Spanish word in place of an English word (e.g., 'abuela' instead of 'grandma'); named identity markers (e.g., 'latina'); first and/or last names (e.g., 'juan'); various cultural objects (e.g., foods); and organizations or entities (e.g., 'puente,' a program designed to help Latinx students enter college).\n\nThere was not strong ethnic variation in terms of who was using Spanish aside from the nonLatinx students (Table 2). This seems to be an example of the widely held notion that Spanish usage and knowledge is universal across the panethnic category; it is also important to note that there are many other commonly used languages, including English, among the people comprising this category and that some Latin American countries do not speak Spanish as the sole dominant language (e.g., Paraguay and Guaran´ ı). Using longer strings was not widespread, as approximately 20% of the time an applicant used any Spanish it included a longer string (right column of Table 2). Among the ethnic subgroups, a range of 13% to 22% of the students who used Spanish used a string of three or more words. South American students were the most likely to use any Spanish in their essay but Central American identifying students were the most likely to use longer strings. Overall, though, most of the Spanish being used in admissions essays is happening at the individual or word pair level.\n\nTable 2: Proportion of all applicants using any Spanish and proportion of Spanish users including a string of three or more words.\n\nTo better get at the distinction between the types of Spanish being used, the strings of three or more words were organized via manual inspection for those which were naming things, people, or places (e.g., 'pan con mantequilla'; 'bread and butter') and excerpts from conversations and sayings (e.g., 'si se puede', 'el que quiere aprender encuentra una manera'; 'yes we can', 'those who want to learn will find a way'). This approach was informed by the linguistic capital literature from both\n\nYosso and Bourdieu, as well as the 'amount' of Spanish approach from (Stevens 1992) (ie. speaking no Spanish, some Spanish, or only Spanish). There was stronger ethnic variation among how often students used conversations or sayings among the students using longer constructions. Mexican and Central American students were doing so about half of the time (49% and 56% respectively) and non-Latinx students were 24% of the time (see Table 3). This result was surprising because Mexican and Central American language practices and association with Spanish have been among the most marginalized in California. Despite this, their essays generally demonstrated the most elaborate and intricate Spanish constructions compared to students from other groups.\n\nTable 3: Proportion of students using conversation excerpts or sayings among those using strings of three or more words.\n\nMany of the conversation excerpts were followed by translations provided by the students, did not contain Spanish punctuation (e.g., ˜, diacritics), and often depicted communications involving n family members (see Excerpt 1). These students seemed to be assuming that the reader will not be familiar with Spanish (thus requiring a translation). In this way, Spanish was central to their narrative and rhetorical strategy in college admissions given the number of words dedicated to both Spanish and translations in English despite the restricted word count. We call these 'substantive' uses of Spanish.\n\n'Escuche que te vas manana' (I heard that you leave tomorrow), said my grandma. 'Si manana me voy, ya hasta me da miedo irme en un avion. Los voy a extranar' (yes, and now I'm even scared to go in a plane. I'm going to miss you guys).\n\nI also felt the power of ' El pueblo unido jamas sera vencido ' ('The people united will never be defeated').\n\n## Excerpt 1: Examples of substantive use of Spanish\n\nConversely, for the students not using conversation excerpts or sayings (the majority of students using Spanish), different trends emerged. Regardless of the length of the string, many of these instances were not coupled with a translation and oftentimes were naming or listing people, titles, food, places, and other objects. Though many of these instances of Spanish had a connection back\n\nto family, Spanish was more nominal than substantive in its usage (see Excerpt 2) because they were generally not meant to be understood (ie. no translation provided) and placed in sentences so as to appear randomly positioned (Guzm´n, Ricard, Serigos, Bullock, and Toribio 2017). a Additional examples of the substantive and nominal uses of Spanish are available in the supplementary materials in Table S3.\n\nI grew up in a suburban neighborhood of soccer moms and Lunchables, where my mom's harsh accent and my simple school lunch of pan con mantequilla were more troubling than confusing to my peers.\n\nFrom spending hours with my abuelo y abuela and the rest of my mother's family I've grown up knowing that helping others and being generous with your money and time is important.\n\n## Excerpt 2: Examples of nominal use of Spanish\n\nWe present additional examples of substantive usage in Table S4 and nominal usage in Table S5. The results of the statistical analyses are presented in the next section.\n\n\n## Income and Spanish Usage\n\n\nSpanish usage was not exclusive to certain class backgrounds (Figure 3). Each dot represents the number of applicants for a given income (x axis) using a certain number of Spanish words (y axis). The densest areas in the figures are from approximately $ 100,000 (median income is $ 75,000 in California according to the US Census) and below and using 10 or fewer words. The figures were generated using log income to demonstrate the distribution of students using Spanish in their essays but are labeled with raw dollar amounts. The 99th income percentiles for all Latinx students is $ 500,000 and $ 900,000 for all non-Latinx students. Though the very highest income applicants tended to use fewer Spanish words than other applicants (which itself might be more of a reflection of the very few applicants from this income stratum), Figure 3 shows that using any Spanish was a strategy widely adopted among students from all social class backgrounds. The average number of Spanish words used for Latinx students was 4.38 and the median was 3. For non-Latinx students, the average was 2.96 and median was 2.\n\nThe results for the logistic regression models using income to predict whether or not they used Spanish and the type of Spanish used are presented in Table 4. Odds ratios of one or close to one mean that a given x , in this case the student's income, is equally or close to equally likely to occur in either condition. Odds ratios greater than one mean that the predictor has a positive relationship with the outcome, so the higher a given x the more likely a given outcome will occur; the opposite is true for odds ratios below one.\n\nFigure 3: Counts of Spanish Words per essay across the income distribution.\n\n<!-- image -->\n\nIncome was a weak predictor of whether or not Latinx students used Spanish at all (an unsurprising outcome given the distribution of usage seen in Figure 3). Higher income Latinx students were more likely to use strings of two or fewer words (though not a statistically significant difference), whereas lower income Latinx students were more likely to use strings of three or more words. These relationships were not as strong as the relationships with income and Spanish usage for non-Latinx students. Lower income non-Latinx students were more likely to use Spanish, regardless of the length of the string.\n\n∗ p &lt; 0 05; . ∗∗ p &lt; 0 01; . ∗∗∗ p &lt; 0 001 .\n\nThe results of the negative binomial regression, where the dependent variable was the total number of words, were split between the total word count; the count consisting of one to two word strings; and the count consisting of strings of three or more words (see Table 5). The results are reported as the coefficients and the odds ratio. Similar to the logistic regression results, lower income was\n\nassociated with the use of more Spanish words among non-Latinx students for all of the dependent variables. Income was positively associated with the total number of words, but this relationship is stronger for the one to two word strings. Lower income students were more likely to use more of the longer strings. These results suggest that lower income students, regardless of ethnic background, were more likely to use longer multi-word constructions of Spanish in their essays. Collectively, these findings indicate income and class relationships with language that have been reported with other elements of the college application, a relationship that could be more robustly examined with other data.\n\n∗ p &lt; 0 05; . ∗∗ p &lt; 0 01; . ∗∗∗ p &lt; 0 001 .\n\n\n## Income, Ethnicity, and Spanish Usage\n\n\nWe synthesize the previous findings and results to describe how often students used Spanish conversation excerpts and sayings split by both income (above or below the median income) and specific ethnic identity. Among the students using strings of three or more words, we generated frequency ratios based on whether or not the strings reflected conversation excerpts and/or sayings. For each ethnic subgroup and income group among the students using longer strings, we generated the ratio with the counts of students using conversations and sayings divided by those who did not (and vice versa). The results are visualized in Figure 4. For all student ethnic groups, lower income students were more likely to use conversation excerpts and sayings than the higher income students. However, lower income Mexican and Central American students were the only subgroups who were more likely to use conversation excerpts and sayings than not. High income non-Latinx and South American students were the least likely to use conversation excerpts and sayings in their essays.\n\nThese results mostly held with a more linear approach using income to predict which applicants used conversation excerpts and sayings among those using longer strings (see Figure S6). Aside from Cuban and European applicants, the use of conversation excerpts was a strategy negatively correlated with income.\n\nFigure 4: Frequency ratios, left of zero for no conversation used and right for used conversation, split by income and ethnicity.\n\n<!-- image -->\n\n\n## Providing Translations\n\n\nThe previous procedures and analyses yielded an important insight: many, but not all, applicants provided English translations of the Spanish words and phrases they included in their admissions essays. Such an example was seen above in Excerpt 1. Providing translations takes the use of Spanish one step beyond solely providing words and phrases for several reasons. As these essays have strict word count limits, providing the translations essentially doubles down on the amount of text committed to the Spanish words and phrases since Spanish and English have roughly similar word and sentence structures. The translations also show in different ways that the student has some kind of assumption that the reader of the essay either does not speak Spanish or is not familiar with even the most common of Spanish words and sayings. For example, some students would describe celebrating 'El D´ ıa de los Muertos', a holiday originating in Mexico that is popular in the US, but also provide a translation in parentheses right after (e.g., '('Day of the Dead')').\n\nTo measure how often students provided translations for the Spanish words and phrases they included, we used a similar procedure as our method for identifying Spanish words and phrases by combining a computational method and human reading of text. To make this final analysis more feasible, we only consider a random sample (n = 634 essays; 353 Latinx essays and 281 non-Latinx essays; 12 and 31% of each group respectively) of the longer Spanish strings of three or more words. We first took the longer strings of Spanish and used OPUS-MT to identify English translations of the words and phrases. Once the Spanish instance is found in the essay, a dynamic word window was used to try tagging a possible English translation. We also included hard rules to find translations: text in parentheses before or after the Spanish string; and text following the word stems 'translat'\n\nand/or 'mean' after the Spanish string to catch students writing things like 'translates to' or 'means'. Given the relatively small sample, we also hand-checked the random sample to see if the essays contained translations. Combining the machine translation checking with the human reading improved the speed of the analysis.\n\nAmong all of the students in the sample, 32% provided translations of the Spanish words and phrases they included. Though this might not seem high, the random sample also included instances of students referencing things that might not have clear translations, such as place names, the names of people, and certain foods; many but not all of these were also labeled as nominal in the previous analysis. Beyond this, there were no clear patterns of the types of things that students were more or less likely to pair with translations, and several strings that appeared in multiple essays (e.g., 'Dia de los Muertos') would variously include or not include translations. After disaggregating the sample by ethnicity, we found similar patterns along class and specific group identities that have been observed in the previous analyses. See Table 6 for the full breakdown.\n\nTable 6: Proportions of applicants in random sample providing translations of longer strings of Spanish broken down by ethnicity and income.\n\nThe students most likely to provide translations of the Spanish words and phrases they included in their essays were the Mexican (45%) and Central American (43%) identifying students. Cuban (17%), Puerto Rican (14%), and European (17%) were the least likely to provide translations, even compared to the non-Latinx students (21%). Among the students less likely to provide translations, there was no clear pattern of the types of words and phrases that would be paired with a translation. For example, among the Cuban identifying applicants in the sample, there were multiple instances of substantive Spanish not including translations. Mexican and Central American students being most likely to include translations also connects back to them being most likely to include substantive Spanish, as these words and phrases are the most likely to not have any well known translation (e.g., not nominal cases like 'Day of the Dead' for 'Dia de los Muertos').\n\nSimilar patterns with the substantive/nominal Spanish by income also emerged. Since the random\n\nsample was comparatively smaller, here we present the average income among applicants providing translations, average income among those not providing translations, and the average and median income for all students within each specific subgroup among the students providing longer strings of Spanish. For everyone except the European identifying students, students providing translations reported lower average incomes than those providing translations. With the exceptions of the European and South American applicants, all students providing translations also reported lower average incomes than the average income for everyone in their groups (among those including longer strings of Spanish in their essay). Although there is notable variation in the group average and median incomes, this results suggests an overall trend with lower income and higher likelihood of translating the Spanish included in their essays.\n\nWe attempted to automate our identification of essays providing translations but did not get strong results using the random sample. Interestingly, the accuracy of our automated approach when compared to the handchecking was approximately 20% higher for the Spanish instances used in essays written by non-Latinx identifying students (60% vs. 80%). This could be due to higher usage of machine translation tools among non-Latinx applicants and/or more more colloquial translations provided by the Latinx students.\n\n\n## Discussion\n\n\nOur analyses found that approximately 33% of Latinx and 15% of non-Latinx first year applicants to the University of California used some form of Spanish in their admissions essays (excluding US-based place names and Latin American country names). Assuming the proportion of non-Latinx applicants seen in the random sample was an accurate reflection, one fifth of all first year applicants to the University of California are using some Spanish in their admissions essays (as we define 'Spanish usage' for our study). To put this into perspective, it could be more common for students to use some form of Spanish in their essays than it is for students to describe domestic instability in essays about the most significant challenge they have overcome (Gebre-Medhin, Giebel, Alvero, Domingue, Stevens, et al. 2022). This is also somewhat comparable to the number of Latinx youth who report speaking English very well as opposed to only speaking English, a typical indicator of multilingualism (50%, though not all Latinx communities speak Spanish (Flores, L´pez, and Radford 2017)). Despite o the many social stigmas about Spanish language usage in California, these results show that using Spanish is a common linguistic strategy among applicants in selective college admissions despite well known legacies of biases and prejudices against Spanish. The results also found structure and variation of Spanish usage in the essays. The strategic use of Spanish in evaluative contexts, an example of 'strategic Spanish', has broad implications for the intersection of language, ethnicity, culture, and evaluation in education and beyond.\n\nAs some theories might have predicted through an indexicality lens, many Latinx students used\n\nSpanish as part of their essays; our results found that many non-Latinx students did as well. The difference for these groups of students is that their usage is either marked (for the Latinx students) or unmarked (for the non-Latinx students). These disparate affordances in linguistic expression might also imply differential reception from college admissions officers, something future studies might examine. Our analysis also highlighted the socioeconomic and ethnic layers to these practices. The counterintuitive results for the low income Mexican and Central American students using the most Spanish could be an artifact of hyper-awareness of the strong association with themselves and Spanish that is less acute for higher income and/or those less racialized. Although these associations are widely reported, it is still the case that the use of this stigmatized linguistic and cultural practice is broadly shared by people across many different ethnicities. Specifically, though we note that Mexican and Central American students seemed to have assumed mismatching the most, the non-Latinx students might also be using this mismatching strategy by challenging the social boundaries and assumptions about who speaks or uses Spanish. These differences could also point to clear future studies which measure the different effects of multilingual mismatching. Beyond these patterns, in the same way that higher income people tend to fare better in these types of social processes, the stratification in practices we describe here might also be linked with social inequality inherent in these systems.\n\nThe format of the admissions essays lent itself to a macro analysis of the frequency and structure of students using strategic Spanish. The words-per-essays distributions in Figure 1 (as well as the log-log plot in Figure S2) resemble word frequency distributions observed in other textual corpora, such as the Brown Corpus (Kucera, Kuˇ cera, and Francis 1967). Statistical structure often entails predictability, and these results provide evidence that, at least in the case of admissions essays, the frequency patterns of using Spanish in admissions essays are predictable and systematic. If the strategic use of Spanish is somewhat predictable, how are educational personnel interpreting this relatively common practice in evaluation contexts? And how does language planning, policy, and assessment relate to these practices? These and similar questions are longstanding in academic and educational communities, but this paper shows how this particular linguistic strategy could be more socially structured than random.\n\nMost of the differences in the types of Spanish being used had to do with the string length (shorter strings containing one or two words vs. longer strings) and the nature of the usage. Some students demonstrate substantive Spanish language knowledge in their essays, as indicated by the use of complex constructions and sayings (oftentimes followed by a translation provided by the student). For most applicants, however, using Spanish was more nominal and ornamental, in that Spanish usage is evident but not a central point of their essay. While both approaches represent Spanish usage, they vary in the type of information they convey and index. The more nominal single or word pair switches were instances where Spanish was conveying culture, diversity, and cosmopolitanism (Linton and Jimenez 2009) at a more surface level. The students using conversation excerpts and sayings were conveying deep knowledge of Spanish and English, an intimacy with language as most\n\nof the excerpts involved family members, and an assumption that whoever would read their essay is not familiar with Spanish by providing translations. Follow up studies might examine how the linguistic stratification we describe here, along with its sociodemographic correlates, are related to stratification in evaluation (or not).\n\nThis last point suggests that the students using this strategy were assuming a linguistic and cultural mismatch between themselves and the University of California. If selective colleges and universities behave like elite firms in terms of selecting applicants that appear to be the best cultural match (Rivera 2012), students might be unintentionally alienating the reader by extensively highlighting how they see themselves as different rather than similar (which they also inherently understand when following with English translations). Understanding language assumptions and practices in college admissions will become more important for schools maintaining their position in the post-SAT universe in response to the Covid-19 pandemic, including the University of California system. It is less clear if the students using word-switches and nomenclature were also assuming cultural mismatch given the show-not-tell nature of their approach and the fewer translations provided. Their strategy seemed to be designed to provide evidence they were familiar with some Spanish speaking culture, possibly as a way to 'bring' diversity (Kirkland and Hansen 2011), with less regard for possible challenges to their English language competence. These perceptions are not experienced equally in society, however.\n\nIn our samples, the students most likely to use conversation excerpts and sayings were lower income Mexican and Central American students; they were also the only groups of students (split by above or below median income and ethnic subgroup) who were more likely to use these conversation snippets among students using longer constructions. The racial, ethnic, and social hierarchies in much of the US are such that these students are, generally, among the most likely Latinx subgroups to face language discrimination and have their linguistic competence challenged in school. Despite this, these students showed a faith in the University of California, regardless of specific campuses or their Hispanic Serving Institution status (see Table S7), to both not discriminate based on language but also to respond affirmatively to their use of Spanish in the holistic review process. Though this is uniquely the case for lower income Mexican and Central American students, all lower income students were more likely to use conversation excerpts and sayings and in some way showed similar types of faith in holistic review that Spanish is something that could be legitimated and not discriminated against.\n\nStudents see the college admissions essay as a means to stand out in their application, and many low income Mexican and Central American students in California and the western US have indeed been singled out for their linguistic practices, often in negative ways. Specific school practices and policies heighten the attention given to Spanish, so its use in this context might be a reflection of students identifying certain patterns. Students could be seeing college admissions as an alternative context with different social and linguistic norms and tolerances. Beyond the cultural mismatch\n\nstrategy from applicants, including English translations would show essay readers that their language skills are not an obstacle but rather a strength in the ability to use both Spanish and English. Doing so would also signal the dual recognition that certain aspects of their racialized experiences, including their Spanish usage, might be viewed more favorably than in K-12 settings but also that they are linguistically assimilated enough to write the essay primarily in English. These results also show an important way that these students use 'elaborated' code as described by Bernstein; future studies in linguistic sociology should attend to how multilingualism could better explain prior theories developed with monolingual contexts and data. Finally, there is a simple social explanation to consider: California schools and communities are highly segregated for Latinx students (Fuller, Kim, Galindo, Bathia, Bridges, Duncan, and Garc´ ıa Valdivia 2019), and it is possible that many students were adopting strategies that the students around them were using. In this way, the process of seeing Spanish as something that could be legitimized by selective college admissions might first need the step of the social legitimacy of seeing peers using Spanish words and phrases in their essays.\n\nBeyond the primary findings of our study, we also demonstrate the promise of using machine translation for social science. Though we did rely on extensive manual checking of the findings, it is also the case that a relatively simple word level approach with machine translation worked quite well. Of the 7,064 words in the Spanish dictionary used in our analyses, 4,494 (64%) of these words were labeled via machine translation. Code-switching, translation, and multilingual settings are all major topics of computer science and machine learning (Yong, Zhang, Forde, Wang, Subramonian, Lovenia, Cahyawijaya, Winata, Sutawika, Cruz, et al. 2023; Pattichis, LaCasse, Trawick, and Cacoullos 2023), and here we see an opportunity for social science to begin incorporating some of these same tools and methods. The viability of our specific method could work well for smaller studies or with qualitative work more generally (Pardo-Guerra and Pahwa 2022), but analyses of larger corpora will need to figure out how to more efficiently scale up. Our study does show that there could reasonably be a path toward this end. This could possibly be accomplished through crowd sourced dictionaries; generative AI methods (to augment qualitative capacities); or through novel methods specifically for machine translation and social science.\n\nFuture studies could examine how evaluators consider different amounts and types of Spanish in a similar spirit to Thornhill's 2019 study on how admissions officers responded differently to varying degrees of racial salience in emails (Thornhill 2019). Students were submitting the same essay to universities of varying selectivity, including some of the most selective public universities in the US (UC Berkeley and UCLA) and some more moderately selective schools (e.g., UC Merced has an acceptance rate of 85%). The applicants seemed to be assume that regardless of which campus they applied to, the person reading their essay would not know Spanish. We argue that this is an example of cultural mismatch as an application strategy among applicants. Providing both the Spanish words and phrases along with translations shows that many students understand how language could be seen as a valuable form of diversity but also that the institutions valuing that diversity need scaffolding\n\n(translations) to make that diversity more legible. If some of these students were using (Spanish) language as a way to communicate ethnoracial membership in an underrepresented group, future studies might also examine the extent to which evaluators are able to make such connections and, in light of the recent affirmative action lawsuit, whether or not they would even be allowed to. In the California context, affirmative action was already banned in public institutions. But it is possible that including Spanish might be too subtle a way to communicate ethnoracial identity to demonstrate 'racial hardship' as allowed by the courts.\n\n",
         "**Final version: https://www.sciencedirect.com/science/article/abs/pii/S0304422X24000421 ** In US K-12 education, the Spanish language is subject to practices and policies that limit its expression, especially among racialized Latinx students. However, higher education claims to view Spanish as a positive form of diversity. We therefore examine college admissions essays to analyze how students strategically deploy Spanish in light of these contradictions. We use two years of undergraduate application essays (n = 276,768) and metadata submitted to the University of California by every self-identified Latinx applicant and a racially representative random sample of non-Latinx applicants. To identify Spanish language usage in the text, we develop a computational mixed methods approach by combining machine translation and human reading. Spanish was used by 33% of Latinx and 15% of non-Latinx students with stylistic variation by class and ethnicity. We also find that lower income Mexican and Central American applicants were the most likely to use substantive forms of Spanish in their admissions essays as well as provide translations into English. We posit that this self-translation is an example of students identifying cultural mismatch between themselves and university admissions offices. This linguistic strategy, which we call strategic Spanish, sheds light on how language, culture, and ethnicity intersect in high-stakes evaluation and also helps surface the potential for machine translation.",
         ""
        ],
        [
         "27",
         "27",
         "## Introduction\n\n\nThe integration of artificial intelligence (AI) into multiple facets of society has been one of the defining technological shifts of the early 21st century. From healthcare and education to finance and national defense, AI systems increasingly enhance decision-making, efficiency, and innovation (Tegmark et al., 2017). However, the potential benefits of AI come with substantial risks, particularly when the technology is developed and deployed with limited ethical oversight or regulatory frameworks (Russell et al., 2019). The year 2030 stands as a key milestone by which AI may have evolved to a point where it permeates global infrastructure, potentially outpacing the capacity of governments and international institutions to manage its consequences effectively (Bostrom et al., 2014).\n\nThis research paper examines a disturbing vision of 2030. A world where AI has advanced at breakneck speed, but where ethical standards and government oversight have failed to keep pace. In such a scenario, AI's capacities for rapid data processing, autonomous decision-making, and predictive analytics could be used by both state and non-state actors in pursuit of strategic advantages. Governments may engage in AI-driven arms races for global power, while private corporations and criminal networks exploit AI's capabilities to manipulate economies, political processes, and international conflicts. The result could be a fractious, unstable global order, marked by ever-evolving forms of warfare, surveillance, and socio-political control (Scharre et al., 2018).\n\nSpecifically, this paper will address four core themes to illustrate the possible outcomes of an AI-driven future without ethical or governmental restraints: (1) the emergence of increasingly autonomous warfare systems; (2) the geopolitical power struggles fueled by AI-driven capabilities; (3) the misuse of AI by authoritarian regimes and rogue actors; and (4) the moral, ethical, and societal implications of a world where AI is unfettered by regulations. By drawing on existing scholarly work, policy reports, and theoretical models, this paper aims to depict the dark side of AI's potential when left unchecked.\n\nA Preprint\n\n\n## Historical Analogies\n\n\nA useful lens for understanding the challenges posed by AI is found in historical analogies to previous disruptive technologies. For instance, the advent of nuclear weapons led to the Treaty on the Non-Proliferation of Nuclear Weapons (NPT), and the horrors of chemical warfare resulted in the Chemical Weapons Convention. Although AI differs significantly from weapons of mass destruction, these precedents illustrate how global powers historically approached regulatory measures when confronted with existential threats. These analogies highlight not only the possibility of forging effective international agreements but also the danger of delayed or fragmented responses emphasize the urgency of proactive regulation for AI.\n\n\n## The Emerging AI Landscape in 2030\n\n\nBy the year 2030, artificial intelligence (AI) will likely be embedded into everyday life. From optimizing mass transportation systems to detecting emerging diseases in real time, AI applications will permeate every sector, driving efficiency and reshaping societal norms (Tegmark et al., 2017). One key reason for this ubiquity lies in the rapid advancement of machine learning (ML) models and deep learning algorithms, which exhibit human-like abilities to recognize patterns, learn from large datasets, and self-improve over time. As these algorithms become more sophisticated, tasks previously confined to highly specialized experts-such as conducting advanced medical diagnostics or developing intricate financial models-will increasingly be handled by AI systems (Russell et al., 2019).\n\n\n## Real-World Case Studies\n\n\nTo understand how quickly AI is evolving, consider real-life developments in autonomous surveillance and drone technology:\n\n- ● Facial Recognition in Public Surveillance : In certain provinces of China, extensive camera networks coupled with advanced facial recognition systems have been used to monitor and profile individuals in real time. These initiatives reflect a growing trend of AI-enabled surveillance that could be replicated worldwide in the absence of strong legal safeguards.\n- ● Drone Swarms in Conflict Zones : Recent reports indicate that smaller, networked drones have been tested for coordinated strikes or reconnaissance missions in active conflict areas. These swarms leverage AI for semi-autonomous navigation and target recognition, demonstrating a proto-version of the advanced, large-scale systems forecasted for 2030.\n\nA Preprint\n\nSuch contemporary cases provide a glimpse of how AI-driven technologies might evolve into even more pervasive and potent instruments, potentially affecting global stability if regulatory oversight remains inadequate.\n\n\n## Exponential Growth and Deployment\n\n\nIn an environment devoid of comprehensive regulations, the development and deployment of AI systems are predicted to grow at an exponential rate, driven by a relentless quest for speed, performance, and cost-effectiveness (Schultz et al., 2023). Innovations such as neuromorphic computing -where hardware is designed to mimic the neural architecture of the human brain will drastically reduce the time needed for AI algorithms to learn and adapt (Brynjolfsson &amp; McAfee, 2017). This leap in computational power stands to accelerate breakthroughs in various domains, from real-time language translation to autonomous vehicle navigation.\n\nYet, it is in the military sector where these advances could have the most dramatic and potentially dangerous impact. Military research labs and defense contractors, fueled by significant government funding and lax oversight, are likely to prioritize AI applications that enhance strategic capabilities (Humble et al., 2024). For instance, swarm intelligence technology -networks of semi- or fully-autonomous drones that can coordinate actions without direct human oversight promises to render conventional defenses obsolete (Scharre et al., 2018). Such 'swarms' can overwhelm an adversary's anti-aircraft systems through sheer numbers or by executing complex maneuvers at speeds beyond human reaction time. In many cases, these swarms will be integrated with advanced surveillance algorithms capable of real-time object recognition and target prioritization, thereby enabling near-instantaneous deployment of lethal force.\n\nMoreover, these AI solutions will likely spill over into mercenary and private security markets, especially in nations where regulatory frameworks are weak or non-existent (Crootof et al., 2018). As a result, smaller actors ranging from wealthy criminal syndicates to terrorist organizations could gain access to potent AI-driven tools. The effect of this trickle-down technology will be a multiplication of global threats, with increasingly sophisticated AI weapons potentially falling into the hands of those who operate outside any legal or moral constraints (Brundage et al., 2018). Without formal oversight or international treaties to govern usage, the exponential growth of AI will thus become a double-edged sword, fueling both constructive societal advances and destructive military escalation.\n\n\n## Blurred Lines Between Civilian and Military Applications\n\n\nA defining characteristic of the AI revolution is the dual-use nature of many technologies-systems initially designed for benign, civilian purposes can be seamlessly\n\nA Preprint repurposed for military or intelligence operations (Geist et al., 2016). For example, machine learning algorithms that track the spread of infectious diseases can also be employed to identify and target enemy combatants in real time, using similar geospatial analysis and predictive modeling (Bergstrom &amp; West, 2021). Likewise, an AI tool created to optimize commercial supply chains may be adapted to streamline military logistics, potentially enabling rapid troop deployment or the efficient management of weapon stockpiles (Lin et al., 2020).\n\nPublic-private partnerships, especially prevalent in nations that view AI as a strategic national priority, further complicate matters (Russell et al., 2019). Technology giants often collaborate with defense departments to advance AI research funding academic labs, sponsoring competitions, or recruiting top talent from universities (Lee et al., 2018). While such collaborations can spur innovation, they also obscure the boundary between purely civilian research and more covert military-oriented projects (Crootof et al., 2018). This intermingling of interests can create scenarios where ethical considerations fall by the wayside, especially if corporate stakeholders prioritize profit and technological leadership over transparency and accountability (Zuboff et al., 2019).\n\nIn a world lacking strong regulatory guidance, the dual-use dilemma becomes even more pronounced. Governments that rely on AI for economic growth may be disinclined to impose restrictive measures, fearing the loss of competitive advantage. Meanwhile, corporations developing AI-based solutions for health care, finance, or energy management may find themselves compelled through direct government contracts or indirect pressures to integrate militarily relevant features into their software (Brynjolfsson &amp; McAfee, 2017). The consequences of these blurred lines extend beyond heightened global tensions; they pose existential ethical challenges. When AI researchers cannot easily determine whether their work will be used to treat a disease or coordinate a drone strike, the moral calculus of innovation becomes murky at best.\n\nUltimately, the lack of transparent demarcation between civilian and military AI raises urgent questions about accountability, oversight, and the potential for catastrophic misuse. While AI holds the promise of solving complex problems from climate modeling to precision medicine, its unchecked application in warfare and surveillance paves a perilous path. As we move further into an AI-driven era, defining and enforcing guidelines that clearly separate civilian uses from military imperatives will be paramount to ensuring that technological progress does not come at the expense of global stability or human rights (Tegmark et al., 2017; Scharre et al., 2018).\n\n\n## Absence of Ethical Standards and Government Oversight\n\n\nThe rapid pace of AI innovation has outstripped the establishment of robust ethical principles and regulatory structures needed to guide its responsible use. In a future where such frameworks\n\nA Preprint either fail to materialize or are too weak to be enforced, the potential for misuse and abuse grows exponentially (Bostrom et al., 2014). On one hand, state actors may prioritize AI research and deployment as part of a broader strategy for economic and military dominance. On the other, private enterprises ranging from tech startups to multinational conglomerates face few external constraints on how they develop or implement AI-driven solutions (Schultz et al., 2023). The confluence of weak governmental oversight, self-interested corporate behavior, and minimal public scrutiny creates a fertile environment for unethical AI applications to flourish.\n\n\n## Ethical and Philosophical Perspectives\n\n\nAdding a deeper moral dimension to this regulatory vacuum reveals the scope of the problem. According to Luciano Floridi's data ethics, uncontrolled data harvesting and AI-driven decision-making systems can erode personal autonomy and agency. Meanwhile, post-colonial critiques highlight the notion of 'data colonialism,' wherein powerful nations and corporations extract resources (i.e., data) from less developed regions without equitable return or consent. These ethical frameworks emphasize that AI is not merely a tool but also a transformative force reshaping human values, rights, and freedoms.\n\n\n## Comparative Regulatory Proposals\n\n\nAlthough comprehensive global oversight is lacking, some attempts at regulation exist in fragmented form. The European Union's AI Act aims to classify AI systems by risk category and impose stricter requirements for higher-risk applications. The United States , for its part, has approached AI governance with executive orders and NIST standards, while China has been aggressively developing AI regulations that both encourage rapid deployment and uphold state-centric control. Additionally, voluntary frameworks such as IEEE's Ethically Aligned Design provide guidelines but lack enforcement mechanisms. The discrepancies among these efforts highlight a patchwork of regulations that often conflict or fail to address global concerns like AI weaponization or transnational data flows.\n\n\n## Weak or Nonexistent Regulatory Bodies\n\n\nGlobal governance structures, such as the United Nations (UN) or specialized agencies, have historically intervened to regulate emerging technologies in fields like nuclear energy and biotechnology. However, if these bodies fail to enact legally binding, enforceable regulations on AI, nation-states and corporations will have scant motivation to adhere to voluntary ethical guidelines (Cihon et al., 2019). This lack of a universal framework not only accelerates the arms race for AI weaponry and mass surveillance systems but also incentivizes actors to develop AI in secret, sidestepping any existing norms or calls for transparency (Humble et al., 2024). National security imperatives often take precedence, as governments fear that restrictive regulations might\n\nA Preprint place them at a strategic disadvantage leading to what scholars term a ' Race to the Bottom ' in terms of ethics and safety measures (Russell et al., 2019).\n\nIn this regulatory void, even well-intentioned efforts to impose checks and balances can falter. The technical complexity of AI compounds the challenge; few policymakers possess the expertise needed to craft detailed legislation that addresses AI's nuances. Consequently, regulations may lag behind technological advances or rely on outdated assumptions that fail to capture the fluid and dynamic nature of AI-driven systems (Lin et al., 2020). As a result, the ethical questions surrounding AI ranging from algorithmic transparency to accountability for autonomous decisions remain unresolved, leaving critical gaps for exploitation.\n\n\n## Corporate Influence and Lobbying\n\n\nSimultaneously, multinational corporations with substantial financial resources exert considerable influence over public policy through lobbying and political contributions (Brynjolfsson &amp; McAfee, 2017). These tech behemoths, some possessing annual revenues that rival or exceed the gross domestic product (GDP) of entire countries, have a vested interest in minimizing regulatory barriers. Their lobbying efforts can dilute or derail attempts to institute ethical guidelines or government oversight that might limit short-term profits or curb market dominance (Zuboff et al., 2019).\n\nIn this scenario, AI solutions can be developed primarily to maximize shareholder value rather than to ensure public welfare, fairness, or safety. Tools that allow for massive data collection and granular behavioral profiling, for instance, might be designed to enhance targeted advertising or manipulate consumer choices (Zuboff et al., 2019). However, these very same capabilities can be repurposed for more nefarious ends, including mass surveillance, political repression, or population-level social engineering (Lee et al., 2018). Lacking robust external checks, corporations effectively become both the gatekeepers and arbiters of AI, wielding tremendous power over how and to what end these technologies are deployed.\n\n\n## Technical Countermeasures and Safeguards\n\n\nEven within lax regulatory environments, certain engineering solutions can mitigate or prevent unintended misuse of AI. These might include:\n\n- ● Adversarial Testing : Stress-tests that expose AI systems to hostile scenarios, identifying vulnerabilities before real-world deployment.\n- ● Explainable AI (XAI) : Algorithmic designs that clarify decision pathways, aiding transparency and accountability.\n- ● Ethical Kill Switches : Hard-coded or hardware-based shutdown protocols for lethal autonomous systems, ensuring human oversight can intervene.\n\nA Preprint\n\n- ● Accountability Layers : Strict logging and auditing features that track AI decision-making for post-incident investigations.\n\nWhile these measures can reduce risks, widespread adoption depends largely on corporate or governmental goodwill-both of which may be compromised by competitive pressures, profit motives, or national security imperatives.\n\n\n## Proliferation of Autonomous Weapons\n\n\nPerhaps the most alarming consequence of insufficient ethical and governmental oversight is the near-certain proliferation of autonomous weapons. Such systems employ AI algorithms to identify, track, and engage targets without direct human input (Arkin et al., 2010; Scharre et al., 2018). They can encompass everything from drone swarms designed to overwhelm enemy defenses to cyber-attack modules capable of infiltrating critical infrastructure at machine speed (Humble et al., 2024). In a race to achieve tactical or strategic superiority, military powers may develop and deploy these systems prematurely, neglecting the rigorous testing and fail-safes needed to prevent unintended escalation or collateral damage (Lin et al., 2020).\n\nMoreover, the diffusion of autonomous weaponry raises profound ethical dilemmas regarding accountability. When an AI-driven system makes life-or-death decisions, it is unclear who, if anyone can be held responsible for errors or war crimes (Crootof et al., 2018). The risk of accidental conflict escalates when AI systems engage each other based on pre-programmed threat assessments, leaving diplomats and commanders little opportunity to de-escalate tensions or verify that a perceived threat was legitimate (Russell et al., 2019). In such an environment, geopolitical rivalries and localized skirmishes could rapidly spiral into large-scale confrontations before human decision-makers are even aware of the unfolding crisis.\n\n\n## AI-Driven Warfare: The Next Frontier\n\n\nThe advent of advanced AI systems without robust ethical standards or governmental oversight will likely usher in a new era of warfare by the year 2030. Traditional paradigms heavily reliant on human decision-making and chain-of-command protocols may give way to automated processes capable of operating at speeds beyond human comprehension (Russell et al., 2019). The convergence of military research, private sector innovation, and the clandestine activities of non-state actors will redefine the very nature of conflict, posing unprecedented challenges for global stability and human rights.\n\nA Preprint\n\n\n## The Rise of Algorithmic Combat\n\n\nAlgorithmic combat revolves around AI-driven analytics and decision-making tools that process massive volumes of data ranging from high-resolution satellite imagery to the real-time monitoring of digital communications (Scharre et al., 2018). Through machine learning and predictive modeling, these systems can identify targets, plan strategic strikes, and execute maneuvers at a pace that far exceeds human capacity (Russell et al., 2019).\n\n- ● Speed and Scale : AI can evaluate terrain, weather patterns, and force distributions instantly, enabling militaries to conduct simultaneous operations across multiple theaters. In a future where reaction time is key, AI-based command-and-control platforms may relegate human oversight to a secondary role.\n- ● Reduced Human Intervention : Although legal and ethical frameworks typically require 'meaningful human control' over lethal actions, the pressure to gain a tactical edge could lead governments and private military contractors to cede more authority to algorithms. An AI system that misidentifies a target could trigger a lethal strike before operators can verify the information (Scharre et al., 2018).\n- ● Algorithmic Bias and Errors : AI is only as reliable as the data it processes and the coding behind it. Biased or incomplete datasets can lead to flawed outcomes on the battlefield. Errors might result in civilian casualties, misattribution of attacks, or unwarranted escalations-all of which become more likely if oversight is weak or nonexistent (Russell et al., 2019).\n\nThe ascendancy of algorithmic combat does not merely speed up warfare; it risks amplifying the magnitude of errors, miscalculations, and unintended consequences (Lin et al., 2020). While the technology promises greater precision, the absence of moral judgment and the potential for opaque decision-making pipelines cast a shadow over its long-term impact on global security.\n\n\n## Cyber Warfare and Information Manipulation\n\n\nThe scope of AI-driven warfare extends beyond conventional battlefields into the cyber realm. AI-enhanced malware, sophisticated social engineering campaigns, and large-scale disinformation efforts represent a new frontier for state and non-state actors looking to undermine adversaries without resorting to overt military engagement (Bergstrom &amp; West, 2021).\n\n- ● Automated Cyber Attacks : Deep learning algorithms can identify network vulnerabilities within seconds, launching strikes that disable critical infrastructure power grids, hospitals, or financial institutions with minimal human supervision. Once deployed, these offensive cyber tools can self-propagate, adapt to new security protocols, and expand their reach, leading to cascading system failures (Lin et al., 2020).\n\nA Preprint\n\n- ● Disinformation at Scale : The use of AI-driven bots and deepfake technologies can produce highly realistic but entirely fabricated images, audio clips, or videos. By flooding social media platforms, these falsified materials can manipulate public opinion, incite social unrest, and erode trust in institutions (Gehl &amp; Bakardjieva, 2017).\n- ● Hearts and Minds : States no longer need to physically invade a territory to sway its population. Instead, AI-generated propaganda can sow discord, pit communities against each other, and even interfere in democratic processes thus destabilizing nations from the inside out (Bergstrom &amp; West, 2021).\n\nThese developments signal a shift from brute-force cyberattacks to sophisticated, AI-driven 'information wars.' The invisibility and scalability of these methods make deterrence incredibly challenging, as attribution becomes murky and digital front lines constantly evolve.\n\n\n## Autonomous Weapons and Human Rights Violations\n\n\nAmong the most disquieting outcomes of unregulated AI advancement is the proliferation of fully autonomous weapons capable of selecting and engaging targets without real-time human approval (Scharre et al., 2018). While some militaries tout these systems as force multipliers, the ethical and humanitarian implications are profound:\n\n- ● Erosion of Accountability : When software algorithms dictate life-or-death decisions, determining liability for civilian casualties or war crimes becomes exceedingly complex (Crootof et al., 2018). The chain of responsibility blurs among developers, operators, and political leaders.\n- ● Authoritarian Enforcement : Beyond external conflicts, regimes may deploy lethal AI for domestic control. Surveillance drones equipped with facial recognition can track and neutralize dissidents in real time, all while avoiding direct culpability for leaders who claim technological automation as 'policy compliance' (Human Rights Watch, 2020).\n- ● Global Arms Race : As more nations adopt autonomous weapons, strategic stability erodes. The risk of accidental or unauthorized engagement escalates when autonomous systems perceive threats in microseconds, leaving no window for diplomatic intervention (Russell et al., 2019).\n\nThe widespread use of lethal autonomous weapon systems undermines international law principles like proportionality and distinction, raising acute moral concerns (Arkin et al., 2010). In the absence of transparent regulations, the line between defensive technology and offensive coercion becomes dangerously blurred.\n\nA Preprint\n\n\n## The Quest for Dominance: Geopolitical Maneuvers\n\n\nAI's transformative potential will compel nations to seek dominance in the field, thereby shaping a new global balance of power (Lee et al., 2018). This pursuit goes well beyond military might, encompassing alliances, data acquisition, and strategic intellectual property theft (Lazard Geopolitical Advisory, 2023).\n\n\n## Major Powers and the Arms Race\n\n\n- ● Escalating Investments : The United States and China already allocate billions to AI research, supporting both public and private entities (Lee et al., 2018). By 2030, competitive pressures may triple or quadruple these investments as states vie for an 'AI edge' in defense, finance, and governance.\n- ● Alliances and Fragility : Weaker nations or emerging tech hubs may gravitate toward major powers for access to AI infrastructure, training datasets, and research grants. Such alliances, however, can be precarious; conflicting national interests or global crises may quickly unravel them (Lazard Geopolitical Advisory, 2023).\n- ● Clandestine Programs : A desire to secure superior AI capabilities may drive clandestine operations, including hacking foreign research labs, recruiting top researchers, or sabotaging competitor programs. These covert efforts intensify mistrust, pushing states further along a spiraling arms race with limited diplomatic recourse (Scharre et al., 2018).\n\n\n## Resource Wars and Data Colonialism\n\n\nBy 2030, data itself collected from billions of Internet-of-Things (IoT) devices, social media platforms, and biometric scans could become the world's most valuable commodity (Zuboff et al., 2019). This leads to the phenomenon of data colonialism , wherein dominant nations or corporations 'harvest' data from less developed regions (Couldry &amp; Mejias, 2019):\n\n- ● Unequal Access : Nations lacking sophisticated data centers or AI expertise may be compelled to trade their citizens' data for technological support, deepening dependency and eroding local autonomy (Kostka et al., 2019).\n- ● Exploitation of Marginalized Populations : Corporations might exploit communities with fewer legal protections, gathering vast amounts of personal information without meaningful consent or safeguards. These datasets fuel AI algorithms, which then reinforce global power imbalances (Zuboff et al., 2019).\n- ● Data-Driven Geopolitics : As data insights inform strategic planning, countries possessing vast, high-quality datasets gain an economic and military edge. This 'data dominance' can manifest as more accurate predictive policing, advanced military simulations, or nuanced economic forecasting.\n\nA Preprint\n\n\n## Global South Perspectives\n\n\nIn many discussions, the focus remains on Euro-American or Sino-American rivalries. However, emerging economies and countries with fewer resources often face unique vulnerabilities and limited capacity for robust AI governance. For instance, small nations in Africa, Latin America, or Southeast Asia might become testing grounds for invasive biometric systems, with local populations bearing the brunt of experimental or exploitative AI deployments. Case studies show that in certain regions, data privacy laws are weak or unenforced, allowing foreign corporations to harvest biometric and consumer data unchecked. Such imbalances risk deepening global inequality and fostering long-term economic dependency.\n\n\n## Surveillance States and Social Control\n\n\nWhile some nations embrace AI for public safety or administrative efficiency, authoritarian regimes can weaponize these same tools for pervasive surveillance and oppression (Kostka et al., 2019):\n\n- ● Social Credit Systems : AI can aggregate citizens' online behaviors, financial transactions, and real-world movements into a single 'trust score.' Those deemed problematic may face travel restrictions, limited job opportunities, or social ostracism (Zuboff et al., 2019).\n- ● Predictive Repression : Powerful algorithms can flag potential dissidents by analyzing digital footprints, social media posts, location history, or communication patterns allowing governments to suppress activism preemptively (Kostka et al., 2019).\n- ● Erosion of Civil Liberties : Even democratic countries may adopt such measures under the guise of national security or counterterrorism. The normalization of constant surveillance can stifle freedom of expression and assembly, altering the fundamental social contract between citizens and the state (Couldry &amp; Mejias, 2019).\n\n\n## The Dark Side of AI Misuse\n\n\nGovernments and corporations are not the only beneficiaries of AI's capabilities. Non-state actors ranging from criminal organizations to terrorist groups stand to gain access to potent AI-driven tools, exacerbating global instability.\n\n\n## Criminal Networks and AI Exploitation\n\n\nIllicit organizations can harness AI to streamline their operations, evade detection, and increase profits (Johnson et al., 2021):\n\nA Preprint\n\n- ● Sophisticated Cybercrime : Automated ransomware, advanced phishing scams, and 'deepfake blackmail' tactics can target financial institutions, hospitals, or government agencies, causing crippling disruptions (Brundage et al., 2018).\n- ● Smarter Trafficking : Drug, arms, and human trafficking rings might utilize AI analytics to navigate police patrols, optimize shipping routes, and manipulate market dynamics. Cartels could also deploy small, autonomous vehicles to deliver illicit goods covertly (Johnson et al., 2021).\n- ● Money Laundering : Machine learning algorithms can identify loopholes in international banking systems, facilitating complex financial transactions that obscure illicit gains. The speed and adaptability of AI-driven money laundering schemes make detection difficult (Lin et al., 2020).\n\n\n## Economic and Developmental Implications\n\n\nBeyond mere crime, the proliferation of AI in unscrupulous hands worsens global inequality . As illicit actors exploit advanced AI to siphon funds from legitimate economies, local communities suffer. This can destabilize job markets especially in regions already coping with automation-induced layoffs and erode trust in financial institutions. Such disruptions feed a cycle of poverty, hampering economic development and fueling social unrest.\n\n\n## Corporate Overreach and Ethical Transgressions\n\n\nAlthough criminal and terrorist groups pose obvious threats, large corporations themselves can misuse AI in ways that harm society:\n\n- ● Consumer Manipulation : Advanced data analytics and behavioral modeling can exploit users' emotional and cognitive biases to drive compulsive spending, subscription renewals, or even political leanings (Zuboff et al., 2019).\n- ● Market Domination : By employing predictive algorithms that monitor competitor strategies, corporations can engage in predatory pricing, acquire or neutralize upstart rivals, and solidify monopolistic control (Brynjolfsson &amp; McAfee, 2017).\n- ● Unchecked Data Harvesting : Lax regulations may allow companies to conduct mass-scale data collection harvesting personal information for profit, selling it to third parties, or using it to engineer tightly controlled consumer 'ecosystems' (Couldry &amp; Mejias, 2019).\n\nWithout government intervention or a global regulatory framework, these practices can further concentrate economic and informational power in the hands of a few major entities. This tilt in the balance of power erodes competition, consumer protection, and democratic accountability on a global scale.\n\nA Preprint\n\n",
         "By the year 2030, the rapid advancement of artificial intelligence (AI) could lead to transformative global changes—particularly if developed and deployed without ethical guidelines or government oversight. This paper explores how unregulated AI might reshape warfare, drive geopolitical rivalries, and enable misuse by state and non-state actors alike. Through an analysis of potential conflicts, power struggles, and ethical pitfalls, this study examines scenarios in which AI-driven militaries clash, states weaponize data for strategic advantage, and corporate entities develop autonomous systems for profit without regard for societal well-being. The findings reveal a dangerous trajectory where AI could fuel human rights abuses, escalate conflicts, and create a world order defined by unchecked surveillance and algorithmic manipulation. Ultimately, the paper underscores the urgent need for international cooperation and regulation to avoid the dystopian outcomes that could arise from an AI-driven world lacking ethical standards.",
         ""
        ],
        [
         "28",
         "28",
         "## 1 Introduction\n\n\nEducational attainment is, together with sex and age, the most important and most often used background variable collected in surveys of individuals. The main empirical indicator of educational attainment is a person's highest educational qualification (e.g. OECD &amp; Eurostat, 2014), which is also used to proxy a range of related theoretical concepts, ranging from cognitive ability and investments in human capital to cultural capital and social status (see e.g. Schneider, 2016).\n\nDespite this fact, there is little standardisation regarding how to ask for educational attainment in survey questionnaires or how to code it in survey data sets. While harmonising sex and age variables is rather straightforward, harmonising educational attainment is more complicated. In principle, there are two paths to standardised variables: Input- and Output-Harmonisation (Schneider et al., 2016; Tomescu-Dubrow et al., 2024). Input harmonisation or standardisation of sociodemographic measurement instruments leads to unified stimuli across surveys and, thus, to a high degree of\n\nmeasurement comparability across surveys. It is thus the gold standard. Yet, given the differences in educational systems, educational institutions and resulting educational qualifications across countries, in cross-national surveys, education needs to be asked with country-specific questionnaire items. In these surveys, standardisation of measurement instruments for education is, in fact, impossible. But even within countries, questionnaire items asking about educational attainment are rarely standardised. Variation in survey questionnaires occurs in terms of how many questions are asked, how the questions are phrased, and how many and which specific educational qualifications (or groups of qualifications) are included in the response categories. Consequently, the resulting education variables are not directly comparable.\n\nTo obtain comparable education variables across countries or across data resulting from questionnaires without standard education items, the variables from different countries or surveys need to be harmonised, which often involves combining information from several questionnaire items. Without standardised measurement instruments, harmonisation of variables in survey datasets can at least achieve comparable coding across surveys. This is facilitated by standardised target variables for output harmonisation . While this approach is well-known in the context of comparative research, it is rarely used to render variables comparable across surveys within countries.\n\nThe German survey landscape is a good example of these issues. Since the early 1990s, there have been recommendations for measurement instruments for sociodemographic variables (for the most recent version, see Hoffmeyer-Zlotnik et al., 2024). However, the recommended standard items themselves change, and it is hard to find two surveys using exactly the recommended (or otherwise the same) instruments. While virtually all surveys ask separately about school-leaving and postschool qualifications, the precise design of these items differs. The degree of standardisation of measurement is thus, at best, mediocre. Practices for derived education variables also differ across German surveys and an official German standard education variable does not exist.  Current practice in social science surveys thus largely involves the provision of (somewhat differently specified) internationally comparable education variables, building on the International Standard Classification of Education (ISCED, UNESCO Institute for Statistics, 2012) or the education scheme developed in the project 'Comparative Analysis of Social Mobility in Industrial Nations' (CASMIN, Brauns et al., 2003; König et al., 1988).\n\nComparable or standardised background variables would facilitate research in many ways. Firstly, standardised background variables would facilitate secondary data analysis because researchers would find identically specified variables in (ideally) all survey data sets. Secondly, research output would become more comparable and thus more amenable for meta-analysis, strengthening the cumulative character of empirical research. Finally, standardised background variables facilitate the combination of datasets from different surveys (also called survey data recycling, Tomescu-Dubrow &amp; Slomczynski, 2016), which is often done to, for example, increase case numbers for small and often marginalised population groups (e.g., the very low educated), extend timelines for time-series analyses, or drill deeper to compare regions within a country. Standardised background variables would also facilitate data linkage by statistical matching. Therefore, there is a strong case for German surveys to include output-harmonised standardised background variables in their data sets.\n\nThis paper aims to develop and test specifications for a standard education variable for German surveys. As ISCED and CASMIN are already well known and commonly used schemes both internationally and in Germany, these are natural starting points. But given the lack of standardisation in their precise application, what would a German standard education variable\n\nideally look like? Should such a variable be based on ISCED or on CASMIN (or a combination of both)? How detailed should it be, or how crude can it be?\n\nIn the following part of the paper, we describe the German educational system and how education is measured in the German General Social Survey. Then, we introduce the international coding schemes ISCED and CASMIN and how these are implemented in German survey datasets. We also examine whether they reflect important features of the German educational system or not. Based on this analysis, we propose specifications for candidate standard education variables, which will then be subjected to a comprehensive empirical validation analysis based on the data of the German General Social Survey in the remaining parts of the paper. In the third part of the paper, we will describe the data and methods, including the analysis strategy. Part four presents the results, and part five summarises and discusses them.\n\n\n## 2 Theoretical and methodological background\n\n\n\n## 2.1 The German educational system\n\n\nThe German school system is highly stratified (e.g., Allmendinger, 1989), with different school-leaving qualifications producing different levels of general basic skills (Maehler et al., 2013; Rammstedt, 2013). While schooling is regulated differently in the 16 federal states, a standing federal body (the ' Kultursministerkonferenz ') ensures some degree of coordination across Germany as a whole. There is a strong differentiation between schooling and vocational education (König et al., 1988). Also within post-school vocational education, there are hierarchical differences between different levels and types of programmes and qualifications (Protsch &amp; Solga, 2016). Vocational education is regulated centrally.\n\nWhile compulsory full-time general education since 1964 lasts nine years, pupils in Germany since 1920 spend the first four years (or six years in Berlin and Brandenburg) in the same school type, ' Grundschule  (primary school). Following  Grundschule , pupils are sorted into different school ' ' ' types originating in the very early history of formal schooling (König et al., 1988), depending on teacher recommendations and -depending on the federal state -parental preferences. The available options were traditionally the nonselective 'Hauptschule' (lowe r track) with grades five to nine (with its predecessor 'Volksschule' lasting 8 years) , the intermediate 'Realschule' with grades five to ten , and the academically selective 'Gymnasium' with grades five to twelve or 13. While the lower and intermediate tracks prepare mostly for vocational training in apprenticeships and vocational schools, the Gymnasium, with its highstatus 'Abitur' examination, prepares for traditional university education. Finishing the ' Gymnasium  a year earlier leads to the entrance qualification for ' universities of applied sciences ('F achhochschulr eife' , see below).\n\nFollowing German reunification, all eastern German states introduced the Gymnasium but most kept one alternative track of lower secondary education instead of implementing two, corresponding to 'Haupt ' and 'Realschule'. Since 'Hauptschule' became more and -more unpopular, some West German states followed suit and integrated these two tracks into a new school type, which has different names in different federal states. In all federal states, these schools nevertheless are required to offer both the school-leaving certificates of ' Hauptschule  and  Realschule , which thus ' ' ' remain important in determining youth's vocational opportunities.\n\nTraditional universities used to offer 'Diplom' (in the natural and social sciences), 'Magister' (in the humanities) and 'Staatsexamen' (in fields preparing for regulated professions such as medicine, law and teaching) degrees after nine semesters (but usually rather five or more years of study). More and more higher education institutions have start ed operating in Germany to respond to the economy's increased need for a higher-educated workforce since the 1960s. 'Fachhochschulen' ('universities of\n\napplied sciences' , abbreviated 'FH' ) were introduced, and existing engineering schools upgraded to this status. In the 2000s, following the Bologna reforms, b achelor's and m aster's degrees were introduced in both types of higher education institutions, with FH diploma being equivalised with the b achelor's level and university degrees with the master 's level. Furthermore, an even more vocationally oriented 'Berufsakademie' (vocational academy) was introduced, offering tertiary education (not resulting in a higher education degree) in combination with an apprenticeship for holders of the Abitur. In a f ew states, these have been upgraded to 'Duale Hochschulen' (dual system higher education establishments).\n\nGermany has a third large sector of education, vocational education and training (VET), which facilitates the transition from school to work for youth not bound towards higher education and ensures a well-qualified workforce in occupations for which higher education is not required. Initial vocational training mostly takes place in the socalled 'dual system' where apprentices work for pay under an apprenticeship contract with an employer while attending vocational school part-time. This type of VET is notably not limited to crafts occupations but extends to business, banking, public service and other non-manual occupations (König et al., 1988). For social and health-related occupations, vocational training rather takes place in full-time vocational schools (Protsch &amp; Solga, 2016). For many occupations, it is possible to either take additional vocational schooling after some years of work experience to reach higher occupational positions (e.g. technicians) and/or take additional exams to qualify as 'Meister' (master crafts person). This is referred to as advanced VET.\n\n\n## 2.2 The Measurement of educational attainment in German surveys\n\n\nFollowing the general structure of the German educational system and the recommendation of the 'Demographic Standards' that define standard questions for socio-demographic characteristics in German surveys (Hoffmeyer-Zlotnik et al., 2016, 2024), most German surveys ask for educational attainment using two or three questions: the first question asks for the highest school-leaving certificate and the second question for the highest vocational or post-school qualification (covering vocational education and training as well as higher education). A third item is sometimes recommended to distinguish different levels of higher education following the Bologna reforms to keep the list of options for the second question manageable.\n\nFehler! Verweisquelle konnte nicht gefunden werden. , Fehler! Verweisquelle konnte nicht gefunden werden. and Fehler! Verweisquelle konnte nicht gefunden werden. show these items as they were asked in the (then interviewer-administered) German General Social Survey 2018 (GESISLeibniz-Institut für Sozialwissenschaften, 2019) from which we use the data for the validation analyses (see sections 3 and 4). As is obvious, the items are more differentiated than what our brief description of the German education system in section 2.1 could cover.\n\nFigure 1: Question F056 on highest school-leaving qualification in ALLBUS 2018 with translation/description in English\n\n## → Liste 56 vorlegen!\n\n## → Present list 56!\n\nAls nächstes kommen jetzt Fragen zu Ihrer Ausbildung und Ihrem Beruf.\n\nBeginnen wir mit Ihrer Ausbildung:\n\nWelchen allgemeinbildenden Schulabschluss haben Sie?\n\n- → Nur eine Nennung möglich! → Nur h ö c h s t e n Schulabschluss angeben lassen!\n- A Noch Schüler\n- B Schule beendet ohne Abschluss\n- C Volks- / Hauptschulabschluss bzw. Polytechnische Oberschule mit Abschluss 8. oder 9. Klasse\n\nThe next questions are about your education and occupation.\n\nLet s start with your education: '\n\nWhich general school-leaving certificate do you have?\n\n- → Only one answer is possible! → Only indicate the h i g h e s t school-leaving certificate!\n- A Still in school\n- B Finished school without a certificate\n- C Lower track school-leaving certificate, or completed 8 or 9 grades of lower secondary school in the former GDR\n\n- D Mittlere Reife, Realschulabschluss bzw. Polytechnische Oberschule mit Abschluss 10. Klasse\n- E Fachhochschulreife (Abschluss einer Fachoberschule etc.)\n- F Abitur bzw. Erweiterte Oberschule mit Abschluss 12. Klasse (Hochschulreife)\n- G Anderen Schulabschluss, und zwar:\n- D Intermediate track school leaving certificate, or completed 10 grades of lower secondary school in the former GDR\n- E University of Applied Sciences entrance qualification\n- F University entrance qualification, or completed 12th grade in upper secondary school in the former GDR\n- G Other school-leaving certificate, namely:\n\n\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n\n\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n\n## → Liste 57 vorlegen!\n\n## → Present list 57!\n\nWelchen beruflichen Ausbildungsabschluss haben Sie?\n\nWas von dieser Liste trifft auf Sie zu? Nennen Sie mir bitte die entsprechenden Kennbuchstaben.\n\n- → Mehrfachnennungen möglich außer wenn M genannt!\n- A Beruflich-betriebliche Anlernzeit mit Abschlusszeugnis, aber keine Lehre\n- B Teilfacharbeiterabschluss\n- C Abgeschlossene gewerbliche oder landwirtschaftliche Lehre\n- D Abgeschlossene kaufmännische Lehre\n- E Berufliches Praktikum, Volontariat\n- F Berufsfachschulabschluss\n- G Fachschulabschluss\n- H Meister-, Techniker- oder gleichwertiger Fachschulabschluss\n- J Fachhochschulabschluss (auch Abschluss einer Ingenieurschule)\n- K Hochschulabschluss\n- L Anderen beruflichen Ausbildungsabschluss, und zwar: \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n\nWhich vocational qualification do you have? Which options on this list apply to you? Please tell me the corresponding code letters.\n\n- → Multiple answers possible except if M is mentioned!\n- A Vocational training on-the-job with final certificate, but no apprenticeship\n- B Semi-skilled worker qualification\n- C Completed trade or agricultural apprenticeship\n- D Completed commercial apprenticeship\n- E Vocational internship, traineeship\n- F Vocational school qualification\n- G Technical college qualification\n- H Master craftsperson, technician, or equivalent technical college qualification\n- J Degree from a University of Applied Sciences (including engineering school)\n- K University degree\n- L Other vocational qualification, namely:\n\n\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n\n- M Keinen beruflichen Ausbildungsabschluss\n- M No vocational qualification\n\n## → Liste 57 A/B vorlegen!\n\n## → Present list 57 A/B!\n\nUm welche Art von Hochschulabschluss handelt es sich dabei? Bitte nennen Sie mir nur den höchsten Abschluss, den Sie erlangt haben.\n\n- → Nur eine Nennung möglich!\n- A Bachelor\n- B Master\n- C Diplom\n- D Magister\n- E Staatsexamen oder Lehramtsprüfung\n- F Promotion\n\nWhat type of university degree is this? Please tell me only the highest degree you have obtained.\n\n- → Only one nomination possible!\n- A Bachelor\n- B Master\n- C Diploma (Pre-Bologna degree after 2 years of study at vocational academy, 4 years at University of Applied Sciences, or 5 years at university)\n- D PreBologna degree ' Magister  after 5 years of ' study\n- E State examination after 5 years of study in law, medical fields, and teacher training\n- F Doctoral degree\n\n\n## 2.3 Existing education standards and their application in German surveys\n\n\nWhen analysing data, the information collected using these questionnaire items is usually integrated into one variable, and categories are condensed at different aggregation levels. So far, there is no standard education coding scheme for German data. However, there are two international coding schemes which are widely used in research and official statistics respectively: the CASMIN education scheme and ISCED. Both are thus also offered routinely in German survey datasets. This section describes both, assesses how well they conceptually link with the German educational system and examines whether they are available in popular German survey data sets.\n\n\n## 2.3.1 ISCED\n\n\nISCED (Schneider, 2013; UNESCO Institute for Statistics, 2012) is the official international framework for education-related administrative and survey data used, for example, by Eurostat and the OECD but also the German national education report 'Bildung in Deutschland' (Autor:innengruppe Bildungsberichterstattung, 2022). It classifies national educational programmes and qualifications based on the 'complexity of content' into nine levels of education on the first digit. Furthermore, it distinguishes between generally and vocationally oriented education on the second digit, where the latter is defined to be 'designed for learners to acquire the knowledge, skills and competencies specific to a particular occupation, trade, or class of occupations or trades' (UNESCO Institute for Statistics, 2012, p. 14). Finally, it defines sub-levels on the third digit, defined by whether a qualification completes a level of education, and if yes, if it gives access to programmes at a specific higher ISCED level. The 1997 version still used in some data sets distinguishes only seven levels because short-cycle tertiary, bachelor and master levels formed one level in ISCED 1997. It also used letters A, B and C for access to (types of) higher education levels broadly corresponding to the third digit in ISCED 2011. Table 5 in appendix 1 shows how German qualifications are officially mapped to ISCED 2011 in detail.\n\nISCED does not well reflect certain key features of the German educational system (see e.g. Schneider, 2008), and ISCED 97 main levels showed to not be very valid for Germany (Schneider, 2010). First, it does not differentiate between tracks of lower secondary education (Hauptschule and Realschule) in Germany because all types of lower secondary schooling in Germany are generally oriented and give access to the upper secondary level. Second, it mixes higher education and advanced VET, which are both classified as tertiary education in ISCED. Its 2011 version for example does not differentiate between higher education degrees at the bachelor's level and advanced VET (e.g. Master craftsperson and technician qualifications and equivalent) even though both have very different prerequisites (having obtained a higher education entrance qualification vs. VET at upper secondary level) and, potentially, outcomes. In ISCED 1997, these were at least differentiated by different destinations (5A for higher education potentially leading to ISCED 6, 5B for advanced vocational education leading to the labour market).\n\n\n## 2.3.2 CASMIN\n\n\nThe CASMIN education scheme (Brauns et al., 2003; König et al., 1988) was developed by sociologists interested in comparative measurement of education for the purpose of social stratification and mobility research, where it is widely used. It defines three broad education levels (minimum, intermediate/secondary and tertiary) and sub-levels within each broad level. Table 3 shows how German education categories are mapped to CASMIN.\n\nCASMIN differs from ISCED in several ways: First, the distinction between the lower (Hauptschule) and intermediate (Realschule) tracks of lower secondary education is fundamental to the implementation of CASMIN in Germany as it constitutes the difference between broad levels 1 (defined as the social minimum) and 2. Second, having completed vocational education leads to a different sub-level but does not elevate the main education level obtained. Third, advanced vocational education is classified together with initial VET rather than higher education so that tertiary education in CASMIN corresponds to higher education in Germany, while tertiary education in ISCED does not. Fourth, within higher education, CASMIN distinguishes types of higher education institutions (applied vs traditional/academic) while ISCED distinguishes levels of education (notably bachelor's, master's, and doctora l levels).  As a result, CASMIN captures important distinctions in the German education system that ISCED does not capture. However, it also omits distinctions that ISCED makes. The analyses in this study will show which ones are actually more important.\n\n\n## 2.4 Application of ISCED and CASMIN in German surveys\n\n\nSeveral German survey data sets offer ISCED-based education variables to their users: ISCED 2011 is offered by the German General Social Survey (ALLBUS, e.g. Baumann et al., 2019), the German Family Demography Panel (FReDA, Bujard et al., 2022, 2023), the German Health Update (GEDA, e.g. Allen et al., 2022), the Microcensus (e.g. Destatis, 2019), and the Socio-Economic Panel (SOEP, e.g. DIW Berlin/SOEP, 2022). They all include an education variable representing the first ISCED 2011 digit (main levels), except for level 0. ISCED level 0 (less than primary education) usually cannot be distinguished in German surveys since the recommended questionnaire items do not make any distinctions within the group of respondents without qualifications between those who completed primary school and those who did not (numbers would also be very low). FReDA and SOEP instead use code 0 for respondents who are still in education. GEDA additionally offers an ISCED 2011 variable with two digits.\n\nISCED 1997 main levels are offered alongside ISCED 2011 by ALLBUS (Baumann et al., 2019) and SOEP (DIW Berlin/SOEP, 2022) with the same treatment of ISCED 0 as for ISCED 2011 mentioned above. The panel surveys Labour Market and Social Security (PASS, Berg et al., 2023) and the National Educational Panel Study (NEPS, FDZ-LIfBi, 2023) offer ISCED 1997 main levels and programme destination, which makes them more informative than data using ISCED 2011 main levels alone. They use ISCED 1997 rather than 2011 because these panels started before 2012. The German Ageing Survey (DEAS, Behagel &amp; Stuth, 2022) offers a three-tiered ISCED variable with tiers  low ,  medium ' ' ' ' and  high . Further survey datasets screened for ISCED variables were the GESIS Panel (Minderop et ' ' al., 2023), the German Longitudinal Election Study (GLES, 2023) and the German Internet Panel (GIP, Blom et al., 2021), which do not offer any ISCED variables.\n\nDerived education variables based on CASMIN are offered by fewer surveys. Only SOEP, NEPS and PASS offer CASMIN variables with nine categories as defined by Brauns et al. (2003). SOEP additionally offers a 0 for respondents who are still in school, consistently with their ISCED variables. To conclude, there is no standard education variable that is consistently offered across German survey data sets. This complicates comparisons across different datasets, especially metaanalyses and cumulating and harmonising data for pooled statistical analysis. If anything, there is a tendency towards ISCED 2011 main levels.\n\n\n## 2.5 Candidate standard education variables\n\n\nTo provide a validated standard education variable to the research community, we developed and tested candidates for a standard education variable for use in German surveys, which would complement the standard questionnaire items recommended by the 'Demographic Standards' (Hoffmeyer-Zlotnik et al., 2016, 2024). The first set of candidates is based on the International\n\nStandard Classification of Education (ISCED), and the second set is based on the CASMIN education scheme. This section describes those candidates. Table 1 shows the different candidates for a minimum and intermediate version of a standard education variable based on ISCED and how these can be derived from the most detailed codes. How these are, in turn, derived from the ALLBUS 2018 education categories, and how the maximum versions are constructed, see Table 2. Table 3 shows the candidate standard variables based on CASMIN.\n\n\n## 2.5.1 ISCED\n\n\nA very popular education variable corresponds to broad ISCED levels, that summarise 'low' education up to and including lower secondary education, 'medium' education with upper secondary and post -secondary nontertiary education, and 'high' education with tertiary education ( including, in the case of Germany, advanced vocational education). This is the minimum version of ISCED (I\\_Min), which is often used in cross-tabulations and reports but also in regression models.\n\nGiven it is already commonly offered in German survey datasets, the most important candidate standard education variable represents the first digit of ISCED 2011, with ISCED 0 and 1 aggregated since they usually cannot be distinguished in German data. Since this is a simplified version compared to the full three-digit ISCED, yet more detailed than the minimum version, it is regarded as the first intermediate candidate (I\\_Int1). Two alternative intermediate candidates with a similar number of categories were developed: Intermediate candidate I\\_Int2 distinguishes advanced vocational qualifications classified at the bachelor's level (in Germany: master craftsperson, technician, and comparable technical college qualifications) from higher education qualifications since these are likely to have different antecedents and outcomes. Most notably, they do not require a higher education entrance qualification for entry but instead require completed VET. Intermediate candidate I\\_Int3 (corresponding to the European Survey Version of ISCED, ES-ISCED; Schneider, 2010, 2020) splits the usually large ISCED 3 by whether a qualification generally gives access to higher education. In Germany, this leads to a differentiation of VET (dual or school-based) and higher education entrance qualifications. It also aggregates ISCED 4 with ISCED 5 and vocationally oriented tertiary qualifications classified at ISCED 6. Finally, it aggregates ISCED levels 0 and 1 as well as 7 and 8, because ISCED 0  cannot be identified and ISCED 8 is very small.\n\nTable 1: Candidates for a minimum version of a standard variable for education based on ISCED and their derivation from detailed codes (Maximum version I\\_Max2) shown in Table 2\n\nWhen using educational attainment as an independent variable, the predictive power and thus validity of education levels as defined by ISCED (especially broad ISCED levels) may be rather low compared to the source education variables from which the ISCED levels were derived (Schneider, 2010). This is due to the fact that a few main levels contain large proportions of cases, and large categories are likely heterogeneous, which depresses associations with the dependent outcome variables of interest (Kerckhoff &amp; Dylan, 1999). Therefore, we also specify several more detailed candidates for a standard education variable (i.e., 'maximum versions' presented in Table 2):\n\nThe first maximum candidate (I\\_Max1) provides, next to the main ISCED level (i.e., I\\_Int1), information on whether the educational qualification is vocationally oriented or not, which is an important feature of education in Germany, especially when analysing labour market outcomes or when using education as a proxy for cognitive skills. This two-digit version of ISCED 2011 is, therefore, the most promising variant of the official ISCED scheme for the German application from a conceptual point of view. This candidate corresponds to the ISCED variable contained in the GEDA dataset.\n\nThe second maximum candidate (I\\_Max2) is a non-official extension of maximum candidate I\\_Max1, which introduces additional distinctions relevant to the stratification of secondary schooling (ISCED level 2 and 3) and higher education systems (ISCED levels 6 and 7). Stratification of educational systems or parts thereof refers to the selection of individuals into different educational pathways, only one of which leads to the maximum number of years of education (Allmendinger, 1989). I\\_Max2 corresponds to the detailed international education variable (variable  edulvlb ) developed for the ' ' European Social Survey (ESS) in round 5.  For Germany, it distinguishes the lower vs intermediate 4 track school-leaving qualifications ( Hauptschulabschluss ' ' vs  Realschulabschluss ), on the one hand, ' ' and university of applied sciences vs (traditional) university entrance qualification ( Fachhochschulreife ' ' vs ' Allgemeine Hochschulreife ), on the other hand. These qualifications are ' associated with different educational transitions in the educational career as well as different opportunities for subsequent education but are not distinguished by ISCED. A distinction is also made at the bachelor's level and the master s level (ISCED 6 and ISCED 7) between qualifications from ' universities of applied sciences and qualifications from traditional universities. Furthermore, candidate I\\_Max2 makes a distinction for vocational qualifications as to whether they offer access to advanced vocational education and training (in the German case, to master craftsperson, technician, and comparable qualifications) or not.\n\nMaximum version I\\_Max3 finally builds on I\\_Max2 and additionally differentiates, within vocational qualifications in ISCED 3 and 6, by the school leaving certificate previously obtained, given this has a large impact on cognitive skills (Maehler et al., 2014). This means that CASMIN (see below) can also be derived from this candidate standard variable, which is not possible with the other maximum versions based on ISCED.\n\nNote that there is no maximum version representing the full three-digit ISCED. The third ISCED digit has only a marginal effect in Germany, as only a few current educational programmes do not offer access to a higher level of education, and, in addition, contain only small numbers of respondents. Since these few programmes are not distinguished in the ALLBUS questionnaire, the full three-digit\n\nversion of ISCED cannot be derived for and validated with ALLBUS data. It is thus also not shown in Table 2, but the fill derivation is shown in Table 5 in Appendix 1.\n\nTable 2: Maximum versions of candidate standard education variables based on ISCED and their derivation from ALLBUS 2018 response categories\n\n\n## 2.5.2 CASMIN\n\n\nPrevious research had shown that CASMIN in some countries performs better than ISCED when predicting some outcome variables (Braun &amp; Müller, 1997; Kerckhoff et al., 2002; Schneider, 2010). Table 3 shows the allocation of German school and post-school qualifications as measured in ALLBUS 2018 to the CASMIN education categories. The candidates for a detailed CASMIN-based standard education variable differ only regarding the distinctions within the higher education sector. In the last published CASMIN version (Brauns et al., 2003), the higher education sector (university of applied sciences vs university) is distinguished rather than the level of degrees in the sense of bachelor's and master's levels. As CASMIN has not been updated since the Bologna reforms, our candidate maximum version (C\\_Max) differentiates between the bachelor's and master's levels in addition to the sectoral distinction. The first intermediate version (C\\_Int1) corresponds to the version by Brauns et al. (2003). Intermediate version C\\_Int2 replaces the sectoral differentiation with the one by bachelor's and master's and higher level. Finally, a minimal version (C\\_Min) reduces CASMIN to the distinction between general basic education and less, intermediate/secondary education and higher education.\n\nTable 3: Candidates for standard education variables based on CASMIN and their derivation from ALLBUS 2018 response categories\n\n\n## 3 Methods\n\n\n\n## 3.1 Analysis strategy\n\n\nFollowing previous research, we defined the validity of a candidate standard education variable as its explanatory power relative to the benchmark (i.e., the most detailed) education variable . Explanatory power was indicated by the partial adjusted R 2 (pa R 2 ) resulting from a multiple linear regression model predicting an outcome by the respective education variable. In contrast to previous research (Braun &amp; Müller, 1997; Kerckhoff et al., 2002; Kerckhoff &amp; Dylan, 1999; Schneider, 2010), we did not only use one or a few outcome variables for the validation, but a broad pool of 157 outcomes from various research topics selected in a data-driven approach to obtain robust and broadly applicable results, like Schneider and Urban (2024, under review) did using cross-national data. We evaluated the validity of the candidate standard education variables in three steps: First, we compared the overall validity of the candidate standard education variables based on the mean of the relative pa R 2 s across all 157 validation variables. Second, we compared the variability in the validity of the candidate standard variables based on a visual inspection of the full distribution of the relative pa R 2 s of the 157 validation variables. Third, we compared the validity of all candidate standard variables for the 20 most important outcomes of education in our data set (i.e., the 20 validation variables for which the benchmark education variable showed the highest pa R 2 ). This step was added to examine whether a candidate standard education variable a) performed equally well across these most relevant education outcomes and b) performed particularly well or poorly for each of these most relevant education outcomes coming from various research topics.\n\n\n## 3.2 Data and measures\n\n\nWe used cross-sectional data from the German General Social Survey (ALLBUS, GESIS-Leibniz-Institut für Sozialwissenschaften, 2019), collected between April and September 2018. The probability-based sample consisted of N = 3,477 persons and aimed to represent the German adult population living in private households. The ALLBUS 2018 includes both detailed measures of educational attainment and numerous items assessing attitudes and behaviour in the context of a wide range of topics, such as the economy, media use, politics, social inequality, national pride, right-wing extremism, and religion. Since respondents living in eastern Germany are oversampled in ALLBUS, the person-based east-west weight ( wghtpew ) was used to proportionally adjust the distribution of respondents to the population.\n\nWe created the most detailed benchmark variable of educational attainment by assigning the specific combination of highest school-leaving certificate (variable ' educ ' , see Figure 1) and highest postschool qualification (extracting the highest one from indicator variables ' de05 ' to ' de18 ' given the multiple response character of the question in ALLBUS, see Figure 2 and 3) to each respondent. This resulted in a variable with 77 categories, which is the most informative variable to which the aggregated less informative but more parsimonious candidate standard education variables will be compared. We excluded respondents who reported to be still in school and those with unknown or missing information on both items. If information on post-school qualification was available but not on the school-leaving certificate, we assumed them to have an intermediate school-leaving certificate to be able to code their level of vocational education and training. Then, we created the candidate standard education variables described in detail in section 2.5 (see Table 1 to 3). We used age (continuous) and sex (dichotomous) as control variables to be parsimonious and close to the usual research practice at the same time.\n\nWe identified a pool of 157 validation variables (889 ≤ n ≤ 3,477). To ensure that the validation variables can be meaningfully predicted by educational attainment, the benchmark education variable had to explain at least 1% of the validation variable's variance beyond the control variables.\n\nIn addition to a few objective (but self-reported) socio-structural characteristics (e.g., income, social status), the pool of validation variables consisted mostly of self-reported attitudes and behaviours within the whole range of topics covered in ALLBUS 2018. They represented those continuous and ordered categorical variables that had been assessed with at least a 5-point Likert scale to be treated like continuous variables. We present the validation variables including their descriptive statistics (i.e., n , minimum, maximum, M SD , , skewness, excess) and their pa R 2 by the benchmark education variable in the Electronic Supplementary Material (ESM) 1 on the project website on the Open Science Framework (OSF; https://osf.io/paxtb/).\n\nThe pa R 2 s of the 20 validation variables most strongly associated with the benchmark education variable ranged from 0.14 (di07: Per capita income) to 0.55 (isei08c: international socio-economic index (ISEI) for the current and, for those not currently employed, past occupation; Ganzeboom et al., 1992). While the top 10 most empirically relevant validation variables mostly represented objective (but self-reported) socio-structural characteristics, the top 11 -20 mainly represented attitudes, opinions, and perceptions.\n\n\n## 3.3 Statistical analyses\n\n\nWe estimated a large number of baseline and full multiple regression models. In the baseline models, we predicted each validation variable only by the control variables. In the corresponding full models, we added one of the education variables (dummy coded) to the baseline model. As our analyses involved the benchmark education variable (i.e., the most detailed education variable with the resulting model serving as benchmark model), seven ISCED-based candidate standard education variables, and four CASMIN-based candidate standard education variables, our approach\n\n- · comprised 12 [education variables] x 157 [validation variables] x 2 [baseline and full models] = 3,768 regression models,\n- · resulted in 12 [education variables] x 157 [validation variables] = 1,884 pa R 2 s ,\n- · and resulted in 11 [candidate standard education variables] x 157 [validation variables] = 1,727 relative pa R 2 s (i.e., pa R 2 s of candidate standard education variables relative to the benchmark variable). This measure of relative explanatory power is our indicator of validity.\n\nCorresponding to the analysis strategy presented above, we present the results on each candidate standard education variable in three complementary ways:\n\n- 1. Mean values: For each of the eleven candidate standard education variables, we calculated the mean of their relative pa R 2 s across the 157 validation variables.\n- 2. Full distributions: For each of the eleven candidate standard education variables, we produced a Kernel density plot (Wickham et al., 2016), that is, we estimated the distribution of their relative pa R 2 s of the 157 validation variables. The Kernel density estimation is an alternative to the histogram for continuous data.\n- 3. Sub-set of empirically most relevant validation variables: In line plots, we present the relative pa R 2 s of each of the 11 candidate standard variables for each of the 20 empirically most relevant validation variables.\n\nWe used the statistical software R (R Core Team, 2020) and estimated the regression models using the svyglm function from the survey package (Lumley, 2020) to account for the person-based eastwest weight (wghtpew). We obtained KL-divergence-based (partial) adjusted R 2 s from the package rsq (Zhang, 2022) using the functions rsq and rsq.partial, respectively. We provide the R analysis scripts (including renv lock-file for reproducibility; Ushey &amp; Wickham, 2020) and the corresponding html output files as ESM 2 and ESM 3 on OSF.\n\n\n## 4 Results\n\n\n\n## 4.1 Means of relative pa R 2 s\n\n\nTable 4 summarises how much explanatory power the different candidate standard variables retain -or, to put it the other way around, lose -relative to the benchmark education variable based on their mean relative pa R 2 s across all 157 validation variables. Among the ISCED-based maximum versions, the loss of explanatory power ranged between approx. 33% (the official I\\_Max1 with nine categories) and 23% (the non-official I\\_Max3 with 19 categories). This means that even the most detailed ISCED-based candidate standard variable, on average, entailed a loss of almost a quarter of the maximally possible explanatory power, and the most detailed official one almost a third. Among the ISCED-based intermediate versions, the often-used official 1-digit ISCED variable (I\\_Int1) leads to a staggering loss of explanatory power of 48% and showed a 15 percentage point higher loss of explanatory power than the non-official ES-ISCED variable (I\\_Int3) with seven categories, just like I\\_Int1. This result shows that the same number of categories can go along with a substantial difference in validity. Moreover, the loss of explanatory power was essentially the same for I\\_Int3 as for I\\_Max1, even though the former has two fewer categories. The popular ISCED-based  low-' medium-high  aggregation (I\\_Min) showed the highest loss of explanatory power among all 11 ' candidate standard education variables with almost 60%.\n\nAmong the CASMIN-based candidates, the two intermediate versions comprising nine categories (C\\_Int1 and C\\_Int2) and the maximum version comprising 11 categories (C\\_Max) showed essentially the same losses in explanatory power (approx. 25%). The CASMIN-based  low-medium-high ' ' aggregation showed a loss of explanatory power of 50%.\n\nComparing the performance of both ISCED and CASMIN-based candidate standard education variables, the CASMIN-based variables were superior to the ISCED-based variables, especially regarding the trade-off between parsimony and explanatory power. The most detailed official ISCEDbased standard education variable, I\\_Max1 with nine categories, showed a validity of 67%, compared to 75% for the CASMIN variable with eleven and 74% for the CASMIN variables with nine categories. Only the unofficial ISCED variables that incorporate some (I\\_Max2) or all (I\\_Max3) of the CASMIN distinctions come close to (I\\_Max2) or outperform (I\\_Max3) the intermediate and detailed CASMIN variables, but need many more categories to do so. The CASMIN-based 3-categorical minimumversion (i.e., low-medium-high), also outperformed its ISCED-based counterpart by almost 10%.\n\nTable 4: Relative explanatory power of candidate standard education variables compared to benchmark education variable averaged across all 157 validation variables\n\n\n## 4.2 Full distributions of relative pa R 2 s\n\n\nFigure 4 shows the Kernel density plots of the relative pa R 2 s of the ISCED-based (top) and the CASMIN-based (bottom) candidate standard variables. The Kernel density plots are interpreted as follows: The further to the right the maximum of a distribution is, the steeper the distribution left to the maximum declines, and the less the distribution curve rises again further to the left, the higher are the relative pa R 2 s of the corresponding candidate standard variable across validation variables, the lower is their variability across the 157 validation variables -and the higher is consequently the candidate standard education variable's validity.\n\nOverall, the Kernel density plots corroborated the mean values reported in Table 4: The ISCED-based candidate standard variables showed the following ascending rank order in validity (i.e., from low to high): I\\_Min &lt; I\\_Int1 &lt; I\\_Int2 &lt; I\\_Int3 &lt; I\\_Max1 &lt; I\\_Max2 &lt; I\\_Max3. The CASMIN-based candidate standard variables showed the following ascending rank order in validity: C\\_Min &lt; C\\_Int2 &lt; C\\_Int1 ≈ C\\_Max. Thereby, the Kernel density plots showed that the lower the mean relative pa R 2 was in Table 4, the higher the variability of the relative pa R 2 s across the 157 validation variables. Thus, if a candidate standard variable showed, by comparison, an overall low validity, its validity for the individual validation variables differed more strongly across the whole range from very low to very high. Likewise, an overall high validity was associated with a small variability in validity across the 157 validation variables. Thus, when a candidate variable showed an overall high validity, this tended to apply also to the individual validation variables. Nevertheless, even the most valid candidate standard education variable performed poorly for a small number of outcome variables.\n\nFigure 4: Distribution of the relative partial adjusted R 2 s for the 157 validation variables of each of the 11 candidate standard education variables (top: ISCED-based, bottom: CASMIN-based variables)\n\n<!-- image -->\n\n\n## 4.3 Relative pa R 2 s of sub-set of empirically most relevant validation variables\n\n\nTurning to step three of the analyses, the line plots in Figure 5 and Figure 6, respectively, show the relative pa R 2 s of all candidate standard education variables for the 20 empirically most relevant validation variables. The line plots are to be interpreted as follows: The stronger and further up the yaxis the validation variables cluster, the better and more consistently across outcomes they are predicted by the candidate standard education variable indicated on the x-axis. By contrast, the greater the dispersion of the validation variables across the y-axis, the more heterogeneously (or inconsistently) the respective candidate standard variable predicts the outcomes and the less generally valid it is as a result. Here, our results indicated whether the validity of the candidate standard education variable varied according to the analysis topic, and if yes, which education variable(s) may be (un-)suitable for which topic.\n\nThe upper line plots of Figure 5 and Figure 6 show the results for the ISCED-based candidate standard variables. In line with Table 4 and Figure 4, among the ISCED-based candidate standard variables, the maximum versions showed the highest validity. In the ten most empirically relevant validation variables, all maximum versions lost no more than up to approximately 10% of the explanatory power relative to the benchmark variable. In contrast, in the top 11 to 20 validation variables, all maximum versions lost already up to 30%, resulting from a rather low performance of I\\_Max2 and I\\_Max1 when predicting gender role and anti-immigrant attitudes and political self-efficacy. I\\_Max3 with the highest number of categories (i.e., 19) showed the highest validity for almost all the top 20 validation variables. The ISCED-based intermediate versions I\\_Int1 and I\\_Int2 showed a greater dispersion along the y-axis of both the top 10 and the top 11 to 20 validation variables, with the loss of information compared to the benchmark variable ranging between approximately 5 and 45%. Thus, the validity of I\\_Int1 and I\\_Int2 depended more strongly on the specific validation variable (i.e., 'research topic') than this was the case for the maximum versions. For example, while both I\\_Int1 and I\\_Int2 worked well for income variables (di07 and di08), I\\_Int2 and especially I\\_Int1 performed poorly in the explanation of some social and political attitudes (e.g., anti-immigrant attitudes, px06 and pa19, or stronger punishments for criminals, pa14). While the Kernel density plots have already suggested such a pattern across the full range of validation variables, the line plots show that it also applies to the subset of the empirically most relevant validation variables. Compared to I\\_Int1 and I\\_Int2, I\\_Int3 showed higher validity and higher clustering across both the top 10 and top 11 to 20 validation variables (i.e., loss in explanatory power ranged between approximately 5 and 20%), comparable to I\\_Max1. I\\_Min showed the poorest performance with an information loss ranging from approximately 30% to 60% compared to the benchmark variable.\n\nThe lower line plots of Figure 5 and Figure 6 show the results for the CASMIN-based candidate standard education variables. The maximum version and both intermediate versions showed a loss in explanatory power of only approximately 5 to 15% relative to the benchmark variable in 18 of the top 20 validation variables. Only the minimum version lost between approximately 15 and 40% of explanatory power across all top 20 validation variables and depended more strongly on the research topic: While C\\_Min showed a comparatively high validity for objective (though self-reported) social indices like own or spouses' Standard International Occupational Prestige Scale (SIOPS, Treiman, 1977) and ISEI, its validity was smaller, amongst others, for some social and political attitudes (e.g., pa19: Stopping the immigration of refugees, or pa23: Left-right party rating of the Christian Social Union in Bavaria).\n\nComparing ISCED- and CASMIN-based candidate variables shows that, except for the ISCED-based I\\_Max3 (which adds CASMIN-specific distinctions to detailed ISCED), CASMIN-based candidates clustered more strongly and further up on the y-axis across the top 20 validation variables compared to ISCED-based candidates. This applied especially to the top 11 to 20 validation variables (i.e., Figure\n\n6) that mainly represent subjective outcomes of education, such as attitudes and perceptions (in addition to those mentioned above, for example, J006: Man earns money, woman does housework, and pt02: Trust: Federal Constitutional Court). Two variables that are notably better predicted by the ISCED- than the CASMIN-based maximum and intermediate candidate standard education variables (except I\\_Int3) are personal income (inc) and whether the respondent well copes on the current income (S16\\_1), while per capita (di07) and equivalised incomes (di08) are well predicted by all candidates except both minimum versions. Regarding the minimum versions, the  dispersion ' pattern' for I\\_Min and C\\_Min is roughly the same, while the relative pa R 2 s tended to be higher for C\\_Min than for I\\_Min.\n\n<!-- image -->\n\noccupation, Validation variables in descending order of the benchmark education variable 's paR 2 : isei08c : ISEI combined (c): Current and past occupation, siops08c : SIOPS combined (c): current and former isei08scp : ISEI current spouse or partner (scp), iscd11scp : ISCED current spouse or partner (scp), siops08scp : SIOPS current spouse or partner (scp), inc : R.: Monthly net income -open+closed, pa14 : Stiffer sentences for offenders, di08 : Equivalent income OECD-modified scale, px06 : Dangerously many immigrants in Germany, di07 : Per capita income, net monthly.\n\nFigure 6: Loss in explanatory power in the 11 th  to 20th most empirically relevant validation variables\n\n<!-- image -->\n\nValidation variables in descending order of the benchmark education variable's paR 2 : pa19 : Stopping the immigration of refugees, pa02a : Political interest (ordinal), hhinc : Monthly net household income -open+closed Q., pa32 : Political compromise is a betrayal of principles, J006 : Man earns money, woman does housework, I006 : Have no influence on the government, id03 : Top-bottom-scale: selfclassification, pa23 : Left-right party assessment: CSU, pt02 : Trust: Federal Constitutional Court, S16\\_1 : Making ends meet with household income\n\n\n## 5 Summary, conclusions, and recommendations\n\n\nThis paper empirically evaluated the validity of eleven candidate standard education variables for output harmonisation across German surveys relative to the most detailed variable that could be constructed using ALLBUS 2018 data. Results show, firstly, that, on average across a wide range of potential dependent variables, the CASMIN education scheme outperforms ISCED when coded at a comparable level of detail (C\\_Int1 and C\\_Int2 vs I\\_Max1 with nine categories each) by six percentage points. Secondly, the detailed CASMIN variable with eleven categories (C\\_Max) has a higher validity (75%) than the already enriched ISCED variable used in the European Social Survey since 2010 with 15 categories (I\\_Max2, 72%). For German data, ISCED is, therefore, less valid, and less efficient than CASMIN. Given the highly stratified structure of the German secondary education system and the importance of the distinction between vocational and general education, these results are not surprising. Thirdly, the most highly performing candidate standard education variable (I\\_Max3) is one that combines the extended version of ISCED and CASMIN so that both, as well as the official ISCED, can be derived. This variable retains 77% of the explanatory power of the most detailed education variable, but it also has 19 categories when implemented in the ALLBUS and is rather complex to derive. Since 2% additional validity does not offer enough added value compared to CASMIN, such a combined variable should likely not become the German standard education variable.\n\nThe second-best candidate standard education variable is the maximum version of the CASMIN education scheme with eleven categories (C\\_Max), which distinguishes between the bachelor's and master's levels within 3a and 3b (not yet foreseen by Brauns et al., 2003), and retains 75% of explanatory power. This version of the CASMIN scheme is thus recommended as the basis of a German standard education variable. Using the somewhat simpler Brauns et al. (2003) version for Germany (C\\_Int1), which is already widely used nationally and internationally in academic research, is fine, too, as long as master's degrees at universities of applied sciences as well as bachelor's degrees at universities remain small highest attainment categories. This may change as younger cohorts with more of these recently introduced qualifications replace older cohorts which could not yet obtain these qualifications. This variable is, however, inferior to the maximum and alternative intermediate versions (C\\_Max and C\\_Int2) and ISCED when analysing income-related variables. The overall good performance of C\\_Max and C\\_Int1 is in stark contrast to the fact that currently, only a few surveys in Germany offer derived CASMIN variables in their data sets. Our findings call for surveys and research data centres to reconsider this omission. A hierarchical coding system was developed to facilitate and standardise such efforts across surveys, and is presented in Appendix 2.\n\nFor many surveys or data users, it may be necessary to be able to derive ISCED to achieve comparability with data from official statistics, which exclusively use ISCED (albeit in various different versions, Schneider &amp; Urban, 2024, under review). Our results lead us to strongly recommend implementing at least the two-digit version of ISCED (I\\_Max1), distinguishing general from vocational qualifications in addition to ISCED main levels, rather than main levels only. Only GEDA currently does so. All other surveys offering ISCED offer the first digit (main levels) only, which has been shown in this paper to be of very limited validity, losing almost half of the explanatory power of the benchmark variable ( while I\\_Max1 'only' loses a third ). It would be even better to implement all three digits of ISCED or the extended ISCED variable used in the ESS since 2010 ( I\\_Max2 or, in the ESS, edulvlb ), which, with a retained explanatory power of 72%, is still substantially superior to the official two-digit ISCED I\\_Max1. From I\\_Max2, it is also possible to derive the rather well-performing ES-ISCED (I\\_Int3), and the various ISCED implementations used in European official surveys. Ideally, therefore, surveys should offer both detailed ISCED as well as CASMIN as separate standard education variables.\n\nIt is also noteworthy that no candidate standard education variable works best across all validation variables. Researchers may thus consult ESM 2 and 3 (output as html files) to check which education variable is most valid for the type of outcome they wish to analyse.\n\n",
         "In German surveys, educational attainment is measured with two questionnaire items, the first referring to the highest general school-leaving qualification, and the second referring to the highest vocational qualification or higher education degree obtained. For analysis, information from both items is usually combined into one variable. There is currently no standard way for doing so, hindering comparisons across studies and the aggregation of research data across data sources. This paper presents the results of a large-scale validation of several candidates for a German standard education variable. The candidates are based on the official International Standard Classification of Education (ISCED) and the academic CASMIN education coding scheme originating in comparative social stratification research, which are both commonly used in Germany even in non-comparative research. The validation uses ALLBUS 2018 data and a data-driven selection of 157 linear validation (dependent) variables. Candidate standard education variables that retain a higher relative explanatory power across validation variables than the most detailed education variable in linear multiple regression models are regarded as more valid than candidates showing larger losses of explanatory power. Results clearly point to the superiority of CASMIN compared to ISCED when predicting a wide range of outcomes. Only for a few dependent variables, ISCED performs better, and only if it is measured in a more detailed fashion than the official way by accounting for specificities of the German educational system. Most survey data sets, however, only offer a derived ISCED variable reflecting main levels. The commonly used aggregation into three broad education levels loses, on average, half the explanatory power of the detailed benchmark, irrespective of whether it is derived from ISCED or CASMIN. Thus, studies controlling for education with just three categories may risk non-measured education effects to bias effects of other variables in the model.",
         ""
        ],
        [
         "29",
         "29",
         "## 1. Introduction\n\n\n\n## 1.1 Background to the study\n\n\nTranslation  is  defined  as  \"an  attempt  to  replace  a  written  message  and/or statement in one language  by  the same  message  and/or  statement in another \"(Newmark,  1988a,  p.  7). There  are  different  types  of  translation,  one  of  which  is literary translation, which is concerned with rendering a literary text from one language to another. Literary translation is different from other types of translation: 'A literary translation must reflect the imaginative, intellectual, and intuitive writing of the author. In fact, literature is distinguished by its aesthetics. Little concern has been devoted to the aesthetics of literary translation because these translations are probably perceived as unoriginal' (Devy, 1999, p. 183).\n\nOne of the most complicated literary texts in English to translate is the famous work Ulysses by James Joyce. Ulysses is one of the most prominent works of literature of the 20th century. According to Wang (2011), Ulysses is the most creative work of fiction of its age, regarded by critics as a kaleidoscope of style. It is a paradigm of the art of modernity that is analogous to the narrative construction of Homer's Odyssey . It is  considered  one  of  the  first  works  in  modernist  literature  to  adopt  the  stream  of consciousness narrative style. In Ulysses , Joyce expresses 'his deep hatred for religious hypocrisy and colonizing oppressions,' alongside a 'well-masked patriotism' for his nation (Wang, 2011).\n\nThus, the present paper draws attention to the different strategies employed by Arabic  translator  to  render  word  formation  in  English  to  Arabic  translations  of  this novel.\n\n\n## 1.2 Problem Statement\n\n\nIt  is  possible  to  determine  the  sources  of  loss  in  translation.  One  of  these sources, as Newmark (1988a) suggests, is in the author's way of using language and their writing style. He claimed that 'the individual uses of language of the text-writer and the translator do not coincide' (Newmark, 1988a, p. 8). The present study provides a thorough dissection of a key issue in translating the English novel Ulysses into the Arabic  language,  which  is  word  formation  in  English.  Plag  (2003)  defined  word formation as the ways in which new, complex words are built on the basis of other words or morphemes. The present study focuses on the techniques that are used by an Arabic translator for the purpose of creating a style close to that of Joyce.\n\n\n## 1.3 Aims and Objectives of the Study\n\n\nThe main aim of the study is to identify the translation techniques that are used by an Arabic translator to render neologisms in Ulysses from English into Arabic. Its secondary aim is to analyze these techniques. The objectives of this paper are therefore as follows:\n\n- 1To analyze an Arabic translation of Ulysses and investigate the techniques used by Taha Mahmoud Taha to translate words created by Joyce.\n- 2To analyze the translator's applied techniques and evaluate their accuracy.\n\n\n## 1.4 Research Questions\n\n\nThe study attempts to answer the following questions:\n\n- 1. Does the Arabic translator apply the Venuti model in his translation? And which other strategies does he use?\n- 2. Does the Arabic translator succeed in translating Joyce's neologisms?\n\n\n## 2. Literature Review\n\n\nA translator may encounter a number of difficult issues in a text. According to Newmark (1988), neologisms are a translator's greatest challenge despite them being a professional. 'Neologism' refers to a new word or a new meaning for an existing word. According to Webster's New World Dictionary, a neologism is a new word or a new meaning for an established word; or the use of, or the practice of creating, new words or new meanings for established words. It is essential for a translator to tackle with new words. There are numbers of word-formation processes in English language such as blended, compounding, borrowing, and etc.\n\nOne of the most important studies on translating new words in literary work is  that  of  Kotliński  (2004),  who  investigated  equivalence  in  Maciej  Słomczyński's translation of word formations in Joyce's Ulysses . The paper indicates both structural and cultural differences between English and Polish, and the use of formal and dynamic equivalence in the translation. The analysis addresses some word formations in Ulysses . Kotliński focuses on the processes of compounding and conversion, and concludes that the Polish translator employs formal and dynamic equivalence, and some omission.\n\nNaugolnykh  (2015)  presented  a  paper  on  neologisms  as  one  of  the  main  literary devices employed in Joyce's Ulysses .  It  outlines  various  techniques used  in Russian and German translations. A comparative analysis of the original text and its Russian and German counterparts allowed the researcher to find some regularity in the selection of translation  methods and to discover the relationship between these choices in the translators' language and the complexity of devices used by Joyce. The author found that some of Joyce's symbols are lost in the target texts. The study concludes that if the author found that some symbols (or symbolism) is lost, which suggests that translators do not always use the appropriate tools.\n\nFrancisco García Tortosa and María Luisa Venegas Lagüéns published the third  Spanish  translation  of Ulysses in  1999.  They  were  interviewed  in  2018.  The interview's goal was to both highlight the translation process of the work and recognize the  significance  of  retranslations  within  the  context  of  cultural  and  literary  change. Lagüéns addressed the process of translating compound words, explaining that she tries to  think  like  Joyce  by  translating  these  compound  words  and  making  them  sound musical, like they do in English. Lagüéns outlined the method and strategies she and Tortosa  applied  in  the  third  translation,  stating  that  she  prefers  domestication  in translation. They aimed for her translation to resemble the Spanish of the start of the 20th century. However,  on  some  occasions, the translators attempted to use foreignization to provide a foreign flavor. Tortosa stated that they applied a specific interpretation of the source text (ST) in the target text (TT), and indicated that their translation leans towards domestication.\n\nTaha Mahmoud Taha stated in an interview that he used to spend days searching for a translation of single Joycean expressions. This paper aims to discover the methods used  by  the  Arabic  translator  in  rendering  a  selection  of  linguistically  challenging examples.\n\n\n## 3. Methodology\n\n\nThis  is  a  descriptive-qualitative  study  that  is  concerned  with  an  analytical examination of the strategies associated with translating English portmanteaus in the novel Ulysses (1922)  into Arabic. Thus, data  for this  study were obtained  from one source: Ulysses by Joyce. The data were gathered by analyzing the Arabic translation ( عوليس 1968) by Taha Mahmoud Taha.\n\nThis novel was chosen because it contains many instances of word formation. Thus, it is a rich source of the kind of data needed for this study. The current study will attempt to analyze the obtained  data (i.e., on borrowing,  coinage,  derivation, conversion, and compound words) from a translational perspective. The analysis will concentrate on the meaning and nuance of Joyce's original words. Appropriately, the data  analysis  will  be  presented  as  follows  in  this  study:  first, the  new  word  will  be presented in a table showing the ST and TT, followed by the discussion.\n\n\n## 4. Theoretical Framework of the Analysis\n\n\nThe study looks at some of the theoretical and implementational issues involved in translating formality in language. The translation model of Venuti is applicable to the TT.\n\n\n## 4.1 Venuti Model\n\n\nThe  American  translation  theorist  Lawrence  Venuti  (1995)  was  the  first  to introduce the translation strategies of domestication and foreignization in the translation field.  He  provides  these  two  major  translation  strategies  with  linguistic  and  cultural orientations. Venuti defines domestication as 'an ethnocentric reduction of the foreign text to target-language cultural values, bringing the author back home,'  and foreignization  as  'an  ethnodeviant  pressure  on  those  cultural  values  to  register  the linguistic and cultural difference of the foreign text, sending the reader abroad' (Venuti, 1995,  p.  20).  Specifically,  domestication  is  designed  to  minimize  the  oddities  and foreign  aspects  of  the  ST  for  target  readers.  In  contrast,  foreignization  keeps  the strangeness of the ST. The choice of domestication or foreignization is not only made by the translator, but more importantly, is also dictated by specific social situations and cultural traditions (Wang, 2013).\n\nVenuti,  in  his  work The  Translator's  Invisibility:  A  History  of  Translation (1995), classified foreignization as ST-oriented translation and domestication as TToriented translation.\n\n\n## 4.1.1 Foreignization\n\n\nThe  principle  of  the  foreignization  strategy  is  preferred  by  some  translation theorists, including Venuti himself. He highly favors this strategy for two reasons. The first is that 'foreignization translation in English can be a form of resistance against ethnocentrism  and  racism,  cultural  narcissism  and  imperialism,  in  the  interests  of democratic geopolitical relations' (Venuti,  1995:20). The second  is that he respects others' cultures and the struggle for cultural equality. The translated text should reflect another culture to the reader. The philosopher and theologian Friedrich Schleiermacher was the first to introduce the foreignization strategy to German culture. He claimed that the  translator  should  keep  and  maintain  the  strangeness  of  the  ST  and  present  the linguistic  and  cultural  otherness  of  the  ST  to  the  target  reader.  Simply  put,  he emphasized  that  the  translation  process  should  be  ST-oriented.  There  are  several advantages of foreignization in translation. The receiver of the target language (TL) 'can  perceive  the  culture  of  the  source  language'  (SL)  and,  consequently,  the  TT provides the receiver with 'the cultural nuance of the source language' (Prasetyo &amp; Nugroho, 2013).\n\n\n## 4.1.2. Domestication\n\n\nVenuti's  preference  for  foreignization  in  translation  has  been  criticized  by scholars  such  Eugene  Nida.  Nida  (1964)  supported  the  domestication  method  and claimed that the language of the ST should not overlap with the language of the TT. Nida strongly encouraged translators to produce a similar response in the TT to that of the ST. He viewed an accurate translation as one where the TT reflects a similar culture to that of the receivers, and he perceived a successful piece of translation to be when the  translator  follows  a  target-oriented  approach.  There  are  several  advantages  to domestication  in  translation.  For  example,  the  receiver  of  the  target  language  'can easily understand the translated text' and, consequently, the TT sounds 'natural and communicative' (Prasetyo &amp; Nugroho, 2013).\n\nThus, this paper  is  concerned  with  whether  the  translator  applies  the  Venuti model in translating word formations into Arabic.\n\n\n## 5. Data Analysis\n\n\nThis section provides an analysis of four types of word formation that frequently occur in Ulysses . It also investigates the strategies used by the Arabic translator Taha Mahmoud Taha when dealing with these types of word formation. In addition to the data  analysis  of  the  applied  translation  strategies,  this  section  also  presents  a  brief discussion  of  the  technical,  linguistic,  and  cultural  factors  that  may  affect  these techniques.  Each  type  of  word  formation  is  discussed  alongside  several  illustrative examples.\n\n\n## 5.1Borrowing\n\n\nBorrowing, or loaning, refers to the adaptation of a word from one language to another. It is a common linguistic feature in which the target language introduces a new form to its own lexicon by borrowing from another. The vocabulary of English has been influenced by loanwords throughout history.\n\nA translator may face problems when translating using the borrowing technique. They  may  be  unsure  about  which  strategy  best  suits  loanwords.  According  to Thawabteh  (2014),  'translators,  or  translation  tutors,  or  translator  trainers  need  to handle borrowing the best way possible to reach natural translation.'\n\nA number of words in English  have Greek and  Latin roots. There are many reasons for using loanwords. One of them is for art purposes. In Example 1, Joyce uses a Latin word, spoken by his protagonist Stephen Dedalus.\n\n## Example1:\n\nThe word ' honorificabilitudinitatibus' refers to 'the state of being able to achieve honours' (Definitions.net). According to World Wide Words, Joyce borrowed it from Shakespeare, 'who in turn borrowed it from Latin .' The translator renders this word as ' فيحالكونهمسبغنبالنعم .' The translator misspells the word to resemble the long form of the foreign expression, meaning ' في حال كونه مسبغن بالنعم .' First, he adds ' ن ' instead of using nunnation, then he joins the words rather spelling them out correctly. The Arabic translator applies Vinay and Darbelnet's calque technique. The calque technique is the transformation of a SL phrase or structure into the TL ( Munday, 2016). The translator imitates  Joyce's  style  by  extending  the  form  of  the  Arabic  language  to  look  like  a foreign expression.\n\n\n## 5.2Coinage\n\n\nThe  word  formation  process of  coinage  refers  to  the  creation  of  new  words without using the other word-forming processes, whether intentionally or unintentionally. Simply, it is the process of inventing or coining a new word to signify a new object or concept. According to Yule (2010), coinage is one of the least common processes of word formation in English. However, it is seen in modern literary works.\n\nJoyce's  novel  follows  a  'stream  of  consciousness'  style.  This  term  refers  to what was then a new technique and style in writing. According to Aminjonov et al. (2018), experimental fiction that uses this technique breaks the law of literature and language. In Ulysses , language experiments are presented through new  word formations.  This  feature  can  be  seen  continuously  in  Joyce's  work.  'In  most  cases coinage words in the novel are formed in direct combining of words are concluded as contradicting to syntactic structure of English, but their semantic cognitive expression can show their trustworthy notion' (ibid.). Simply put, in Ulysses , Joyce coins words by compounding two words in false order. For instance, example 3 may follow a N + Adj structure. Examples 2 and 3 show this.\n\n## Example2:\n\nExample 2 shows 'noserag,' coined by Joyce, where he joins two words to form one. It refers to a rag for your nose, or a handkerchief (Collins Dictionary). In this case, the speaker asks for the rag to clean his razor. The translator renders this term into ' خرقة '.مخطمك He uses literal translation for the correct order of the words (rag for nose). The translator presents the term to the audience formally and uses neither domestication nor foreignization.\n\n## Example 3:\n\nExample 3 shows a coined word. Here, Joyce uses 'snotgreen' to describe a new, revivalist direction of Irish poetry. In the last two decades of the 19th century and the first two of 20th century, the Irish Literary Revival was a phenomenon in Ireland. Joyce calls  this  nationalistic  cultural  movement the  Irish  Renaissance.  According  to  Joyce Project  Online  (2011),  during  this  period,  non-governmental  organizations  not  only supported new Irish writing, but also helped revive the language and culture of the past. Moreover,  Ireland's  millennial  has  a  connection  with  the  color  green,  which  Joyce refers to as snot.\n\nThe translator uses literal translation to render this term. He translates  it into '.مخاطى  اللازوردي' His  translation  of  the  first  part,  'snot,'  retains  Joyce's  mocking metaphor. However, he does not maintain the explicit meaning of green, which is the color associated with the new movement. He translates it into ' ',لازوردي which is 'the blue color of the clear sky' (Merriam-Webster.com).\n\nThis process resembles conversion in its changing of a word category to create a new word. The difference is that derivation requires the addition of other units. These new words are created by using several small units of the English language 'which are not usually given separated listings in dictionaries and called affixes' (Anora, 2020). A word that an affix must be attached to is called a 'root, stem, or base' (Plag, 2018). Leminen et al. (2019) define derivational morphology as the way a new entity is created by combining a base with affixes (e.g., suffixes and prefixes). A prefix is a unit that attaches to the beginning of a root and a suffix is a unit that attaches to the end of a root (Yule, 2010). Anora (2020) categorizes suffixes into nominal suffixes, verbal suffixes, adjectival  suffixes,  and  adverbial  suffixes.  Each  type  refers  to  a  different  change  in word category. Joyce uses this process in his work, as shown below.\n\n## Example 4:\n\nIn Example  4,  the narrative describes the action and manner  of two unfashionable women coming to the sand from Dedalus own perspective. An adverbial extension  of  'lourdly'  (adj.)  is  from  the  French  'lourd,'  meaning  'heavy.'  The translator omits the adverb and leaves it untranslated. However, the translator could have translated  it  using  domestication  into  ' '.تؤرجح  الحقيبة  بعفاشة Moreover, he could have used functional translation and translated it into ' '.تؤرجح الحقيبة بغلاظة A functional equivalent is the usage of a 'cultural neutral word' (Newmark, 1998). Newmark also states that these words can be replaced by a functional or generic term if they are not well known in the target culture.\n\n\n## 5.3 Compounding\n\n\nCompounding is the process of joining two or more words together to create a new meaning. According to Yule (2010), it is very common in languages like English. Joyce applies this technique in his works continuously to create new meanings. The two examples below illustrate this.\n\n## Example 5:\n\nThis example mocks theosophy. In this scene, Dedalus expresses his thoughts on  the  Theosophical  Society  in  a  comic  manner.  According  to  Sutcliffe  (2006), Mulligan's presence in the scene is evidence of the failed attempt (based on historical fact) to benefit from the heist of the Ur-book of Theosophy.\n\n'Yogibogeybox' has been defined as a room or place in which spiritualism is practiced  or  studied  (Lexico.com).  Peters  (2015) indicates  that the  Oxford  English Dictionary defines this term as the paraphernalia of a spiritualist. 'Yogibogeybox' is a compound of 'yogi' + 'bogey' + 'box.' Joyce applies two processes to form it: first compounding, then coinage. While box can refer to a room or 'container, Yogj means an acetic and + bogey means the devil' (James Joyce Online). Its context may suggest that Joyce uses this term to compare where meetings are held in society with a hall that conjures devils associated with Sufi practices.\n\nThe translator translates it into ' '.حجرجينولوجى He translates 'box' using literal translation and uses naturalization in translating ' '.جينولوجي Naturalization adapts the SL word to the normal pronunciation of the TL (Newmark, 1988b, p. 82).\n\nIn this example, the translator keeps the foreign term without explanation or domestication.\n\n## Example 6:\n\nIn  the  past,  people  did  not  believe  that  Adam  and  Eve  had  navels. Consequently, Michelangelo was accused of heresy for giving a belly button to Adam in  the  Sistine  Chapel  (Joyce  Project  Online,  2015).  In  Example  6,  Dedalus  uses 'whiteheaped' to modify 'corn', which functions as a metaphor for a navel.' According to James Joyce Online Notes, 'whiteheaped' is an adjective formed from 'white' and 'heap.'\n\nThe  translator  uses  ' 'ص برة  بر  ناصع to  translate  'whiteheaped  corn.'  He  uses literal  translation  to  translate  'heap,'  ignoring  its  contextual  meaning,  which  is  not precisely  a  heap,  but  a  small  grain  that  resembles  the  navel.  He  uses  functional equivalence for the first part, 'white,' and renders it into ' '.ناصع The translator thus fails to create a metaphor for the navel.\n\n\n## 5.4 Blending\n\n\nBlending  is, like compounding,  concerned  with  creating  new  words  by combining two or more separate words. However, blending 'is typically accomplished by taking only the beginning of one word and joining it to the end of the other word' (Yule, 2010). Joyce is famous for this process, especially in his long coined words, as shown below.\n\n## Example7:\n\nAccording to the Word Sense online dictionary, this word, coined by Joyce, is blend\n\n'Jew,'  'bang,'  and  '-ity';  perhaps  modelled  on  'transmagnificandubandanciality,' which is a nonsense word with no intelligible meaning. In contrast, Urban Dictionary provides a detailed meaning of this blended item. Urban dictionary suggests a meaning for each part of this word, as presented in Note  . 1\n\nThe Arabic translator translates this word into ' ',لبنمعلربزم which means nothing according to dictionaries and online sources. Here, he tries to create new word, like Joyce, but he fails because his translation does not appear in any dictionaries.\n\n\n## 6.Results and Discussion\n\n\nThe present analysis isolates four major problems relevant to translating new English words into Arabic: (1) some  neologisms, both words and expressions, have been dropped in translation, as shown in Example 4; (2) in the translation of certain new  words,  there  is  a  considerable  loss  of  the  sense  of  the  creativity  of  Joycean language; (3) the translator tries to imitate and coin new words in Arabic like Joyce but produces meaningless words, as shown in Examples 1 and 7; and (4) in this analysis, the translator does not use the Venuti model to translate neologisms.\n\nThe present analysis shows that four translation strategies were adopted by the translator: literal translation, omission, naturalization, and functional translation.\n\nTherefore, the translator does not rely on the Venuti model; he uses Newmark's strategies  to translate  new  words. The  Venuti  model  could  have  been  used  in  some cases, as suggested for Example 4. However, it fails in some contexts. Newmark (1988) suggests  some  procedures  for  each  category  of  neologism.  He  approaches  the translation  either  by  using  a  word that  already  exists  in  the  TL, or  by  using  a  brief functional or descriptive term to reuse old words and imbue them with new meanings.\n\n\n## 7. Conclusion\n\n\nLiterary translation is one of the most complex types of translation because the writer may use new words in their language to reflect their creativity. A significant feature in Joyce's Ulysses is  the  usage  of  new  English  words.  This  paper  studies  the  Arabic translation عوليس and draws attention to whether the translator uses the Venuti model or not. The analysis shows that the translation of the Arabic version does not regularly use one model. The translator is not consistent in his choice and application of methods. He uses Newmark's translation and the Vinay and Darbelnet's model. In addition, he tries to imitate Joyce's style especially through coinage. However, in most cases, he fails to present new senses of words as Joyce does. Moreover, in some cases, he presents Arabic words without any sense or meaning in an attempt to create new words like Joyce. He does not use domestication in translating neologisms. Word formation needs more flexible strategies to render the sense and meaning of the original text to the target audience. Much analysis is needed to support this study.\n\n",
         "The present study investigates strategies for translating word formation in Ulysses (1922) by James Joyce. The study also identifies the translation strategies used by an Arabic translator to render neologisms in the novel into the target language. The study draws on the Venuti model of translation. Applying the Venuti model to the translations of word formations into Arabic will test their adequacy. Different new words resulting from the word formation process were used in the selected data. The findings show that these new words were translated into Arabic using different strategies. The Arabic translator used literal translation in many cases of word formation due to the lack of similar equivalent words in the target language. The study shows that the Arabic translator tries to imitate Joyce by coining words in Arabic. The study should be continued in further analyses that use other data to prove that the Venuti model is not sufficient for translating this type of literary text.",
         ""
        ],
        [
         "30",
         "30",
         "## 1. The historical background of Seoul in the post-war period\n\n\nThe population of Seoul, the capital city of South Korea, was around 1 million in 1953 right after the Korean War (Han &amp; Kang, 2016). This grew to 2.45 million, which was an increase around 1.5 million just in 7 years (Kang, 2015). Urbanisation had accelerated due to the explosion of population without proper preparation or planning (Kang, 2015; Han &amp; Kang, 2016; Kim, 2020). Therefore, the quality of life in the city had become significantly poor and new slum areas were formed as a result (Han &amp; Kang, 2016). Moreover, urban sprawl had occurred regardless of the city centre or suburban area (Kwon, 2012; Kang, 2015). The unplanned urbanisation had continued without order (Son, 2002; Kim, 2020). This encroached on mountain, river, public area and even road networks, occupied by the illegal residents from the extended slums (Kang, 2015).\n\nThe problems such as lack of housing and poor quality of house were very serious in all districts of the city (Kang, 2015). The number of officially registered house property was only around a half of the total households and, at least, one third of houses was illegal housing or  shanty  (Son, 2002; ' ' Kwon, 2012; Han &amp; Kang, 2016). Dirty water or polluted sewage were discharged to the natural streams and caused hygiene problems (Kang, 2015). The water service facility, including tap water, was officially calculated 56% installation rate but even this figure included the part time distribution of water (Kang, 2015). The road rate within the city was counted only 8% (Kang, 2015). Hence, the commuting time was longer than 2 hours, despite the size of Seoul was only 16km between the west end and the east end (Figure 1; Kwon, 2012).\n\nThe infrastructure of school and educational facility was not enough to accept enrolment of pupils and students in the school age population (Kang, 2015; Kim, 2020). A lot of temporary schools were built,  made by tent to host students (Kim, 2020). However, this measure was not enough, even though morning school and afternoon school were separated to accommodate as many students as possible (Kwon, 2012; Kang, 2015; Kim, 2020). Many citizens were unemployed, roamed around streets and exposed to crimes (Kim, 2020). The overall condition of Seoul was undoubtedly terrible by the end of 1950s (Kwon, 2012; Kang, 2015).\n\nFigure 1. Seoul in 1965. Seoul was  full  (Han &amp; Kang, 2016). ' '\n\n<!-- image -->\n\nThe  metropolitan  government  of  Seoul  ( Seoul  City )  had  to  promote  a  series  of  consecutive ' ' development  and  renovation  practice  on  the  existing  facilities  to  accommodate  the  increasing population (Kwon, 2012). Based on the urban centre and established buildings, new facilities were urgently constructed as an emergency supply of urban infrastructure for temporary purposes (Han &amp;  Kang,  2016).  However,  such  stopgap  measures  were  not  suitable  to  solve  the  serious consequences from the explosion of population (Kwon, 2012; Han &amp; Kang 2016). For example, around 0.3 million population increased in Seoul per year during the 1960s (Kang, 2015). Therefore, at  least  50,000  housing  (assuming  6  people  per  family)  had  to  be  supplied  within  the  city  or suburban area (Kang, 2015). However, the stopgap measures were sufficient only for a few thousand households (Kang, 2015), whereas others were driven to poverty below minimum standard of living (Kim, 2008; Kim et al., 2009; Kwon, 2012). Hence, Seoul City realised the necessity of a large-scale development plan to create a new urban area (Kang, 2015; Kim, 2020).\n\n\n## 2. Theoretical frameworks\n\n\nA long-term developmental policy requires appropriate exchange of opinions to discuss directions of  spatial  development  between  authorities,  firms  and  residents  (European  Commission,  2009). Especially for a development of large-scale metropolitan city, a series of rational and reasonable discussions are supposed to be preceded before beginning of the first construction (Ross &amp; Leigh 2000; European Commission, 2009).\n\nRational planning, also known as comprehensive planning, approaches development by solutionbased (in the order of definition, identification, evaluation, implementation and monitoring) models to  design  and  execute  urban  development  (Taylor,  1998;  Ross  &amp;  Leigh,  2000).  Planning  should contain rational actions in each stage to assess alternative actions and possible outcomes (Taylor, 1998). Specific objectives and methods are supposed to be identified to achieve the overall goal of development  through  rigorous  assessments  (Ross  &amp;  Leigh,  2000).  It  is  possible  that  there  are numerous alternatives while selection procedure of planning is based on effectiveness to accomplish the pre-selected object and continuous reviews (Taylor, 1998; Ross &amp; Leigh, 2000).\n\nHowever, Lindblom (1959) argued that rational planning tends to be excessively simplified and, thus, not realistic to deal with on-site developmental problems. Many realistic problems are expected when pre-discussed plans are ruled out but do not accommodate reality in the developmental scene (Migone  &amp;  Howlett,  2015).  Problems  such  as  economic  crisis,  shortage  of  cash  flow  or  spatial miscalculation may hinder developmental process or cause social challenges (Fainstein &amp; Markusen, 1992;  European  Commission,  2009),  although  rational  planning  would  have  already ' rationally ' considered such issues beforehand (Lindblom, 1959).\n\nAlternatively,  incremental  planning  suggests  that  recognition  of  new  changes  in  response  to immediate circumstance (Mier, 1994), allowing flexible modification of details within the framework of original planning (Mier, 1994; Ross &amp; Leigh, 2000). Advocacy planning focuses on democratic process  of  collecting  opinions  from  under-represented  groups  within  society  (Davidoff,  1965), assuming further acquiring available information and technical issues (Mier, 1994), thus planners try to represent the benefits of various groups (Davidoff, 1965).\n\nHowever,  not  all  groups  within  society  have  equal  influence  over  decision-making  process  of planning (Lindblom, 1959; Migone &amp; Howlett, 2015). According to Oppenheim (1978), power is exercised to respondents by coercion of power by powerholders. The higher the power, the more authority and information are available before determination of urban developmental policy due to information  asymmetry  (Lindblom,  1959;  Sergiu,  2010;  Lambert et al., 2012). This makes powerholders to force the procedure of urban developmental policy according to their own interest rather than the benefit of all groups in society (Oppenheim, 1978; Lambert et al., 2012), whereas citizens without power tend to be neglected and oppressed by institutions (Sergiu, 2010).\n\n\n## 3. The Gangnam development plan -the core of the population measure in Seoul\n\n\nThe eminent problem was the population density per area in Seoul (Han &amp; Kang, 2016). There were too many people in Seoul compared to the available land resources and infrastructure (Son, 2002; Kim, 2008). Seoul City considered to expand the metropolitan area to the northern direction as this region  had  traditionally  developed  cities  (Jeon  et  al.,  2008).  However,  the  central  government approached this development plan from a military point of view (Jeon et al., 2008; Kwon, 2012). The northernmost part of Seoul is just around 40 km away from the Military Demarcation Line against North Korea since the end of the Korean War in 1953 (Graham, 1991; Han &amp; Kang, 2016). Meanwhile, excessively numerous populations and national facilities were centred in Seoul (Kang, 2015; Han &amp; Kang, 2016).\n\nThe central government, established and maintained by military dictatorship from 1961 to 1979, was particularly concerned with the potential outbreak of war against North Korea (Graham, 1991) and decided to intervene the development plan of the capital city (Kwon, 2012; Han &amp; Kang, 2016). In addition, South Korea was not able to afford another war against North Korea to retrieve the full capacity of the industrialised northern cities above Seoul (Graham, 1991; Kwon, 2012). Hence, the central government decided to expand Seoul by developing the southern region which had not been part of the traditional capital areas (Graham, 1991; Kang, 2015; Han &amp; Kang, 2016; Kim, 2020).\n\nThe development plan of the Seoul metropolitan area was a one-sided planning by Seoul City and the central government (Kang, 2015; Kim, 2020). Consultation with firms and residents was omitted in  the  process  of  planning  finalisation  (Kwon,  2012;  Kang,  2015;  Kim,  2020)  due  to  the  urgent implantation of development plan (Han &amp; Kang, 2016). In case of decision-making conflicts, the suggestions from Seoul City were overruled by the central government (Oppenheim, 1978; Taylor, 1998; Han &amp; Kang, 2016).\n\nOn the first day of January in 1963, the central government approved to change the administrative districts of Seoul to accept significantly large territories below Han River (Figure 2). This area was known as  Gangnam  which means  the south of the river  (Kang, 2015). In September 1966, Seoul ' ' ' ' City  requested  the  central  government  to  declare  Gangnam  as  a  special  district  for  land reorganisation in accordance with the development plan proposed by the National Department of Development (Kwon, 2012; Han &amp; Kang, 2016; Kim, 2020). However, other than the administrative approvals, there were not enough resources, both capital and labour, to advance the development of Gangnam and the expansion of the Seoul metropolitan area yet (Kwon, 2012; Kang, 2015; Han &amp; Kang, 2016; Kim, 2020).\n\nFigure 2. The commencement of the expansion of Seoul by integrating Gangnam (Kang, 2015)\n\n<!-- image -->\n\nIn February 1968, the Gangnam development had begun to build new urban and suburban areas, simultaneously with the inauguration for the construction of the first national highway (Graham, 1991; Son, 2002; Kwon, 2012). The size of Gangnam was finalised by doubling the traditional land size of Seoul (Figure 2). Seoul City initially planned to develop Gangnam district-by-district on a gradual scale (Kwon, 2012). However, the population increased far exceeding the capacity of the Seoul metropolitan area (Son, 2002; Kang, 2015; Han &amp; Kang, 2016). Thus, Seoul City and the central government decided to turn the  empty  Gangnam into a modern urban area as quickly as possible ' ' (Son, 2002; Kwon, 2012). Eventually, Gangnam has been transformed into a completely functioning modern city within two decades (Kang, 2015; Han &amp; Kang, 2016; Kim, 2020).\n\n\n## 4. The Gangnam development and the expansion of the Seoul metropolitan area\n\n\n\n## 4.1. The dissolution of shantytowns and civil resistance\n\n\nThe development of housing area was one of the core urban policies during the early 1960s in Seoul (Jeon et al., 2008; Kwon, 2012). There were many former farmers who moved to the Seoul metropolitan area and became  urban poor  due to the lack of economic foundation (Kim, 2008; ' ' Kim et al., 2009; Kwon, 2012). This was the main reason for the explosive increase of population and low quality of life in Seoul (Son, 2002; Kang, 2015; Han &amp; Kang, 2016). However, a lack of housing facilities and low income of labourers made them unable to afford the skyrocketed housing price (Korea City Institute, 1998; Jeon et al., 2008). As a result, some of them were driven to build  shanty ' ' nearby mountain, hill and riverside areas which were not occupied (Kim &amp; Ha, 1998; Son, 2002), formed widespread shantytowns in Seoul (Park et al., 2005; Kim et al., 2009).\n\nThese shantytowns were not able to co-exist with the development plan established by Seoul City for the reorganisation of urban space (Son, 2002; Jeon et al., 2008; Kim et al., 2009). Seoul City demolished shantytowns one-by-one at the beginning of the urban expansion (Kim &amp; Ha, 1998; Park et al., 2005; Kim, 2008). However, the compensation for the evictees was nothing or very little (Kim, 1999; Kim, 2008). Hence, new shantytowns were formed nearby the former shantytowns (Korea City Institute, 1998; Lim, 2015; Kim, 2019) and the size of the shantytowns in general was increased over time (Kim; 1999; Kim, 2008).\n\nThe  evictees  resisted  against  public  authorities  in  between  the  demolition  and  formation  of shantytowns  (Korea  City  Institute,  1998;  Kim,  1999).  However,  Seoul  City  and  other  regional governments  were  not  concerned  with  the  welfare  of  the  evictees  (Lim,  2015;  Kim,  2019)  but continued the demolition of the existing shantytowns to build modern buildings (Kim, 2019). Thus, the only choice of the evictees from the former shantytowns, who had become the residents of the new shantytowns, was to  fight by body  (Kim, 1999; Lim, 2015; Kim, 2019). ' '\n\nFigure 3. The civil uprising in Gwangju.  Is the parliament, our spokesperson, sleeping?  (Lim, 2015) ' '\n\n<!-- image -->\n\nIn August 1971, the residents in the Gwangju housing area uprose against Seoul City (Lim, 2015). They used to live in Seoul but were being evicted and moved to Gwangju (Korea City Institute, 1998; Kim, 2019). Seoul City promised them a new factory district for job security and low housing price (Lim, 2015; Kim, 2019) but there was no sign of building industrial facility and housing infrastructure (Kim, 2019) because this area was not part of the Gangnam development plan (Kang, 2015; Kim, 2019). Hence, the promise of Seoul City was proved to be empty words to evict the shantytown residents out of Seoul (Kim, 1999; Lim, 2015).\n\nUnder this unsteady circumstance, the residents in the Gwangju housing area received a tax bill for the land where they had been occupying (Lim, 2015; Kim, 2019), which had ignited the uprising (Figure 3; Kim, 2019). Policemen were sent to stop the uprising (Kim, 2019) but the residents quickly neutralised the police force and destroyed the police station (Lim, 2015). As they had begun to march toward Seoul, the mayor of Seoul immediately apologised and declared to turn Gwangju housing area into a new city (named  Seongnam ) with temporary tax exemptions (Lim, 2015; Kim, ' ' 2019).\n\nThe resistance of the evictees in Gwangju made Seoul City to modify the development plan (Jeon et al., 2008; Kim et al., 2009). Group struggles of evictees could potentially cause an overall social unrest (Korea City Institute, 1998; Kim, 2008). Therefore, Seoul City and the central government had begun to reconsider forced eviction and evaluate the economic ability of potential evictees before carrying out dissolution of shantytowns since the 1970s (Kim &amp; Ha, 1998; Jeon et al., 2008; Kim et al., 2009). In addition, 28 years after the Gwangju housing area incident, the constitutional court confirmed that land confiscation and eviction by public authority without consent of owner and resident is illegal in 1999 (Constitutional Court, 1999).\n\n\n## 4.2. The completion of the Gangnam development and thereafter\n\n\nSince the struggles of evictees continued and the history of resistance accumulated (Kim &amp; Ha, 1998; Jeon et al., 2008; Kim et al., 2009), residents in shantytown had grown more organised against the execution of the Gangnam development plan that could drive them away from where they lived (Korea City Institute, 1998; Kim, 1999; Han &amp; Kang, 2016). Thus, Seoul City had begun to reorganise the existing shantytowns (Jeon et al., 2008; Kim et al., 2009) and listen to the opinions of the private sector (Han &amp; Kang, 2016; Bae &amp; Joo, 2020). This was a win-win strategy for both Seoul City and construction companies because Seoul City tried to achieve efficient reorganisation of urban space (Kim et al., 2009) by granting more initiatives to construction companies (Jeon et al., 2008), whereas construction  companies  could  acquire  a  breakthrough  when  the  oversea  market  had  been recovering from the oil shock in the early 1970s (Seoul Museum of History, 2011; Han &amp; Kang, 2016).\n\nDuring the later stage of the Gangnam development, Seoul City showed a tendency to delegate major construction companies for both benefit and responsibility of urban development projects from planning to execution (Kim &amp; Ha, 1998; Son, 2002). In summary, the control of individual projects  was  granted  to  the  major  construction  companies  with  previous  record  of  completed construction during the early stage of the Gangnam development (Kim, 2008; Kim et al., 2009). Thereafter, this remains the mainstream development methodology in South Korea (Kim, 2008; Kim et al., 2009). This was a shift of policy from government-driven work process to privatisation (Son 2002; Jeon et al., 2008). Although the original design of the Gangnam development remained in Seoul  City,  the  practice  was  carried  out  by  construction  companies  operating  in  the  Gangnam construction sites (Han &amp; Kang, 2016).\n\nThe main result of the new development strategy, led by private sector (Kim et al., 2009), resulted in the efficient demolition of the existing shantytowns (Kim &amp; Ha, 1998) and achieved high market value of newly built apartments in Gangnam (Kim, 2008). The public welfare of the urban poor was not a priority during the development process (Korea City Institute, 1998; Kim, 1999). Therefore, the conflict between the government and residents had turned to the conflict between the construction companies and tenants (Korean City Institute, 1998; Kim, 2008; Kim et al., 2009). The Gangnam development plan has been completed in 1985 while the population and GDP per person grew significantly during the rest of 1980s (Kang, 2015).\n\nFigure 4. Gangnam, the modern metropolitan area and economic centre in Seoul (Shin, 2022)\n\n<!-- image -->\n\nThe completion of the Gangnam development has established Gangnam as a new economic centre in Seoul and the richest urban area in South Korea (Kang, 2015; Han &amp; Kang, 2016). As Gangbuk (which means  the north of the river , the traditional city centre of Seoul) was already filled up by ' ' the existing companies (Son, 2002), Gangnam was recognised as a business-friendly region by newly established companies and start-ups (Bae &amp; Joo, 2020; Shin, 2022). Considering 1970s as the period for the highest economic growth in South Korea (Graham, 1991), Gangnam could attract financial investment from both national capital and foreign direct investment throughout the 1970s and 1980s (Han &amp; Kang, 2016; Bae &amp; Joo, 2020). Thus, since the 1990s, Gangnam has become the financial hub of Seoul (Bae &amp; Joo, 2020) and the symbol of wealth where the South Korean citizens would like to live (Bae &amp; Joo, 2020; Kim, 2020).\n\nIn  addition,  the  prestigious schools in Seoul were relocated to Gangnam during the 1970s and 1980s (Kang, 2015; Kim, 2020) as well as the relocation of public transport hubs such as major bus terminal facilitated both citizens and capital to go through Gangnam or settle down in Gangnam throughout 1990s (Kang, 2015; Han &amp; Kang, 2016). Once Gangnam has been established as a new metropolitan  area  of  Seoul  (Figure  4),  Gangnam  developed  further  independently  without government support (Kim, 2020). The price of land properties in Gangnam had skyrocketed and caused the polarisation of economic power since 2000s (Kim et al., 2009; Shin, 2022). Gangnam is no longer the place for development but the centre of economic activity and wealth as it is (Kim, 2020).\n\n\n## 5. Conclusion\n\n\nThe fundamental priority of the Gangnam development was to improve housing infrastructure in residential area by achieving the expansion of the Seoul metropolitan area (Kwon, 2012). As a result, most of the illegal  shantytowns in Seoul  are demolished (Korea City Institute, 1998;  Son, 2002) except Guryong town which is the last remaining shantytown in Gangnam for redevelopment (Ki, 2024). The Gangnam-style development transformed a poor countryside region into the richest district in Seoul and South Korea (Kang, 2015). On the other hand, many evictees lost their home and disappeared as nameless citizens behind the scenes of the development (Korea City Institute, 1998; Kim, 1999). An economic polarisation of rich and poor also divided Seoul and South Korea (Bae &amp; Joo, 2020).\n\nSeoul has already lost a necessity of development plan as a large-scale project. Most of houses are under the distribution system of tap water and electricity (Son, 2002). The  urban road network already exists to connect residential areas (Jeon et al., 2008). Seoul is in a developed stage that requires maintenance and repair (Kim, 2020). No more fundamental development plan is required that  Koreans say, ' creation out of nothing . The expertise for planning and execution of urban ' development acquired in Gangnam can be thoroughly studied and transferred to other regions in South  Korea  and  developing  countries  in  the  world.  The  era  of  eviction  and  construction, represented by Gangnam, still has a strong impact on the Korean society as the legend of wealth (Lim, 2015; Kim, 2019) as the people who have undergone and witnessed its process are still alive. Therefore,  a  new  paradigm  for ' urban  regeneration   is  necessary  to  recover  the  function  of ' metropolitan economics and society.\n\nGangnam has become a successful urban development case but the economic polarisation and social injustice in the Seoul metropolitan area remain unsolved until today.\n\n",
         "The population of Seoul had exploded from 1 million to 2.45 million in 7 years right after the end of the Korean War (from 1953 to 1960). Many parts of Seoul were converted into slum areas and aimless urbanisation lowered the quality of life in the Seoul metropolitan area. Pupils were excluded from education due to the lack of school infrastructure while citizens were exposed to crime and unemployment. In the middle of the population crisis, the metropolitan government of Seoul and the central government of South Korea paid attention to the potential of Gangnam as one of the candidate regions for the expansion of the Seoul metropolitan area. This review presents how Gangnam has transformed from an “empty land” to the “symbol of wealth” in the history of the Gangnam development and the expansion of the Seoul metropolitan area. The initial development plan tried to solve immediate housing problems derived from the lack of urban space and facility. After 20 years of the intensive development, Gangnam has transformed from a poor countryside region into the new economic centre and financial hub. Gangnam has become a symbol of wealth in South Korea where citizens and private companies would like to reside. On the other hand, many evictees lost their home and disappeared as nameless citizens behind the scenes of the development. The Gangnam-style development, the expertise of urban development acquired in Gangnam, can be thoroughly studied and transferred to other regions in South Korea and developing countries in the world, thus establishing Gangnam as a model case of metropolitan area expansion.\n\nKey words: construction, eviction, Gangnam, housing crisis, metropolitan area, Seoul, shantytowns, urban development",
         ""
        ],
        [
         "31",
         "31",
         "## Introduction\n\n\nDigital Game-Based Learning (DGBL)  is increasingly popular in enhancing educational outcomes, especially in teaching primary school students English as a Foreign Language (EFL). As educators search for more engaging and effective teaching methods, integrating game elements, such as rewards, into the learning process has gained significant attention. These rewards, from virtual points to certificates, enhance motivation and improve academic performance. However, the specific effects of rewards in the context of DGBL,  particularly in educational settings like Kazakhstan, have yet to be thoroughly explored. Understanding how these incentives influence student engagement and  learning outcomes is  crucial for optimizing educational strategies in diverse cultural contexts.\n\nGamified learning in primary schools has been shown to improve students' computational thinking skills and increase their engagement in learning (Ma Zong-bing, 2018). Furthermore, game-based learning has positively impacted students' achievement in various subjects, including science ￼. Implementing efforts to foster a motivational culture that focuses on students' strengths and learning processes can enhance their sense of belonging in school (Vaz et al., 2015). The digitization of education has led to the rapid integration of ICT in elementary schools, which can improve the development of students' creative abilities (Demchenko et al., 2022).\n\nIt  is  essential to  consider teachers' knowledge  and  attitudes towards  digital game-based language learning, as they significantly impact language instruction in contemporary education (Belda-Medina &amp; Calvo-Ferrer, 2022). Recently, digital technologies have been widely used in education,  potentially enhancing  academic performance and  student  motivation. One  specific application of  digital technologies in  education is  gamification, which  involves incorporating elements of  games  into non-game contexts. It  is  worth  noting that  gamification can  heighten student engagement in learning English as a foreign language, particularly at the primary school level.\n\nMotivation in digital game-based learning is influenced by various factors such as game design, personalization, social engagement, curricular integration, and instructor support (Syifa et al.,  2024). Integrating technology through digital gameplay has enhanced students' motivation, engagement, and language performance, resulting in more effective learning outcomes (Tawafak et al., 2023). Virtual awards, points, and certificates are rewards that play a significant role in gamification and can  significantly influence students' motivation. However,  the effects of  this reward system on students' performance and motivation are poorly understood, mainly when using digital games for teaching a second language or other subjects. The present study aims to fill this gap.\n\nThe main objective of this study is to examine how  rewards influence student motivation and academic achievement in a Digital Game-Based Learning (DGBL) environment for teaching English as a foreign language to primary school students in Kazakhstan. This research is essential as it fills a gap in the existing literature on the effectiveness of rewards in improving motivation and performance in educational settings. The results of this study could offer valuable perspectives for  educators  and  policymakers  who  aim  to  enhance  language  learning  outcomes  through innovative teaching methods.\n\nDesigning  incentive systems in  digital game-based learning is  essential for  maintaining learner engagement. Elements such as points, scores, stars, levels, and performance feedback play crucial roles (Lomos et al., 2023). Early childhood experiences in learning English can have a long-term  effect  on  students'  achievements  in  English  and  other  subjects,  highlighting  the\n\nwww.awej.org\n\nISSN: 2229-9327\n\n\n## Literature Review\n\n\n\n## Global Application of DGBL in EFL\n\n\nGamified learning  has  proven  to  be  useful  not  only  in  attracting and  keeping  students interested but also in helping them express their thoughts in English more effectively. Additionally, it promotes more efficient teaching in general (Zhang Yao, 2017). English language learners can acquire essential skills for their learning process through games. To facilitate this transfer, web tools for communication are necessary, as they aid learners in transitioning from elementary to secondary schooling and prepare them for college-level academics. This aspect allows them to acquire the essential basics and be better equipped for higher academics (Maher, 2010). As a result, they are better academically and psychologically prepared for their first year at university.\n\nOur purpose is to build upon these insights by examining the influence of rewards on players within a game format. Previous studies have demonstrated that introducing English through digital gaming methods at a young age could lay a solid foundation for future academic success. Children who study English from their first year of school tend to outperform those who do not (J. Chen et al., 2021). Interventions like CASE, which aim to facilitate a seamless transition from elementary to secondary education, exemplify the vital role of intentional support in achieving success in\n\nwww.awej.org\n\nISSN: 2229-9327\n\n\n## Kazakhstan-Specific Studies\n\n\nIn recent years, Kazakhstan's educational landscape has been experiencing notable changes, especially regarding teaching foreign languages at the primary school level. According  to the Minister of Education and Science, Askhat Aimagambetov, English language instruction will now commence from the 3rd grade instead of the 1st grade. This decision is based on research and analysis showing  that it is  difficult for  first graders to master three languages simultaneously (Aimagambetov, 2022).  Consequently,  there  is  an  increasing  focus  on  discovering  effective teaching methodologies that can facilitate the learning process for young students.\n\nIn Kazakhstan,  several  factors  have  been  identified  as  key  influencers  on  students' motivation and reading skills development in learning English. These factors include the socialcultural environment, integrative orientation, instrumental motivation, perceptive competence, and parental involvement in reading materials (Akhmetova et al., 2021). These factors emphasize the complex nature of motivation in language learning and the need to address different aspects to improve students' engagement and proficiency.\n\nThe decision to delay English instruction until the 3rd grade in Kazakhstan emphasizes the importance of implementing innovative teaching strategies to effectively support young learners in acquiring a new language. To address these challenges, gamification has been proposed as a practical method  to  enhance  students' interest and  proficiency in  language  learning. Previous research in  different settings has  demonstrated that  DGBL  can  significantly enhance  student motivation and learning results when paired with suitable reward systems. However, research is still being conducted on how these approaches function within Kazakhstan's particular cultural and educational environment, especially during the initial phases of language acquisition.\n\nIn  teaching English as a foreign language to primary school pupils, technology has been effectively utilized to foster creative thinking and improve communication skills (Aigerim et al., 2022).  Gamification, which  integrates game elements into non-game contexts, is  increasingly recognized as a powerful tool in education, especially in teaching English as a second or foreign language. Using elements like competition, rewards, and interactive challenges, gamification can significantly impact students' motivation and  outcomes in  language  learning. Using  gamified approaches has  encouraged competition among  students, motivating them to  outperform their peers and achieve higher scores or rankings, thus enhancing their motivation (Duisenova et al., 2024). This competitive aspect can be particularly advantageous for independent learners, as it creates an engaging environment that promotes active participation and learning  (Kassymova et al., 2024).\n\nIn conclusion, integrating gamification strategies into teaching English as a foreign language in  Kazakhstan  can  significantly impact  students' motivation and  outcomes.  By  incorporating gamified elements, educators can create a vibrant and stimulating learning environment that sparks students' interest, encourages competition, and improves their language proficiency. Technological infrastructure, cultural attitudes towards technology, and  effective socio-affective strategies all play a vital role in shaping students' motivation and success in language learning. Therefore, by\n\n\n## Methodology\n\n\n\n## Participants\n\n\nThe  study  included  46  fourth-grade  students  from  two  primary  schools  in  Shymkent, Turkestan  region,  Kazakhstan.  Comprehensive  Secondary  School  No.  85,  named  after  H. Alimzhan, and Schoolgymnasium No. 25, named after T. Ryskulova. The students were divided into two groups: an experimental group of 23 students who engaged in digital game-based learning with  rewards  and  a  control group  of  23  students  who  received  traditional English  language instruction. The study took place during the 2023-2024 academic year.\n\n\n## Research Instruments\n\n\nData were  collected using a combination of pre-tests and  post-tests to measure students' English  proficiency  and  motivation  levels.  Additionally,  semi-structured  interviews  were conducted with a  sample of students and their teachers to gather qualitative insights into their experiences and perceptions of the learning process. The instruments used included questionnaires to assess motivation and academic performance before and after the intervention.\n\n\n## Research Procedures\n\n\nThe  study  used  a  quasi-experimental  design  to  examine  how  rewards  affect  student motivation and achievement in digital game-based learning. The experimental group participated in challenging yet enjoyable digital game-based learning activities. They received rewards such as points, badges, and virtual incentives as they advanced through the game. The control group, on the other hand, continued with traditional instructional methods. Pre-tests were administered at the beginning of the study to establish a baseline for both groups. Post-tests were conducted after the intervention to evaluate the impact of the rewards system. Interviews were carried out over two weeks,  and  thematic  analysis  was  performed  on  the  data  to  identify  key  themes  related  to motivation and academic performance.\n\n\n## Data Analysis\n\n\nThe action research cycle was developed following the framework proposed by EL-Asri and El Karfa (2024) and Kemmis and Mctaggart (1988). The teacher manually documented the cycle stages in a reflection logbook to monitor the planning, implementation, observation, and reflection of the activities and their influence on students' critical thinking. The data from the questionnaire were computed and analyzed using the Statistical Package for the Social Sciences (SPSS) Version 29.0.2.0 (20). Lastly, the interviews were transcribed and organized into themes using a content analysis approach.\n\nwww.awej.org\n\nISSN: 2229-9327\n\n\n## Results\n\n\nData analysis was performed on both groups' motivation and achievement levels, gathered through  individually administered questionnaires. The  study  findings significantly influenced student motivation and achievement when rewards were employed in digital game-based learning. Specifically, the  students in  the  experimental group  showed  higher  levels  of  motivation and achieved better learning outcomes than those in the control group.\n\nOur  analysis generated four themes that characterized the determinants affecting student motivation and  achievement in  digital game-based  learning: (1)  Reward  Structure, (2)  Game Design Features, (3) Teacher Facilitation, and (4) Classroom Environment. Our results confirmed that different types of rewards significantly impact student engagement.\n\n\n## Reward Structure\n\n\nStudents were mainly motivated by rewards they perceived as meaningful and aligned with their personal goals. Student A explained, \" When the rewards were things we genuinely wanted, like extra time to play our favorite games, every one put in more effort .\" Such rewards provided students with clear, immediate goals to strive for, creating an environment where consistent effort was seen as rewarding. Teachers observed that students showed higher motivation and better task persistence when  the rewards were  linked to specific achievements and perceived as valuable. Teacher  A  noted,  \" Students were  particularly eager  to  earn  rewards  that  carried real-world benefits, such as extra recess time or a homework pass.\"\n\n\n## Game Design Features\n\n\nThe design of the games also played a crucial role. Games that are challenging yet achievable promote higher levels of engagement and  facilitate better learning outcomes. \" The  games  that facilitated our  learning  the  most  were  those  that  increased  in  difficulty as  our  proficiency improved ,\" said Student B, highlighting the importance of a meticulously designed progression of difficulty that effectively sustains user interest by offering attainable obstacles. Teachers reported that games with adaptive difficulty levels were more effective in accommodating varying skill levels within the classroom. Teacher B explained that the lessons integrated games that included adaptive difficulty, modifying the challenge according to the student's ability level. This effectively maintained  a  balanced  degree  of  difficulty, ensuring  that  students  were  neither  bored  nor overwhelmed.\n\n\n## Teacher Facilitation\n\n\nEffective facilitation by teachers was essential for integrating game-based learning into the curriculum. Teachers who actively engaged with students and the game content enhanced learning outcomes. \"Our teacher helped us understand how the game fits what we're learning in class. It made more sense,\" noted Student C. The teachers' active involvement facilitated the creation of strong  connections  between  the  gaming  experience  and  academic  lectures,  enhancing  the educational value of digital games. The teachers played a crucial role in guiding the game-based learning  process,  which  was  essential  for  its  success.  Effective  facilitation included  giving instructions and support and integrating game content into the educational curriculum. According to Teacher C, \" Students frequently related game situations to their lessons, which helped them grasp the importance of their gaming achievements within a broader educational framework. \"\n\nwww.awej.org\n\nISSN: 2229-9327\n\n\n## Classroom Environment\n\n\nThe overall classroom atmosphere, including peer relationships and established classroom norms,  influenced the  level  of  student  participation in  game-based learning.  An  encouraging classroom atmosphere facilitated increased cooperation and passionate participation. \"I enjoyed the collaborative experience of playing together and assisting each other in solving the games,\" said Student D. These interactions fostered a sense of collaboration as students learned to cooperate and  shared  strategies to  succeed in  the  game, enhancing  their educational achievements. The effectiveness of game-based learning was greatly influenced by the classroom environment, which, in  turn,  was  influenced by  peer  relationships and  the  overall learning atmosphere. Educators discovered that a classroom environment that fosters support and collaboration motivates students to  actively and  extensively participate in  game-based assignments. According  to  Teacher  D, 'Students who worked together in teams were able to inspire and support each other and share methods. This led to a better understanding of the subject matter and fostered the development of stronger interpersonal skills'.\n\nOur investigation concludes that several interconnected factors influence the efficiency of DGBL. Student motivation and achievement are affected by the structure and nature of incentives, well-designed  games,  proactive  instructor  facilitation, and  a  positive  classroom  atmosphere. Understanding and effectively integrating these elements can enhance the educational impact of game-based learning for elementary school children.\n\nThe second topic emphasizes the significance of establishing a supportive and stimulating educational environment. The  students in  the  experimental group  reported a  positive learning experience, as they were motivated to actively participate in the digital game-based activities. This indicates that the design of the learning environment, which integrated elements of challenge and enjoyment, contributed to enhancing their motivation and overall satisfaction with the learning process.\n\nThe  third  subject focused  on  the  influence of  technology-driven interactive settings on student motivation. According to the interviews, the interactive aspect of the digital game-based learning activities was crucial in capturing students' attention and maintaining their engagement throughout the learning process. This discovery is consistent with other studies that suggest the beneficial impact of interactive technology on student motivation in language acquisition.\n\nFinally,  the  fourth  topic  highlights  the  significance of  employing  innovative  teaching methods to boost student motivation. By following the SMART education principles, as suggested by Huh and Lee (2019), students can engage in self-directed learning by  utilizing technology. Consequently, this considerably enhances their motivation and facilitates the improvement of their language skills.\n\nTable 1: Comparison of the level of motivation and academic performance of students in the control and experimental groups\n\nwww.awej.org\n\nISSN: 2229-9327\n\n\n## Discussion\n\n\nFor RQ1, the study found that rewards in DGBL  significantly positively impacted learner motivation. The experimental group, who received rewards, showed higher motivation levels than\n\nwww.awej.org\n\nISSN: 2229-9327\n\n\n## Conclusion\n\n\nThe primary objective of this study was to evaluate the influence of rewards on motivation and  student  achievement in  digital game-based  learning  environments. This  was  specifically examined in the context of teaching English as a foreign language to primary school students in Kazakhstan. The  findings unequivocally demonstrate that using rewards significantly enhances\n\nwww.awej.org\n\nISSN: 2229-9327\n\nstudent  motivation  and academic  performance.  While  rewards enhance motivation  and achievement in digital-based games, teachers must balance extrinsic and intrinsic motivators. It is important  to  establish  an  educational  system  that  values  both  immediate  rewards  and  the cultivation of deeper knowledge and skills.\n\nIn  the future, researchers could  investigate the long-term effects of  rewards on students' motivation and  academic achievements. Students who  engage in  digital game-based language learning  incorporating  incentive  systems  find  opportunities to  enhance  their  motivation  and improve  learning  outcomes.  Moreover,  exploring  how  rewards  are  implemented  in  diverse educational contexts would be valuable. This research would assist in tailoring reward systems for different student groups and specific learning objectives. Rewards have been shown to enhance English instruction through computer video games. Additionally, teachers possess a strong grasp of motivation and achievement, enabling them to utilize rewards that sustain student interest and positively influence their learning.\n\nOur findings indicate that rewards effectively encourage foreign language learning through digital games. However,  a  comprehensive approach that considers both  extrinsic and  intrinsic incentives is necessary to ensure long-lasting and high-quality learning outcomes.\n\nFunding: The article was completed as part of a research project commissioned by the Ministry of Science and Higher Education of the Republic of Kazakhstan (Grant No. AP15473538)\n\nAcknowledgments: The authors thank the educators and students of Comprehensive Secondary School No. 85 and School Gymnasium No. 25 in Shymkent for their invaluable participation in this study.\n\nConflicts of Interest: The authors declare no conflict of interest.\n\nAuthenticity: This manuscript is an original work\n\nDeclaration of Generative AI and AI-assisted technologies: During the preparation of this work, the authors used ChatGPT and Grammarly to format references in APA style, to improve readability and language, and to check for grammar, syntax, and organization. The technology was used with human oversight and control. After using this tool, the authors reviewed and edited the content as needed and took full responsibility for the content of the publication.\n\n",
         "This study examines the impact of rewards on motivation and academic performance in digital game-based learning (DGBL) for teaching English as a foreign language to primary school students in Kazakhstan. The main objective is to evaluate how incentive systems influence student engagement and achievement, addressing a gap in the existing literature on the effectiveness of rewards in educational environments. Using a quasi-experimental design, 46 fourth-grade students were divided into a control group that received traditional instruction and an experimental group that engaged in DGBL with rewards. Data were collected through questionnaires measuring motivation and academic performance before and after the intervention. The results showed that students in the experimental group demonstrated significantly higher motivation and better educational outcomes than the control group. This study concludes that rewards can effectively enhance motivation and performance in DGBL, providing practical recommendations for educators to incorporate rewards in a balanced manner to sustain long-term engagement and learning success. Future research should explore the long-term effects of such interventions in different educational contexts.",
         ""
        ],
        [
         "32",
         "32",
         "## Introduction\n\n\nEquality of opportunity is a widely-held ideal and an explicit goal of much policymaking. Comparing societies to better understand the factors that facilitate or hinder this has long been a major research area for social scientists. To measure equality of opportunity, researchers mostly estimate some form of association between parent and child socio-economic position in terms of a single indicator (Breen and M¨ uller, 2020; Chetty et al. , 2017; Hout, 2018; Sorokin, 1927). However, operationalizing family background in this way underestimates its effects. Not only do multiple dimensions of parental socio-economic position play a role in the intergenerational transmission of advantage (Bukodi and Goldthorpe, 2013), but so too do a plethora of other difficult-to-observe parental characteristics (Lareau, 2011; Putnam, 2015).\n\nThis study focuses on an alternative measure, namely the sibling correlation (SC)-the degree of similarity between siblings on a given outcome. The SC corresponds to the proportion of variance attributable to factors that increase sibling resemblance. The major dimensions of parental socio-economic position-income, wealth, occupation, and education-all act in this way and their effects are thus captured without needing to be measured, as too are the effects of other family-level factors such as ethnicity, and important unobservables such as parental motivation. Accordingly, the SC estimates the total effect of social origins. This makes it a valuable measure of a society's inequality of opportunity, albeit the theoretical correspondence is more nuanced than is typically appreciated. We provide a reinterpretation of the link between the SC and inequality of opportunity, and compare this measure's strengths and limitations to alternatives.\n\nWe focus on the SC in education , a highly important pathway in the transmission of advantage from one generation to the next and a key predictor of children's life chances. In our study, we compare SCs in education across countries and birth cohorts. We report the results of a systematic literature search for all published SCs in educational attainment. Next, we employ meta-regression\n\nto describe cross-national and temporal variation, and then to test whether equality of opportunity systematically differs across contexts characterised by different levels of income inequality.\n\nBringing together SCs from the broadest possible range of country-cohort contexts allows us to contribute new insights to current debates on cross-national differences in inequality of educational opportunity (Gr¨tz a et al. , 2021; Hertz et al. , 2008) and the idea that more economically unequal societies exhibit greater intergenerational persistence (Blanden, 2013; Corak, 2013; Jerrim and Macmillan, 2015)-the so-called 'Great Gatsby Curve.' Prior research using SCs in education mostly comprises single-country studies. A few studies have compared SCs in education across countries (Gr¨tz a et al. , 2021; Sieben et al. , 2001; Sieben and de Graaf, 2001, 2003; Sirni¨ o et al. , 2020), but these investigations have not yet succeeded in 'replacing the notion that 'nations differ' by statements formulated in terms of specific variables' (Przeworski and Teune, 1970, p. 29-30). By investigating the role of income inequality, we build upon this prior work to enhance our understanding of the correlates of a society's opportunity structure.\n\nWe proceed by first discussing SCs in detail. Next, we elaborate on the relevance of income inequality. Then we present our empirical analysis.\n\n\n## Sibling correlations\n\n\nThis section aims to clarify what SCs measure, in what sense this corresponds to inequality of opportunity, and how this complements two alternative measures of (in)equality of opportunity, genetically-sensitive variance decompositions, and parent-child associations.\n\n\n## What sibling correlations measure\n\n\nMost straightforwardly, SCs measure how strongly siblings in a population resemble one another on an outcome. A value of zero means that siblings are as similar as randomly-chosen individuals of the same birth cohort, in expectation; one means that siblings in a family all share the same outcome-from which it is easy to intuit that family background likely plays an important role.\n\nSCs are usually estimated in one of two ways. The first is simply the Pearson correlation between the outcomes for two randomly-selected siblings within each family. For intuition, imagine plotting sibling A's outcome on one axis and sibling B's on the other for a sample of families. An extension yielding the same\n\nexpected value is to include all sibling pairs and weight each family equally to account for differences in sibship size.\n\nSecond, SCs may be estimated within a variance-components framework. The outcome Y for individual i is decomposed into an individual-specific component S if and a family component C f common to siblings in the same family f :\n\n<!-- formula-not-decoded -->\n\nS if and C f are thus assumed uncorrelated (Conley and Glauber, 2005; Lundberg, 2020). Variance in the outcome is decomposed into a between-family component σ 2 C and a within-family component σ 2 S . The SC is given by the intraclass correlation coefficient σ 2 C σ 2 S + σ 2 C , i.e. the proportion of the variance that is between rather than within families.\n\nSCs, then, measure the proportion of the variance in an outcome attributable to factors whose effect is to increase similarity among siblings (on that outcome). 1 Insofar as they increase sibling similarity, then, influences captured by the SC include all relevant parental characteristics and behaviours, and a family's economic, social, and cultural resources. They further include school, community, and neighbourhood factors as well as extra-nuclear kin. The SC also captures the effect of the, on average, 50 % of genes that siblings share. Together we term these factors a sibling set's 'common inheritance,' to emphasize both that environmental and genetic factors are included, and that the remaining variance is explained by individual-specific factors, albeit these may be rooted in the family. For consistency with the wider literature, we use the terms 'social origins' and 'family background' interchangeably with 'common inheritance', albeit we argue the latter provides a more precise descriptor.\n\nCorrespondingly, one minus the sibling correlation (1 -SC ) gives the variance explained by factors that generate differences between siblings and thereby bring their similarity closer to that between random individuals. These 'individualizing factors,' as we term them, arise from the corresponding non-shared 50 % of genes and from non-shared environmental effects (Plomin, 2011). Sources of the latter include birth order and spacing (Barclay and Smith, 2022; Black et al. , 2005; Chan et al. , 2019), maternal age (Gr¨tz and Wiborg, 2024), sex (Breen a et al. , 2010; Buchmann et al. , 2008), and non-systematic sibling-specific experiences such as random allocation to a particular schoolteacher. Importantly, sibling differences are also rooted in differential experience of what might normally be understood as the shared environment (Conley, 2008; Gr¨tz, 2018). Families, a schools, and communities may change over time, varying the age-specific exposures of different siblings. As discussed further below, siblings may be treated\n\ndifferently by parents and teachers, and fall into different peer groups. 2\n\nSiblings are not just the passive recipients of differences in their individualspecific environments, but also generate these differences in a process of dynamic interplay. Parents respond to initial differences in early temperament with differential parenting (Bates et al. , 2012; Hern´ndez-Alava and Popli, 2017; Huh a et al. , 2006; Kiff et al. , 2011). Children's genetic propensity to educational attainment elicits more of some forms of cognitively-stimulating parenting in early childhood (Breinholt and Conley, 2023). Siblings actively seek to differentiate themselves from one another and occupy a unique niche, consistent with evolutionary theory's prediction that this strategy increases parental investment (Healey and Ellis, 2007; Sulloway, 1996). In this light, some sources of within-family inequality can be viewed not as inexorable forces but as circumstances to which children respond as individual agents, shaping their own micro-environment.\n\n\n## Sibling correlations and inequality of opportunity\n\n\nHow does the foregoing relate to inequality of opportunity? We first critique the conventional answer before providing our own.\n\nBoth answers share the point of departure that the SC captures the effect of social origins, and one's social origins are beyond one's control, meaning (following, among others, Roemer, 1998) that one cannot be held accountable for their effects, whether positive or negative. Inequality of opportunity in this context refers to the extent to which individuals' outcomes are determined by factors beyond their control. However, invoking equality of opportunity requires an account of what constitutes merit, the set of characteristics for which one can be held accountable, and which determine success under a regime of equality of opportunity.\n\nThe SC is conventionally characterized as a lower-bound estimate of the total effect of social origins (Bj¨rklund o and J¨ antti, 2012; Schnitzlein, 2014). 'Lower-bound' because factors such as birth order and sibling-specific parenting that increase sibling differences are explicitly framed as family background effects which are however missed (Bredtmann and Smith, 2018; Halliday and Mazumder, 2017; Karhula et al. , 2019; Lillehagen and Isungset, 2020).\n\nAs a link between the SC and inequality of opportunity, this account is unsatisfactory because it leaves unclear what falls outside the scope of social origins and thus remains as a basis for merit. The SC literature rarely offers\n\na direct answer. Rather, it is usually noted as a limitation that the SC does not fully capture the effects of family background. Discussing how to move from this lower bound towards a more complete measure, Bj¨rklund and J¨ntti o a (2012, p. 468) survey the factors that ideally would be included. Among these are 'all [one's] (initial) genes' and 'all family and environmental influences.' But what else is there? This account leaves no conceptual room for the individual as distinct from their family background, and thus no basis for merit. Equality of opportunity is valorized for describing a world in which, for example, a hardworking individual can overcome the constraints imposed by family background. But the concept becomes incoherent if the characteristic of being hard-working itself necessarily falls within the all-consuming scope of 'family background.'\n\nWe argue instead that SCs make sense as a measure of inequality of opportunity only under an understanding of social origins as limited to common inheritance. Thus, there is conceptual room for merit, and merit on this account has its origins in individualizing factors. If individualizing factors have a relatively strong influence, the sibling correlation is relatively low and equality of opportunity relatively high. And vice versa where common inheritance plays the greater role. We do not propose that the SC is thereby a perfect measure of inequality of opportunity, but this perspective helps clarify its strengths and limitations. It is attractive because it expunges from merit all differences between families of origin, yet allows that individual differences in merit exist.\n\nThis raises the question of how far the division between common inheritance and individualising factors corresponds to that between (non-meritocratic) ascription and (meritocratic) achievement. The previous section makes clear that the correspondence is imperfect. We lack the space for a full discussion, but in the next section touch on the issue as it relates to genetics, and here briefly address one source of sibling differences that may appear non-meritocratic: differential parental investment. Insofar as this occurs in response to differences in ability between siblings rather than being idiosyncratic, it is consistent with SCs measuring inequality of opportunity. A rich literature studies whether-and which groups of-parents compensate for or instead reinforce sibling differences in ability (Fan and Porter, 2020; Frijters et al. , 2013; Gr¨tz and Torche, 2016; a Hsin, 2012). However it is agreed that differential investment occurs in response to observed signals. Reinforcement, which decreases sibling similarity, is the efficient strategy to enable the maximal realisation of potential (Becker and Tomes, 1976). By contrast, compensation (Behrman et al. , 1982), or equalization, increases sibling similarity and in doing so constrains the expression of innate potential, albeit equalising outcomes within families.\n\nDifferential investment by birth order or sex, however, would be a nonmeritocratic source of sibling differences. More generally, this discussion highlights the value of sex-specific SCs. When brothers and sisters are both included,\n\nsex is treated as an individualizing factor: to the extent that it explains variation in the outcome, it will reduce the SC. Sex-specific SCs are thus more appropriate for measuring of inequality of opportunity, and indeed allow comparison across sexes.\n\n\n## Sibling correlations and genetically-sensitive variance decomposition\n\n\nGenetically-informed designs such as the classical twin study allow a decomposition of variance into additive genetic ( A ), common environmental ( C ), and non-shared environmental ( E ) factors (Knopik et al. , 2016). This can inform debates on inequality of opportunity under the view that genetic differences represent differences in innate ability and thus merit or potential, whereas the common environment stands for ascribed factors such as parental wealth (Engzell and Tropf, 2019; Guo and Stearns, 2002; Nielsen, 2006). The literature linking behavioural genetics to social stratification has so far had relatively little to say about the interpretation of the non-shared environmental component, despite its large share in many contexts (Branigan et al. , 2013; Erola et al. , 2022).\n\nThe sibling correlation approach, by contrast, decomposes variance into two parts, C + 0 5 . A (i.e. SC ) and E + 0 5 . A (i.e. 1 -SC ). 3 It is therefore an important limitation of the SC that it does not distinguish between genetic and environmental channels of transmission. Indeed, at the extremes, a given sibling correlation might be due entirely to C or entirely to A.\n\nNonetheless, we believe the two approaches are complementary. SC data is more easily collected and is available for a wider range of contexts (cf. Branigan et al. , 2013). Heritability as a measure of a context's equality of opportunity is not without limitations: in particular, the inherited traits that influence attainment may extend beyond ability and effort to non-merit characteristics such as skin color (Diewald et al. , 2015). Most importantly, behavioural genetics designs involve several much-debated assumptions that SCs do not (Felson, 2014; Fishkin, 2014; Wolfram and Morris, 2023).\n\nHow can the foregoing be reconciled with an interpretation of the SC as a measure of inequality of opportunity for outcomes subject to substantial genetic effects? Under the view that one's genome is simply who one is and is thus a legitimate basis for merit, the SC is limited as a measure of inequality of opportunity by the fact that it picks up the effect of the on average 50 per cent of genes shared with siblings. It follows from our account in the previous section that to interpret the SC as a measure of inequality of opportunity is instead\n\nto view that shared genetic component as a non-meritocratic factor, another (dis)advantage to happening to be born in a particular family-and to view the individual-specific genetic component as part of what makes one an individual distinct from one's family background, and thus a basis for merit. A corollary of this interpretation is that 'merit' (with respect to a particular outcome) is relative to one's siblings.\n\n\n## Sibling correlations and parent-child associations\n\n\nParent-child associations are very widely available and offer easily interpretable measures of intergenerational persistence. SCs however have important comparative advantages insofar as inequality of opportunity is at issue. Whereas parent-child associations describe the strength of association between child education and parent education, SCs describe the strength of association between child education and a much wider range of social origin factors. If we are interested in the extent to which one's background as a whole constrains or enables educational success, the more expansive concept is desirable (Hout, 2015). Parent-child associations in education mask variation in the outcome according to income, wealth, and myriad other parental factors, even among those with the same level of parental education. 'Parent'-child associations are also often father-child associations in practice, ignoring the role of maternal characteristics.\n\nHow much of the influence of social origins is missed by parent-child associations is made explicit by comparing the SC to the variance in child education accounted for by parental education. The SC can be decomposed into the sum of two components: the squared intergenerational correlation and other factors generating sibling similarity but uncorrelated with parental education (Solon, 1999). 4 Bj¨ orklund and J¨ntti (2020, p. 5) find that squared intergenerational a correlations in education for Sweden and the US (.09 and .21) fall far below SCs from the same countries (.43 and .60 respectively), and adding further observables to the model does little to close the gap: ''other factors' are the most important ones that siblings share.'\n\nSCs may also be more suited to comparative research than parent-child associations. The correlation between parental education and other family background characteristics that affect education is likely to exhibit substantial variation across time and place. One source of such variation would be the 'great deal of heterogeneity . . . across countries' in the wage returns to schooling (Trostel et al. , 2002, p. 2); that is, the link between parental education and parental earnings. This means that the extent to which parent-child associations capture the influence of social origins may vary considerably and in unclear ways across contexts, as suggested by the figures for Sweden and the US.\n\nAdditionally, since the SC depends upon the educational distribution within one generation rather than two, it is without difficulties of interpretation that arise from mapping persistence over two generations, across which the meaning and distribution of education may change (and in different ways in different countries). For example, Hertz et al. (2008) reach differing conclusions about global change in educational persistence depending on whether the intergenerational coefficient or correlation is used. 5 The choice between the two also strikingly changes the rank order of countries. Our meta-analysis can therefore further contribute to a picture of country rankings of intergenerational persistence, where currently there is considerable uncertainty (Str¨mberg and Engzell, o 2023).\n\n\n## Educational inequality of opportunity in comparative perspective and the role of income inequality\n\n\nComparative social mobility research has shed a great deal of light on factors underlying variation across time and space in the educational and occupational opportunity structure of societies (Breen and M¨ller, 2020; Bukodi and u Goldthorpe, 2021; Smeeding et al. , 2011). At the same time, most of this work is based on intergenerational associations and thus paints a potentially incomplete picture. Comparative research into inequality of educational opportunity using SCs has been sparse so far. One study compared SCs among recent cohorts from across Europe and the US (Gr¨tz a et al. , 2021). Though the authors describe potentially relevant ways in which the countries under study differ, including their educational institutions and level of income inequality, with only six cases they do not attempt to link measured contextual factors to the size of the SC. Nonetheless they interpret certain results as running 'contrary to the Great Gatsby Curve hypothesis' (Gr¨tz a et al. , 2021, p. 1027). Sieben and de Graaf (2001, 2003) tested whether SCs varied systematically with indicators of modernisation (energy consumption per capita), individualization (divorce rate), and socialism (seats in parliament held by leftist parties). Whereas the effect of measured family background variables was negatively related to all these indicators, the total effect of social origins was not significantly related to any, raising the possibility that social origins taken as a whole exhibit a more invariant association with education than observables-based approaches would lead us to believe.\n\nThe Great Gatsby Curve (GGC) refers to the positive cross-national association between income inequality and intergenerational persistence, usually put\n\nin terms of income or earnings. Theoretical accounts of the mechanisms underlying this relationship focus almost exclusively on how economic inequality creates educational inequality (Durlauf et al. , 2022; Ermisch et al. , 2012). However we are aware of only a few studies testing whether income inequality is cross-nationally associated with greater intergenerational persistence in education, none of which employ SCs (Blanden, 2013; Jerrim and Macmillan, 2015; Neidh¨ ofer et al. , 2018). As Blanden (2013, p. 58) argues, evidence of an association between income inequality in childhood and educational persistence is in line with a causal interpretation of the GGC, since it is inconsistent with the idea that inequality and immobility 'tend to be generated by the same factors' (that is, are confounded) and therefore only correlate 'at the end of the process,' when the child generation are adults.\n\nIncome inequality's relation to the SC is likely to depend on the extent to which financial resources determine educational attainment. In terms of educational performance, or 'primary effects' (Boudon, 1974), greater income secures better health and nutrition and a home environment more conducive to learning (Breen et al. , 2009). As for educational decision-making conditional on performance, or 'secondary effects,' financial resources affect the perceived costs and benefits of continuing in education (Breen and Goldthorpe, 1997). Income is thus relevant to both primary and secondary effects, and higher income inequality indicates that it is more unevenly distributed. Under such circumstances we would expect a stronger effect of social origins on educational attainment (DiPrete, 2020; Durlauf et al. , 2022). Moreover, in high-inequality contexts the relative risk aversion mechanism of secondary effects (Breen and Goldthorpe, 1997) may be stronger, as the steeper income distribution implies a greater absolute loss from downward mobility.\n\nOn the other hand, for many of the cohorts in our study secondary education was free and tertiary education either free or subsidised to the point of widespread affordability, potentially nullifying the importance of income differences. Another possibility, since the SC captures influences beyond income, is that where incomes are relatively equal, high-status families develop and make greater use of cultural resources, social connections, and other substitutes for high income. The SC may then remain stable if advantaged parents are able to draw on alternative mechanisms through which to reproduce their position (Sieben and de Graaf, 2003).\n\nThe reduction of economic inequality may then be one policy option for weakening the link between origins and education. We aim to inform this debate by testing whether SCs correlate with cohort-specific indicators of income inequality at the national level. In common with other comparative macro-level research, this is necessarily a descriptive exercise. Rather than providing causal evidence, the benefits of our analysis lie in testing whether the hypothesized\n\nassociation is evident across a wide range of contexts, and in identifying where and when deviations appear.\n\n\n## Data and method\n\n\nOur analysis has three main stages. The first comprises a systematic review. We undertook a literature search with the aim of identifying all studies which report at least one estimate of an SC in educational attainment. We extracted these estimates and other estimate-level information (e.g. sample size, dataset, model), constructing thereby a dataset of SC estimates nested in studies. The Supplementary Materials contain a list of the included studies and a reproduction package including the dataset of estimates we have assembled. Our descriptive statistics characterise this raw dataset, giving an overview of the literature.\n\nSecond, we use meta-regression to explore variation in the SC by country and (decadal) birth cohort. 6 We use random-effects models in all cases. In a preliminary step, because multiple estimates are often based on the same sample, we save one predicted estimate per sample. These predicted estimates come from a meta-regression of estimates on sibship type, model type, and sample fixed effects. At this stage we also exclude estimates from non-nationally representative samples, and those with a range of birth years so wide they cannot be assigned to a particular birth cohort.\n\nThird, after using meta-analysis to pool estimates from different samples of the same country and cohort, we examine associations between these countrycohort estimates and indicators of income inequality.\n\nThe remainder of this section provides further detail underlying our analysis. Figure 1 provides a roadmap of our approach.\n\n\n## Results\n\n\n\n## Description of the sibling correlation literature\n\n\nTable 1: Sibling correlations from the literature: basic descriptive information\n\nNote: Counts Germany, East Germany, West Germany, England, Scotland, and the United Kingdom as separate countries. For the meta-regressions, Germany and West Germany are combined, as are England and the United Kingdom. The title of this study refers to the 18 countries included in the meta-regressions.\n\nWe begin by characterizing the SCs identified in our search. As Table 1 shows, 300 estimates from 63 studies met our inclusion criteria. All-siblings, brother, and sister correlations were present in a ratio of approximately 2:2:1. We found estimates for 23 countries, based on 59 distinct datasets ranging from national registers to primary data from small surveys. Estimates range from\n\n.13 (Czechoslovakia) to .75 (US), though these values are based on rather small samples (34 and 200 families respectively). The mean is .45 for all-siblings correlations, and slightly higher for brother (.47) and sister correlations (.48).\n\nFigure 2 provides further detail. Panel A shows a steady growth in the number of SC studies over time. Panel B shows that early studies focused on brothers, but the number of all-siblings estimates has since caught up. There are still relatively few estimates of sister correlations, and in fact 33 of these 61 come from a single study (Wiborg and Hansen, 2018) and refer to Norway. Though the majority (63 %) of studies report just one or two estimates, a small group contain a large number. Panel C identifies six studies that together contain 157 estimates. These six include two which present estimates from Norwegian register data for many distinct cohorts, and four of the five previous studies to compare SCs cross-nationally.\n\nPanels D and E of Figure 2 show which countries and datasets, respectively, are most represented in the literature. 31 studies have estimated SCs for US samples, by far the most. Next are the Nordic countries and Europe more widely. Apart from Australia, the non-European countries represented in the literature each appear in only one study. Notably, these are all (Indonesia, Israel, and Japan) excluded from our meta-regressions because the samples they refer to span a wide range of birth years. Besides register data, the PSID stands out as much-used. More recently-initiated household panel studies from other countries may be an untapped source of new SC data, since they largely adhere to the PSID's design. Panel F of Figure 2 shows the distribution of SCs: approximately normal, with 94 % of estimates falling within two standard deviations of the mean.\n\nFigure S3 in the Supplementary Materials plots some additional descriptive information. As Panel A of Figure S3 shows, the sample sizes behind these estimates span several orders of magnitude, and are concentrated among the small and the very large. Panel B gives the distribution of the first year of birth for each estimate's sample. Coverage spans the late 19th century and most of the 20th, with younger cohorts yet to complete their education. The distribution of samples peaks in the 1950s and early 1960s. Panel C gives the length of these cohorts, that is, how long a span of birth years is included in each sample. This exhibits a long tail of studies in which nationally representative samples of adults were asked about their siblings' education. Usually however the estimates refer to more specific birth cohorts spanning under ten years.\n\n\n## Meta-analytic and meta-regression results\n\n\nBefore making comparisons across countries and cohorts, we regress estimates on sibship type, model type, and sample fixed effects. Using this model, we predict a single, comparable SC estimate for each sample. This also constitutes\n\nFigure 2: An overview of the sibling correlations literature. Panel A : cumulative frequency of sibling correlation studies over time. Panel B : cumulative frequency of sibling correlation estimates over time, by sibship type. Panel C : studies containing more than 10 estimates. Panel D : number of studies per country. Panel E : number of studies using each dataset. Panel F : kernel density plot of all sibling correlation estimates (Epanechnikov kernel).\n\n<!-- image -->\n\nTable 2: Random-effects meta-regression of sibling correlation estimates on sibship type, model type, and sample\n\nNote: ∗∗∗ p &lt; . 001.\n\na test of whether SC estimates vary systematically by sibship and model type. Coefficients from this model are shown in Table 2. Sister correlations are larger than those among brothers ( b = 0 031) and those among all siblings ( . b = 0 045). . The coefficients must be interpreted carefully, as they are on the Fisher's z scale and so vary across the range of correlation values; z is almost equivalent to r in the range 0 to .5, but notably diverges from r at r ≥ . 5. For the median estimate recorded in our literature review, .46, an increase of 0.031 would represent an increase of 0.024 on the correlation scale.\n\nThe three predominant approaches to estimation ( model type in Table 2) are variance decomposition models either including ( N = 85) or excluding (61) only-children, and Pearson correlations with adjustment for family size if applicable (68). Variance decompositions including only-children are expected to be larger, since only-children add between- but not within-family variance. This is reflected in their positive coefficient. Nonetheless, there are no significant differences among these three main approaches or the few estimates from structural equation models (5), but contrasts were significant between variance decompositions including only-children and both the 26 estimates whose model type we could not discern, and Pearson correlations without the family size adjustment (10).\n\nWe conclude that estimates are somewhat larger among sisters, estimates for all siblings are not significantly different from those among brothers, and the way in which a sibling correlation is estimated generally makes little difference. This is a reassuring note on which to predict a single estimate for each sample, holding sibship type at all siblings and model type at Pearson's r , while acknowledging that for many samples we in fact only observe correlations for brothers or sisters only, or estimated from other types of model. This yields\n\nestimates for 94 distinct samples. A forest plot in the Supplementary Materials (Figure S4) shows each estimate with a confidence interval and relative weight, plus the overall meta-analytic average of .46 (95 % CI .44, .47). The I 2 statistic of 90 % indicates that variation between these estimates is almost entirely due to between-estimate variance in the true effect size, rather than variance arising from sampling error.\n\nOur focus is on modeling variation in these estimates rather than estimating an overall average which has no clear interpretation in this context. Figure S5 in the Supplementary Materials presents coefficients from a random-effects metaregression of the 94 predicted correlations on country and birth cohort. The R-squared statistic indicates that these covariates explain 54.3 % of the variation between estimates. Estimates do not differ significantly according to birth cohort and thus produce no evidence of a cross-national time trend in the size of the SC.\n\nThe SC does however exhibit significant cross-national variation. The coefficients shown in Figure S5 are again on the Fisher's z scale; we first therefore discuss the rank ordering of countries and the significance of differences between them, rather than magnitude: Bulgaria and Spain exhibit the largest correlations, followed by France and then the US. The coefficient for the US does not differ significantly from that of the next few countries: Czechoslovakia, the Netherlands, Germany, Australia, Poland, Russia, and the United Kingdom. Continuing in descending order, Sweden, Hungary, Scotland, Norway, Finland, Denmark, and finally the former East Germany all exhibit significantly lower sibling correlations than the US (at the .05 level).\n\nThe random-effects model conservatively assumes that the true effect may vary even across different nationally representative samples of a given country and cohort, for instance due to subtle unmeasured differences in survey design and data quality. Under the alternative fixed-effects meta-regression, with its assumption that sampling error is the only source of differences between different estimates within each country and cohort, contrasts between the US on the one hand and the Netherlands, Germany, Australia, and the UK are all statistically significant at p &lt; . 001.\n\nThough the US differs significantly from the Nordic countries under the random-effects assumption, it is worth emphasising that the random-effects model produces especially conservative standard errors in the case of the Nordic countries, where estimates are based exclusively on register data. The availability of such comprehensive and high-quality data makes the collection of further samples redundant. From the perspective of the random-effects model however, this is equivalent to sampling just one estimate from a normal distribution of true effects.\n\nTo give an indication of the magnitude of the differences between countries\n\nFigure 3: Predicted sibling correlations with 95 % confidence intervals, by country, from a random-effects meta-regression on country and cohort. Birth cohort held constant at 1960s.\n\n<!-- image -->\n\nNote: For the meta-regression analyses, England is coded as United Kingdom and West Germany as Germany.\n\non the correlation scale, we plot in Figure 3 predicted sibling correlations for each country, holding birth cohort at 1960. This yields predictions mostly in the range .4 to .5, with only Bulgaria, Spain, and France higher, and Finland, Denmark, and East Germany lower.\n\n\n## Income inequality\n\n\nWe next present meta-regressions of SCs on two different measures of income inequality. Each SC estimate in this case represents a single 'context,' or countrycohort combination, such as those born in France in the 1970s. To arrive at these country-cohort estimates ( N = 80), we take, separately for each context, the weighted mean from a random-effects meta-analysis of all available samples of that context. These country-cohort estimates are shown in Table 3, which also indicates for which contexts each measure of income inequality is available. Table S2 in the Supplementary Materials additionally shows each context's value for each income inequality measure.\n\nTable 3: Country-cohort meta-analytic sibling correlation estimates\n\nNote: italics indicates the top decile share measure is available, bold indicates the Gini measure of income inequality is available. Bold and italic indicates both measures are available.\n\nTo measure income inequality, we first use Gini coefficients from the World Income Inequality Database (WIID) Companion dataset (Grad´ ın, 2021a,b; UNU-\n\nWIDER, 2022a). 8 In most cases this measure is only available from the 1960s onward. Second, we use top decile shares of pre-tax national income from the World Inequality Database (wid.world). This measure is available for more of our contexts and extends back to the early 20th century in some cases. In each case, we average all available values for the decade following the cohort's decade of birth, to capture conditions prevailing while sample members were in education.\n\nIncluding all available country-cohort contexts, the association is weak and non-significant when using the Gini ( p = 564, Figure 4). . Driven by the early 20th century US, the association is significant when using top decile shares ( p = . 002). A cluster of high sibling correlation-low inequality points from Eastern Bloc countries raises the question of whether the hypothesis of a Great Gatsby Curve (GGC)-type association meaningfully applies in these contexts. Previous studies of the GGC which identified useable data for these countries have nevertheless excluded them, arguing that theorized GGC mechanisms depend upon democracy and a market economy (Andrews and Leigh, 2009; Jerrim and Macmillan, 2015).\n\nMight it be possible to argue that the Eastern Bloc cases in fact represent a cluster of low-inequality countries which are within the scope of the GGC hypothesis but fail to support it? This argument does not seem strong. The literature attests a number of mechanisms specific to the state-socialist context by which advantaged parents were able to secure educational success for their children even under conditions of relative income inequality, Communist Party membership being an important example (Hanley, 2001; Hanley and McKeever, 1997; Shavit and Blossfeld, 1993). 9 Studies of inequality in postsocialist transitional societies emphasize the role of long-standing networks of clientelism (Nee and Cao, 2002). We therefore present results excluding these state-socialist contexts.\n\nResults shown in Tables 4 and 5 extend our analysis and enhance its interpretability. Table 4 shows additional specifications including cohort and country fixed effects. For both measures, associations are similar albeit somewhat attenuated when analysing within-cohort cross-national variation. When analyzing within-country variation across cohorts, results diverge and the association remains evident with the top share measure-whether including or excluding the early 20th century US observations-but not with the Gini. This divergence would appear to result from the narrower range of cohorts and lower number\n\n    (    )\n\n<!-- image -->\n\n<!-- image -->\n\nTable 4: Meta-regressions of country-cohort sibling correlation estimates on income inequality\n\nNotes: ∗ p &lt; 0 05, . ∗∗ p &lt; 0 01, . ∗∗∗ p &lt; 0 001. . FE: fixed effects. Coefficients are on the Fisher's z scale; see text.\n\nTable 5: Meta-regressions of country-cohort sibling correlation estimates on income inequality: predictive margins on the correlation scale at selected values\n\nNotes: ∗ p &lt; 0 05, . ∗∗ p &lt; 0 01, . ∗∗∗ p &lt; 0 001. . FE: fixed effects.\n\nof observations overall for which the Gini measure is available. There are more than three observations for only Norway and the US, which each exhibit little change in the Gini across the period covered. The top decile share result is similarly non-significant and imprecisely estimated when restricting analysis to the Gini sample. Estimates become highly imprecise when including both cohort and country fixed effects. We thus find qualified support for an association between income inequality and the SC both cross-nationally within cohorts, and within countries across cohorts.\n\nBecause the meta-regressions are run on estimates transformed to the Fisher's z scale (as is the norm in meta-analysis), the slopes of the meta-regressions are slightly nonlinear on the original correlation scale. Figure 4 and Table 4 should therefore be interpreted in conjunction with Table 5, in which we present change in the predicted SC across a relevant .1 contrast in our contextual indicators. Focusing on the results shown in Figure 4, a .1 increase in the Gini from .25 to .35 is associated with a .077 increase in the SC. Moving from a top decile share of 25 % of pre-tax income to 35 % is associated with a .087 increase in the SC-comparable to the difference between the US and Norway presented in Figure 3.\n\nExisting estimates of GGCs take countries as the unit of analysis and focus on a single birth cohort. Cohort fixed-effects are one way of accounting for dependence between multiple cohorts from the same country. As a robustness check we additionally re-run the meta-regressions from Figure 4 with the robust variance estimator of Hedges et al. (2010), using the user-written Stata command robumeta (Hedberg, 2014). The associations are almost identical in magnitude and remain statistically significant with both the Gini ( p = 024) . and top decile share measures ( p = 006; . p = 014 excluding the three early US . cohorts). 10\n\n\n## Discussion\n\n\nThe sibling correlation (SC) represents an estimate of the total effect of social origins, capturing the influence of all factors that increase sibling resemblance on an outcome. We have termed such factors, which include ethnicity and all aspects of parental socio-economic position, a sibling set's 'common inheritance,' and contrasted it with the 'individualizing factors' that generate sibling differences. The SC thus measures inequality of opportunity insofar as common inheritance corresponds to ascription and individualising factors to achievement.\n\nSCs in education have been much-studied, but only rarely used in compar-\n\native research despite their attractive properties for this purpose. We aimed to exploit this opportunity by systematically searching the literature and collating all available estimates of SCs in educational attainment, using meta-regression to explore variability in the estimates, and examining how they vary across contexts marked by different levels of income inequality. Existing accounts of the link between economic inequality and intergenerational persistence have suggested educational inequality of opportunity plays an important intermediating role, but prior research has not explored whether the total effect of social origins on educational attainment systematically varies with income inequality.\n\nOur two most important findings concern country differences in SCs and the strong positive association between the SC and income inequality.\n\nThe SC exhibits substantial cross-national variation. Of the (primarily European) countries for which we find estimates, Spain and Bulgaria stand out as having the largest correlations (.60; see Figure 3), while the former East Germany is at the lower extreme (.28), echoing the findings of Betth¨user's (2019) a study of German reunification. Within the narrower range spanned by the majority of countries, France (.54) and the US (.50) are at the top end, and Norway (.41), Finland (.37), and Denmark (.34) at the lower end. It is important to understand the strengths and limitations of producing a single number for each country. These should be interpreted as reflecting average differences between countries, for cohorts born across the early to late-middle 20th century. This is necessarily an exercise in data smoothing.\n\nThese results nonetheless make an informative contribution to the comparative study of educational inequality. Prior country rankings have all been based on associations between parental education or occupation, and children's education (Beller and Hout, 2006; Hertz et al. , 2008; Jerrim and Macmillan, 2015; Pfeffer, 2008). They capture only part of the effect of social background on education-a part whose size as a portion of the total effect may vary crossnationally. A point of wide interest as regards such rankings, and a popular topic more generally, is the position of the US relative to the Nordic countries (Andrade and Thomsen, 2021; Heckman and Landersø, 2022; Karlson and Birkelund, 2024). We find significantly lower SCs in Sweden, Norway, Finland, and Denmark than the US, with US sibling correlations on the order of .1-or 25 %-higher. 1112 In terms of the rank ordering of this subset of countries, our results are thus broadly in agreement with Jerrim and Macmillan (2015) and the intergenerational correlation results of Hertz et al. (2008), but not-particularly\n\nas regards Sweden and Norway-with those of Beller and Hout (2006), Pfeffer (2008), or Hertz et al. 's (2008) intergenerational coefficient results. It is beyond the scope of this study to explain differences among these other rankings, but future research should do so in the context of our results and, further, try to identify and comparatively study the unobserved factors captured in the sibling correlation that are masked in measures based on intergenerational associations. More data collection and analysis inclusive of all of the 'big four' dimensions of socio-economic status would be an important step in this direction, as would work using genetically-sensitive designs (H¨llsten and Thaning, 2022). a\n\nWe find larger SCs in educational attainment among cohorts growing up under conditions of greater income inequality. We are aware of no prior tests of this relationship, and the results provide support for theoretical accounts of the Great Gatsby Curve that emphasize education as a mediating pathway in the link between economic inequality and social immobility (DiPrete, 2020; Durlauf et al. , 2022). The mechanisms implied by these accounts are varied and multi-sited, from constraints on family investment, to neighborhood and school segregation, to the effects of inequality on the political process and support for public education. The policy implication of our finding is that greater equality of educational opportunity likely requires a reduction in economic inequality.\n\nGreat Gatsby Curve-type findings typically present a cross-sectional association. We harness observations of multiple cohorts to also test for a withincountry association, and find qualified support for this. The finding is sensitive to the measure of income inequality used, though primarily because one is available for a wider range of contexts. Behind this overall finding, the data we have collated show that the US descends in both income inequality and the SC in three fairly distinct steps (1900-20, 1930, 1940-70), and Australia follows a similar trend. 13 Albeit somewhat noisily, the Netherlands, Sweden, and UK also tend in this direction across cohorts. Norway's SC is stable in the face of a declining top share of income, while Germany's exhibits trendless fluctuation against a stable top share. The association between income inequality and the SC is complex and contingent, but our results show a correlation between the two in aggregate.\n\nWe have three other noteworthy results. First, despite seeking all available SC estimates, in the end our sample is one of mostly mid-20th century cohorts from the Global North-specifically Europe, the US, and Australia. The main barrier to including existing estimates from Global South countries was sample inclusion depending on co-residence; education is likely to influence co-residence patterns among adult siblings. 14 The addition to existing surveys of questions\n\nasking about family members outside the household would be valuable.\n\nOur income inequality results are particularly striking in this light: for the most part we are looking through a narrow window offering a view dominated by low-inequality contexts. We miss many high-inequality contexts from the early 20th century, whole other regions in the mid-to-late 20th century, and the widespread increase in income inequality from the 1980s onward. We would expect at least as strong an association to be evident if we had more estimates from these three broad sets of contexts.\n\nSecond, SCs between sisters are modestly higher on average than between brothers and between all siblings regardless of sex. This implies that even in the mid-to-late 20th century Global North where our estimates are concentrated, women's educational opportunities have tended to be more strongly constrained by social origin factors than men's. Since sex is a source of inter-sibling difference, sex-specific SCs are a preferable measure of inequality of opportunity. Figure S7 in the Supplementary Materials shows that the pattern of country differences changes little when brother-only and sister-only correlations are used. However, we found sister correlations for a relatively narrow range of contexts and therefore used (modelled) all-siblings correlations to accomplish our aim of comparison across a wide range of contexts. Future studies should report sex-specific SCs in addition to all-siblings ones.\n\nThird, we find no overall differences between cohorts in the size of the SC. While this result is based on a meta-regression including country as a covariate, one should interpret it whilst keeping in mind the unbalanced nature of our panel (see Table 3). Data on earlier cohorts from more countries may have yielded a different conclusion with respect to the overall pattern of temporal change. We have used our limited space to focus on other questions, but this result and the data we have collated may be of interest to scholars of temporal change in the origins-education link. Further research should compare our estimates to those from in-depth country-specific studies based on intergenerational associations, which have reached conflicting conclusions (Breen et al. , 2009; Breen and M¨ller, u 2020; Shavit and Blossfeld, 1993).\n\nAn important limitation is that the estimates we analyze refer to years of educational attainment and thus assume that all years of education are of equal standing. However, advantaged families seek qualitative as well as quantitative differentiation in their children's educational credentials (effectively maintained inequality, Lucas, 2001). Our analysis is blind to such qualitative inequality, though we would expect it to play the most pronounced role in countries with an elite stratum of higher education, such as the US, UK, and France. Nordic higher education is less stratified, suggesting that our main conclusion contrasting the latter with the US is only reinforced by this consideration. We also\n\nnote cautiously that that Pfeffer (2008, p. 549) undertakes a stability analysis incorporating differentiation into academic and vocational streams, and reports that 'These atalyses do not yield any evidence of systematic bias arising from the exclusive focus on the vertical dimension of the educational hierarchy.'\n\nWe have already discussed the nature of SCs at some length. Briefly, however, some further limitations should be noted. First, SCs are restricted to families with two or more children in most cases, albeit only-children can be included in a variance decomposition approach. Across the 20th century, onlychildren have tended to comprise no more than 12.5 % of each birth cohort in the countries we examine, Russia being an exception (Pr¨g a et al. , 2020). Differences between only-children and others in terms of social background and educational outcomes vary across contexts, but we are aware of no reason to believe the explanatory power of family background varies systematically between the two groups (Choi and Monden, 2024; Gr¨tz a et al. , 2021). Further, we have shown above that conditional on sibship type and dataset-cohort, estimates including only-children are not significantly different from those that exclude them, in the set of estimates we find. Nonetheless, this is a substantial subpopulation that most of our estimates exclude.\n\nSecond, as regards comparability, the need for data on multiple siblings entails a risk of studies diverging in their sample construction in potentially consequential ways. Our inclusion criteria help to mitigate this risk, and our meta-regression results suggest that the most prominent differences of approach are not systematically related to the size of the estimated correlation. Some studies imposed further restrictions which we did not measure and include, as most studies did not describe their sample construction to that level of detail. The main such concern surrounds restrictions on the age spacing of siblings, as siblings closer in age are likely to experience a more similar environment. However, an explicit comparison of results for closely- and widely-spaced siblings in Norway and the US 'does not find any substantial differences' (Bj¨rklund and o Salvanes, 2011, p. 208). Another such concern is that differences may arise between designs where a parent reports their children's education and those where an individual reports their siblings' education. Sieben (2001) tests this possibility on a wide range of datasets and finds no significant differences. Finally, studies usually did not clarify whether half- or step-siblings were included. This likely reflects relatively low levels of family complexity across the contexts under study. However, family complexity has grown across societies in recent decades (Van Winkle, 2018; Van Winkle and Fasang, 2021), so future studies of younger cohorts will need to attend to this distinction.\n\nAbove, we compared SCs with heritability as a measure of equality of opportunity. One attraction of heritability is that, unlike the SC, it isolates the explanatory power of genes-within a given environmental context, it must be\n\nemphasized. This is an important consideration for educational attainment since heritability may widely exceed 50 % when assortative mating is taken into account (Wolfram and Morris, 2023). On the other hand, current molecular genetics estimates suggest far lower heritabilities (Fletcher et al. , 2023; Howe et al. , 2022), albeit methodological advances may in future reduce this missing heritability (Tropf et al. , 2017). We would sound a note of caution, however, as to the further claim that by disentangling common environment and genes, heritability automatically points to clear policy implications. 'Heritability does not imply immutability' (Plomin et al. , 2016, p. 4). It is by no means clear that genetic differences either cannot or should not be attenuated by educational policy (Engzell and Tropf, 2019; Fishkin, 2014; Manski, 2011).\n\nWe hope that the results reported here act as a spur for further research. A similar review of SCs in other stratification outcomes would be illuminating. We found comparisons of correlations for different outcomes within a given sample (Conley and Glauber, 2008) and tabulations of selected estimates of correlations in long-run earnings (Bj¨rklund and J¨ntti, 2020; Schnitzlein, o a 2014), but no comprehensive account. Our dataset of SC estimates is available for others to use. We have also identified many contexts of interest for which we do not currently have such estimates. Estimates for cohorts that have recently completed their education will shed further light on the role of (recent increases in) income inequality. The more we can expand coverage beyond the contexts examined here, the richer will be our picture of the broad-scale institutional determinants of equality of opportunity.\n\n",
         "The sibling correlation (SC) estimates the total effect of family background, or 'social origins,' and may be interpreted as measuring a society’s inequality of opportunity. Its sensitivity to both observed and unobserved factors makes it an all-encompassing measure and an attractive choice for comparative research. We gather and summarise all available estimates of SCs in educational attainment (M = .46, SD = .09), before employing meta-regression to explore variability in these estimates. First, we find significantly lower SCs in Sweden, Norway, Finland, and Denmark than the US, with US correlations on the order of 0.1 -- or 25% -- higher. Most of the other (primarily European) countries for which we find estimates fall in between. Second, we find a novel Great Gatsby Curve-type positive association between income inequality in childhood and the SC, both cross-nationally and within countries over time. This supports theoretical accounts of the Great Gatsby Curve that emphasize the role of educational inequality as a link between economic inequality and social immobility, and implies that greater equality of educational opportunity likely requires a reduction in economic inequality. Additionally, we find that correlations between sisters are modestly higher on average, and we find no overall differences between cohorts.",
         ""
        ],
        [
         "33",
         "33",
         "## 1. INTRODUCTION\n\n\nWe suggest that dualisation and downward de-dualisation can be interpreted as two phases of the labour market liberalisation process by scrutinising fifty years (1970-2020) of reforms in Spain and Italy.\n\nDualisation literature argued that trade unions and social-democratic parties partially deflected international pressures for employment protection reduction and wage moderation, contributing to an expansion of the secondary labour market segment. Therefore, unionised workers with permanent contracts ('insiders') preserved their labour market protection and employers acquired cheaper and flexible workforce via the proliferation of atypical contracts (available for 'outsiders'). The result has been a growing labour market dualism: a regulatory divergence  in  employment  protection  and  other  labour/policy  rights  for  employees  under different contract types (Busemeyer and Kemmerling, 2020).\n\nLabour  market  dualism  in  continental  and  Mediterranean  Europe  came  to  be  considered  a different  model  of  employment  relation  in  comparison  to  liberalism  in  the  Anglosphere (Emmenegger  2014).  Therefore,  dualisation  has  been  perceived  as  a  stable  alternative  to liberalisation (Emmenegger et al., 2012; Rueda, 2005; Thelen, 2014; but see Ferragina and Arrigoni  2021).  However,  after  the  Great  Financial  Crisis  (GFC),  research  has  shown  a reduction of labour market protection in Mediterranean and continental Europe also for insiders (Eichhorst &amp; Marx, 2021; Prosser, 2016). As insiders were previously regarded as shielded from liberalisation pressures, this development necessitates an updated framework to explain shifting patterns of labour market protection. Our research endeavour moves from this context: (1) how can labour market protection reforms be categorised according to their (de)commodification potential for insiders and outsiders? (2) How can we interpret long-run labour market protection reform trajectories in relation to dualisation and liberalisation?\n\nWe contribute to the literature in two ways. First, we develop a taxonomy of labour market protection reforms in relation to their (de)commodification potential (Polanyi 2001). Our work offers a classification methodology to code qualitatively policy change and its intensity. This allows replicability of the study and a transparent appraisal of our interpretation based on a systematic classification of labour market policy reforms in Spain and Italy (for a database of reforms see Appendix Table A1). This classification can be applied to other policy fields and countries.  Second,  we  interpret  a  fifty-years'  reform  trajectory  in  Spain  and  Italy  -  two prominent examples of labour market dualism - employing  comparative historical analysis (CHA).\n\nWe  define  liberalisation  as  a  process  of  commodification  through  which  market  relations expand into more spheres of social life (Polanyi 2001). Decommodification entails instead a reduction of the weight of market relations in these spheres. Commodification enhances greater discretionary  power  for  market  dynamics  and  employers,  while  decommodification  offers protection for workers: 'politics for markets' (commodification) vs. 'policy against markets' (decommodification) (Esping-Andersen's 1985).\n\nBuilding on Eichorst and Marx (2021), we develop an eight-fold taxonomy of labour market protection  reforms  on  the  basis  of  their  (de)commodification  potential  for  insiders  and outsiders, and we apply it to three policy domains (employment, unemployment and collective protection).  A  commodification  process  entails  a  reduction  of  employment  protection,  a retrenchment of unemployment protection, and a decentralisation of bargaining negotiations (Baccaro and Howell 2011; 2017; Emmenegger 2014; Esping-Andersen 1990; Ferragina and\n\nFiletti 2022; Picot and Tassinari 2017). Dualisation takes place if outsiders are commodified to a larger extent than insiders, while de-dualisation entails a reduction of protection inequality among them. (De)commodification processes can hit insiders and outsiders independently, and therefore  labour  market  protection  reforms  can  increase  or  decrease  dualisation  upward  or downward.\n\nApplying this taxonomy to Spain and Italy we observe a process of 'liberalisation through dualisation' characterised by two phases: (1) from a crumbling Fordist order to dualisation which  mainly  hit  outsiders'  protection,  and  (2)  downward  convergence  of  labour  market protection for insiders. Spain and Italy both experienced liberalisation through dualisation, but exhibit differences in the timing and characteristics of the legislative process. This original account advances research on labour market protection trajectories by investigating the end of dualisation equilibrium and reframing it as part of a broader liberalisation process.\n\nIn Spain, the authoritarian and corporatist Fordist model was quickly eroded with the transition to  democracy.  Deep  economic  and  political  changes  led  to  a  key  reform  in  1984  which generalised the use of temporary employment, rapidly creating a dual labour market. In Italy, the resistance to substantial labour market protection reforms extended through the 1970s and 1980s,  with  upward  dualisation  in  unemployment  protection  and  a  dynamic  of  wage moderation. Significant contextual changes led to reforms in 1997 and 2003 which fostered the use of atypical contracts (Ferragina and Arrigoni 2021).\n\nIn both countries, downward de-dualisation followed these reforms. In Spain, reforms during the 1990s - with an acceleration during the GFC - reduced employment, unemployment and collective protection for insiders. Italy joined Spain in the labour market liberalisation process (reducing EPL for insiders) in the aftermath of the GFC. However in the Italian case, outsiders lost further employment and collective protection; a change only partially compensated by a modest improvement of unemployment protection.\n\nIn what follows, we review the literature on dualisation and develop our taxonomy. We then historically  trace  labour  market  protection  reforms  in  Spain  and  Italy.  We  conclude  by comparing the two cases and illustrating some general implications of the study.\n\n\n## 2. LITERATURE REVIEW\n\n\nThe demise of Fordism put under pressure the system of labour market relations established in the post-WWII period (Jessop 1993). Since the late 1970s, stagflation, deindustrialisation and the rise of the service sector transformed the structure of the Spanish and Italian economies and their workforce composition (Amin 1994; Ferragina et al. 2022). Globalisation and the fall of the Bretton Woods' monetary agreement increased international competition, capital flows and contributed to the financialisation of the economy (Boyer 2000; Strange 1997; Watson 2009). The 1980s witnessed a rise of neoliberal ideas, a shift from demand- to supply-side politics, and the promotion of market-based solutions to social and political problems (Harvey 2005; Mirowsky  and  Plehwe  2009).  As  a  reaction  to  these  international  political  economy developments, Spain and Italy increasingly competed on labour costs with strong downward pressures on wages and employment protection (Baccaro and Howell 2011; Bengtsson and Ryner 2015; Burrows et al. 1992, Ferragina and Arrigoni 2021).\n\nDualisation literature explores how trade unions contributed to deviate these pressures towards peripheral labour market segments. This literature rests on a distinction between insiders (with permanent contracts) and outsiders (with atypical contracts). Emmenegger (2014) argues that trade  unions  in  the  UK  unsuccessfully  attempted  to  enforce  an  intransigent  defence  of  all workers' protection against the liberalisation process, while in continental and Mediterranean Europe, trade unions accepted an alternative strategy of concertation. This consisted in the diffusion of atypical contracts, which resulted in a dual labour market.\n\nEconomic, social and political arguments support the contention that dualisation is a stable alternative to liberalisation. In economics, scholars suggest that dualisation benefits insiders securing their wages and employment protection - and disfavours outsiders that support on their shoulders the cost of economic crises (Bentolila et al. 2012; Polavieja and Richards 2001). Dualisation as a stable equilibrium would be also anchored to employers' interests and the structure  of  the  economy.  Palier  and  Thelen  (2010)  argue  that  dualisation  in  France  and Germany was the result of a producer coalition between manufacturing employers and insiders. This also resonates with the idea that a two-tier labour market represents a functional match with the economic structure of Continental and Mediterranean countries, characterised by a core manufacturing sector and a large and low-productivity service sector (Eichorst and Marx 2021). Another argument for the stability of dualisation is that insiders can defend their labour market protection because they are more socially and politically relevant than outsiders. Rueda (2005, 2006) develops a partisan line of reasoning, asserting that workers in manufacturing industries (insiders) form the core constituency of social-democratic parties. Outsiders are less politically mobilised (Esping-Andersen 1999) and this creates powerful incentives for workers' representatives to defend a dual equilibrium Bonoli 2005). Simoni and Vlandas (2021), in a more nuanced way, argue that trade unions may not favour dualisation per se , but just accept it  in  exchange  for  social  democratic  government  concessions  in  other  policy  fields  (e.g. unemployment protection).\n\nAgainst these elements of stability, recent scholarship shows that Mediterranean labour market protection  reform  trajectories  are  complex.  The  EU  and  the  IMF  influenced  governmental action, requesting labour market liberalisation measures to access bailout funding (Balbona and Begega 2015; Hastings and Heyes 2018). In Spain, labour market reforms in 2010 and 2012 eroded  collective  bargaining  institutions,  retrenched  unemployment  benefits  and  cut  down dismissal  costs  (Cárdenas  and  Villanueva  2021;  López  Andreu  2017;  Picot  and  Tassinari 2017). The picture is similar in Portugal (Cardoso and Branco 2018) and Greece (Matsaganis 2019; Theodoropoulou 2016). The position of Italy is more contentious. Picot and Tassinari (2017), considering reforms between 2010 and 2015, argue that differently from Spain, Italy is not a case of liberalisation. This is because despite a reduction of dismissal costs for permanent workers, the government increased the coverage of income support and active labour market policies. Other scholars taking a longer term view and considering the 2015 Jobs Act argued that overall reduction in employment protection shapes a process of 'selective neoliberalism' despite a limited extension of coverage in other domains (Ferragina and Arrigoni 2021).\n\nWhile the literature might hint to the fact that the age of dualisation ended in Mediterranean countries, there is divergence on how to characterise the new phase.\n\nSome  research  suggests  that  insider  and  outsider  protection  is  converging  downwards  interpreting  current  reforms  as  a  reduction  of  protection  of  hitherto  untouchable  insiders (Prosser 2016). Eichhorst and  Marx  (2021)  confirm  this  interpretation by  reviewing employment protection legislation (EPL) across 9 countries. They find that Italy, Spain and France display a trajectory of 'downward de-dualisation'. With this concept, they refer to the deregulation and flexibilisation of permanent contracts, which reduced inequality of protection between  insiders  and  outsiders.  Along  the  same  line,  Ferragina  and  Filetti  (2022)  show  a reduction  of  EPL  for  permanent  contracts  across  Europe  -  a  widespread  trajectory  of liberalisation. Although these studies concentrate on liberalisation processes after the GFC, some research shows that some downward de-dualisation has happened also before (in the Spanish case, Sola 2013).\n\nIn contrast to this strand of literature, other scholars interpret the reform process as an upward de-dualisation trend; where outsiders conditions have improved thanks to the promotion of more inclusive social assistance and enhanced employment protection.  Tassinari et al. (2023) consider the introduction of employment protections for temporary and platform workers in Spain as the provision of greater protection for outsiders. Similarly, Branco et al. (2024) argue that Spain's 2021 labour reforms addressed temporary employment and introduced protections for  platform  workers,  while  Portugal's  2023  'Decent  Work  Agenda'  focused  on  reducing precarious work and increasing employment protections for outsiders. In the Italian case, some scholars argued that unions shifted their role from opposition to active support of a minimum income scheme that would benefit outsiders (Jessoula and Natili 2020; Natili and Puricelli 2023; Cigna 2024; Cigna and Fabris 2024).\n\nThis  literature  demonstrates  that  labour  market  dualism  in  Mediterranean  Europe  has  been shaken, however there is no agreement and sufficient empirical evidence on how to interpret the long-term trajectories of labour market protection reforms. Scholars addressing employment protection and generosity and duration of contributory benefits interpret the longterm trajectory as downward convergence, while others focusing on mostly assistance-based benefit coverage and active labour market policies portray it as upward convergence.\n\nWe foresee at least two major gaps in the literature. First, it does not offer a taxonomy and empirical  categorisation  of  labour  market  reforms  that  embrace  not  only  changes  in employment protection but also in unemployment and collective protection. Second, it does not  provide  a  systematic  and  comparative  long-term  view  of  such  changes  in  the  largest Mediterranean countries. We propose to address this gap by (1) developing a taxonomy of the (de)commodification potential and intensity of each reform and (2) systematically interpreting long-term  reform  trajectories. Substantively,  we  illustrate empirically  that the age  of dualisation is part of an overall process of liberalisation in Spain and Italy. In the process, we devise a replicable and transparent methodology that can be applied beyond labour market reforms and Mediterranean Europe.\n\n\n## 3. RESEARCH DESIGN\n\n\n\n## 3.1. Taxonomy of Labour Market Protection Reforms\n\n\nThe  dualisation  concept  denotes  preservation  of  labour  market  protection  for  insiders  and deregulation  for  outsiders,  while  liberalisation  refers  to  overall  deregulation.  Moving  from Polanyi (2001) we define labour market protection liberalisation as a commodification process. On the one hand, commodifying reforms increasingly transform a 'fictitious' commodity like labour into a marketable component of the productive process. On the other hand, reforms going into the opposite direction (decommodifying) re-embed labour into the social sphere, constituting  a  countermovement  of  increased  social  protection.  Commodifying  reforms increase the power of employers in controlling job creation and destruction, workplace activity, wages,  and  other  working  conditions.  Instead,  decommodifying  reforms  limit  market dynamics, establishing workers' rights such as maximum working hours, minimum wages, dismissals regulations or collective organisation.\n\nLabour market reforms may either affect both insiders and outsiders simultaneously, or each of them independently. We define insiders as workers employed through typical permanent contracts  and  outsiders  as  those  employed  with  other  contractual  agreements.  Dualisation happens when inequality between both groups increases, while de-dualisation is the opposite process. We evaluate each labour market reform using the concepts of (de)commodification and (de)dualisation. To account for both dimensions simultaneously, we consider whether a reform moves in a decommodifying (upward) or commodifying (downward) direction, and whether  it produces  dualisation  or  de-dualisation.  The  result  is an  eight-fold reform categorisation (Figure 1).\n\n## [Figure 1]\n\nWe owe to Eichorst and Marx (2021) the idea that de-dualisation can happen in an upward, downward  or  stable  liberalisation  direction.  We  extend  their  argument  in  two  ways:  (1) considering that dualisation can also take place 'upward' (with an increase of protection for permanent contracts) or 'downward' (with a decreased protection for atypical contracts); and (2)  including  unemployment  protection  and  collective  bargaining  other  than  employment protection.\n\nThe nine quadrants in Figure 1 represent the reform categories resulting from varying degrees of  (de)commodification  among  insiders  and  outsiders.  The  four  corners  represent  pure (de)commodification  or  (de)dualisation  when  reforms  affect  both  insiders  and  outsiders (quadrants 1, 3, 7 and 9). If decommodification levels for typical contracts remain constant, higher decommodification for atypical contracts entails upward de-dualisation (quadrant 6), while  higher  commodification  levels  constitute  downward  dualisation  (quadrant  4).  When decommodification for atypical workers is constant, higher decommodification level for typical contracts  entail  upward  dualisation  (quadrant  2),  while  lower  decommodification  levels constitute downward de-dualisation (quadrant 8).\n\nOur  taxonomy  considers  both  whether  a  reform  increases  or  decreases  inequality  between permanent and atypical contracts, and how decommodification levels can change for insiders and outsiders independently. This conceptual demarcation between dualisation and liberalisation  helps  to  clarify  how  reforms  impact  (de)commodification  levels  overall  and, therefore in a Polanyian sense, whether a process of liberalisation is in route. We consider that downward  reforms  commodify,  and  upward  reforms  decommodify,  while  contradictory reforms for permanent and atypical contracts range in between (note the grey dashed line in Figure 1). It follows that if an increased protection for permanent contracts drives dualisation, the reform does not contribute to commodification (although it amplifies inequalities between permanent and atypical contracts).\n\n\n## 3.2. Data and Methods\n\n\nWe  proceed  in  two  interrelated  steps:  (1)  we  classify  each  reform  in  the  domains  of employment, unemployment, and collective bargaining protection and measure its intensity. We go beyond employment protection because income support during unemployment and the regulation of workers' bargaining capacity are areas where (de)commodification in a Polanyian sense is explicit.  Reform data is extracted from governmental and official sources, and then 1\n\nanalysed according to our taxonomy. For each reform, we code separately its implications across  the  three  policy  fields.  (2)  We  carry  out  a  CHA  of  the  Italian  and  Spanish  reform trajectories  for  the  period  1970-2020.  The  CHA  is  based  on  our  reform  classification, contextual data and secondary literature.\n\n## (1) Reforms Classification\n\nWith reference to employment protection, we consider as commodifying reforms that reduce EPL and severance pay. To distinguish reforms that dualise from those that de-dualise, we analyse  the  conditions  the  legislation  imposes  on  permanent  and  temporary  contracts. Concerning unemployment protection, we consider commodifying those reforms that retrench generosity or reduce the duration of unemployment benefits (UB). Therefore, commodifying UB constitutes downward de-dualisation because it largely affects insiders. Dualising reforms are  those  that  impose  harder  conditions  of  access  (such  as  longer  periods  of  work  and contribution) and vice-versa. In regard to collective protection, we consider as commodifying reforms those that decentralise collective bargaining, hamper the ability or validity of collective agreements,  and  affect  the  wage-setting  system  in  favour  of  employers.  We  observe  that commodifying collective bargaining reforms affect both insiders and outsiders, except if they directly  influence  the  ability  of  different  contractual  categories  to  organise  and  bargain employment conditions.\n\nWe also code the intensity of each reform on the basis of Hall's (1993) classification of policy change. Hall's framework distinguishes between first-order changes, which adjust the level of a policy instrument, second-order changes, which alter both the level and the instrument, and third-order changes, which reshape the overarching policy goals. We adapt this approach to labour market reforms as follows. First-order reforms adjust a single policy aspect, such as increasing  the  duration  of  unemployment  benefits.  Second-order  reforms  modify  multiple aspects of a policy instrument or alter one to the extent that it transforms the instrument itself. Third-order reforms imply a fundamental redirection of labour market regulation.\n\nWe categorise each reform considered and its relevance in Table 1 for Spain and Table 2 for Italy (Table A1 describes all reforms considered). When a reform entails changes in more than a policy field, we classify the change in each of them independently. To our knowledge, this is the most detailed collection of labour market protection reforms in Spain and Italy over the analysed period.\n\nOur  qualitative  categorisation  of  reforms  helps  us  discerning  changes  that  are  invisible  to quantitative indicators. Figure A1 in Appendix shows how the OECD EPL indicator does not capture  several  reforms  we  observe.  We  support  Castles'  contention  (1994,  2002)  that qualitative case studies are key to capture policy change, because they provide a finer analysis of policy reforms than quantitative indicators (Taylor-Gooby 2002). However, differently from most qualitative work on policy change, our coding is replicable and transparent. The details provided in Appendix (Table A1) allows the reader to verify how each reform was coded. Therefore, our methodology can be applied to other policy fields and countries.\n\n## (2) Comparative Historical Analysis\n\nBy combining a deductive reform analysis with a systematic qualitative exploration of country trajectories,  we  provide  a  rich  historical  study  with  rigorous  analytical  foundations.  The analysis begins in 1970 because labour market protection was inscribed within a Keynesian\n\norder that preceded the dualisation and liberalisation processes. We exclude policy changes after the Covid-19 pandemic because our inquiry concerns long-term historical trends and these measures  might  be  contingent.   The  categorisation  of  each  policy  change  is  the  empirical 2 support of our analysis. However, limiting the inquiry to this step would obscure the long-term reform process. Therefore, the CHA  helps us to grasp temporally-oriented macroconfigurational outcomes grounded in well-established theories (Mahoney and Thelen 2015).\n\nIn  a  nutshell,  we  go  from  theory  (our  taxonomy)  to  a  deductive  empirical  approach  (our categorisation of each reform in eight categories), and back to our long-term interpretation (the CHA  based  on  dualisation  and  liberalisation  concepts).  This  research  process  requires  to aggregate sometimes small policy changes and therefore imposes some subjective choice. We reduce the degree of subjectivity employing: (a) comparative analysis, (b) established theories and (c) secondary literature to ponder the relevance of each reform. We acknowledge that there are no perfect data, methods or timeframes to measure policy change and scholars need to be humble  in  their  claims  and  in  drawing  implications  from  their  analysis  (Ferragina  2022; Wenzelburger et al. 2013).\n\n\n## 3.3. Case Selection\n\n\nSpain and Italy are prominent examples of labour market dualism due to their consistently high levels of atypical employment (Beramendi et al. 2015; Jara Tamayo and Tumino 2021) and fragmented labour market protection (Ferrera 1996). Low coordination between social partners and strong state intervention characterise the Mediterranean model of labour relations (Crouch 1993;  Mingione  1995).  This  contributed  to  high  support  for  male-breadwinner  industrial workers on permanent contracts, high informality, and limited protection for atypical workers (Ferrera 1996). Therefore, Spain and Italy can be considered as least-likely cases for a stable dualisation equilibrium to break, and constitute a hard test to verify whether a transition from dualisation to downward de-dualisation took place.\n\nSpain and Italy occupy a peripheral position in the International Political Economy context with  a  late  post-industrial  transformation  (Burroni  et  al.  2022,  Ferragina  and  Arrigoni Forthcoming ).  This  provided  their  governments  with  little  margin  of  manoeuvre  to  reform welfare  state  structures  in  a  period  of  'permanent  austerity'  (Bonoli,  2007,  Pierson  2001). Additional economic pressure came with the European integration monetary process, which contributed to further reducing their fiscal capacity to pursue demand-led growth and deprived them of  monetary  devaluation  tools  (to  compensate  for  the  lack  of  domestic  demand  with export-led growth, Baccaro et al. 2022).\n\nDespite being often categorised under the 'Mediterranean model', significant differences exist between the two countries (Burroni et al. 2022). The workers' movement and the organised left were historically stronger in Italy than in Spain. The authoritarian Francoist institutions shaped Spanish labour relations,  enforcing  a  top-down  system  of  social  concertation  and  reducing worker  organisation  and  demands  (Afonso  et  al.  2022).  There  are  also  differences  in  the political system. Post-WWII Italy saw the dominance of the Christian Democratic Party (DC), who hegemonised the political space with a variable geometry of alliances to its left and right. After  the  collapse  of  the  political  system  in  1992,  the  Italian  party  system  became  more fragmented and divided across two (centre-right and centre-left) blocs (until the GFC and the rise of the Five Stars Movement [M5S] and the far-right). This fragmentation and instability\n\nled  to  a  policymaking  process  characterised  by  numerous  interventions  and  non-linear legislative reforms. Conversely, the Spanish transition to democracy directly established an imperfect  two-party  system,  dominated  by  centre-left  and  centre-right  parties,  along  with smaller  but  influential  regional  and  left-wing  parties.  Therefore,  Spain  experienced  greater political  stability  and  the  executive  power  proposed  fewer  but  more  substantial  reforms (Estevez-Abe and León 2022).\n\n\n## 4. 'LIBERALISATION THROUGH DUALISATION'\n\n\nThis section classifies labour market protection reforms and their intensity (1, 2, 3) illustrating the  overall  path  of  'liberalisation  through  dualisation'  (Table  A1  provides  the  database  of reforms and details on the coding). We refer to each reform by their legal number and year, and we catalogue them with a country code and a progressive number (i.e. ES1, IT1; Tables 1 and  2).  Our  CHA  sequences  the  1970-2020  period  in  two  phases:  (1)  from  Fordism  to dualisation, and (2) downward de-dualisation. The reform trajectory is earlier and faster in Spain,  while  the  Italian  reform  process  is  more  complex  and  fragmented  (including  39 legislative interventions against 15 in Spain). Table 3 documents the number of reforms and their relative intensity for each period.\n\n[Tables 1, 2]\n\n\n## 4.1 From Fordism to the Age of Dualisation\n\n\n## The Spanish Swift Transition to Dualisation\n\nAfter decades of clandestineness, during the 1960s trade unions increased their strike activity. A reason for this conflict was the extension of collective bargaining with the 1958 Law , that 3 warranted annually renewed agreements in consideration of workers' demands (Tébar-Hurtado 2020). Labour market protection in the Franco era rested on employment stability; atypical contracts were used sparingly and with an enclosed justification (Galacho 2006). After Franco and the turbulent period of crisis, a rapid reform process normalised atypical employment.\n\nInitially the labour movement obtained the introduction of a comprehensive labour relations law  (L.16/1976;  ES1).  ES1  re-affirmed  that  temporary  contracts  were  'exceptions'  to  the principle of employment stability and restricted paid-free dismissal (employers were obliged to  rehire;  Art.35).  However,  Adolfo  Suárez's  government  (Union  of  Democratic  Centre [UCD]) suspended Art.35 a few months after its approval because of employers' opposition (Galacho,  2006).  In  1980  the  workers'  statute  (ES2)  constituted  the  foundation  (although without  providing  specific  legislation)  for  the  regulation  of  temporary  work,  part-time employment, unemployment protection, collective protection and increased dismissal flexibility. ES2 promoted temporary and part-time work, which in the words of the Labour Minister (Carlo Sotelo), should have helped to adjust workforce levels in times of economic uncertainty. Under this view, the permanent nature of contracts was a barrier for employers and the expansion of atypical employment aligned with the practices of the European Economic Community.  Beyond  safeguarding  temporary  contracts,  the  workers'  statute  increased  the margins for rehiring and dismissing at employers' discretion, and reduced the compensation for unfair dismissals (from 48 to 42 monthly wages; Galacho, 2006). The Communist Party (PCE) criticised these measures as they were 'opening the floodgates to dismissal'.\n\nIn this context, despite many voices in the political arena advocated for the liberalisation of dismissals to deal with the rigidity of the labour market and the high unemployment rate, the Socialist Party (PSOE) decided to promote further temporary employment (Wilhelmi, 2021). The González government built upon the worker' statute to depart from the stability of the previous  employment  model  and,  more  importantly  for  our  analysis,  to  choose  downward dualisation (L.32/1984;  ES3).  ES3  wanted  to  'mitigate  uncertainty  among  firms  and corporations regarding actions that drive job creation and in the necessary adjustment of the demand to the characteristics of the labour supply' (preamble ES3). It eliminated the necessity for  an  'extraordinary  cause'  for  temporary  hiring  and  expanded  the  variety  of  available temporary contracts. Temporary contracts had a maximum duration of 3 years with a fixed dismissal indemnity of 12 days per year worked, and also the length of apprenticeships and training contracts was extended (from 1 to 3 years; Galacho, 2006).\n\nThe effects of the reform manifested rapidly: 25% of the workforce had 'unjustified' temporary contracts in 1988. These prevailed among young people and low-skilled and seasonal workers (Toharia and Malo 2000; Arranz and García Serrano 2010). The employment recovery of the 1980s  relied  on  the  proliferation  of  these  contracts,  spreading  low  wages  and  weaker employment  and  collective  protection  (Galacho,  2006).  Meanwhile,  insiders  continued  to benefit from a comprehensive labour market protection.\n\nFrom our analytical perspective, ES1 (second order) and ES2 (third order) reforms maintained a Fordist regime. In contrast, ES3 brought a third-order change that opened the passage to the Age of Dualisation (Tables 1).\n\n## The Italian Complex and Fragmented Transition to Dualisation\n\nDuring the 1960s and the first part of the 1970s, worker activism led to a re-regulation of labour market protection. This can explain the strong resistance against liberalisation in the following decades. However, already towards the end of the 1970s and in a context of crisis, different governments began to prioritise  wage  moderation.  The  adoption  of  some  employment  and unemployment  protection  measures,  often  introduced  to  avoid  more  extensive  measures workers demanded, resulted in a protection system that segmented the labour force (low vs. high-skilled workers, big vs. small company workers): an anticipation of what would have become a dual protection system in the 1990s.\n\nArt.18  of  the  workers'  statute  strengthened  protection  against  unlawful  dismissals,  and provided compensation and reinstatement rights in workplaces with more than 15 employees (L.300/1970; IT1). In 1975, the system of wage adjustment to inflation (the so-called Scala Mobile) was revised with a beneficial mechanism ( punto unico di contingenza ) for low-wage earners  (IT2).  However,  growing  political  concerns  about  the  inflationary  potential  of  this measure rapidly led to a revision.\n\nIn 1977 the government and trade unions agreed on a social pact reducing the impact of the Scala Mobile revision on the indennità anzianità ( L.91/1977; IT3). Indennità di anzianità was calculated by looking at the latest wages of employees before retirement. IT3 brought to a calculation  of  the indennità  anzianità that  did  not  consider  IT2.  In  response, Democrazia Proletaria -  a  small  left-wing  party  -  submitted  a  referendum  to  repeal  IT3.  Voiding  this referendum, Spadolini's government replaced indennità anzianità with the Trattamento di Fine Rapporto (TFR)  (L.297/1982;  IT4):  a  deferred  wage  paid  to  workers  at  the  end  of  their employment history (a form of severance pay). Overall IT3/IT4 eroded some of the protection established with IT2. Wage moderation accelerated with a 15% cut of Scala Mobile ( Accordo\n\nScotti; IT5) and a further reduction proposal Craxi's government formulated (Socialist Party, PS)  (another  3%).  Trade  Unions  split  on  the  proposal:  CISL  and  UIL  agreed  (signing  the accordo  di  San  Valentino ;  IT6),  while  the  CGIL  rejected  it.  CGIL  and  PCI  called  for  a referendum to repeal IT6 in 1985, but they were unsuccessful.\n\nDuring the 1980s unemployment protection reform was characterised by upward dualisation, with the introduction of the Indennità di Disoccupazione Ordinaria (IDO) and the Indennità di Disoccupazione Ridotta (IDR) (L.160/1988; IT9). IT9 offered a low replacement rate (7.5%), had  short  maximum  durations  (6  months  for  IDO  and  156  days  for  IDR)  and  came  with eligibility  criteria  hard  to  meet  for  atypical  workers.  It  required  a  minimum  of  2  years  of seniority plus 52 weeks of contribution in the past 2 years for IDO and 78 days of contribution in the past year for IDR. The Cassa Integrazione Guadagni (CIG) - a fund covering payments for  working  hours  lost  during  the  suspension  of  productive  activities  in  certain  cases  and specific  industrial  sectors  -  continuously  expanded  since  the  post-WWII  period   until  two 4 legislative interventions introduced some limitations (L.160/1988 [IT9]; L.223/1991 [IT11]). The reform included also the creation of a special unemployment benefit ( indennità di mobilità) for  workers  that  reached  the  maximum  CIG  length.  Because  of  their  stringent  access requirements, IT9/IT11 created the conditions to magnify dualisation in conjunction with the subsequent employment protection reforms of the 1990s.\n\nBy the end of the 1980s, labour market reforms reflected a mix of early liberalisation and emerging  dualisation.  While  wage  moderation  hit  all  workers,  initial  signs  of  downward dualisation appeared through measures like the introduction of part-time (L.863/1984 [IT7]) and temporary contracts (L.56/1987 [IT8]). Simultaneously, elements of upward dualisation emerged, including the restrictive unemployment benefits introduced under L.160/1988 (IT9) and the partial expansion of dismissal protection through L.108/1990 (IT10), enacted to preempt a referendum on extending Art.18 to all workers. These fragmented reforms laid the groundwork for the more structured dualisation processes that took place in the 1990s.\n\nThe context of international and domestic crisis in 1992 - marked by the end of Cold War, the Mani Pulite judiciary  investigations,  and  the  draconian  economic  reforms  to  avoid  default (Ferragina et al 2022; Ferragina and Arrigoni 2021) - favoured a downward dualisation of labour market protection. Trade unions agreed to reduce protection accepting the abolition of Scala Mobile (IT12) and the extension of collective bargaining at territorial and firm levels 5 (IT13). Unemployment protection was strengthened to deal with the economic downturn and the  process  of  light  upward  dualisation  continued  in  line  with  1980s  reforms  (IT9/IT11). 6 L.236/1993 (IT14) increased the generosity of unemployment benefits, but did not simplify entry  requirements.   Thus,  atypical  workers  were  still  unable  to  qualify  for  unemployment 7 protection.\n\nDini's  1995  reform  (L.335/1995;  IT16)  anticipated  downward  dualisation  on  employment protection,  creating  the  employment  category  of parasubordinati (including  Co.Co.Co. Collaborazioni Coordinate e Continuative ) and establishing a special pension fund ( gestione separata ) with  a  lower  generosity  level  for  self-employed.  In  1997  Prodi's  centre-left government  approved  the Pacchetto  Treu (L.196/1997;  IT17),  which  promoted  temporary contracts and introduced Temporary Work Agencies (TWA) ( lavoro somministrato ). 8 After a lengthy  process,  dualisation  of  employment  protection  was  now  a  reality.  Berlusconi's government  pushed  further  downward  dualisation,  liberalising  temporary  contracts  (D.l. 368/2001; IT20) and approving the so-called Legge Biagi (L.30/2003; D.l.276/2003 [IT21]). IT21  introduced  new  atypical  contracts  (like  Co.Co.Pro. Contratto  di  Collaborazione  a Progetto) ,  zero-hour  contracts  ( lavoro  a  chiamata )  and  the  possibility  to  pay  for  casual activities with vouchers (later expanded by L.80/2005). It also extended the possibility to resort to  TWAs  to  lease  workers  with  permanent  contracts  ( staff  leasing )  (the  only  change  to employment protection for insiders during this period). The centre-left returned to power in 2007 and introduced some re-regulation corrective measures: abolishing staff leasing, zerohour contracts, and limiting the maximum duration of temporary contracts (L.247/2007; IT23). However, the subsequent centre-right government reversed these changes (IT24; IT25; IT27). 9\n\nThe 1990s marked a decisive phase in Italy's transition to a dualised labour market. While earlier reforms, such as IT4 (severance pay) and IT10 (dismissal protection), were incremental and inconclusive, major changes like IT17 (introducing TWAs) and IT21 (liberalising atypical contracts)  firmly  established  dualisation.  While  the  labour  market  reform  process  took  a downward dualisation path, we recall that heated debates on the possibility to reduce EPL for insiders characterised the 1990s and 2000s. The idea to fully liberalise labour market protection flowed like a karst subterranean river to re-emerge when the resistance of trade unions was broken in the 2010s (for more detail see Ferragina and Arrigoni 2021).\n\nOverall the Italian reform process during this phase was long, fragmented and nonlinear in comparison to Spain, including 27 reforms: 6 third order policy changes (IT1, IT9, IT12, IT13, IT17, IT21), 7 second order policy changes (IT4, IT7, IT20, IT22, IT23, IT24, IT25), and 14 first order policy changes (IT2, IT3, IT5, IT6, IT8, IT10, IT11, IT14, IT15, IT16, IT18, IT19, IT26, IT27) (Tables 2).\n\n\n## 4.2 Downward De-Dualisation\n\n\n## Downward de-dualisation in Spain: From Maastricht to the GFC\n\nThe transition from dualisation to downward de-dualisation unfolded in two phases: the first during  the  1990s  in  connection  to  the  Maastricht  treaty  and  the  second  after  the  GFC. Successive governments employed a downward de-dualisation strategy to address the legacy\n\nof the 1984 reform and reduced insiders' dismissal costs, deregulated permanent contracts and decentralised collective bargaining to the firm level.\n\nGonzález's government began the downward de-dualisation movement (ES4/ES5/ES6/ES7) near the Maastricht treaty approval. The L.22/1992 (ES4) tightened unemployment benefits eligibility criteria - increasing the minimum contribution period to 12 months - and decreased their  generosity. 10 The  L.22/1993  (ES5)  further  reduced  unemployment  benefit  generosity requiring the payment of tax and social contributions on their reception. In 1994 typical and atypical  contracts  and  collective  protection  were  reformed  (L.10/1994;  ES6/ES7).  ES6 constitutes the only de-regulation reform during the period analysed. On one hand, it broadened the applicability of objective dismissal: in addition to existing economic, technological, and force majeure reasons, organisational and production causes were introduced. On the other hand,  it enhanced  flexibility  and  expanded  opportunities  for  part-time  and  temporary employment. 11 ES7 decentralised collective bargaining from sectoral to firm level.\n\nAnother strong liberalisation wave took place with Aznar's conservative government (Popular Party  [PP]).  The  starting  point  was  the  1997  tripartite  social  pact  (L.67/1997;  ES8)  which introduced a new contract (CFCI) 12 aimed  at  promoting  permanent  employment  for  young people  and  those  above  45  years  of  age.  However,  the  CFCI  reduced  the  maximum compensation cost for unfair dismissal due to 'objective economic reasons' from 45 to 33 days of salary per year worked. Therefore, it reduced dismissal costs for insiders (but it was applied only to those who signed a new contract) (Malo and Toharia, 1997). The Minister of Labour (Arenas Bocanegra) emphasised the necessity to promote stable contracts for social groups highly  affected  by  unemployment  and  to  align  with  the  Economic  and  Monetary  Union requirements.\n\nIn  2001,  the  PP  government  undertook  a  dual  strategy  of  light  upward  de-dualisation  and marked downward de-dualisation via Law 12/2001 (ES9). ES9 granted permanent validity to the  CFCI  and  extended  eligibility  to  other  social  groups  (generalising  lower  dismissal compensation for insiders). ES9 also reduced the maximum duration for temporary contracts from  13.5  months  to  12  months,  promoted  the  conversion  of  temporary  contracts  into permanent ones, and introduced severance pay at the end of the most frequently used temporary contracts (amounting to 8 days' salary per year worked). L.45/2002 (ES10) went further with downward de-dualisation, reducing dismissal costs,  and  eliminating  the  duty  to  pay  wages between  the  moment  of  dismissal  and  an  eventual  trial  ('salaries  for  processing  time') (Galacho, 2006). The process continued with Zapatero's government (PSOE). The clearest example is the extension of the CFCI (ES11) to the rest of the workforce in 2006 (application to 30-45 age bracket). The title I of ES11 suggested to address 'the persistence of divisions between temporary and permanent contracts and, above all, the high rate of temporality'. ES11 introduced stricter regulations on temporary hiring and reduced social security contributions for firms that converted temporary into permanent contracts. According to PSOE, this reform tackled the prevalence of atypical employment; however, the extension in the application of the CFCI implied a low protection for those who signed it.\n\nThe GFC and subsequent pressure from European institutions and the Bank of Spain, led to a new  reform  tackling  'unbalanced'  de-dualisation:  it  significantly  reduced  employment protection for insiders and slightly increased protection for outsiders (RD 10/2010; ES12). On the one hand, it extended the perimeter of justified dismissals to 'losses' or forecasted future losses  and  reduced  severance  pay  for  unjustified  dismissals  of  insiders. 13 Moreover,  it expanded (again) the potential eligibility for CFCI. On the other hand, ES12 imposed temporal limits on certain atypical contracts (e.g. in the construction sector) and increased severance pay for temporary contracts (from 8 days to 12 days per year worked).\n\nRajoy's  government  (PP)  continued  with  both  de-regulation  and  downward  de-dualisation strategies (RD 3/2012; ES13/ES14). It expanded the scope for dismissal and encouraged both part-time  and  temporary  employment  (ES13),  while  also  promoting  internal  flexibility  by conceding firms greater freedom to adjust job tasks and schedules (ES14). Additionally, it reduced  the  generosity  of  unemployment  benefits  starting  from  the  seventh  month.  Four months after the major ES13/ES14 reform, Rajoy's government took another step by further deregulating unemployment benefits for both insiders and outsiders (Royal Decree 20/2012 ES15). 14\n\nOverall,  this  period  was  marked  by  a  trend  toward  downward  de-dualisation,  primarily targeting insiders through reduced dismissal costs and increased flexibility (e.g., ES8, ES9, ES10, ES12, ES14), while also incorporating limited upward de-dualisation measures, such as modest protections for temporary workers (e.g., ES9, ES12). This period includes 12 reforms, with 2 third order policy changes (ES8, ES14), 7 second order changes (ES4, ES6, ES9, ES11, ES12, ES13, ES15) and 3 first order changes (ES5, ES7, ES10) (Tables 1 and 3).\n\n## Downward de-dualisation in Italy: the GFC and the Reduction of EPL for Insiders\n\nThe year 2011 marked the advent of de-regulation of collective protection. Building on the A ccordo interconfederale 15 aprile 2009 (IT26), the Accordo interconfederale del 28 Giugno 2011 (IT28) specified the conditions for firm-level bargaining. During the 2011 debt crisis, the European Central Bank urged Italy to further decentralise collective wage bargaining. Few days later Berlusconi's centre right government allowed - without consulting trade unions - firmlevel agreements to regulate several aspects of atypical contracts such as job duties, working hours, and hiring/firing procedures (D.l 138/2011, later modified by L.148/2011; IT29).\n\nThe following Monti's technical government deregulated employment protection for insiders with the Riforma Fornero after 20 years of resistance and debates on Art.18 15 of the workers' statute (L.92/2012; IT30/IT31). It also eased the requirements to use vouchers and the legal restrictions  on  temporary  contracts  (the  need  for  a  causal  justification),  but  limited  their duration. 16 IT31 re-regulated unemployment protection, improving access for outsiders thanks\n\nto the introduction of ASpI ( Assicurazione Sociale per l'Impiego ), Mini-ASpI and a special fund (FIS) for workers not covered by CIG.\n\nOne  year  later,  a  grand  coalition  (led  by  Letta  [PD])  implemented  further  reductions  to vouchers' requirements 17 (D.l.  76/2013,  L.99/2013;  IT32)  and  introduced  the  possibility  of renewing a-casual temporary contracts. 18 IT32 also reduced the mandatory breaks between two consecutive  temporary  contracts.  Over  the  same  period,  also  a  de-regulation  of  collective bargaining - negotiated with trade unions and Confindustria - established common rules to form  representative  bodies  within  companies  and  enacted  firm  level  agreements  ( Accordo Interconfederale  sulla  Rappresentanza [2013;  IT33], Testo  Unico  per  la  Rappresentanza [2014; IT34]).\n\nIn 2014, Renzi's government (PD) proposed a further revision of Art.18. CGIL responded with a demonstration reportedly attracting a million participants. Renzi downplayed trade unions concerns and compared Art.18 to outdated technology: 'It's like asking where the coin slot is on an iPhone'. In this context of open social dissent, Renzi's government enacted the Jobs Act (L.183/2014): a series of reforms de-regulating employment protection for insiders and reregulating  unemployment  protection  (IT35/IT36).  D.l.  23/2015    (IT35)  introduced  a  new permanent contract ( contratto a tutele crescenti ) - guaranteeing increased protection over time. The  reform  limited  reinstatement  rights  and  tied  monetary  compensation  for  wrongful dismissal to seniority and company size. The decreto Poletti extended the maximum duration of temporary a-causal contracts to three years (renewable up to five times), raised the annual earnings  limit  of  vouchers,  abolished  Co.Co.Pro.  and  restricted  the  use  of  Co.Co.Co (D.l.34/2014;  L.78/2014;  IT35).  D.l.148/2015  expanded  CIG  coverage  and  established solidarity  funds  for  ineligible  workers,  and  D.l.22/2015  (IT36)  increased  the  coverage  of unemployment benefits introducing Naspi, Asdi, and Dis-coll. 19 Gentiloni's government (PD) faced a referendum initiative by CGIL aimed at abolishing vouchers. The government blocked the referendum abolishing vouchers (D.l. 25/2017; IT37), but reintroduced them a month later with stricter regulations (D.l. 50/2017; IT37). The government introduced fiscal advantages and extended unemployment benefits for parasubordinati (L.81/2017; IT38).\n\nThe 2018 elections resulted in the formation of the Conte I government (M5S and Lega Nord), the first executive not led by a centre-right or centre-left coalition since 1994. This government contributed  to  partial  upward  de-dualisation,  reintroducing  the  one-year  limit  to  temporary contracts and imposing additional restrictions on their use. It also gave greater importance to collective bargaining agreements at national and firm levels for the regulation of temporary contracts (Decreto Dignità D.l.87/2018; L.96/2018; IT39).\n\nThis period saw extensive downward de-dualisation through deregulating insider protections and  decentralising  collective  bargaining  (e.g.,  IT29,  IT35),  alongside  limited  upward  dedualisation improving unemployment benefits for outsiders (e.g., IT31, IT36). However, the generosity level of unemployment benefits remained way below that of other large European countries  (Scruggs  et  al.  2017).  Moreover,  in  response  to  the  deregulation  of  collective\n\nbargaining  protection,  trade  unions  and  employers  negotiated  a  restructuring  of  workplace representation. As in Spain, this period includes 12 reforms that we categorised as follows: 3 third order policy changes (IT29, IT31, IT35), 3 second order changes (IT30, IT32, IT36), and 6 first order changes (IT28, IT33, IT34, IT37, IT38, IT39) (Tables 2 and 3).\n\n\n## 5. COMPARING THE SPANISH AND ITALIAN CASE: WHAT WE LEARNED\n\n\nThere is a growing awareness in the literature that the age of dualisation is coming to an end. While workers in atypical contracts continue to face worse employment conditions than those in typical contracts, cumulative policy trends clearly indicate a movement towards a reduction of this gap. However, the characterization of the period that is following the end of the age of dualisation is  contested.  Recent  interpretations  emphasise  an  upward  de-dualisation  trend: faced  with  a  shrinking  base  of  permanent  workers  in  their  ranks,  labour  unions  and  social democratic parties are advocating for outsiders' protection. Modest expansions of assistancebased social protection and active labour market policies are the main policy tools that have been used for this purpose (Jessoula and Natili 2020; Natili and Puricelli 2023; Cigna 2024; Cigna and Fabris 2024). The adoption of a systematic fifty-year examination of labour market reforms in the fields of employment, unemployment and collective protection seems to shed scepticism on these interpretations as they attribute perhaps excessive weight to recent light reforms. We suggest instead that Italy and Spain shifted from dualization to downward dedualisation, a process that we labelled 'liberalisation through dualization'. A process that we characterised in two phases: (1) from fordism to the age of dualisation , and (2) downward dedualisation.\n\nFirst, dualisation emerged earlier and progressed faster in Spain, where economic pressures after  the  dictatorship  led  to  the  1984  reform.  This  reform  generalised  temporary  contracts, creating  a  secondary  labour  market  with  low  employment  protection  and  limited  access  to unemployment and collective safeguards. In Italy, dualisation was delayed until the 1990s due to strong worker militancy and a re-regulated labour market during the 1970s. However, the political rupture of 1992 paved the way for reforms in 1997 and 2003 that introduced atypical contracts and decentralised collective bargaining.\n\nSecond, both countries experienced downward de-dualisation, but again, Spain moved earlier. Beginning in the early 1990s, Spain expanded dismissal grounds (1994) and reduced dismissal costs for insiders (1997), followed by further reforms in 2001, 2010, and 2012. These changes progressively eroded insider protections, while light de-dualisation measures, such as limiting temporary contract  durations,  were  also  enacted.  Italy's  downward  de-dualisation  occurred later, between 2012 and 2014. The de-regulation of employment protection for insiders and outsiders was only partially counterbalanced by a re-regulation of the unemployment benefits (which  remained  at  a  very  low  level  of  generosity).  Overall,  the  combined  reform  of employment  and  unemployment  protection,  together  with  a  further  decentralisation  of collective bargaining, contributed to a downward convergence of labour market protection for insiders and outsiders.\n\nTable  3  systematically  summarises  the  differences  in  timing  and  the  legislative  process between the two countries. The phase of the shift from Fordism to the Age of Dualisation included only three reforms in Spain and two of these were third order policy changes. In Italy a similar change required 27 legislative interventions of different magnitude, with 6 third order policy changes, 7 second order policy changes, and 14 first order policy changes. The phase of downward dualisation was more similar, entailing in both cases 12 legislative interventions.\n\nThese  findings  corroborate  and  expand  previous  studies  through  a  systematic  long-term analysis of two extreme cases (Prosser 2016, Eichorst and Marx 2021, Ferragina and Filetti 2022). The development of a standard taxonomy, the measurement of the intensity of each reform, and a systematic CHA helped us to disentangle the similarity of the reform trajectories and 'normalise' the Italian case thanks to the observation of the Spanish process. If the devil is in the detail of the various reforms, the clarity of the interpretation might rest within the holistic nature  of  the  comparative  design.  We  hope  that  the  classification  methodology  of  reforms developed in this study could inspire other systematic studies on policy change and its intricate temporal and legislative nature.\n\nSpanish and Italian labour market protection reform trajectory achieved similar results and passed  through  two  analogous  phases,  but  with  a  different  timing  and  complexity  of  the legislative process. In both cases bi-partisan political decisions (involving the centre-right and centre left), the influence of the international political economy context, the role played by European institutions and the advent of economic crises contributed to a long-term trajectory that  brought  from  stable  employment  relations  during  Fordism  to  liberalisation  through dualisation.  In  Spain  the  faster  and  more  linear  process  (in  the  first  phase)  is  perhaps  a consequence of the weaker strength of the labour movement during Fordism and a reflection of a more stable political system after the end of dictatorship. In Italy strong resistances to the reform process delayed the temporal scale of the passage from Fordism to the age of dualisation and, in our view, hid the nature of the general liberalisation process to many observers. The fact that the legislative process of reform during the downward de-dualisation phase took place more similarly between the two countries seems to confirm this interpretation. Once the social resistance 'was broken' in the passage from Fordism to the age of dualisation , the prosecution of the liberalisation process with downward de-dualisation in Italy assumed a more similar shape  to  Spain.  Future  research  could  explore  whether  differing  political  conditions  and institutional frameworks produce similar/divergent outcomes in other countries.\n\n",
         "We suggest that labour market dualisation can be part of a liberalisation process employing a two-step methodology. First, we develop an eight-fold taxonomy to classify labour market protection reforms – covering employment, unemployment and collective protection – based on how they affect (de)commodification levels for insiders and outsiders. Second, through a comparative historical analysis over fifty years (1970-2020), we examine reform trajectories in Spain and Italy, two prominent examples of labour market dualism. We reveal a process of ‘liberalisation through dualisation’ characterised by two phases: (1) a shift from a declining Fordist order to dualisation, which primarily weakened outsiders’ protection, and (2) ‘downward convergence’ of protection for insiders. Spain and Italy shared this path but differed in the timing and characteristics of the legislative process. More broadly, we offer a replicable and transparent methodology to qualitatively code policy change and its intensity.",
         ""
        ],
        [
         "34",
         "34",
         "## 1. Introduction\n\n\nMost high-income countries are wagering a sustainable future on green growth: policies that attempt to simultaneously pursue drastic reduction in environmental impacts and sustained economic growth. However, recent studies suggest that green growth will not achieve the required reduction, except in the case of wholly unprecedented and/or controversial technological transformations (Hickel and Kallis, 2020; Keyßer and Lenzen, 2021). Thus there is a slow shift across high-income countries towards discussions of degrowth. Simulations suggest that degrowth has not only environmental benefits, but may have social benefits as well, e.g., reducing income inequality and lowering unemployment (D'Alessandro et al., 2020).\n\nDespite these potential benefits, degrowth faces substantial challenges: political feasibility. Both political and popular assumptions emphasize degrowth will lead to a decline in economic standards (e.g., household income), which will, in turn, lead to lower rates of happiness and wellbeing (Büchs and Koch, 2019; Milanovic, 2021). Adopting policies that reduce wellbeing would inevitably be difficult in democratic societies. This assumption of infeasibility explains, at least in part, why degrowth did not feature in over 200 scenarios run by the Intergovernmental Panel on Climate Change (Keyßer and Lenzen, 2021).\n\nDegrowth advocates often respond by pointing out that improvements in economic standards do not always lead to an improvement in subjective wellbeing for highincome countries. However, those like Büchs and Koch (2019) counter that this cannot be extrapolated to the case for falling economic standards that degrowth entails. Indeed, across high-income countries declines in subjective wellbeing have been observed during short-term economic recessions (e.g., Diener and Tay, 2015).\n\nWhat is missing in the debate is empirical understanding of how happiness and wellbeing respond to long-term, as opposed to short-term, declines. Unlike economic recessions that unfold over several years, degrowth accompanies a long-term decline in economic standards spanning decades, with no defined end. To fill this gap, this study explores the case of Japan where a long-term decline in economic standards has not lead to long-term decline in subjective wellbeing. When economic standards started declining, the level of subjective wellbeing did, in fact, decline during the first five years. However, the level of subjective wellbeing subsequently stopped declining and even started improving, despite no apparent recovery in economic standards.\n\n\n## 2. Materials and Methods\n\n\n\n## 2.1.Economic standards\n\n\nTo examine changes in Japan's economic standards, we first analyzed changes in nominal Gross Domestic Products (GDP) per capita (World Bank, 2022) and prices of goods represented by the Consumer Price Index (i.e., the weighted average of prices of a basket of consumer goods and services, Statistics Bureau of Japan, 2022). We then analyzed data for household income and expenditure (Statistics Bureau of Japan, 2022). Previous studies suggested that household indicators were stronger determinants than aggregated, national indices, such as GDP per capita (Diener et al., 2013). Throughout our analysis, we excluded data for 2020 and 2021 because these data would be strongly affected by the COVID-19\n\n\n## 2.2.Subjective wellbeing\n\n\nTo examine changes in subjective wellbeing, we primarily analyzed data derived from\n\nthe Public Opinion Poll on Citizens' Life conducted by the Cabinet Office (2022) annually since 1948. This survey offered the most reliable estimates of temporal changes in subjective wellbeing because of a larger sample size (typically 6,000 valid samples) and a shorter survey interval (1 year) than other similar surveys conducted in Japan. Data for this survey were publically available in reports published by the Cabinet Office (2022). The Public Opinion Poll on People's Life selected 10,000 people at the age of 18 or older using the stratified random sampling method considering the geographical region and population. Investigators visited those selected and asked a range of questions about the respondents' life through structured interview. One of the questions asked how satisfied they were with their current life. Respondents were required to choose one among the following five options: (1) satisfied, (2) somewhat satisfied, (3) can't say either way, (4) somewhat dissatisfied, and (5) dissatisfied. Using the response data for this question, we examined changes in the mean level of subjective wellbeing among respondents.\n\nTo supplement this analysis and the analysis for changes in the concept of wellbeing, we also analyzed data derived from similar surveys, i.e., the Survey of Japanese Attitudes (NHK Broadcasting Research Institute, 2019) and the Japanese National Character Survey (Institute of Statistical Mathematics, 2022). Data for these survey were publically available in reports published by these institutes. Both these surveys had smaller sample sizes (typically 3,000) and longer time intervals (5 years) than the Public Opinion Poll on Citizens' Life. The former asked respondents at the age of 16 or older how satisfied they were with their lives as a whole. Respondents were required to choose one of the following five options: (1) satisfied, (2) rather satisfied, (3) rather dissatisfied, (4) dissatisfied, and (5) don't know. The latter survey asked respondents at the age of 20-80 whether they were satisfied with their overall lives. Respondents were required to choose one of the following options: (1) satisfied, (2) somewhat satisfied, (3) somewhat dissatisfied, and (4) dissatisfied.\n\nAll three datasets used in this study employed single-item scales to measure subjective wellbeing. Despite the simplicity of single-item scales, many previous studies reported a good correlation between scores derived from single-item scales and those derived from multi-item scales in various cultural contexts, including in Japan (Shimai et al., 2004).\n\n\n## 2.3.Underlying processes\n\n\nBuilding on leading social science theorists in Japan (Furuichi, 2011; Mita, 2018), we hypothesized that the recovery of subjective wellbeing in the recent decades was associated with a shift in the concept of wellbeing. These theories suggested that Japan previously emphasized individual achievement and status, the dominant form of wellbeing underpinning modernity. Yet, there has been a shift in understanding of happiness and wellbeing: away from individual achievements towards harmonious relationships. This shift in the concept of wellbeing might have occurred in accordance with the decline in economic standards. Individual achievements would require an abundance of resources, opportunities, and thus greater materialistic consumption, a difficult set of conditions to maintain in a society with declining economic standards (Uchida and Ogihara, 2012; Uchida, 2020).\n\nWe examined whether this hypothesis would be supported by existing data. Two major domestic surveys in Japan included questions related to the relative importance of individual achievements as compared with harmonious relationships. The Japanese National Character Survey (Institute of Statistical Mathematics, 2022) asked whether (1) the respondents preferred to do what they themselves wanted to do or (2) they preferred to do something for others. The same survey also asked whether respondents\n\nbelieved that most people were (1) thinking about themselves or (2) trying to help others. In both questions, the former option emphasized individual achievement.\n\nThe Survey of Japanese Attitudes (NHK Broadcasting Research Institute, 2019) asked respondents about their goal of life. Respondents were required to choose one of the four options: the goal was (1) to 'spend each day freely and happily', (2) to 'develop a clear plan and move towards prosperity', (3) to 'spend time harmoniously with others around me', and (4) to 'work with others to make the world a better place.' The second option emphasized individual achievement, whereas the third option emphasized harmonious relationships.\n\n\n## 3. Results\n\n\n\n## 3.1.Economic standards\n\n\nJapan's nominal GDP per capita continuously increased in the post-war period until 1995, but there has been virtually no increase over the three decades since ( Figure 1a ). Meanwhile, the price of goods has remained almost constant since 1995 ( Figure 1b ). Due to this absence of economic growth and increasing social security costs, both the mean household income and expenditure declined during 1995-2018 by 16% and 13%, respectively ( Figure 1c ). Relatively large expenditure declines were observed for clothing and footwear (34%), children's education (17%), and housing (17%, Figure 2a ), although the prices of goods and services for these components were largely unchanged during the same period ( Figure 2b ).\n\n\n## 3.2.Subjective wellbeing\n\n\nData from the Public Opinion Poll on Citizens' Life showed that the percentage of people who were 'satisfied' or 'somewhat satisfied' with life declined from 1995 to 2000 ( Figure 3a ), mirroring declining economic standards ( Figure 1c ). However, beginning around 2005 - about 15 years after the decline began - this percentage started increasing. In recent years, the percentage approximated or even surpassed the peak value recorded in 1995, despite no apparent improvement in economic standards. The results were qualitatively the same even when we shifted the focus to those 'dissatisfied' or 'somewhat dissatisfied' with life ( Figure 3a ). The same results are further confirmed when analyzing two independent datasets ( Supplementary Figure S1 ). The gradual recovery of wellbeing over the past two decades was greatest among younger age cohorts ( Figure 3b ), a point we return to below.\n\n\n## 3.3.Underlying processes\n\n\nThe hypothesis was supported by our findings from analyzing existing data. Respondents who chose the options emphasizing individual achievement ('do what they want' and 'think about themselves') in the Japanese National Character Survey decreased, while those who chose the options emphasizing harmonious relationships (i.e., 'do something for others' and 'help others') increased over the same two decade span ( Figures 4a and 4b ). Interestingly, these tendencies were more pronounced for younger age cohorts ( Figure 5 ). That is, the shift in the concept of wellbeing was primarily due to the arrival of new generations that lacked memory of high economic growth rates and lifestyle patterns generated by the wealth of the 1980s. These new generations were indeed much more satisfied than previous generations at the same age ( Figure 3b ).\n\nIn the Survey of Japanese Attitudes, two options that respectively emphasized individual achievement ('develop a clear plan and move towards prosperity') and harmonious relationships ('spend time harmoniously with others around me') were the most popular options among the four in the early 1990s ( Figure 6 ). Those who chose the former decreased, whereas those who chose the latter increased.\n\n\n## 4. Discussion\n\n\nOur findings (i.e., the recovery of subjective wellbeing in the recent decades was associated with a shift in the concept of wellbeing) resonate with those of psychological studies. One recent review has suggested that reducing an excessive focus on the individual self is one effective way to achieve happiness within material constraints (Elf et al., 2022). In the context of degrowth for environmental sustainability, other studies also reported associations of an excessive focus on the individual self with less frequent pro-environmental attitudes and behavior and with greater environmental impacts (Komatsu et al., 2019, 2021, 2022; Duff et al., 2022). This latter finding might partly explain why Japan as a whole, and despite the lack of strong government control, reduced its environmental impacts in the same time span (see also Supplementary Text S1 ). Indeed, per capita Ecological Footprint for Japan in 2018 (4.61 g ha) was 18% lower than the historical maximum (5.63 g ha) recorded in 1995 (Global Footprint Network, 2022). Similarly, the Material Footprint in 2019 (24.9 t year -1 ) was 27% lower than the historical maximum (18.3 t year -1 ) recorded in 1995 (International Resource Panel, 2022).\n\nMoreover, the shift in the concept of subjective wellbeing is recognized domestically in popular, political, and media discourses throughout Japan: so many youths have internalized the new outlook that they have been collectively labeled as the satori generation . Satori means the enlightened state in Buddhism, in which one recognizes full relationality with surroundings and nullifies materialistic desires. The term first appeared on an Internet bulletin board around 2010. It then gained a wider following via a popular book written by a famous financial analyst in Japan (Harada, 2013). The term became so popular it was nominated for one of the annual New Buzzword Prizes in 2013, an award given to next concepts appearing in the popular lexicon with significant impact (U-Can, 2022). Low material consumption of Japanese youth generations is confirmed by quantitative data (Consumer Affairs Agency, 2017). Importantly, low material consumption is not simply due to low income, but attributed to a specific mindset and lifestyle (Hiam et al., 2017). Indeed, satori signifies a shift in mindset. A similar shift in the concept of wellbeing is arguably visible in other East Asian countries as well: in Korea ( sampo generation ), Taiwan ( strawberry generation ), and China ( tang ping ), youth appear to be less interested in individual achievements and material consumption than previous generations at the same age (Kuo, 2021).\n\nViewed within the degrowth debate, the lack of long-term decline in subjective wellbeing in Japan suggests that political and popular feasibility might be higher than expected. One prominent economist (Milanovic, 2021) has marked degrowth as 'a political suicide', because living happy lives with much less materials is possible 'for some special people like Christian or Buddhist monks' but impossible 'for the remaining 99.99% of the people'. Japan's experience over the past three decades offers a counterpoint: the majority of the population are successful in living happy lives with less materially.\n\nReaders might argue that such a shift in the concept of wellbeing is possible only among non-western countries. An emphasis on individual achievements might be much stronger in the West, particularly in countries with a strong Protestant tradition (e.g.,\n\nThe Protestant Ethic), than non-western countries (Markus and Kitayama, 1991; Komatsu et al., 2021). This may also explain why Japan has a history of sustainable development, i.e., low economic and population growth, prior to contact with the modern West (Ochiai, 2007; Kito, 2010). Yet, we are optimistic, given that having harmonious relationships with others appear to be much more important, even in the West, than generally imagined in political and popular discourses there. Recent psychological studies confirm this. Hitokoto and Uchida (2015) reported that a happiness scale focusing on harmonious relationships explained subjective wellbeing of American university students more than a scale for positive self-regard did. Delle Fave et al. (2016) examined lay people's definition of happiness for 12 countries including the United States, Italy, and Norway and found that harmonious family and social relationships were key components of subjective wellbeing for all these countries. This point is highlighted in the latest World Happiness Report (Lomas et al., 2022). Moreover, we must acknowledge that even in Japan, a portion of the population face difficulties in developing harmonious relationships with others in Japan (Norasakkunkit and Uchida, 2014; Uchida and Norasakkunkit, 2015). So culture appears more malleable and varied that we might initially assume. Education, for example, is an institution charged with cultural learning that can change its emphasis, and change culture in turn. Japanese youth's shift to happiness in relations is arguably afforded by a strong educational emphasis on relations found there (Rappleye and Komatsu, 2017; Rappleye et al. 2020). We thus suggest that shifting the emphasis from individual achievements to having harmonious relationships is a viable option worldwide, even in the West, as we (re)learn to live happily with less.\n\n",
         "Degrowth, i.e., a planned reduction in environmental impacts and economic scale, is increasingly discussed as a viable option for achieving sustainability. Yet, opponents counter that degrowth entails declines in economic standards, which will, in turn, reduce individual happiness and collective wellbeing. Our study explores the existing theoretical debate empirically, examining the case of Japan. There long-term decline in economic standards has not led to long-term decline in subjective wellbeing, thus bolstering the case for degrowth.",
         ""
        ],
        [
         "35",
         "35",
         "## Introduction\n\n\nA good deal has been made about the advances in recent decades concerning equality for people with intellectual disabilities, however in terms of sexual identity, it continues to be taken for granted they are either asexual or heterosexual, but seldom seen as lesbian, gay, bisexual, or transgender (Noonan and Gomez 2011; Wilson et al. 2018).  Scholars draw attention to the importance of recognising the challenges faced by LGBT+ intellectually disabled people who have  to  negotiate,  on  a  daily  basis,  a  heteronormative  world  with  its  restricted  ideas  on disability  and  sexuality  (Abbott  2013;  Hodges  and  Parkes  2005; Wilson  2006). Yet  sexual orientation is a fundamental characteristic of being human, demonstrating how people relate to one another-what relationships are fostered, how love and affection are established, and the ways in which individuals experience their lives. Nevertheless, even with advancements such as person-centred planning, and personalised care, there remains a complicated relationship between individual rights, supported action, and risk. The chances of same-sex intimacy for adults with intellectual disabilities is regularly frowned on by families, hindered by care staff, and decisions are made using policies focused on eliminating risk (Wilson and Frawley 2016; Wilson and Plummer 2014). This is despite the fact as Appel (2010) points out, hindering sexual intimacy is of itself a violation of a human right (see Equality Act 2010; Human Rights Act 1998). Denying individuals with intellectual disabilities the opportunity to learn about their sexuality,  and  develop  social  relationships  with  others,  is  a  denial  of  their  right  to  selfrealisation (Swango-Wilson  2008). Even  so,  considerable  numbers  of  support  staff  feel uncomfortable  when  confronted  by  a  service  user  wishing  to  discuss  same-sex  attraction. Prejudice  against  LGBT+  individuals  is  motivated  by  a  range  of  factors,  but  personal conviction  emerges  as  a  recurring  theme.  People  of  faith  consider  homosexuality  a  'sin' believing gay people have chosen a sinful lifestyle. It is a way of living which goes against their convictions and one not to be encouraged. A support worker of faith claims:\n\nPeople  are  not  born  homosexual  or  lesbian,  it's  their  CHOICE!  The  word  of God, the Holy Bible states this is SIN! (Old &amp; New Testament). So does the Jewish Torah &amp; the Islamic Qur'an! (Somerville 2015, 18. Capitalisation in original).\n\nOther reasons staff are reluctant to support people with intellectual disabilities identifying as LGBT+ is the fear they might violate their duty of care, should they be seen to encourage samesex  intimacy.  As  a  consequence  they  express  concern  their  conduct  may  be  viewed  as irresponsible  and  lead  to  an  investigation  (Leven  2021). Furthermore,  doubts  about  the legitimacy of consent communicated by each person is highlighted as a further issue, along with a lack of training to facilitate LGBT+ service users (Abbott and Burns 2007; Abbott and Howarth 2007; Swango-Wilson 2008).\n\nSet against an historical background of segregation and control, this article demonstrates that even though progress has been made for heterosexual adults with intellectual disabilities  in  terms  of  sex  and  relationships,  the  same  claim  cannot  be  applied  to  nonheterosexual intellectually disabled people. Accordingly, relations deemed inappropriate are suppressed through codes of conduct that maintain everyone is, or should be, heterosexual (Marchia and Sommer 2019; Wilson and Plummer 2014). Against this backdrop, the article\n\nraises  a  number  of  fundamental  yet  important  questions  relevant  to  social  policy  and professional practice by considering the implications for people with an intellectual disability who are non-heterosexual. It reviews the literature drawing on sources of qualitative data which have sought to give 'voice' to these individuals using their personal accounts. The accounts are of interest because they reveal the complex ways in which discrimination in social care operates to re-enforce prejudice and exclusion (Concannon 2006; Leven 2021).The narratives emphasise how heteronormative 'norms' have thus far limited inclusive services for intellectually disabled gay service users. Consequently, heteronormativity as a social construct is examined, and within this theoretical framework the ways in which power relations are maintained in care services, is investigated. The narratives of service users propose that in order to productively respond to their  wants  and needs,  existing government policies must be translated into workable local strategies.  Strong  feelings  of  powerlessness  are  revealed  but  the  accounts  also  offer  hope  by illuminating positive ways in which such experiences can inform the future development of care provision.  The  conclusion  presents  an  opportunity  to  consider  fresh  ways  in  which  agencies, commissioners, and professionals, can empower their clients. It reflects on current thinking to recommend areas where further research could inform social policy and advance professional practice.\n\n\n## Controlling sexual intimacy: lessons from the past\n\n\nSex is an innate part of life, yet for adults with intellectual disabilities throughout much of history, it has been a segment consistently denied to them (Noonan and Gomez 2011).  In the past,  social  acceptance  of  what  was  proper  and  'normal'  behaviour,  resulted  in  oppression towards those displaying sexual affection. The powerlessness that resulted from such control has been a key feature enabling the exploitation and sexual abuse of people with intellectual disabilities (Noonan and Gomez 2011) with examples continuing to surface from time to time in the media. But before discussing present day attitudes towards intellectually disabled people and sexuality, it is useful to shed light on the topic by locating it within a historical context. The  core  of  the  past  narrative  for  this  group  is  one  depicting  them  as  'innocent  children' incapable  of  individual  choice  and  responsibility  (Concannon  2005).  It  was  due  to  early discourses examining the concept of free will and original sin, in the writings of St Augustine (bn.354 - d.430) and his work Anti-Pelagian , that the notion of the 'idiot' as childlike-' holy innocents '-was first introduced (Allan 2012). ( The word 'idiot' is used in its historical context along with similar such terms ).  By using religiosity, Augustine argued that, because children cannot 'reason,' it is not possible for them to be responsible for their 'sins.' He claimed, 'infants could never commit an offence … [since they have] great weakness of mind and body [and] their great ignorance of things [means] the complete absence … of all perception' (Warfield 1956, 27-8). In other words men and women with intellectual disabilities lacked capacity to make  meaningful  choices,  and  applied  to  relationships,  this  maintained  they  could  not understand the consequences of sexual intimacy (Concannon 2005). Augustine's philosophy began a longstanding association between the notion of adults with intellectual disabilities, and children lacking acuity. So ingrained did this powerful image of the helpless child become that for some it endures to the present day. By the mid 19 th Century a growing dissatisfaction had arisen about the degeneration of society resulting in a demand for segregation of 'subnormals.'\n\n4\n\nThey were to be detained in asylums which Goffman (1961) famously referred to as 'total institutions.' Structures of confinement that functioned as dumping-grounds for undesirables, where men and women were separated for fear of intimacy and procreation (Foucault 2001, 1961;  Scull  1979).  The  work  of  the  British  medical  researchers  George  Shuttleworth  and William Potts at the beginning of the 20 th Century, had a significant influence in propagating the argument for partition. Shuttleworth and Potts proposed restrictions between the sexes was necessary because:\n\nthough  children  in  mind,  they  are  often  men  and  women  in  wickedness  and vice; and it may be necessary to place them under restraint … There is a  tendency to  low  and  depraved  habits,  to  brutish  sensual  enjoyment  [with]  an  absolute disregard for right behaviour (Shuttleworth and Potts 1910, 114).\n\nThe controlling regimes inside asylums reflected a growing moral panic governing the outside world (see Royal Commission 1908). Over time the solution to eliminating the 'problem,' set in motion a dark response, culminating in an embracing of eugenics and Darwinian Biology. It was social engineering by means of forced sterilisation to eradicate people with intellectual disabilities, under Nazi rule, during the second world war, where the most extensive expression of this practice was realised.\n\nIn the UK, control and restraint continued to dominate institutional care by the time Pauline Morris published her ground breaking work, 'Put Away' in 1969. Her study described hospitals as Dickensian and grotesque, with working practices revolving around authoritarianism. Fundamental to many codes of practice was the parent-child model signifying the enduring influence of Augustine's holy innocents , and was the relationship employed by most staff (Smith 1994).  It was not until the introduction of the Normalisation Principle that social  and  political  attitudes  towards  safeguarding  the  rights  of  people  with  intellectual disabilities  experienced  a  transformation  (Concannon  2005).  The  pioneer,  Bengt  Nirje, declared  policies  founded  on  Normalisation  had  been  designed  to  enable  citizens  with intellectual disabilities to live as near normal patterns of daily life as possible (Perrin 1999). But critics remained unconvinced, arguing it was an unattainable ideology for all except the most articulate and capable individuals (for background context see Culham and Nind 2003; Wolfensberger 1980). In spite of criticism, the foundations were laid for ordinary living seeking to 'make the quality of life the same for disabled people as for non-disabled, based on notions of equality, quality of life and quality of services' (Alaszewski and Roughton 1990, 22). As the advent of care in the community dawned from the late 1980s onwards, attempts were made to radically change the relationship between staff and service users to one that was optimistic and equitable. However, critics viewed this as misguided and 'based on the unreal idea of staff as friends of users and equal colleagues' (Concannon 2005, 39). They claimed professionals were becoming irresponsible by blurring the boundaries and glossing over the need for limitations, that had been introduced to ensure protections. With the development of care packages, and the policy of individual assessment, the plan was for choice and control to pass to the service user. In reality overall control remained in the hands of social workers-renamed care managers in the 1989 White Paper, Caring for People (see Griffiths 1988). The challenge for social policy was to create methods through which individuals could articulate their wants and choices, and\n\nhave them respected and met (Abbott and Burns 2007; Stainton 1994). Included was supporting the development of personal relationships. Nevertheless, although these moves saw a growing encouragement for heterosexual relationships, and in some cases led to marriage and children, the question arises: did such innovatory developments have a positive impact on support for same-sex  relationships,  or  did  the  paternalistic  philosophy  of  Augustine  translate  into  a contemporary form of homophobia?\n\n\n## Identity, disability, and powerlessness\n\n\nNotwithstanding innovatory moves to improve the lives of intellectually disabled people, the disadvantages  faced  by  those  who  identify  as  LGBT+  has  been  referred  to  as  a  cohort  of powerlessness  (Wilson  et  al.  2018).  A  similar  argument  can  be  found  in  the  model  of intersectionality pioneered by Crenshaw (1989) which suggests ways a person's social and political identity can fuse to create a new form of oppression. Applied to LGBT+ people with an intellectual  disability,  the  theory  sees  them  marginalised  because  of  their  disability,  and ostracised  farther  from  mainstream  society  due  to  their  sexual  orientation,  or  gender expression.  Powerlessness  can  lead  to  family  and  professional  relationships  becoming problematic owing to restrictions imposed on a desire for same-sex activity. Yet the layers of discrimination and homophobia can extend further to include rejection from fellow service users; on the part of organisations who fail to introduce supportive policies; and from within the gay community itself who may perceive intellectual disabled people negatively (Abbott and  Howarth  2003;  Stauffer-Kruse  2007).  Significant  numbers  of  adults  with  intellectual disabilities live either in a residential facility, supported living, or the family home. Such forms of communal living lack privacy. Residential accommodation is not only a home, but a place of work for staff, where approaches towards expressions of homosexual intimacy can mean they are regulated (Aylott 1999; Noonan and Gomez 2011).  Withers et al. (2001) came across one such example whereby male participants in their study voiced concerns that staff would not tolerate them bringing male partners home. As a result sexual activity occurred in public spaces, such as toilets, where access to condoms and negotiations around safe-sex was seldom possible. The researchers also stated parents of two of the men approached them to express apprehension about their sons coming into contact with potential sex partners by attending the sessions.  They  needed  to  be  reassured  that  the  group  had  a  genuine  focus  on  mental  and physical wellbeing. The  powerlessness these gay men experience offers an insight into the subtle ways in which control continues to operate in the care system. Agencies can be guilty of constructing barriers against LGBT+ clients through an absence of policies to facilitate them. Barriers  deriving  from  a  top  down  authoritarian  management  structure,  where  decisions determine intentionally or inadvertently, to prohibit the rights of non-heterosexual intellectually disabled service users to express themselves sexually. Noonan and Gomez (2011) assert having a  policy  of  privacy  in  residential  care,  by  providing  a  separate  bedroom,  where  inquisitive young adults can explore their bodies, is a simple answer to countering this. Educating that masturbation and sexual fantasy is a normal and healthy part of human growth (Tarnai 2006) and that it is acceptable to experiment in the privacy and safety of their room, is another way. However, gay men with intellectual disabilities living independently who can bring men home, are equally at risk of exploitation (Withers et al. 2001). While professionals must recognise and\n\n6\n\nrespond with protective  measures,  for  the  client,  getting  help  can  proven  to  be  difficult  to negotiate. In order to effectively empower gay service users, the organisation must demonstrate a  commitment to confronting homophobia through person-centred planning and the review process (Stauffer-Kruse 2007). Yet examples of poor practice are easy to locate. Richard, an 'out'  gay  man  with  intellectual  disabilities  is  one  such  case.  Now  in  his  late  twenties,  he attended  special  schools  as  a  child  and  afterwards  went  into  residential  care.  His  account demonstrates the obstacles faced when he began to talk to staff about the feelings he was having towards other men.\n\nUnfortunately, in special schools you never had any sexual relationship training or any sex education, it just didn't happen. So in the time I was going through it, it was a bit like actually, 'What are these feelings? What is happening to me? Why do I fancy this person?' And you don't understand the reasons why, because you start thinking is it just a learning difficulty, or do I have something else wrong with me? (SCIE 2021).\n\nFeelings  of    powerlessness  which  have  been  a  key  feature  in  the  past,  continue  to  make individuals like Richard vulnerable. Hindrances such as failing to provide comprehensive sex education in the transition from childhood to adulthood is absent, and is of particular concern when the person is alone in the community (Noonan and Gomez 2011). Richard's move to independence brought with it a new sense of freedom, but when he turned to staff for help on 'coming out,' the type of support he needed was more challenging to get than expected. He explained:\n\nI wanted to have a relationship, and when you live independently, you have what they call Person Centred Review, so you have a monthly review, or yearly review. And for about three years all they wanted to talk about was how am I doing with spending?  What  am  I  like  with  doing  my  laundry,  cooking  and  washing?  And actually all very important things to talk about, but I wanted to talk about having a relationship.  And  every  single  time  it  was  brought  up,  it  always  seems  to  be 'Well, we can talk about that a bit later on' but we never actually got to a point of talking about it, it always sort of got swept under a carpet. What I decided to do was to  have  a  review,  who  were  people  [ sic ]  I  wanted  to  invite,  so  I  could  say  to them, 'Look, this is who I am, and this is the support I need' (SCIE 2021).\n\nEducation promotes the  ability  to  make  good  choices  around  sexual  activity  and  enhances capacity based on an understanding of safety and wellbeing. Imparting knowledge not only contributes  to  reducing  vulnerability,  but  also  to  the  reduction  of  inappropriate  sexual expression (Swango-Wilson 2008).  Education can be a powerful weapon against exploitation in that the person is equipped with the language needed to defend themselves and inform others of potential abuse (Noonan and Gomez 2011). Nevertheless, although the guidance in care assessments and the review process seeks to proactively support service users in all aspects of their lives, little evidence exists to suggest overall, local services are making enough effort to meet the basics for people like Richard. A social worker admits:\n\nThere is a shocking lack of importance placed on awareness of issues surrounding sexual  orientation.  Racial  issues  and  those  from  ethnic  minorities  are  seen  as important;  indeed  information  detailing  these  issues  are  required  as  part  of  the assessment  process.  However,  sexual  orientation  is  often  ignored  or  sidelined  as irrelevant to a community care assessment, which I feel results in a lack of knowledge about that person (Somerville 2015, 24).\n\nSimilarly, the limited involvement of LGBT+ people with intellectual disabilities in empirical research means their specific care needs and wellbeing, and how they differ from heterosexual individuals with  intellectual disabilities, remains  chiefly undetermined.  This  void  has consequences for the successful development of local health and social care policies. Frustrated with his sexuality not being taken seriously and needing support, Richard decided to confront the system by taking out a formal complaint. Remembering the courage it required, he recalled:\n\nI got the confidence to actually say to somebody, 'Look, this is who I am. You're being paid to give me the care that I need, and this is part of the care that I need. I need someone for support to be the person who I am.'\n\n## As a result his support transformed.\n\nMy support became the best support you could imagine, so I think if I hadn't done … hadn't put that complaint in, then the support would never actually have really changed very much (SCIE 2021).\n\nShaun discussed the barriers he faced when he came out as bisexual. He has short-term memory problems and dyslexia. Throughout his years attending special school, Shaun says he received no sex education to help him understand his bisexuality. Looking back he said:\n\nI thought I was going mad, I thought there was something wrong with me. I didn't know what bisexual meant. Special needs schools didn't do proper sex education for people   with  learning  disabilities.  They  think  people  like  us  don't  have  sex.  [Sex education mainly focused on] making babies rather than explaining terms like gay, bisexual, trans and non-binary. Coming out when you're 38 is a big thing to do. It's life-changing;  a huge weight had been lifted (Ebrahim and Hunte 2021).\n\nNowadays Shaun lives with his wife and children. He received an MBE for his dedication to helping people with intellectual disabilities in the UK and abroad.  Shaun said, 'I feel proud to be a role model for people with a learning disability to help them to understand about their sexuality' (Ebrahim and Hunte 2021).\n\n8\n\n\n## Promoting self-worth through positive representation\n\n\nThese experiences draw attention to the importance of encouraging non-heterosexual service users  to  develop  confidence  as  a  way  of  increasing  self-worth,  fostering  a  sense  of empowerment, and enabling 'voice.' However, before staff can support LGBT+ clients, they must first recognise their own prejudice in a world that imposes heteronormativity. Marchia and Sommer (2019) propose the social order is organised around codes of conduct that deem everyone should be heterosexual. Scholars likewise agree adding there are dominant 'norms' of behaviour in relation to disability and sexuality; norms that inevitably demand conformity to heterosexuality (Abbott  2013;  Hodges  and  Parkes  2005;  Wilson  2006).  Imposing heteronormativity can intensify feelings of segregation and inequality in a group of people who are  already  one  of  the  most  prominently  marginalised  and  socially  excluded  (Wilson  et  al. 2018). Regardless of sexual identity the important matter is being able to choose whom to have a relationship with, bearing in mind that to obstruct the choice of a partner based on sexual orientation is a breach of a human right (Appel 2010). Of equal importance is how best to quantify an individual's capacity to make the choice (Murphy and O'Callaghan 2004). The following case illustrates tensions that can arise.\n\n[A] young man's mother was not comfortable with her son's relationship and argued that he was not capable of providing valid consent, and that he was not homosexual. The  other  side  of  the  argument  was  that,  after  careful  observation,  there  was  no coercion, there was no (actual) sexual activity between the two, and female clients were available but the son chose the male bed partner (Wilson et al. 2018, 190).\n\nThis example raises questions about capacity and the right of each person to make a choice about forming an intimate relationship. Although he was an adult, this mother saw her 'child' as incapable of giving consent. Provider organisations tend to be more concerned with liability and protecting  themselves  when  confronted  with  issues  of  capacity  and  consent  by  family members, than they do with enhancing the right to sexual expression. This is particularly the case where the person has limited communication, or is cognitively impaired  (Lyden 2007; Murphy  and  O'Callaghan  2004). What  the  example  also  underlines  is  the  importance  of delivery of specialised training. In keeping with the principles of the Care Act (2014) and those of the Mental Capacity Act (2005) training can ensure social workers empower their clients to be at the centre of their care plan, reflecting choice and needs (Concannon 2005; DOH 2005; DOH 2014). Notably, the focus of the Mental Capacity Act (2005) is on-as far as possible without  endangering  the  client-providing  liberty  to  make  mistakes  in  the  same  way  as everyone else does. The legislation provides a context within which professionals can have a rational  dialog  relating  to  sexual  identity,  gender  and  sexual  relationships.  Empowering  a person  who  may  be  considered  vulnerable  might  be  difficult  for  staff,  but  this  should  not impede  the  person's  right  to  decide  about  engaging  in  a  sexual  relationship  (Bates  2018; Maguire et al. 2019).\n\nStaff can facilitate their clients using a range of activities such as group sessions that promote 'voice.' Learning from each another in a safe and confidential environment (Elderton\n\nand Jones 2011). Life stories are useful as a tool to assess a person's needs and wants, while also offering an insight into their history and helps shed light on how and why they make the decisions they do (Concannon 2005). Shared narratives can have a twofold benefit in that the individual is an expert in their own experience, their story can inform staff training, as well as fellow group members. Exchanging experiences about sex in a group is a more relaxed way of exploring  sexual  orientation  and  gender  identity  (Robinson  et  al.  2020).  Groups  provide  a forum through which sexuality can be discussed as part of ordinary life, and where information and guidance on sexual practice is made available. Knowledge of the health consequences of certain types of sexual activity, as well as activity which might constitute a criminal act, and how to avoid them, can be shared. Participants are able to speak about exploitation and abuse, while correspondingly being informed about tactics someone might use to take advantage of them (Tarnai 2006).  In addition, ensuring images of sexual diversity including; photographs, posters, and books portraying positive representations of LGBT+ individuals and couples, are placed around day and residential settings, can heighten feelings of self-worth and confidence. Targeted  education,  accessible  information  and  support,  representation  of  diversity  and advocacy, are all required to progress positive changes to improve self-esteem (McClelland et al. 2012; Wilson and Frawley 2016). Health and social care staff should be committed to keep informed about the unique needs of intellectually disabled clients who are LGBT+ in order to create  change  that  supports  wellbeing,  counteracts  heterosexism,  ableism  and  oppression (Thompson  et  al.  2001).  In  contrast,  the  adverse  outcomes  associated  with  sexuality  and marginalisation  can  leave  individuals  at  risk  of  STIs,  HIV ,  and  other  issues  such  as psychological damage or physical attack (McClelland et al. 2012).\n\nNevertheless, surveys exploring the lives of the LGBT+ population, including people with an intellectual disability, continue to paint a bleak picture of prejudice and discrimination. In 2017, the government launched a national survey in which it set out to investigate the main areas  where  inequality  exists  for  LGBT+  citizens  those  of  personal  safety,  education,  the workplace and healthcare (GEO 2018a). Arising from the findings, the government published the  LGBT  Action  Plan  the  following  year  (GEO  2018b).  As  a  key  part  of  the  survey, participants were probed about their involvement with health services, social care, and gender identity clinics. Contributors were asked if they had disclosed their sexuality or gender identity to professionals and as a result, believed their disclosure had affected the delivery of care. Many offered examples of discriminatory practice such as alleging staff used inappropriate questions based on curiosity rather than necessity. While others claimed their specific needs were ignored (p.165). The findings highlighted that at least 38 per cent had a negative experience which they attributed to their gender identity, and 51 per cent who tried to access mental health services, said they were kept waiting too long. Additionally, 80 per cent of trans people who tried to engage with gender identity clinics were left feeling upset. There is a perception among the general LGBT+ populace that health inequalities are the consequence of prejudice on the part of health professionals-notably relating to gender identity-and are liable for causing higher rates of mental distress (Robinson et al. 2020). These barriers mean non-heterosexual people with intellectual disabilities need additional support. Furthermore, the Action Plan suggests there is a pathologisation of transgender people, where the person's mental health difficulties are  ascribed  to  their  identity.  Ray  is  a  case  in  point-a  21-year  old  trans  man  with\n\n10\n\ncommunication  problems  who  also  struggles  with  audio  and  visual  processing.  For  Ray, negotiating trans health services has been overwhelming, whereby the main difficulty has been:\n\nprocessing information especially when it comes to gender identity clinics, which are a whole minefield. They have a checklist of things you need to be able to explain and I  have difficulty expressing myself properly. There are a lot of invasive questions about your sex life. That makes me uncomfortable. And when I'm uncomfortable it's even harder to express myself … Trans people are always infantilised to some degree and so   are  people  with  learning  disabilities , so  it  becomes  really  challenging (Ebrahim and  Hunte 2021. Emphasis added).\n\nThe Action Plan proposed a set of objectives to improve health and social care support to all LGBT citizens. This included people with intellectual disabilities where it resolved to:\n\nreview, collate and disseminate existing best practice guidance and advice regarding LGBT issues and learning disability; and … ensure that training requirements for support staff and advocates who work with people with learning disabilities includes advice regarding LGBT people (GEO 2018b, 10).\n\n\n## From asylums to safeguarding: the changing face of control\n\n\nYet, the historic maltreatment of people with intellectual disabilities in asylums, documented in the work of Goffman (1961), Foucault (1961, 2001) and Pauline Morris (1969) has been the foundation on which discriminatory practices towards non-heterosexual intellectual disabled individuals, has been shaped. Until relevantly recently, anti-libidinal medication was used by staff to control sexual expressions in people with intellectual disabilities, rather than teaching boundaries. Support staff failed to respect the self-determination of the individual denying them the right to engage in meaningful relationships (Leven 2021; Robinson et al. 2020). In the present  day,  some  agencies  persist  in  stigmatising  homosexuality  and  same-sex  intimacy, regarding the subject as interdicted (Bates 2018; Maguire et al. 2019). This is mirrored in the lack of training that educates on the inclusivity of LGBT+ citizens. Even when courses are provided, critical areas of significance about the rights of LGBT+ people have been neglected. For example, only 30 per cent of staff who contributed to research conducted by Stonewall, said  they  were  informed  about  the  legal  protections  for  LGBT+  clients  (Somerville  2015). While some training sessions included material on the use of language and practices that related to the LGBT+ community, 25 per cent of all care staff alleged their employer did not offer any equality and diversity guidance. This figure increased to 34 percent in the independent sector. Reflecting on the training delivered, a service manager concluded it was, 'very basic and does not cover how to work with people from a diverse range of backgrounds.' A nurse said, 'training is invariably online and pretty rubbish to be honest.' While another stated, 'I fail to see the need for this type of training' (Somerville 2015, 24, 26). When probed about training on policy, staff reported  that  discussions  tended  to  be  around  policies  dealing  with  internal  matters  of  the agency, such as staff bullying, rather than broader themes linked to social policy and inequality.\n\nA dilemma faced by many staff is in reaching a balance between protecting their clients, and empowering the development of their sexual identity. Coupled with a lack of training and an over zealous desire to rigidly follow safeguarding practices, support staff have been culpable of restricting sexual relationships between service users (Bates 2018; Cambridge 2013; Harflett and Turner 2016; Maguire et al. 2019). Safeguarding procedures are important for protecting the wellbeing of service users, as well as the staff who care for them, yet some decisions made in the interests of safety, deny personal choice and autonomy. Having concern for the welfare of people with intellectual disabilities requires not only having a duty to protect them, but also respecting their preferences and valuing their right to a particular lifestyle (DOH 2009; O'Brien 1998; Tindall 2015). Nevertheless, for some staff, accountability is about doing the 'right thing' that will attract the least amount of criticism should something go amiss.  As Tindall (2015) notes:\n\nthe lives of many people with learning disabilities are unduly restricted because the people they rely  on,  in  order  to  live  an  ordinary  life,  are  fearful  of  having  to  go through the process of justification if something negative happens.\n\nDespite this a main component of the Care Act (2014) emphasises the importance of having the voices of service users heard and respected. It is within this framework that the safety needs of LGBT+ people with intellectual disabilities must be steadfastly located. The majority of safeguarding protections relate to explaining how harm occurred, and ensuring the possibility of it happening again in the same manner is avoided. While these are essential processes, at the same time they are imprudent because they result in preventing clients from having access to aspects of life that are important to them, and beneficial to their physical and mental health (DOH 2014; Tindall 2015). Being alert to abuse, and taking action when it occurs, should never be used to validate needless restrictive decisions that are then passed off as protective measures. Intensifying  regulations  around  safeguarding  which  often  negatively  impacts  people  with intellectual disabilities, but rarely involves them in a consultation process, is not the answer (Concannon  2005,  2006;  Tindall  2015). Rather  it  lies  in  positioning  support  firmly  in  the context of encouraging people with intellectual disabilities who identify as LGBT+ to foster meaningful companionships, and loving relationships with others.\n\n\n## Conclusion\n\n\nSexuality is a multidimensional paradigm that contributes to a person's sense of self-worth and incorporates identity, sex, gender and intimacy (Bates 2018; Maguire et al. 2019).  Achieving self-actualisation  and  fulfilment  can  be  realised  through  the  loving  companionship  that  a relationship provides. Feelings of belonging which intimacy can offer is an essential part of human growth (Robinson et al. 2020). While it is acknowledged that discrimination and social exclusion are key factors in the lives of the general LGBT+ community, providing health and social care to non-heterosexual adults with intellectual disabilities, brings with it an added need to  balance  rights,  responsibility,  and  risk.  This  article  argues  that  LGBT+  people  with intellectual disabilities, like the rest of society, are sexual beings who have a right to express themselves  through  same-sex  loving  relationships.  The  study  combines  the  literature  on\n\n12\n\nsexuality,  social  exclusion,  and  intellectual  disability  to  give  'voice'  to  the  experiences  of LGBT+ intellectually  disabled  people  with  the  aim  of  informing  social  policy,  improving professional  practice  and  to  recommend  better  outcomes  for  service  delivery.  Even  though examples  of  St  Augustine's  philosophy  that  infantises  adults  with  intellectual  disabilities continue to surface, since the introduction of the Normalisation Principles, policy development has made impressive strides in terms of empowering people with intellectual disabilities to broaden healthy lifestyles, take more control of their lives, and procure their place as equal citizens.\n\nBelonging  to  a  community  can  reduce  marginalisation,  increase  happiness,  and dismantle barriers resulting in improvements to physical and mental health. Weeks et al. (2001) describes the importance of 'families of choice' emphasising the bonds and friendship they create through shared experiences of discrimination and powerlessness. But it continues to be the case that for LGBT+ intellectual disabled individuals, accessing these communities is not an easy task, due to the lack of appropriate support. The barriers which they encounter include safeguarding procedures aimed at protecting them from abuse. As a means of countering this, training that includes the theory of intersectionality, will help support staff to understand the multiple layers of discrimination, and highlight the importance of accessing communities to support identity and individualism. Policy-makers, commissioners, and service providers must acknowledge the importance of these communities when designing local strategies. In addition, as part of innovatory local policies, provider agencies need to encourage their staff towards positive risk-taking (Robinson et al. 2020).  Introducing mentoring programmes which draw on members of the gay community without intellectual disabilities, who are willing to support service  users  to  access  'gay  spaces,'  is  one  way  of  achieving  this.  LGBT+  intellectually disabled people could engage with interest groups, social events, and outings to gay pubs and clubs. Nonetheless, the key to the full social inclusion of LGBT+ citizens with intellectual disabilities lies in providers equipping their staff with appropriate training to support the sexual identity and gender expression of their clients.  This study has evidenced the lack of awareness about sexuality among many social care staff and clinicians. It recommends that health and social  care  providers,  involved  in  supporting  people  with  intellectual  disabilities,  must implement compulsory LGBT+ equality and diversity training for all staff.  The training should be completed by employees on a regular basis, and sessions should be group based as opposed to online, covering topics such as: language, diversity, homophobia, biphobia, transphobia, and health  inequalities.  Training  policies  must  be  designed  at  a  local  level  that  include  the experiences and thoughts of, not only the service user but also draws on members of the gay community, involved in the mentoring programmes. This will allow for first hand experiences to be shared and moreover it will enable staff to empathise.  A part of the training should allow staff time to examine their own negative beliefs and prejudices about gay people. Provider organisations need to communicate clearly in the training strategy and subsequent group based sessions  that  homophobic,  biphobic  and  transphobic  abuse  or  bullying  is  unacceptable. Literature placed in prominent parts of day centres, residential accommodation and supported living  should  be  there  to  encourage  the  reporting  of  bullying  or  abuse.  The  complaints procedure should be up-to-date and it must be made clear that complaints about homophobia and transphobia will be taken seriously. Alongside routine training,  monitoring of sexuality and gender identity needs to be implemented to improve health and social care outcomes. The\n\ninformation  gathered  from  monitoring  can  be  used  to  inform  and  revise  policy  annually. Commissioning, partnership and consultation boards must allow for the inclusion of service users with intellectual disabilities who are LGBT+ to accurately reflect the full and diverse range of clients, that services endeavour to support. Finally, this study recommends the next stage in advancing the rights and protections for non-heterosexual citizens with intellectual disabilities  is  to  create  within  local  environments,  pioneering  educational  programmes, community awareness, and health promotion plans that will generate empirical data offering fresh perspectives to inform the development of local strategies.\n\n",
         "Feelings of marginalisation impact the lives of LGBT+ people in a fundamental way, but for those who have an intellectual disability, and are gay, there is a heightened sense of alienation. This article examines the unique oppression faced by these individuals in a heteronormative and ableist world, where a long history of extreme control of sexual intimacy has resulted in harsh forms of social exclusion. Although moves have been made to empower service users who are intellectually disabled and identify as LGBT+ to participate fully in life, there is also a need to assess the relationship between rights, responsibility, and risk. This article further explores whether by drawing upon government social policy, barriers are being dismantled through the development of innovative local strategies that aim to deliver non-discriminatory person-centred services.",
         ""
        ],
        [
         "36",
         "36",
         "## THE POST-HUMAN AND ITS COMPLEXITIES\n\n\nBefore examining specific works, it is necessary to outline the two key themes - namely the posthuman and cybersexuality. Post-human as an academic term has been debated widely since the late 1970s. Ihab Hassan's Prometheus as Performer: Toward a Posthuman Culture? , published in 1977, contends that technology not only influences medical science but also governs our daily consumer culture. Meanwhile, Steve Nichols's Posthuman Manifesto , published in 1988, maintains that people today are already living in a post-human condition. Related critical theories began to flourish in the West during the 1970s and 1980s, while several other familiar terms prefixed 'post-' may all be related to the philosophical aspects of the post-human, which is a notion that concerns the 'other' while also inferring a sense of undecidability (Miah 2008: 71-94). Meanwhile, Judith Halberstam and Ira Livingston have described the proliferation of academic 'post-isms' as 'simultaneously the necessary or regrettable failure to imagine what's next' (1995: 2). Consequently, the phenomenon of the 'post-human' reveals a state of anxiety and uncertainty resulting from the condition of being between human and inhuman. The post-human takes the shapes of our bodies, but is a hybrid of our biological forms and technology, such as a cyborg, which according to feminist philosopher Donna Haraway is 'a cybernetic organism, a hybrid of machine and organism, a creature of social reality as well as a creature of fiction' (1991: 69). Features of the 'post-human' in Lin's work may also be seen  via  her  imagined  Eve,  which  is  itself  a  cyborg,  a  mixture  of  mechanical  and  biological organisms. Furthermore, according to Rosi Braidotti:\n\nAfter the post-human, the postcolonial, the post-industrial, the post-communist and even the much contested post-feminist conditions, we seem to have entered the post-human predicament. Far from being the nth variation in a sequence of prefixes that may appear both endless and somehow arbitrary, the post-human condition introduces a qualitative shift in our thinking about what exactly is the basic unit of common reference for our species, our policy and our relationship to the other inhabitants of this planet. (2013: 1-2)\n\nLin's Eve Clone series may be related to Haraway's concept of the cyborg, where the post-human demonstrates a form of tension and undecidability between the human and the non-human and the idea of the phenomenon of combining the human body with technology. A cyborg is an organism in a digital domain, as well as the mixture of artificial and organic life, while it is also both a social reality  and  an  element  of  science  fiction  (Haraway  1991:  149-81).  A  cyborg  as  an  individual\n\ntranscends gender duality in the material world, and by rejecting gender duality cyborgs further deconstruct  gender  identification  and  re-present  the  bodily  symbols  of  post-humanist  desire.  A cyborg may be fluid and virtual without a physical form, or it may be an image that exists in digital technology, or it may be presented in concrete forms via multi-media technology, such as in Lin's Eve Clone series.\n\nIn  addition  to  the  phenomenon  of  the  cyborg,  the  concept  of  cloning  has  long  been  an essential of Lin's work. A clone is produced asexually via technology or natural birth, and the birth of Dolly, the cloned sheep, signalled the moment at which humans could themselves become the subject of propagation via biotechnology. Lin's belief is that God created Eve, while a human (i.e. the artist herself) created Eve Clone , as a hybridized human or a cyborg. The post-human body is a cyborg body existing in virtual domains on the Internet, including the 'organic' body of hybridized organisms and the 'non-organic' body stemming from the combination of robots and technology. Lin's Eve Clone responds to this concept of the post-human body, and the ideas of cybersexualities.\n\nFrederick Abraham stated that '[c]ybersexualities emerge from the confluence of postmodern cultural theory, feminist theory, and recent trends in science fiction, and extrapolations from fields related to artificial intelligence, which are largely due to advances in technology' (2010: 3). It is now evident that technology has realized people's imagination of science fiction and fairy tales from the past. Creating the perfect being is quite different from creating a Frankensteinian monster. Lin's Eve Clone series  consists of  several items including technology, screens, projected images and other materials, which are either virtual or physical, but which are non-biological, and are the imagined surfaces created by the artist.\n\n\n## LIN'S EARLIER WORK AND THE FEMINIST IDEOLOGY\n\n\nWhen examining Lin's early experiences and inspiration for her art, it is evident that a consciousness of feminism influenced her artworks from the outset, and across Lin's twenty-year career as an artist it is not difficult to see several repeated concerns and themes in her works. In 1989, she returned from  studying  in  America  and  commenced  her  energetic  participation  in  the  activities  and exhibitions of the alternative art space Apartment 2, where she began to develop a new approach in her work,  while at the same time as working as a busy and productive artist and teacher, she also 2 had to negotiate the dual roles of being a wife and a mother. Lin then began to be influenced by western feminism while in Australia during 1993 when she studied for her Ph.D. in Creative Arts.\n\nAfter returning to Taiwan once more in 1995, she attended several Taiwanese organizations and activities related to feminist art. Although Lin is deeply influenced by feminism from the 1980s and early 1990s, it is worth noting that her recent artworks using digital art do not initially appear to directly criticize patriarchal ideology. On the contrary, with a more macroscopic view, it appears as though there has been a shift in the issues within her works from an emphasis on feminism to caring about life and nature in more general terms.\n\n<!-- image -->\n\nLin was inspired to create the beautiful, sensual body of Eve in the Eve Clone series by her earlier work, Antithesis and Intertext (1995) (Figure 1), displayed at the Taipei Biennial 1997 held at Taipei Museum of Fine Arts.  In 3 Antithesis and Intertext , Lin arranged five images inside water lilies,  depicting  a  conventional  notion  of  beauty  in  women's  faces  in  contemporary  Taiwan. However, these are western women's faces with large blue eyes, thick eyebrows, blond hair, high noses and full lips. In the bottom left-hand part of the work, large-breasted western women are shown, while high-heeled shoes are represented in the water lilies above. In the top right-hand section of the work,  five  representative  Oriental  women's  faces  grow  from  the  water  lilies,  illustrating  a stereotypical view of ancient beauty. Such Oriental beauties were said to have 'willow eyebrows, apricot eyes and a cherry mouth' (these are the terms used to describe beautiful women in classical Chinese Literature). In Antithesis and Intertext , she criticized 'materialized female bodies' and the male gaze in modern society, which has long been restricted under Confucian values. Being one of the first Taiwanese feminist women artists, Lin's earlier works were created primarily to challenge\n\npatriarchal values in Taiwan, and her recent works also follow this route, yet with more critical views about the impact of technology on people's lives.\n\nSuch characteristics are part of a broader ecofeminist philosophy with which she is engaged, in which it is generally asserted that capitalism and patriarchy take both nature and the female as colonized objects. Karen Warren has asserted that 'Ecological feminism [takes] the position that there are important connections between how one treats women, people of colour, and the underclass on one hand and how one treats the nonhuman natural environment on the other' (1997: 4). She further argues that 'What makes ecofeminism distinct is its insistence that nonhuman nature and naturism (i.e., the unjustified domination of nature) are feminist issues' (1997: 4). In other words, among  the  wide  variety  of  feminisms  (liberal  feminism,  Marxist  feminism,  radical  feminism, postcolonial  feminism  and  so  on),  ecofeminism  considers  non-human  nature  and  naturism  as feminist issues. Consequently, in an ecofeminist vision, the freeing of nature and women will lead to a return to a more caring relationship between human beings and the natural world around us. Criticizing  the  superego  and  exploitation  of  nature  is  replaced  by  a  caring/custodial  approach towards the natural environment, and this approach may be traced in Lin's 1999 artwork Treasure: Back to Nature (1999-2004) (Figure 2), which shows the transformation of her artistic concerns in this direction. Back to Nature , consisting of billboard light boxes of digitally printed skies, seascapes and grass in the shape of square boxes, ovals, balls and other irregular forms, creates a kind of artificially fictitious landscape. Since then, Lin has been producing virtual images via technology, which often interact with the audience, yet she also exhibits sculpture-based objects, such as Hands of Eve Clone , which are physical objects displayed in the gallery space. Her interest in ecofeminist patterns of thought moved to another level in 2001, after beginning teaching in the Department of Multimedia  and  Animation  Arts  at  the  National  Taiwan  University  of  Arts.  Here,  her  direct engagement with science and technology to create art led her to a digital rendition of the female body  of  Eve.  Lin  remains  critical  of  a  technocratic  vision  of  civilization  as  transcending  and improving upon nature and rather seeks to reclaim the importance of nature, using the problematic figure of Eve to reconceive our relationships in a digital and technological world.\n\n<!-- image -->\n\n<!-- image -->\n\nAny analysis of works of art made with new technologies cannot be undertaken merely by focusing on innovations in the use of technology in art. The cultural and symbolic meanings behind artworks,  and  their  relationship  with  society,  remain  the  most  significant  elements  requiring interpretation during the analysis of a contemporary work. The analysis of Lin Pey-Chwen's work also needs to follow this kind of method. Lin's earliest work in the series, Eve Clone II (Figure 2) was created in 2006. Eve is represented here as a perfect female without any body hair, an unreal and quasi body, wholly created by the artist. It is a digital human situated somewhere between the\n\nreal and the fake, between the organic and the inorganic. Lin combined the portrait with images of butterflies  and  pupa to create a human body like a butterfly's pupa, and through the interaction between  the  audience  and  a  computer  program/screen  using  the  effects  of  sound  and  light  the butterfly becomes animated and begins to flap its wings. Through her colourful lighting effects and sounds, the artist explores issues of artificial life in a digital world, while suggesting a conflict in the relationship between science and nature by her juxtaposition of (the perfect) Eve and the short life cycle of a butterfly. Eve Clone II was an interactive installation, comprising an interactive device, three-dimensional (3D) computer-generated animation and webcams. In this piece, Eve Clone was created like a cloned human living in a laboratory tube, while the tube in which Eve Clone is hidden also  resembles  a  larva  and  she  looks  as  though  she  is  in  the  process  of  metamorphosing  into  a butterfly. Lin's statements about Eve Clone II explain how there are many bubbles in the tube, which can be seen as the nutrients (the computer programmes) for Eve Clone. When audiences view this work, the webcam will be operated to capture their images, which will then be integrated within the bubbles. (Chiu 2009: 15)\n\nIn Eve Clone II , we are confronted by a living cyborg undergoing the process of cloning, and, with the aid of technology, Lin invites visitors to take part in this process, through which the computer generates images of the cyborg Eve Clone, and those of people who are hybridized together to create a unique interactive piece of art.\n\nThe  form  of  a  larva  was  first  seen  in  Lin's  earlier  solo  show, Larva  Series ,  held  at  the National Taiwan Museum of Arts in 1993. Lin has explained that 'in that exhibition, [she] illustrated round shapes to resemble larvae and to depict the desire of breaking through 'restrictions', which were  [employed]  to  describe  [her]  yearning  to  challenge  the  patriarchal  ideology  of  Taiwan's society'.  Thus, for Lin, larvae have strong symbolic connotations with the suppression of women 4 in patriarchal society.\n\n\n## THE EVE CLONE SERIES AND ITS BIBLICAL SYMBOLISM\n\n\nTo re-emphasize how the work uses both technological and substantial views of feminist ideas, the concepts of the post-human and cybersexuality are used here to offer a different narrative of Lin's work Portrait  of  Eve  Clone .  While  formally  innovative  in  her  development  of  a  figure  created\n\nthrough  or  displayed  via  a  post-human  creation,  Lin  also  explores  how  religion  (specifically Christianity in this case) offers a different dimension to her portraits. The religious theme is not visualized in traditional iconography, as Lin transforms the religious theme into her art, which is not predominantly a religious reading of Eve. The artist herself was keen to point out that she was recently  interviewed  and  featured  by  IGNITE,  a  US-based  organization  that  features  stories  of women  and  girls  who  are  leading  and  innovating  in  science,  technology,  engineering  and mathematics. 5 IGNITE picked up on the religious  text  evident  in  the  work  and  described  Lin's Revelation of Eve Clone III (Figure 4), exhibited at 'Post-humanist Desires', curated by myself and held at the Museum of Contemporary Art Taipei in 2013-2014, as follows:\n\nThe clones are distinguished by various Biblical references: skin tones based on materials referred to in the Bible; hymns as backing music; and a line from the Book of Revelations translated into multiple major languages. […] Eve Clone is presented as the 'Great Image' of human desire as well as a testament  to  human  greed  and  attempts  to  gain  virtual  power  through  technological  civilisation. (http://ignite.globalfundforwomen.org/gallery/eve-clone-series, accessed 13 December 2014)\n\n<!-- image -->\n\n<!-- image -->\n\nFurthermore, Eve represents a kind of avatar that strongly re-presents different concepts of the  body  in  Lin's  work.  The  adaptation  of  a  cyborg-like  body  in  her  work  seems  to  relate  to technophiles' dreams of uploading themselves onto the Internet, refashioning their own bodies, or developing a perfect avatar in cyberspace. Lin's Eve Clone may appear to create the perfect being in cyberspace through artistic aesthetics and new media technologies, but she shows both its dark and strange  sides  simultaneously.  Another  critic  who  has  taken  an  interest  in  Lin's  work  is  the Australian curator currently based in Taipei, Antoanetta Ivanova, and she has also described the Eves in Lin's work as 'alien beauties' (2011: 9-10). Lin's 2010 version of Portrait of Eve Clone (Figure 5) is very different from Eve Clone II , as this Eve was specifically inspired by the line in the book of Revelation: '13:18. God prophesied that the mark of the beast, 666, will be marked on people's foreheads'. 6\n\nAnother significant body of work in Lin's oeuvre is Portrait of Eve Clone series, which was exhibited in The Museum of Contemporary Art, Taipei, in 2011, and which expresses a sense of evil through  the  half-human-half-beast  body. 7 It mocks  the  potential  damage  to  mankind  by  its progressive development of technology, and in an active and direct way it reveals social restrictions upon the female body as a trapped beast. Lin explains how:\n\nI have attempted to represent the luxury and urbanization of artificial landscapes. The frames, glass medical tubes and medical jars show the process of the birth of artificial life, and how it is preserved\n\nand  experimented  upon.  The  numbers,  symbols,  sounds  and  images  in  my  works  describe  an important 'appropriation' concept. The number shown on the specimen insects, Eve Clone, 666 (the mark of the best), computer time codes, tattoos, scriptures from the book of Revelation in the Bible and holy songs define the artificial life's character and status. (2011: 4)\n\nEve's head is hybridized with many kinds of beasts through Lin's use of 3D dynamic holograms, so the body is rendered in different colours and the textures of minerals. Thus, the skin of Eve, with its diverse textures and colours, displays several possible hybridized forms of human and beast. The number 666 is shown in various languages, including Chinese, Japanese, German, Arabic, Egyptian and Hungarian, all of which are mentioned in the Bible. Through this work, the artist expresses her fears about the negative effects on humans that result from the extreme development of technology.\n\nThis particular series is also important because it continues and develops the concept of an earlier work, Specimen (2006), in which the portraits of Eve, which have been placed in black frames made  of  transparent  acrylic  material,  are  reminiscent  of  specimens  of  dead  bodies.  Eve's  eyes strangely move and follow the viewer as they walk past the frame and in this movement she seems to be alive and watching her human audience. The work generates a sense of tension and unease, similar to that between science (inorganic) and nature (organic), which is what the artist is asking us to question. As a result of the viewer walking back and forth in front of the work, the figure appears to be seen through a 360-degree image effect. Here, again, the rendering of Eve's skin is critical: the hybridized epidermis is made of different patterns, colours and textures and is presented in a form of cyberspace within the frame of the screen, this utilizing Lin's dream of presenting her post-human Eve via the lens of digital art forms and holographic technologies.\n\nFurther  analysis  of Portrait  of  Eve  Clone through  iconography  is  revealing,  specifically because,  prior  to  the  emergence  of  what  we  now  identify  as  modern  art,  iconography  was  the dominant method employed by art historians to analyse religious artworks, focusing on the symbols used and how they were deployed and depicted in the picture plane. Although Christian religious imagery as a direct source of inspiration has not been widely adopted by contemporary artists, it remains  valid  as  it  is  undeniable  that  Christianity  is  still  taken  as  a  source  of  motivation  and inspiration for creating critical forms of contemporary art. For example, the Swedish photographer, Elisabeth  Ohlson,  created  her  controversial Ecce  Homo series  based  on  Christianity.  Ohlson employed people who were lesbian, gay, trans-sexual and transvestite and placed them in religious\n\nsettings, such as the crucifixion of Jesus and the Last Supper. Ohlson's Ecce Homo deliberately raised  issues  of  sexuality  with  strong  biblical  references  to  challenge  people's  views  towards sexuality and Christianity (Artsfreedom, 2012). The religious references in Lin's works are both direct  and  indirect;  however,  the  focus  on  the  number  imprinted  on  Eve's  forehead  is  widely recognized as a symbol of the Devil. This is another crucial element, revealing Lin's management of how the work should be read, since, like many works using specific religious symbolism, the audience needs to be able to understand the specific iconography of the images. Members of the audience need to have prior relevant knowledge to understand the particular symbolic transformation or the artist's interpretation of familiar images, or they will easily become immersed in the visual effects  of  the  technology  of  the  artworks,  thereby  overlooking  any  meaning  the  artist  wants  to express. While the work is undeniably clever in its use of digital technology, the central motif of the three sixes indicates the artist's intended interpretation.\n\nAt this point, it is worth commenting on Eve's place in Christian beliefs. Eve is recognized both as the first and as the ideal woman, but she was also manufactured from a part taken from a man, and her creation implies a sexual hierarchy in which she is a lesser being who is always placed second in the scheme of life. In modern society, Eve has often been seen as the ideal woman for man, and is also seen as the purest fantasy form of a woman by scientists who have ostensibly taken the place of God and can now fashion their own Eve if they so wish. Consequently, Eve Clone has been created by Lin to challenge and re-interpret Christianity's estimation of Eve, women and the role of scientists in fashioning human beings.\n\nSexual hierarchy is a part of Christian theology, and not only is Eve the second sex but, through her disobedience, she is also marked as distinctly inferior to Adam and, thereafter, all men. Thus, the universal bias in the Judaeo-Christian tradition began with the story of Adam and Eve. The objectification of women can also be seen in Greek stories, such as Pandora's Box , in which Pandora removes the lid of the box and unleashes all evils into the world. As Gerald Kreyche states, 'women long have been honoured in theory, but debased in practice' (2004: 82). Kreyche goes on to give an example from the Catholic Church in which Mary, the mother of Jesus, is also called the Queen of Heaven, and yet the Pope will not allow women to be priests. Nuns perform second-class duties  for  the  priesthood,  by  being  house-keepers  for  pastors,  maintaining  flowers  on  the  altar, teaching youngsters, etc. Earlier feminist literature challenges this form of sexual inequality, and attempts to offer another picture of Eve, who has long been regarded as second to Adam. Phyllis\n\nTrible provides an inspiring and ingenious re-reading of Genesis 2 and 3, and creates a form of mutuality between the sexes (1978: 72-143). She argues that the creation of Adam in Genesis 2 is not necessarily the creation of the male sex, but rather it is the creation of an 'earth creature', which does not identify sexual differences (Trible 1978: 79-82). Sexual identity only appears when woman is created and the 'earth creature' becomes two mutually companionable beings of male and female sexes. Following such perspectives on gender, it is evident that Lin's work is heavily influenced by the ideas of sexuality and gender. Lin's reinterpretation of Eve has gone beyond her earlier feminist criticism  of  sexual  dualism  (e.g. Antithesis  and  Intertext ).  Rather,  she  is  more  interested  in  the symbolic signs carried by her Eve created through artificial life and new technologies, because she represents a threat to our living environment, life and society.\n\n<!-- image -->\n\nAlongside the various appearances of Eve, made with 3D dynamic holograms, Lin has also created Portrait of Eve Clone III (Figure 6), which makes use of interactive images. Six Eve Clone faces  are  presented  through  the  combining  of  six  different  mineral  colours  and  textures  with interactive images within a hexagonal site, made through the use of digital imaging technologies. When the viewer moves in front of the artwork, Eve's appearance seems to change continuously. Sometimes the image shows a frontal view, sometimes the back, and sometimes the image appears to be turning around. After Eve turns around, the image moves up and down as though it is about to leap out of the frame. Portrait of Eve Clone III was shown with six interactive projection devices when it was first exhibited in The Museum of Contemporary Art in 2011, and then at the  2012\n\nTaiwan Biennial at the Taiwan Museum of Fine Arts. Lin used 3D computer animation technology and kinetic sensors in an interactive computer system to create the mysterious Eve Clone faces. With ambient  sound,  this  work  takes  flowing  water,  light  and  shadows  as  its  background.  Eve's appearance continues to change with the movement of the audience, while the reflection from the water and the light also changes. The changes to Eve's image result from people's physical presence in the space and their interference as they move, combining the interaction between humans and technology in a new way. However, it is a relationship of ambiguous, mutual influence and blindness being emphasized in this work, as explained by Lin: 'God created Eve [but] humans created the Eve Clone'.  Lin's emphasis on the fact that a human (i.e. the artist) created the Eve Clone indicates the 8 God-like creativity of people resembling the capability of Creator. The Eve Clone image is the result of  human  creation  through  technology,  while  the  strange  beauty  of  the  Eve  Clone  reflects  the negative influences of artificial and technical civilization on nature. At the same time, Lin expresses the unique characteristics of Eve through a mix of human and beast. There can be little doubt that this interactive work creates stronger sensory effects than those of her 3D dynamic holograms.\n\n<!-- image -->\n\nThe number 666 appears again on Eve Clone's right hand. In 2011, Lin produced Hands of Eve Clone (Figure 7), six pairs of hands all made of resin, which she placed in the type of glass jars that are commonly used to store organs in hospitals. The skin on the hands is composed of snake skin, tree bark, pupa skin, shell, metal, ore and other materials, representing the genetic mutations of Eve Clone.  The properties of Lin's work can be seen in the artist's statement for her solo show 9\n\nheld at MOCA Taipei in 2011, in which she quoted Roland Barthes: 'The best weapon against myth is perhaps to mythify it in its turn, and to produce an artificial myth' (2011: 4). The Eve Clone hands are  a  complex  creation.  First,  Lin  made  sculpture  moulds  and  then  transferred  the  work  into transparent resin. The artist arranged blue-green lasers and bubbles on the hands in the glass jars to invoke a more mysterious atmosphere. Looking closely at the hands with their strange textures and images, it seems that they symbolize the same concept as Eve - a body, or part of a body, which is a  hybrid  of  human  and  beast.  Displaying  the  hands  as  3D  objects  placed  in  glass  containers emphasizes their properties as specimens, which is to strengthen the idea that Eve Clone is artificial, responding to the impact of technology. Similarly, in Lin's Fingers of Eve Clone (2011) (Figure 8), she has placed transparent resin finger sculptures into medical test tubes, and then exhibited them in black acrylic frames. As with Hands of Eve Clone ,  Lin  illuminated the fingers with green light. Through  this  more  recent  work,  Lin  again  offers  a  view  of  Eve  in  the  process  of  creation, emphasizing what is artificial and produced through scientific endeavour, rather than something that is natural. Rather, the artist proposes going 'back to nature' through science and technology. Via Eve's inorganic, artificial genes, the work again criticizes digital technology and artificial life as transcending nature, while calling for an eco-feminist approach to a new relationship working with nature.\n\nIn Lin's solo show, held at the Gallery Grand Siècle in Taipei in August 2011, she exhibited three new works, Mass Production of Eve Clone (Figure  9), Revelation of Eve Clone I and The Inspection of Eve Clone . Mass Production of Eve Clone consists of eighteen digital frames of Eve Clone, hung on a wall. Revelation of Eve Clone I is a multi-media interactive installation and The Inspection of Eve Clone is a body of digital images. Eve Clone spreads the fingers of her right hand and gently touches her breast. Her left hand is placed in front of her eyes, which look downwards. The eighteen images show the same Eve Clone, but like the earlier works they are expressed in different colours and textures. At the same time, across the sequence of works, the figure rotates through 360 degrees, with each frame showing a different angle. The work is extremely similar to Hands of Eve Clone in that the figures look as though they are immersed in liquid and placed in medical tubes or jars. For this work, Lin explains how 'mass production and normalisation represent the production process, through which it creates something which is completely the same as the original, using a cloning technique'. 10 Eve Clone's character is exposed in this work as both artificial\n\nand  mechanical.  Expressed  through  its  neat  presentation  of  eighteen  digital  frames,  the  work provides a metaphor for artificial and inorganic life characters in a clone factory.\n\n<!-- image -->\n\n<!-- image -->\n\nThe Taiwan-based critic and curator Hongjohn Lin reviewed Lin's Eve Clone series, arguing that  'the  installation  creates  a  situation  of  a  sci-fi  laboratory  to  archive  and  preserve  the  cloned version of Eve, as if ruins of technology' (2011: 7). It is interesting to read that, despite the fact that\n\nLin's Eve Clone is created with advanced technology, the work itself actually embodies the idea of , which was shown through a huge interactive display system using  two synchronized projectors.  With  such means, the artist attempted to overlay different and sometimes overwhelming images of Eve Clone.\n\nthe 'ruins of technology'. This concept can also be seen in Revelation of Eve Clone I Through a special computer program, Lin displayed against each image an accumulating number, calculated in milliseconds. The accumulation of the number was triggered each time an audience member entered the exhibition space. When the viewers left the space, the number automatically stopped accumulating and the colour of the image would gradually turn to black and white. Lin's works use such techniques to construct her criticism of the confrontation between the artificial and the natural, by showing how each element both parallels and resists the other, and this has been evident since her early work, the Back to Nature Series from 1999. The transformation of numbers and images caused by the presence of the viewers of Revelation of Eve Clone I again responds to the artist's attempts during the past ten years to represent different versions of artificial life. In addition, the background music creates an uncanny atmosphere, adding to the viewer's perception that on entering the installation space they are being immersed in an unreal world. Eve Clone's beautiful but evil image and the continuously changing Bible scriptures and the eerie music offer the audience a  haunting  yet  rare  sensory  experience,  designed  to  stimulate  the  audience's  imagination  and perception towards sexuality, the body and virtuality.\n\nThe next piece to consider is Lin's Inspection of Eve Clone (Figure 10), which reveals two aspects of her quasi skin. First, Eve Clone is constructed from digital skin and, second, the tattoos on her quasi skin show some of the many ambiguities surrounding both body and technology. The tattoos selected by the artist include a rose, a dragon, a phoenix, a snake and a scorpion. The patterns of the tattoos connect to the idea of taking a specific iconography and transforming its symbolic connotations. Both the tattoos and Eve Clones signify a 'beautiful trap', something alluring and at the same time repulsive, but they also combine within the installation to produce an atmosphere laden with references to hidden danger and evil. Inspection of Eve Clone is presented through digital prints, each of which shows different angles and parts of Eve Clone's body using infrared rays. Lin marks the number, date, time and the artist's name at the top and bottom of the work, as thought the artist is like a doctor, examining and diagnosing Eve Clone's physical appearance with a medical device. For Lin, 'the tattoo's pattern symbolises and reveals the hidden danger of the beautiful Eve\n\nClone under the inspection of infrared rays'. 11 In other words, through the infrared rays, the artist reveals the negative symbolic meaning of Eve Clone's beauty.\n\n<!-- image -->\n\n<!-- image -->\n\nIn  2013,  Lin  exhibited Revelation of Eve Clone III (2013)  (Figure  11)  at  'Post-humanist Desire',  a  group  exhibition  held  at  the  Museum  of  Contemporary  Art  Taipei.  Installed  in  an\n\nindependent gallery room, this work was a large multi-media and interactive installation, comprising moving 3D animation, interactive systems and a stereo system. When the audience walked into the gallery space, they were confronted with a bank of curved and wide projection screens that showed a  series  of  computer-processed  images  of  Eve  Clone,  which  is  created  with  a  simultaneously activated and interactive system, resulting in the movement of Eve Clone and the playing of some calm, religious music in the background. Eve Clone represents an existence that is both beautiful and dangerous, and yet worshipped. Her body echoes the concepts of cloning, reproduction and cyborgs. The ideas of the post-human reveal a state of anxiety and uncertainty resulting from the condition of being between human and inhuman. Features of the post-human in Lin's work can be seen  via  her  imagined  Eve,  which  is  itself  a  cyborg,  a  mixture  of  mechanical  and  biological organisms.\n\nLin's  Eve  Clone  may  appear  to  create  the  perfect  being  in  cyberspace  through  artistic aesthetics and new media technologies, but at the same time she shows its dark and mysterious side. Eve Clone is represented as a perfect female without any body hair, an unreal and quasi body, created by the artist. It is a digital human situated somewhere between the real and the fake, between the organic and the inorganic. The dark and haunting beauty of the Eve Clone reflects the negative influences of artificial and technical civilization on nature via a woman's hybridized body. Here, there is a remarkable similarity to the robot-shaped woman featured in Fritz Lang's celebrated early Science Fiction film, Metropolis (1927), about which Claudia Springer makes thought-provoking comments on cybersexuality and the connection between sexuality and technology:\n\n[ Metropolis ] combines celebration of technological efficiency with fear of technology's power to destroy humanity by running out of control. This dual response is expressed by the film in sexual terms: a robot shaped like a human woman represents technology's simultaneous allure and powerful threat. The robot is distinguished by its overt sexuality, for it is its seductive manner that triggers a chaotic worker revolt. (1999: 36)\n\nLang's use of the robot in the form of a human woman (who is a fake and evil copy of the character  of  Maria,  a  beautiful  and  essentially  well-meaning  woman)  is  particularly  telling  and interesting in the context of the threat and allure of technology. It is also interesting to note the similarity between the motivation of Lin's creation of Eve Clone (itself another fake and evil copy of an essentially beautiful or perfect woman) and the thrust of Springer's statement. Collapsing the\n\nboundaries  between  humans  and  technology  is  often  exemplified  via  sexuality  (especially  via women's bodies) in postmodern culture. To further illustrate this point, Andreas Huyssen also argues that  modernist texts tend to juxtapose machines with women, displaying and projecting fears of overpowering technology onto patriarchal fears about female sexuality (1981-1982: 221-37). Thus, it  is  evident  that  when  humans  interface  with  computer  technology  in  postmodern  culture  and creativity, the process is not simply about adding external robotic prostheses to bodies; rather, human identities are integrated within the mechanized human forms.\n\n<!-- image -->\n\nLin's  latest  animation, Great  Babylon (2015)  (Figure  12),  continues  the  artist's  style  of utilizing a sensual, yet artificial Eve Clone as the primary subject. Lin has placed Eve Clone in a real-life setting (i.e. the photograph of a bird's eye view of the Empire State Building in New York City) to warn people about the desires and sins they acquire when they vigorously and selfishly pursue success in politics, economics, culture, technology, religion, etc. 12 Opening her arms wide, and standing straight and firmly on top of the Empire State Building, Eve Clone seems like the great creator, a God, looking down on the twisted and surreal streets, which is the world in which we live. Lin's  exploitation  of  a  sensual  and  erotic  woman's  body  to  question  the  'sins'  people  are experiencing suggests a kind of human fear about the future, echoing both Springer's and Huyssen's views on cybersexuality.\n\n\n## CONCLUSION: TRANSCENDING THE RELIGIOUS EVE?\n\n\nLong before the terms post-human and cyborg had even been coined, artists, philosophers, authors and scientists imagined and interpreted the phenomena in diverse, complicated and multiple ways.\n\nExamples include the mechanical bird in the fairy tale The Nightingale (1843) by Hans Christian Anderson, the monster in Mary Shelley's Frankenstein (1818), and the robots in Isaac Asimov's science fiction novels, all of which are imaginary creation between biological bodies and technology. Arguably, there is also a contemporary example of a cloned Eve, in the shape of Repilee, a female robot made by Professor Hiroshi Ishiguro at Osaka University in Japan. It is indeed fascinating to examine the connection between woman, technology and cyborg, and the connection between the female cyborgs of Lin's Eve Clone, Lang's Maria and Ishiguro's robot Repilee, all of which suggest that technology's fantasized other is often in the shape of a woman. Undeniably, the evolution of technology is still an integral part of our interpretation of post-human issues today. Through Eve Clone, Lin demonstrates her own particular interpretation of the post-human, the transformation of the human body, mixed with organisms, robots or nature.\n\nIt is worth emphasizing that in any analysis of Lin's works it is hardly possible to separate her religion and faith from the art, because these are at the root of her work. Any valid reading of Lin's work should acknowledge the strong Christian references, but it is not appropriate to analyse Lin's works solely in terms of its religious connotations. This is a crucial truth of Lin's oeuvre , since it is underpinned with a maker's skill in the exploitation of cutting-edge media, where the aesthetics, techniques and the professionalism of the construction in her art undoubtedly surpass any religious meanings in the images and works. This is perhaps the major paradox; the heavy reliance on direct symbolic  connotations  from  the  Bible,  which  for  some  could  make  Lin's  work  appear  rather traditional and restricted, stands in stark contrast with the use of twenty-first-century technology, and yet this is precisely what is at the root of the message.\n\nConsidering  the  work  from  a  retrospective  viewpoint,  it  is  evident  that  Lin  has  been challenging the patriarchal order from within the value system itself. Lin created her Eve Clone series (and her earlier works) under a patriarchal ideology. That is, Eve's body represents easily recognizable  stereotypes  of  women  found  in  works  of  art  across  the  centuries;  however,  it  is interesting to consider whether Lin's post-human and hybridized Eve transcends the religious and symbolic cultural connotations of Eve. It is also evident that there is clear transition in Lin's work from the earlier period when she focused predominantly on a feminist approach to the representation of women in the patriarchal culture of Christianity, to her recent critique of technology.\n\n",
         "This article takes post-human and cybersexuality as the main perspectives from which to contextualize the Taiwanese artist Lin Pey-Chwen’s (born 1959) Eve Clone series, on which she has been working since 2006. It describes how Eve Clone’s virtual body of Eve expresses Lin’s perceptions of the symbols and imaginings of the post-human. The latest Eve Clone series explores issues of femininity, but is also related to the religious symbolism that Lin has adapted in the creation of her work. Although using science and digitality to create art, Lin criticizes technical civilization while reclaiming the importance of nature. In Portrait of Eve Clone, the cyborg body has been created from the main technical operation of digital technology, and this adaptation of a digital body examines the discourses of both the body and sexuality. Lin’s Eve Clone has created a perfect being in cyberspace through artistic aesthetics and new media technologies.",
         ""
        ],
        [
         "37",
         "37",
         "## THE DISCOURSES AROUND GUOXUE IN TWENTIETH-CENTURY CHINA: A BRIEF REVIEW\n\n\nThe  present  usage  of  the  word  guoxue  to  refer  to  traditional  Chinese  learning  first appeared in the reformist discourse at the turn of the twentieth century, with a strong indication of its supposed opposition to xixue (western learning); before that, the term was mostly used to stand for educational institutions established by the imperial court (Liu  2008:  16).  The  leading  late-Qing  reformist  Liang  Qichao  (1873-1929),  for example, once proposed to launch a newspaper titled Guoxue bao/The Newspaper of Chinese Learning (Fogel 2004: 178). For Liang and his colleagues, a redefinition of 'Chinese learning' with reference to the newly imported modern knowledge could serve as a foundation for political, social and intellectual reform. Zhang Taiyan (1869-1936), a more radical anti-Qing revolutionary who later became a master of traditional learning, also  enthusiastically  advocated  a  modernized  vision  of  'international  pluralism' (Murthy 2011: 52).\n\nSuch reformist approaches towards guoxue remained quite popular among modern Chinese intellectuals in the following two decades. For instance, Hu Shi (1891-1962), a leading figure of the New Culture Movement in the 1910s and 1920s, included both 'import [western] scholarship' and 're-organize traditional learning' in a famous series of slogans he proposed (Hu 2013: 74-79). Many print products bearing the catchword guoxue  mushroomed,  and  there  emerged  a  'Xin  guoxue'/'New  Chinese  Learning' movement in the 1920s when several institutions of higher learning set up departments devoted to such studies.\n\nIn the public discourse of the 1930s through the 1950s, however, as the advocates for traditional Chinese learning and for modern western ideologies gradually formed two polarized sides, terms such as guoxue and guocui ( 國粹 / national essence) became further politically charged and ideologically sensitive, which exerted a strong impact upon the Chinese film industry. In 1933, when the Shanghai-based Lianhua Film Studio proposed 'the promotion of national essence' as one of its guiding objectives, it was forced, under the pressure from left-wing film-makers and critics, to revise the slogan into 'the promotion of culture' (Cheng 1980: 246-47). The advocacy of Confucianism during the 'New Life Movement' launched in the  mid-1930s by  Chiang Kai-shek's Nationalist  government  further  led  many  radical  left-wing  intellectuals  to  associate guoxue with rearguard conservatism. Luo Mingyou, for example, encountered severe obstruction and criticism when making the film Guo feng/National Customs (1935), which was criticized for 'demonstrat[ing] the importance and effects of the New Life Movement through the story of a love triangle' (Hu 2003: 108). Fei Mu's 1940 movie Kongfuzi/Confucius was  also  disparaged  by  left-wing  critics  for  favouring  'national essence' and political conservatism (Chen 2000: 194). Meanwhile, the various explicit and implicit tensions and conflicts between the 'traditional' and the 'modern' also led to numerous debates over which aspects of Chinese culture should be kept as part of guoxue  and  which  should  be  discarded,  hence  the  popularity  of  such  antonyms  as guocui and guozha (national dregs). While the distinctions between the two sides were by no means always clearly defined, such vocabulary frequently occurred in not only intellectual discussions but also literature, film and popular culture.\n\nThe condemnation of traditional learning intensified even more after the founding of the People's Republic of China in 1949. Confucianism was considered as not only moribund  but  also  counter-revolutionary,  and  the  criticism  reached  its  peak  in  the 'Criticize Lin, Criticize Confucius' 2 Campaign launched in 1974. Yang Mo's 1958 novel Qingchun zhi ge/Song of Youth and its 1959 eponymous film adaptation by Chen Huaikai and Cui Wei provide good examples of a politicized and instrumental view toward traditional Chinese learning in the literary and film production of the Maoist period. In this story, the young female protagonist Lin Daojing undergoes her Bildung , or formation, by choosing a Communist college student devoted to political activism over a conservative young scholar of traditional Chinese learning.\n\nSince the late 1970s, however, there has occurred a 'New Confucian Revival' in post-socialist Chinese intellectual and academic circles to help fill up the 'ideological vacuum' after Mao's death (Nylan 2001: 337). As terms such as 'a new enlightenment' became impressively  hot during the 'culture  fever' of the 1980s, when  intellectuals 'busily proliferated their own discourse on thought enlightenment' (Wang 1996: 37), many  critical  reflections  emerged  upon  the  earlier  canonical  critique  of  traditional Chinese  learning,  and  enthusiastic  calls  were  voiced  for  re-evaluations  of  guoxue. Drawing upon the neo-Confucianism theorized  by Harvard professor Tu Wei-ming, scholars  such  as  Tang  Yijie  from  Peking  University  argued  for  the  significance  of Confucian traditions in the contemporary domestic and global contexts. According to Tang, 'China's positioning itself in [Chinese] culture' does not purport a simple return to old ideologies but, instead, seeks for an 'assurance that Chinese culture can root itself rigorously  in  society'  (Solé-Farràs  2014:  28).  Li  Zehou,  arguably  'China's  most important Marxist thinker in the postMao decade' (Liu 1993: 32), contended that the iconoclastic vision of the May Fourth tradition was too oversimplified and proposed a 'Marxist reconstruction of Confucianism' (Wang 1996: 93).\n\nAs  the  discussions  on  guoxue  went  on,  the  previous  questions  about  'national essence' and 'national dregs' have also been brought back. A few early Fifth Generation films, such as Chen Kaige's Huang tudi/Yellow Earth (1984), actively responded to these historical and cultural reflections. CCTV's 1988 TV documentary He shang/River Elegy ,  directed by Xia Jun, provided one of the most vehement critiques of Chinese civilization, considering it as inferior - backward, closed and lacking in the capability of  self-renewal  -  to  its  western  counterparts.  Due  to  its  radical  approach,  the documentary triggered intense debates and was later banned by the government.\n\nState  endorsement,  on  the  other  hand,  favours  a  more  positively  mediated reconstruction of guoxue as part of its own 'ideological mobilization […] to legitimize its power and rule' (Lai 2008: 109). In order to promote cultural nationalism, state-run media have launched numerous lectures and other programmes on guoxue since the 1980s. At the same time, China's successful economic growth, which is often seen as a long-awaited recovery from the many national failures in the nineteenth and twentieth centuries,  also  encourages  the  domestic  audience's  yearning  to  reconstruct  cultural identities, memories and confidence. The confluence of all these factors has led to a socalled  'Chinese  traditional  learning  craze',  as  announced  by  the  official  state  news outlet Renmin ribao/People's Daily in the mid-1990s (He 2001: 159), which continues into the new millennium and has attracted much attention from Chinese film-makers.\n\n\n## FORMAL PLURALISM VERSUS THE IDEOLOGY OF TIANXIA: DEFINING CHINESE-NESS IN HERO\n\n\nZhang  Yimou's  2002  blockbuster Hero draws  upon  the  many  assassination  stories around the First Emperor of Qin (259-210 bc), the controversial tyrant and first unifier of China. The movie's twist in the relationship between the Emperor (then still King of Qin) and the assassin, however, noticeably differs from earlier literary renditions such as  the  Grand  Historian  Sima  Qian's  (c.145-86  bc)  masterpiece Shiji/Records of the Great Historian and the anonymous Han dynasty book Yan Danzi/Prince Dan of Yan . While both ancient texts highlight Jing Ke's loyalty to his patron, Zhang's movie, on the  other  hand,  features  the  fictional  character  Nameless  coming  to  terms  with  the Emperor's unification cause and replaces the bond between the assassin and his patron with the hero's lofty concern for tianxia (all under heaven).\n\nIn order to avenge his family and mother kingdom, Nameless of Zhao persuades three other assassins (Long Sky, Broken Sword and Flying Snow), who have failed in their own attempts, to pretend to surrender their lives in fake duels with him, so that he can approach and kill the King of Qin when turning in the three's swords in the Qin palace. The plan works smoothly at the beginning, which earns Nameless more and more proximity to his target, but the King realizes the trick before allowing Nameless the last advancement of ten paces. Surprisingly, when confessing the plan, Nameless reveals a secret conversation between him and Sword, where the latter suggests that the only way to achieve peace is to unify all the warring states and the sole person who can do it is the King. With Nameless's masterful swordsmanship, ten paces is a distance short enough to carry out the assassination, but he chooses to give up for the better good for  'all  under  heaven'.  Even  though  the  King  is  deeply  touched  both  by  Sword's understanding of him and by Nameless's selfless heroism, he gives an order to execute Nameless so as to exemplify to the world his strict and impartial rule.\n\nAlthough the director himself has openly denied that the decision to make Hero was based on the critical acclaim and box office success of Ang Lee's 2000 martial arts blockbuster Wo hu cang long/Crouching Tiger, Hidden Dragon (Shih 2007: 37), the latter's influence is more than obvious. Like Crouching Tiger, Hero 's representational strata  of  Chinese-ness  as  a  cinematic  spectacle  includes,  firstly,  the  distinctively Chinese  martial  arts  genre;  secondly,  a  splendid  visualization  of  traditional  arts  and skills,  such as swordsmanship, calligraphy and music; and thirdly, the integration of traditional Chinese philosophies and ideologies into its narrative framework. Yet in this third respect, Hero 's forceful utilization of Confucianism and Legalism, as in contrast to the  much  more  mild  mingling of Taoism  and  Confucianism  in Crouching Tiger , abandons  the  supposed  opposition  between  jianghu  (martial  arts  underworld)  and miaotang  (the  court  and  government)  in  the  martial  arts  tradition.  Such  a  selective remapping  of  traditional  Chinese  culture  seems  to  readdress  the  earlier  intellectual question about 'national essence' and 'national dregs'. The major concern, however, is no  longer  about  how  to  save  or  push  forward  the  nation  when  faced  with  global competition, but, instead, about how to come to terms with sacrifices that are seen as necessary, meaningful and heroic along the line of national progress.\n\nFrom the opening scene to the last shot, Hero negotiates between a pluralistic presentation of cultural heritage and a monumentalist longing for a unified cultural and political  entity.  The  film  devotes  more  than  half  of  its  length  to  the  exhibition  and celebration of the heroes' exquisite mastery of arts and skills, which are claimed to have significantly inspired their swordsmanship. Noticeably, the art forms presented here guqin (a traditional seven-string zither) and writing/calligraphy - used to be among the 'liu  yi'  (six  arts)  once  required  of  aristocratic  students  in  the  Confucian  school.  As Zhang  later  did  in  the  opening  ceremony  of  the  Beijing  Olympics,  such  an  aweinspiring  display  of  the  nation's  cultural  pride  constitutes  an  elaborate  selection  of audience-friendly cultural elements, where the plural strata itself is part of the splendour. On the other hand, just like the King's expressed ambition to unify the writing system, what looms over the fabulous picture of divergent arts and skills is an aspiration for a totalized visual  feast of 'Chinese' culture, one that can incorporate, for instance, the calligraphy of Zhao into a further unified canon. This rationalized choice of 'Qin' as the one legitimate representative of 'China' and 'Chinese-ness' was also evident at the movie's domestic premiere  in the Great Hall of the  People  in Beijing, when Zhang Yimou had 200 athletes dressed up as soldiers of Qin and greeting the guests in Shaanxi (the region where Qin stood) accents (Dai 2006: 160).\n\nIn  addition  to  its  plot,  the  disparity  between  the  plural  cultural  strata  and  the totalizing unification project can also be found in the film's narrative structure, music and visual effects. The  layer-by-layer revelation of truth by Nameless and the King provides  the  audience  with  competing  narratives  about  Nameless's  agenda,  and different segments of their conversation are accompanied by the employment of sharply divergent and highly suggestive colours. Yet such a formal pluralism is disrupted when the respective leitmotifs for individuals get overwhelmed by a collective narrative of 'history' in the film's music (Jiang 2002: 40), and when the ethereal renditions of the assassinators' fighting scenes are weighed down by the solemn, repressive presentation of the Qin palace. What ultimately manifests the movie's onedimensional ideological aspect is the King's epiphany about the three levels of achievement in swordsmanship. According  to  this  instrumental  and  hierarchical  judgment,  the  highest  level,  the resolution of violence and the attainment of the ideal of peace for 'all under heaven', can  only  be  achieved  by  the  King,  the  supposed  historical  agent  of  the  unification project.\n\nThe advocacy for 'all under heaven' as the ultimate political ideal can be traced back to traditional Confucianism, which often ties this goal with ren (benevolence). In The  Analects , Confucius  is  said  to  have  set  'tianxia  gui  ren'  (all  under  heaven submitting to a benevolent lord) as the highest ideal for social order (Yang 1986: 274). And indeed, in Zhang Yimou's film, the King of Qin does possess a sporadic trait of benevolence: rather than directly taking the initiative to kill Nameless, he seems forced to accept the proposal from his court officials to do so. In this brief moment of hesitation, the camera alternates between the King and Nameless, with close-ups to catch their respective  facial  expressions,  as  if  to  reconfirm  the  agreement  between  these  two 'heroes'. What is problematic, however, is the apparently imbalanced power structure between the two sides. Like Broken Sword, who is considered by the King to be the only  one  who  can  understand  him,  Nameless  is  only  endowed  with  limited  and temporary agency. And even this, ironically, can only be fulfilled with the killing of Nameless, plus the numerous casualties that will be brought about by Qin's military conquest of other kingdoms.\n\nNot surprisingly, the film's  justification  of  tyranny  has  drawn  many  criticisms, which see it as going against the 'traditional understandings of heroism' (Louie 2008:\n\n137). Film critic Evans Chan, for example, considers Hero's glorification of the King as a reinvention of 'the founding myth of China - not China as an ethnic, cultural entity, but China as an empire' (2004: 18). If, as Kam Louie has argued, the film's idealization of  heroes  and  heroism  can  be  seen  as  based  upon  a  holistic  vision  of  the  wen-wu (scholar-martial)  paradigm  (2008:  137),  its  departure  from  standard  tales  about merciless tyrants and heroic assassinators probably lies more in its re-attribution of wen qualities to characters that are typically seen as otherwise. In the traditional Chinese literary imagination, heroic knight-errant figures, according to James  J. Liu's summarization, 'were neither intellectuals nor politicians, but men of strong will and simple faith, who lived and died the way they wanted' (1979: 13). Compared with them, Sword  and  Nameless  are  much  more  mentally  sophisticated,  and  their  spirit  of  xia (knight-errantry),  which  was  once  dominant  in  classical  stories  about  the  King's assassinators, is largely overwhelmed by a Legalist vision of law and order, as well as an abstracted ideal of benevolence and peace that is promised but never really realized within the span of the film.\n\nWhat, indeed, is the prime essence of Chinese cultural heritage presented by Hero? The  film  seems  inconsistent  in  its  depiction  of  the  rational  and  the  emotional dimensions of its story. On the one hand, the much respect it pays to the cultural heritage and  the  transmission  of  learning  in  the  Kingdom  of  Zhao  arouses  a  sentimental recognition of its authenticity and admirablity. When Zhao is attacked by the troops of Qin, all the residents try to run away to safe places except for the teacher and students of the school where Sword and Snow reside. With digitized special effects to highlight Qin's formidable attacks, the camera presents the teacher at the centre of the screen, calmly  continuing  writing  in  the  dense  rain  of  arrows,  as  if  an  embodiment  of  the undying spirit and moral integrity of the culture of Zhao. On the other hand, as is seen from  this  scene,  and  the  scene  of  Nameless's  execution,  the  film's  obsession  with massive crowds of emotionless soldiers taking uniform actions tends to project an aura of dominance and determination onto the military troops and the cold-blooded power politics  they  stand  for.  As  a  result,  the  audio-visually  impressive  presentations  of traditional arts and skills become mere decorations of a mythical Chinese culture, where what to be kept and what to be discarded finally have to be defined through political and military agency, instead of cultural agency.\n\n\n## THE MASTER AND HIS ART IN FOREVER ENTHRALLED\n\n\nThis  2008  film  by  Chen  Kaige  can  be  seen  along  two  entwined  storylines  wellillustrated by its Chinese and English titles Mei Lanfang and Forever Enthralled . That is, it is both a biographical homage to Mei Lanfang (1894- 1961), a Peking opera master best-known for playing dan (female) roles, and a story about the enthralling power of this traditional Chinese art form as part of the guocui canon. At the confluence of these two storylines, the becoming of a great master and the reform and elevation of Peking opera as 'national essence' are constantly defined by each other, and the aura around the man and his art also constitutes a mystified narrative about national revival.\n\nLike Hero  Forever , also features a lack of balance between individuals' personal emotions and a supposedly cohesive view of history. In a way, its tri-fold Bildung - of the man, the art and the nation - makes it a perfect case of what Emilie Yeh has termed as a 'rehabilitation of the wenyi genre' (Yeh 2013: 228). Roughly a Chinese counterpart of the western melodrama, the earlier wenyi film tradition usually features a formulaic plotline - suffering, transformation, and then survival and success - and an expressive as well as instrumental deployment of emotions and sentiments. Yet, on the other hand, the film's subtle treatment of the master's dilemmas and inner struggles also seems to carry  on,  if  only  partly,  the  elitist  intellectual  approach  in  the  director's  own  major works of the 1980s and takes a step, even if compromised, away from the stock way of entirely subjecting an individual's fate to collective experience and memory. In both these aspects, Peking opera as 'national essence' not only serves as a major spectacle but also mediates the protagonist's and the nation's self-renewals.\n\nPeking opera brings the individual, the family and the nation all together when the film starts with the adolescent Mei reading a bitter letter from his uncle. In it, the older Peking opera performer tells his nephew about his unjust humiliation and penalty by his royal patrons, who apparently stand for a backward system of 'national dregs' in 'old China'. Later, the image of the uncle wearing a set of cangue and shackles made of paper is brought back once again, forming a traumatic memory that keeps reminding the protagonist of the perilous nature of his profession, unless he can manage to change it. Whenever faced with a difficult and critical situation, Mei is able to make the right choice under the inspiration from the letter.\n\nAn interesting comparison can be made between Forever and Chen's 1993 Palme d'Or-winning Bawang bie ji/Farewell My Concubine , which also depicts the turbulent history of twentieth-century China through the personal sufferings of two Peking opera actors. In the earlier film, Cheng Dieyi and Duan Xiaolou, a pair of performing partners who  have  grown  up  and  been  trained together, live through  the tremendous sociopolitical  vicissitudes  between the end of the Qing dynasty and the catastrophic Cultural Revolution (1966-76), enduring whatever is brought to them by their Peking opera  careers.  Here  the  bond  between  the  actors  and  their  performing  careers  is 'permanent' (Dai 2004: 313), as much as the art form of Peking opera itself, especially in the extreme case of Cheng Dieyi, whose roles on and off the stage become almost one and the same. In Forever, on the contrary, both the master and his art are endowed with the capability of renewing themselves in response to the call of times. Despite all the  historical  turbulences,  the  protagonist  overcomes  all  kinds  of  difficulties  and gradually  develops  from  a  fledging  opera  singer  to  a  popular  star,  and  finally  to  a national cultural  figure known not only for his artistic achievements but also for his noble patriotism. With the help of his friends and supporters, he manages to carry out reforms in Peking opera performing, making the traditional art form more thematically and stylistically appealing to the modern audience. In this way, both the artist and his art become active participants in the making of history, rather than passive endurers.\n\nLike the unification of China in Hero , nevertheless, the rejuvenation of Peking opera is  not  realized  without  painful  costs:  the master  himself  has  to  make  a  lot of sacrifices - freedom, friendship, love and health - at each milestone he achieves. Also like in Hero , these personal pains are rationalized and justified by the film's crediting their  contributions  to  some  greater  cause,  this  time  the  art  of  Peking  opera  and  its audience. As the defeat of Shisan is imbued with a symbolic success of the 'new' over the 'old' and an implicit promise about the reform and revival of Peking opera, the patriotic retirement during the Second Sino-Japanese War (1937-45) proves his moral integrity and adds another layer of aura to his art. Likewise, giving up his extramarital affair both helps to protect his reputation and contributes to his productive loneliness, which, according to Mei's agent Qiu Rubai, is the sole source of his art.\n\nDespite  such  a  'sadistic  equilibrium  by  which  [his]  every  achievement  is accounted for in some part of his personal suffering' (Zou 2000: 83-84), however, the film also seems to indulge in sentimental sympathies that potentially question its own rationalization of the master's sufferings in exchange for a holistic elevation of his art. For instance, the arrival of a new era for Mei is first and foremost marked by the failure and death of Shisan, but the latter's last words reveal that this beloved 'Grandpa' that\n\nMei defeats and loses is actually his most committed ally in the defence and promotion of  Peking  opera.  The  conflicts  between  the  pure arena  of  art  and the  evils  from  the mundane world, where crafty businessmen lure Shisan into the dangerous trap, further complicate the emotional undercurrents towards Mei's triumph. On the last night of the competition, when Shisan's performance is hostilely received with boos and heckles arranged  by  the  treacherous  teahouse  manager,  Mei  is  performing  'Daiyu  Burying Flowers', a sad episode from the Qing dynasty novel Honglou meng/Dream of the Red Chamber by Cao Xueqin (c.1715-1763). His lines, among which is 'what comes to this world with a pure nature should return to the other world with equal purity', serve as a sentimental and respectful elegy to the old maestro.\n\nSuch a tension between a manifest belief that history is on the side of the master and a sentimental sense of loss can also be found in the farewell scene between Mei and Meng Xiaodong, as well as in the conclusive moment of the movie. When Mei watches his lover depart, the camera catches Meng walking down the hallway and then reverses  its  angle  to  depict  the  heartbroken  Mei  in  the  corner  with  a  dolly-out, effectively arousing a tragic sense that may question the worthiness of the decision. Similarly, when the tri-fold Bildung is at last accomplished and Mei finally returns to the stage, the great master voices a longing very incongruous with his restored stardom: that  he  simply  wants  to  be  an  'ordinary  person'.  If,  as  the  director  has  repeatedly claimed in interviews, his original intention was, indeed, to demystify Mei Lanfang and restore his image as an 'ordinary person' (Song 2009: 80), the film seems more like a further mystified portrayal unconvincingly grafting 'ordinary' feelings and emotions onto an extra-ordinary character, or vice versa.\n\n\n## REINVENTION OF THE SAGE IN CONFUCIUS\n\n\nWith the great master forced to leave his home kingdom at the middle point of the film, Hu Mei's film can be easily divided into two parts: Confucius' service at the Lu court, and  his  fourteen-year  exile  and  final  return.  While  the  former  is  devoted  to  the exaltation of the versatility and extraordinary morality of this semi-deified figure, the latter adds to his humanistic aura by focusing on the emotive side of his banishment.\n\nThe skipping over of the earlier stages of Confucius' life makes this film different from a Bildungsroman -like movie like Forever Enthralled . Rather, here the audience is introduced to a versatile sage in his prime at the starting point. In the first half of the film,  Confucius  is  presented  as  a  wise  thinker,  a  smart  debater,  a  masterful  arrow shooter, a triumphant diplomat and a valiant general. Part of these source materials the meeting between Duke Ding and Duke Jing and Confucius' attempt to demolish the inappropriately high walls of three cities - draw upon such classics as The Analects, Zuozhuan/The Zuo Commentary and Shiji/Records of the Grand Historian . But the film also grafts other people's stories onto the already heroic protagonist. The speech on the cruelty of human immolation, for instance, is originally an anecdote about Chen Zikang in Liji/Book of Rites , and the trick of raising dust to scare away the enemy comes from the characterization of Zhang Fei in Sanguo yanyi/ Romance of the Three Kingdoms .\n\nShifting to Confucius' much tougher years of exile, the second half further exhibits a rather conventional melodramatic structure, in which the great master roams from one kingdom to another with his students, suffers from many and lengthy hardships, but finally regains his stature and is invited back to Lu. After the past wrongs are corrected, he completes his great book Chunqiu/Spring and Autumn and is recognized as the 'Sage for the Ages' after his death. Such a plotline strongly reminds the audience of some earlier  mainstream  films  directed  by  Xie  Jin,  whose  formulaic  storytelling  has  been summarized by Zhu Dake into four stages: 'the good person being wronged', 'the good value being discovered', 'the influence of morality' and 'the triumph of good over evil' (Zhu 2002: 235-37). Specifically, parallels could be easily found between Confucius' rise  and  fall  in  Hu  Mei's  film  and  the  persecution  and  rehabilitation  of  innocent intellectuals in the 'shanghen' (scar) films that Xie Jin made after the infamous Cultural Revolution.  Like  Xie's  melodramas,  Confucius  encourages  a  conviction  in  the collective agency of history through the rehabilitation of its honourable protagonist, but such a depiction of the self-recuperation of justice seems more taken for granted than rationalized on the individual level.\n\nBecause  of  the  myth-making  exaltation  of  Confucius  and  the  cliché  narrative pattern employed by the film, some critics consider it as a sign of the re-emergence of film-making  based  on  the  principles  of  'gao  da  quan'  -  'loftiness,  integrity,  and perfection' (Yang 2010: 56) - which were the guidelines set for literary and cultural production  during  the  Cultural  Revolution.  These  principles  and  the  'revolutionary heroes without any human weaknesses' created under them in the late 1960s towards the 1970s, as Rong Cai has pointed out, 'accor[d] with the fundamental assumption behind  the  Marxist  conception  of  the  individual  in  pre-Communist  society',  where individuals are treated as 'carrier[s] of class consciousness serving the grand collective course' (2004: 32). Hence, like some Chinese writers' compliance with Party-imposed literary  formulas  that  is  examined  in  Joe  C.  Huang's  study  of  Maoist  literature, the film's reference to such stock patterns can be seen as a kind of 'intellectual lethargy' (1973: 320) that yields, if not caters, to the ideologies of the state.\n\nOn the other hand, it is also worth noticing that the film's illustration of Confucius' human and mortal side has actually taken a departure from the much more clichéd role models of the Maoist period. Therefore, like Chen Kaige's Forever , Confucius allows a  somewhat  ambivalent  gap  between  the  mystified  aura  of  its  protagonist  and  the ordinary human side of the story. When depicting the hard days of Confucius' exile, the film includes an anecdotic description cited from the Records of the Grand Historian, which pictures his poverty and discomposure as 'like a lost dog'. Such a down-and-out image  forms  a  pointed  contrast  to  the  delineation  of  his  superhuman  wisdom  and prowess  in  the  earlier  part  of  the  film.  Furthermore,  compared  with  the  standard 'loftiness, integrity and perfection' model, Hu's film is much less charged with radical political ideologies and is, instead, more accommodating to human relationships.\n\nIn a more recent vein, the formulaic portrayal of the protagonist as a perfect man echoes  the  zhuxuanlü  dianying  ('mainstream  melody'  films)  -  defined  by  Yingjin Zhang  as 'productions intent on reinstalling a correct political ideology and nationalistic pride in the population' (2004: 240) - that was first advocated in the late 1980s by the Film Bureau. Like the heroes in Wang Jixing's Jiao Yulu/Jiao Yulu (1990) and Lei Xianhe and Kang Ning's Likai Lei Feng de rizi/Days without Lei Feng (1996), Hu  Mei's  Confucius  is  presented  as  a  sublime  figure,  selfless,  strong-willed  and magnificently inspirational. In this sense, although the director manifestly declared that her goal was to make an emphatically non-mainstream melody film (Zhang 2008), the film's portrayal of the de facto representative of guoxue still very much fits into the pattern, only a more humanistic version thereof, which incorporates the everyday side of the sage as part of his sublime nature, rather than treating it as an incidental weakness to be overcome.\n\n## COPING  WITH  HISTORY  AND  INDUSTRY:  A  TALE  OF  TWO  FIFTH GENERATIONS\n\nThat all the three films examined in this article are works of the once so-called Fifth Generation  directors  is  in  many  ways  more  natural  than  intentional,  as  these  film- makers  not only  played  a  significant  role  in  the  reconstruction  of  the  Chinese  film industry  in  the  post-Cultural  Revolution  era  but  still  retain  very  close  ties  with  the human, capital and studio resources of the industry. The conspicuous transformations that have occurred in their modes of filmmaking shed much insight on the changing logic of cultural production in the new millennium. If Chinese history, both ancient and modern, has been, as Dai Jinhua pointed out, a 'haunting' theme in Chinese cinema since the 1980s (Dai 2004: 310), the cinematic representations of it has become quite different over the years, and the contributing factors to these changes range from the reform of the industry to China's deeper participation in the global film market and the revised imaginations about 'China' on the part of film audiences, both domestic and international.\n\nBack in the 1980s when Zhang Yimou, Chen Kaige, Hu Mei and a few other young film-makers first emerged collectively as the Fifth Generation, this arguably arbitrary and oversimplified tag was often associated with an experimental, even iconoclastic, approach towards Chinese traditions. Their  early works are not only  subjective and symbolic  but  also  self-consciously  intellectual.  While  Zhang's Hong  gaoliang/Red Sorghum (1987) and Chen's Yellow Earth can be read as allegorized pictures of Chinese folk life that challenge the traditional cultural logic defined by the order of the Father, Hu's  Nüer  Lou/Army  Nurse (1985)  provides  an  allegory  of  female  subjectivity  and desire against the strains of the gender-biased cultural discourse on women and social progress in modern China. Such an 'allegorical mode', as Shuqin Cui has argued, involves interactive engagement, where one set of agents 'allegorizes' another. As one discourse consistently encounters the other, the interplay creates a double vision, inviting the audience to observe not only what but also how meaning is constructed in a given text. (Cui 2003: 102, emphasis added)\n\nThe use of 'old China' or Chinese traditions as (often exotic) spectacles, however, has also brought about debates and criticisms. For instance, Zhang Yimou's 'red trilogy' Red Sorghum, Judou/Ju Dou (1990) and Dahong denglong gaogao gua/Raise the Red Lantern (1991)  -  has  long  been  criticized  from  postcolonial  perspectives  for  its exploitation of Oriental touches to cater to foreign tastes and to 'a reading of China's modernity  and  'ethnicity'  that  is  a selfsubalternization '  (Chow  1995:  148,  original emphasis). Also, the critical and intellectual probes into the nation's psyche and history sometimes  turned  out to  be  in  disaccord  with  the  official  ideologies  in  mainstream media, making them victims of the state-controlled film censorship.\n\nWhat the state warmly endorses and financially incentivizes, on the other hand, is a more positive reconstruction of guoxue. As Ben Xu has argued, drawing upon Jurgen Habermas, contemporary China is faced with a legitimation crisis that affects not only 'the political and moral credibility of the government but, more profoundly, how the individual Chinese [i]s henceforth to draw a worthy identity from his or her nation' (Xu 1999: 24, original emphasis). Therefore, like the intellectual discourses of the 1980s and  the  1990s  over  the  redefinition  of  the  Chinese  identity  under  post-socialist conditions,  the  celebratory  return  to  guoxue  in  the  Chinese  cinema  of  the  new millennium cannot be separated from the many urgent attempts to restore the political and cultural legitimacy of Chinese culture.\n\nAt the same time, the re-presentation of guoxue also speaks to China's continuing economic success in the recent decades and an ensuing new imagination about Chinese traditions as in relation to the West. Instead of selfsubalternization via the portrayals of a  backward  'old  China',  the  three  films  examined  here  celebrate  the  mythical  and holistic aura over its traditional arts and culture. In their much more positive depictions, however,  the  designation  of  interpretative  agency  becomes  singular,  thus  'double visions' are missing. In these recent films, a hegemonic history is no longer a target of elitist  criticism,  but  a  glorious  spectacle  that,  in  paradoxical  ways,  appeals  to  the different  fantasies  of  the  domestic  and  the  international  audiences.  Ironically,  while departing from the kind of mythically primitive 'China' in Zhang Yimou's 'red trilogy', which, as Rey Chow has argued, is at once both 'the China constructed by modernity the modernity of anthropology, ethnography, and feminism' and 'a 'China' exaggerated  and  caricatured,  in  which  the  past  is melodramatized in  the  form  of excessive and absurd rituals and customs' (Chow 1995: 145, original emphasis), these films  turn  to  an  intrinsically  similar  set  of  film  language  in  their  respective  representations of China and cultural traditions.\n\nThe impacts from the marketization of the film industry are quite prominent as well. The above-mentioned elitist 'double vision' in the earlier 'Fifth Generation' films, while  bringing  them  to  international  attention, was  not  always  enthusiastically welcomed by the general domestic audience. For the state-run studio system of the 1980s, which was 'centrally planned […] with little concern for the market' (Zhu and Nakajima  2010:  26),  box  office  was  often  not  the  first  priority,  which,  ironically, contributed to experimental cinematic explorations and the successful emergence of the younger generation of film-makers. As the Chinese film industry gradually grows out of planned economy and moves towards marketization, studios and film-makers have become more and more sensitively concerned with financial calculations. Particularly, with China joining the WTO (World Trade Organization) in 2001, the Chinese film industry is faced with severe challenges as to how to protect its domestic market share from  its  foreign,  especially  Hollywood,  competitors.  Star-studded  emulations  of Hollywood blockbusters have thus often been favoured by the industry, as well as by veteran  film-makers  like  Zhang,  Chen  and  Hu.  The  normally  huge  budgets  of  such blockbusters require that studios and film-makers take into serious account both the intended audience's preferences and the risks with film censorship.\n\nObviously, the three movies' adoptions of the guoxue-related themes have been results  of  careful  and  practical  calculations,  actively  responding  to  the  'craze  for traditional learning' in the new millennium as well as to the growing global attention to China brought by its economic growth. Hero 's combination of the First Emperor of Qin, assassinations and traditional arts and ideologies was one of the major contributing factors for its box office success - with a total worldwide revenue of US$177,394,432 (Liu 2008: 167). Forever and Confucius , both of which were prominently advertised as guoxue pian/ guoxue dianying (film of traditional learning), also respectively achieved quite good and decent domestic box office returns and were released overseas.\n\n",
         "This article examines Zhang Yimou’s Yingxiong/Hero (2002), Chen Kaige’s Mei Lanfang/Forever Enthralled (2008), and Hu Mei’s Kongzi/Confucius (2010) and discusses how they respectively re-construct narratives of a mythical national spirit via sublimated portrayals of guoxue and how such re-presentations respond to both earlier cinematic traditions and the more and more intense trend of commercialization in the Chinese film industry. What makes these films’ shared investment in guoxue even more interesting is the fact that all these three directors are representative figures of the so-called ‘Fifth Generation’, a group of filmmakers who were best known for their self-consciously critical approaches towards Chinese cultural traditions in the 1980s. Their recent collective enthusiasm for guoxue and much more positive re-presentations of it not only indicate a revisit to the heated discussions over indigenous cultural roots two to three decades ago but also reflect the restructured relationships among filmmakers, their audiences, and the state.",
         ""
        ],
        [
         "38",
         "38",
         "## INTRODUCTION\n\n\nThe most significant among examples of new media art in China to first receive critical attention are those that tend towards re-engineering early video games while riffing off on aspects of the 'political pop' genre in contemporary Chinese art. Focusing on the game art installation, Long March: Restart (2006-2008), by Beijing artist Feng Mengbo (b. 1966), this article argues that one of the politico-cultural implications of the Mao Goes Pop art movement going digital, 8-bit to be precise, concerns the link between digital art's 'precarious playbour' that 'effectively masks labour as play' (Kücklich 2005), the rise of gaming in Asia, and emergent techno-Orientalist discourses about  media  art  and  technologies  in  China.  These  artworks  are  not  only  products  of  but  also interventions into the current parameters established for Chinese media, political censorship and game  worlds,  reflecting  the  fault  lines  of  the  growing  interest  in  networked  cultures  and participatory media in contemporary art in general. In the second half of the article, I bring in three\n\npersonal vignettes, or what I call snapshot scenarios, that are related to game art and recent digital and visual culture in China. These scenarios enable other optics into how, since the 1990s, Feng's game-related works have been progressively introspective of the transnational art world and global media convergence.\n\nThe term 'game art' used in this article is as defined by Matteo Bittanti: 'game art is any art in which digital games played a significant role in the creation, production, and/or display of the artwork'  (2006:  9).  With  the  'Beijing  International  New  Media  Arts  Exhibition  and Symposium' since 2004, followed by the 'International Triennial of New Media Art' since 2008 (with three editions to date), there is a substantial discourse on Chinese media arts (ranging from video art, digital art and animation to flash art and sound art) emerging both in China and abroad, one in which Feng's work also figures regularly, if sporadically. Since the first video art exhibition curated by Wu Meichun in 1996 in Hangzhou (capital of East China's Zhejiang Province) where the China Academic of Fine Arts is located, to the tenth and eleventh Documenta exhibitions in Kassel, Germany, both of which Feng participated in, media arts in China has come a long way from 1988 when Hangzhou-based artist Zhang Peili used a video camera to record a performance exhibition he staged. In his book Performance Art in China , art historian and curator Thomas J. Berghuis makes the distinction between two early strains of media arts, circa 1994-2004, in terms of  highbrow  (intellectual)  or  lowbrow  (popular)  culture,  writing  that  'Yang  Fudong  and  Feng Mengbo represent an important generation of artists who grew up during the Cultural Revolution (1966-1976), and their works become useful in distinguishing two different approaches to new media  art  in  China  over  the  past  decade'  (Berghuis  2006:  137-9).  The  new  media  artworks discussed in this article prove these categories to be more fluid in the context of recent game art.\n\n\n## RESTARTING ENDGAMES\n\n\nFeng's Long March: Restart premiered at the Third Guangzhou Triennial in Guangdong Province, China, in 2008. Its acquisition in 2010 by the Museum of Modern Art in New York was marked by a solo exhibition at MoMA PS1, from 12 December 2010 to 4 April 2011. It was the institution's first solo exhibition by a contemporary Chinese artist, and the artist's first solo exhibition in the United States. As the artist proudly stated: 'I am the first Chinese who has the honor of having the chance of a solo exhibition in MoMA PS1' (Feng, quoted in Lin 2010). Long March: Restart is the grand culmination of a series of game-based paintings and animations presented in 1994 as\n\nFeng's  first  solo  exhibition,  'Game  Over:  Long  March',  at  Hong  Kong's  Hanart  TZ  Gallery (Figures  1  and  2).  The  game  art  installation  continues  the  earlier  series'  adaptation  of  the graphically simple aesthetics of vintage 8-bit video games but efficaciously revives, by recreating the 1980s stylized sprite-based animation motion for its characters, the look and feel of the early interactive  game  experience.  The  entire  project  is  obviously  a  pop  art  riff  on  Mao  Zedong's infamous year-Long March, referring to the massive military retreat from the Chinese Nationalist Party by the Chinese Communist Party's Red Army under Mao that began in 1934.  In 370 days, 1 the troops travelled over 6000 miles from Jiangxi to Shaanzi through some of the worst terrain in China, including eighteen mountain ranges and 24 rivers.\n\nFigures 1 and 2: Feng Mengbo, Game Over: Long March , 1994. A series of 42 paintings, each 100× 88 cm, acrylic on canvas. Collection of the Guggenheim Museum, New York. Image credit: Feng Mengbo.\n\n<!-- image -->\n\n<!-- image -->\n\nFeng's Long March: Restart is a game mod that 'modifies' the classic Cold-War-era game Street Fighter (Capcom, 1987) and the hugely popular Super Mario Bros. (Nintendo, 1985) into a twisted  Communist  China  landscape  with  fantastical  embellishments.  Created  by  Japanese videogame designer, director and producer, Shigeru Miyamoto, the character Mario first appeared as a carpenter named 'Jumpman' in the classic arcade game, Donkey Kong (Nintendo, 1981). It was up to this game character to rescue the damsel in distress, Pauline, kidnapped and holed up on the top level of a construction site by a giant gorilla. Presumably after the princess was rescued, Mario and his brother, Luigi, both became plumbers in the sewers of New York City with the release of Mario Brothers (Nintendo, 1983). By the time of Super Mario and then the numerous New Super Mario Bros. series (Nintendo, 2006-2012), Mario and Luigi have traversed not only\n\nseveral worlds in Mushroom Kingdom, but also different lands, galaxies and outer space to save rulers, family members and several princesses. 'Modding', or computer game modification, has been a computer game production model for over two decades. It involves players - tech-savvy fans -creating their own  games  using  authoring  tools  provided  by  commercial  games manufacturers, resulting in new user-created additions, tools and utilities applauded as user-driven innovation, or, in this case, customized user-created content.\n\nFigures 3 and 4: Figures 3 and 4: Feng Mengbo, Long March: Restart , 2008 (still). Video game installation  (colour,  sound),  custom  computer  software,  and  wireless  game  controller.  Dimensions  and duration variable. Collection of the Museum of Modern Art, New York. Image credit: Feng Mengbo.\n\n<!-- image -->\n\nIn Feng's Long March: Restart , Super Mario and Mao have 'roles in the same war game' (Shen 2003: 9). To the catchy chip tune of a well-known Cultural Revolution propaganda song, Super Mario is quickly disposed of by 'a little Red Army soldier who fights forcefully and wins all  the  battles  under Chairman Mao's command' using crushed Coca Cola cans as ammunition (Feng 2008: 104). With the inclusion of background scenes and characters from other games such\n\nas the Street Fighter martial arts fighting game series (Capcom, 1987-2016) and the futuristic run and gun game, Contra III: The Alien Wars (Konami, 1992), the screen worlds of Long March: Restart become one big smorgasbord of loud, familiar iconic references. Spliced into the Super Mario side-scroller platform, which is one of the most famous in the game industry, the on-screen realms and encounters range from Tibetan grasslands to Tiananmen Square Soviet-era platforms; from Guomindang troops in hutongs and the busy traffic of contemporary Beijing to a fleet of US missile-armed space ships; from the Statue of Liberty above New York City to Street Fighters, Teenage Mutant Ninja Turtles, Godzilla and other video game bad guys (Figures 3 and 4).\n\nImportantly, the screen conditions that constitute the game play for this artwork are not console-based as is typical of this cosy basement den form of entertainment. Rather, on every level, the  gigantic  projected-image  game  installation  was  intended  for  and  featured  in  an  art  world, museum setting. Moving between two parallel 80×20-feet-long large-screen projection walls, up to two participants can take turns playing (Figure 5). Equipped with wireless game pads to guide the pixel character through the twelve different levels, players move up and down the corridor-like space to engage in battle through a complex system of sensors and digital side-scrolling projections. The game screens switch intermittently, with the pixel image of the Red Guard enlarged ten times on the opposite screen, forcing players to physically move around if they want to follow the action, becoming an active participant of the piece. In terms of its design concept, the installation is a continuation of Feng's early interactive installation Ah\\_Q (2004) using the open source software of  the  Massively  Multiplayer  Online  Role-Playing  Game  (MMORPG) Quake  III  Arena (Id Software,  1999)  in  which  viewers  physically  participate  as  the  player  in  the  game's  twodimensional space (Feng 2008: 104). Ah\\_Q was in turn based on his interactive three-screen video game installation, Q4U , shown at 'Documenta 11' in 2002, which was controlled by a dancing pad instead of a mouse pad. Both installations feature the artist as the on-screen avatar who is in army fatigues but bare-chested and armed with a plasma gun on one hand and a camcorder on the other. For Long March: Restart , Feng 'wanted to enable the character to move freely along the stretched scroll. Because of the vast space of the exhibition hall and the intentionally designed pace of the character, the gamer and the audience would have to dash to catch up with the character' (Sandfort 2010). Long March: Restart could thus be said to effectively remediate Feng's early Game Over series of 42 acrylic on canvas paintings from 1993 to 1994. According to the artist, it was 'just a sketch for a video game in the future' (quoted in Chang 1994: 81), but this series, as 'an unlikely,\n\nfascinating  combination  of  the  digital  and  the  hand-made,  the  historic  and  the  contemporary' (Ullens Center for Contemporary Art [UCCA] 2009), was the first of his works to come close to what could be called game art.\n\nFigure 5: Figure 5: Feng Mengbo, Long March: Restart , 2008 (installation view, MoMA PS1, New York). Video  game  installation  (colour,  sound),  custom  computer  software,  and  wireless  game  controller. Dimensions and duration variable. Collection of the Museum of Modern Art, New York. Image credit: Feng Mengbo.\n\n<!-- image -->\n\n\n## PLAYBOUR AS ART/WORK\n\n\nAs with most artist-made video game mods, gameplay is not the endgame, or at least not the only one for Long March: Restart . There is a point counter, and the Red Guard is expendable only to always fully recover to restart right where he began. All the same, the sheer scale of the screen and the time constraints of the museal environment tend to dissuade hard-core gameplay. And while there are reports the adept have been able to achieve all twelve levels and win the game, Katelyn Sandfort,  Coordinator  of  MoMA's  Department  of  Media  and  Performance  Art,  observes  that Feng's ' Long March: Restart is no simple game of Wii Tennis' (2010). According to game theorist Alex  Galloway,  'most  artist-made  video  game  mods  to  date  are  mods  of  game  technologies (whether at the visual level or the physics level), not mods of actual gameplay' (2006: 108). There is no arguing that there are inevitably visitors to the installation who succumb in submission to the game characteristics of this work. I suggest, however, that the screening conditions  - an open-\n\nended  corridor  between  two  moving  image  screen  walls,  and  familiar  icons  -  also  allow  for something else to occur: a presentness of mind that entertains the option of a refusal to play.\n\nThe narratives of these kinds of earlier 8-bit video games that populated the golden age of arcades in the 1980s were conceived during the Cold War's final years. During this period, China's position was gradually changing not only as a result of Deng's economic reforms begun in 1978 but because of the collapse of Eastern European communism by 1989. Despite the tragedy of the Tiananmen Square Incident in Beijing on 4 June 1989, China would continue to rise to be the emergent superpower that it is today in the early twenty-first century. Seen from a nostalgic late Cold  War  vantage point as a  historical  frame  of  reference,  it  might  be  said  that Long March: Restart 's jumbled cast of characters makes distinguishing the bad guys from the good ones not as clear cut or heroic as it may seem. Does, for example, 'one gladly become […] complicit in this quest to destroy symbols of democratic capitalism' and 'become willing performers in a game of self-display' (Sutton 2011)? To this, Kevin Holmes insightfully notes:\n\n[ Long March: Restart ]  takes  imagery  a  modern  tech-savvy  audience  is  well-acquainted with and subverts it, giving it a Communist twist while imbuing it with nostalgia from a different  time  and  place.  In  marrying  the  iconography  of  Communism  and  Capitalism, Mengbo is jabbing at both ideologies and their tendency to use the 'hero' as a means of promoting their propagandist agendas. Highlighting their similarities, he unites them in the anything-goes world of gaming. (Holmes 2011)\n\nIn an ironic manner, the ways in which the museum context has traditionally been a 'hands-off' environment may in fact deter average visitors/potential players (and this may include the seasoned, world-weary art tourist who can experience works through subterfuge) from picking up the game pad, despite the gallery attendant's invitation to do so.\n\nIt is in this moment of deliberation that brings forward a consideration of how the logic of Julian Kücklich's ideological concept of fan-based 'playbour' comes into the picture in interactive digital art. Describing forms of labour carried out in or around computer games and popular culture more  generally,  the  term  playbour  within  the  game  industry  concerns  both  paid  (although remuneration is seldom) and free forms of highly valued work (such as modding) performed while ostensibly at play. Arguably, in the case of modding, and the hours of testing, or work as play or\n\ntinkering and vice versa, willing fans 'do not necessarily see their input as being directly valuable, or themselves as being exploited as a source of free labour' even though their practices are an increasingly important source of value for the industry's revenue streams as well as for research and  development  (Goggin  2011:  358).  According  to  Kücklich  (2005),  the  precariousness  of modding 'as a form of unpaid labour is veiled by the perception of modding as a leisure activity, or simply as an extension of play'. A similar operation is at play in the leisure industry itself. For example, in the museum, an institutional bastion of the leisure market, the valorization of play, the wasting of  time  playing,  is  an  expected  strategy  to  draw  crowds  in  and  generate  gate  sales.  A refusal to play in these conditions - that is, a refusal to waste time efficiently - is potentially an act of  resistance  against  the  control  of  entertainment  providers  who  strive  precisely  to  convince visitors  that  they  are  engaging  in  an  enjoyable  ludic  activity  void  of  self-expropriation  or exploitation.\n\nFeng's Long March: Restart thus brings to the fore the very idea of playbour as a kind of art/work . If visitors do interact with it, they in fact are engaging with a work of art that basically already has accrued value as a product of a hybrid form of what I shall call 'artworld playbour'. If no one interacts with the work, the post-artist mod is capable of providing it the means to activate the aesthetic  experience  by  simply  kicking  into  self-automation  for  conventional  passive spectatorship. In this case, without physical engagement, the participation-required art/work may be  deemed  incomplete,  incapable  of  'productive  leisure'  to  source  value.  Consciously  or unconsciously,  somewhere  in  between  these  two  extremes,  visitors  will  assess  their  level  of satisfaction towards this work of art and move on to the next room, time of course being a major motivating factor either way.\n\nAn avid gamer since the early 1980s when the first video games went on the market and onto  the  international  art  scene  at  the  cusp  of  the  contemporary  Chinese  art  boom,  Feng  is considered among the first contemporary artists in China to receive critical attention for work in new media since the late 1990s, as well as to have been able to consistently maintain an equally successful  painting  practice.  In  addition  to  his  game-based  paintings  and  large-scale  game  art installations such as Long March: Restart and its 2012 spinoff versions of life-size customized arcade consoles in an edition of four, Feng has experimented with interactive CD-ROMs, net art, and performance installations that adapt open source role-playing game, as well as machinimas (films made in virtual spaces) and screen-captured photos created with 3D virtual cameras, which,\n\nin some cases, are then copied as oil paintings. Despite the range in media and years apart, much of Feng's more recent artistic output is often still steadfastly associated with and often exhibited within, if somewhat more ambivalently than in previous decades, the 'political pop' category of contemporary Chinese art. Coined by pre-eminent Chinese art critic Li Xianting, the term describes work beginning  in  the  late  eighties  into  the  nineties  that  'characteristically  combines  political symbols of the Mao era […] and symbols of Western consumer culture to create a feeling of irony or absurdity' (quoted in Safronova 2012: 124). Writing on 'political pop' in 1993, Li explains the reuse of socialist realist and propagandistic visual production as follows:\n\nAn existence saturated with politics has become the accustomed state of being for most contemporary Chinese.... Political Pop uses the acknowledgment of this political reality as its starting point, but then proceeds to satirize politics, providing an effective (but by no means heroic) means of neutralizing the hold of a politically saturated mentality on the inner  mind.  ... In  a  sense,  'Mao  Fever'  and  Political  Pop  art  are  linked  in  that  there  is inherent in both the use of past icons or 'gods' to criticize, or in the case of the latter, to satirize, current reality. (quoted in Lago 1999: 50)\n\nLike the artist peers of his generation working in this vein particularly in the nineties and into the 2000s, Feng  is well known  for combining  iconic Cultural Revolution  imagery with ubiquitous signs of the new Chinese socialist-capitalist economy in his work, although, unlike his peers, he has repeatedly downplayed a political stance in his doing so that has made categorizing the artist's diverse media art projects challenging, particularly within 'political pop'.\n\nI am in agreement with writer and journalist Valeriya Safronova's analysis of Feng's game artworks, that the 'artistic category into which Feng Mengbo might fit is not at stake here' because his  use  of  game  media  'allows  for  a  further  and divergent  exploration of  power  dynamics  and history' in how it 'delves into the construction of history, alternative realities, nostalgic idealism and the significance of digitization in the formation of living history' (2012: 124). Safronova's article  is  concerned  with  understanding  how  Feng  'utilizes  certain  methods  associated  with Political Pop in the very unique structure of the video game, a medium that by its nature probes the issues of control and history' by parsing out the meaning of the artistic category (2012: 124). In contrast, I am interested here in pressing the ways in which the transference of 'political pop'\n\nidioms - as part of the more euphemistically titled Mao Goes Pop art movement - to recent work created  using  new  media  technologies  speaks  to  a  renewed  attempt  to  prolong  the  artistic category's criticality of not only the New China but global capitalism vis-à-vis media democracy as a whole.\n\n\n## MAO GOES POP ONLINE\n\n\nFeng's Long March Restart is  but  one  of  many  examples  of  recent  media  art  produced  in  the People's Republic of China that mod game technologies - Feng himself has been modding since 1999 (Lin 2010). Now a whole new generation of artists has been combining game modding with the  latest  display,  social  networking  and  Web  2.0-enabled  technologies  to  create  participatory media projects that are, comparatively speaking, more sophisticated, more topical and slicker than the  nostalgic  feel  of  Feng's Long March Restart .  Exhibited  at  the  2008  Guangzhou  Triennial, Wang  Jiahao's  video  installation F1City (2002,  2008),  for  example,  combined  telepresence technologies with a mod of the popular car-racing game F1 ,  to  critique  how the  Formula  One World Championships (which celebrated its 60th anniversary in 2010 in Bahrain in the Gulf) are encroaching into so-called now developing countries. The installation provided visitors a synthetic viewing experience of the car race in three different formats: through close circuit TV transmitting real and  real-time  navigational  views  through  the  city,  live  telecast  of  the  visual  circuit (telepresence), and as seen through existing routes of the virtual F1 game. The importation of this extensive product planning on the part of the artists to the art world could be seen to speculatively strengthen Formula One`s bid to expand not only its participant base (drivers, sponsors) but also its global audience base in other ways and through other means - for example, by showing up as a new series of bundled consumer services or sports entertainment packages. Notably, relative to its  costly  investment  in  R&amp;D,  Formula  One  has  the  smallest  number  of  official  participants compared to other international sports (Wang 2008: 464).\n\nAsian-themed avatar-based games and role-playing games that let players take on a pretend virtual persona are the take-off points for artists Xu Dian and Cao Fei, who have both delved into the uncanny phenomenon of Cosplay on- and off-line, the latter being real-life 'costume players' who dress up in their favourite manga, anime or game characters. As Katrien Jacobs and Anne Peirson-Smith write:\n\nIt looks like great fun - but [Cosplay] is in fact a deadly serious game for those who choose to  play  it.  […]  Despite  the  public  display  of  extraordinary  outfits  at  events  and  the appropriation of the public domain of city space to meet and greet other cosplayers, it is a secret closed world only accessible to a specific demographic set. (2009: 2-3)\n\nLike Formula One, Cosplay signifies the limited number of actual participants within respective fandoms. In the case of Beijing-based Cao's acclaimed user-created virtual art community, RMB City (2007-2011), commissioned by the Serpentine Gallery in London, artistic explorations have extended to Second Life, a three-dimensional virtual universe of different user-created worlds, launched in 2003 by Linden Lab. Although by a younger artist, Cao's RMB City , like Feng's Long March Restart ,  notably  also  combines  iconic  Chinese  Communist era  imagery with  mimicked structures of  real-world  real  estate,  urban  planning  and  art  ecologies.  These  clichéd  signs  of  a raging post-Mao social market system are submerged under water in a later dystopic view of a future  late-capitalist  China  encapsulated  by  Cao's  installation, Apocalypse  Tomorrow:  Surf  in RMB City (2011), which despatches the fate of RMB City, as if the blind idealism of both her RMB City and Feng's Long March: Restart has never been more than a game (Jim 2013).\n\nConcerning iconography, these activities indicate two ongoing developments: (1) the longstanding appeal and effect of Mao Fever as a social phenomenon in China over the last two decades; and (2) the long shelf life, since the contemporary Chinese art boom in the early 1990s, of the 'political  pop'  style  of  art  out  of  which  arose  Feng's  artistic  career,  despite  his  adamant protestations to the contrary. To produce his interactive CD-ROM work, Taking Mount Doom by Strategy (1997), for example, Feng juxtaposed elements of the popular first-person shooter game Doom (id Software, 1993) with the 1970 Cultural Revolution model opera and film Taking Tiger Mountain by Strategy (Xie, 1970), but he denied any political agency in his act of remediation. Today, 'political pop' or Mao Goes Pop categorizations of contemporary Chinese art remain, if somewhat depoliticized, a driving force in contemporary Chinese art; in fact, as observed of the game-related art of Cao Fei, Feng Mengbo and others, it has now also gone online. The question remains: If the initially subversive impetus of Mao Goes Pop art in painting has somewhat petered out (notwithstanding its ongoing successes in the art market), can the transfer of 'political pop' art to online participatory media platforms critically interpolate works in this genre in ways relevant to the contemporary moment? How, for example, is Feng's Long March: Restart a reflection of\n\nand on the tendencies theorized by concepts such as playbour, or other forms of immaterial and affective  labour,  to  increasingly  virtually  control  the  empirical  day-to-day  realities  of  the contemporary  social  subject?  Would  these  global  tendencies  be  framed  differently  in  Asian contexts?\n\n\n## THE MANY VISUAL CULTURES OF GAME WORLDS\n\n\nIn order to make preliminary observations on several broader contexts that may provide points of access into this question, the remaining section sketches out three 'originary scenarios' for this research  that  correspond  to  connected  phenomena  that  inform,  drive  and  ultimately  shape  an understanding of the convergence of game and art worlds in China: an expanded digital visual culture  of  gaming,  game  entries  into  museums  and  the  art  market,  and  techno-Orientalist perspectives on Chinese ICT and cultural industries.\n\nScenario 1: 8 August 2008. Wow, I'm thinking: the opening ceremony performances at the 2008 Beijing Olympics has to be recognized as the quintessential example of human Pixel Art  in  my  life  time.  That  is,  until  I  see  Li  Ning,  China's  former  Olympic  gymnastics champion,  running  horizontally  along  the  500-metre-long,  14-metre-wide  projection screen  hanging  from  the  inside  brim  of  the  Bird's  Nest,  keeping  pace  with  a  gigantic 'painting  scroll'  unfolding  ahead  of  him  (Xinhuanet  2008).  Lifted  with  computercontrolled wires around his waist, Li Ning's exaggerated leaps are stunt-like, calculated, and on TV we see him in isometric perspective; his one and only task was to light that colossal torch. For a split second, I am reminded of the book Gamescenes in which Henry Lowood noted that 'the adoption of isometric perspective in computer games has been closely  associated  with  strategies  and  tactics  of  control'  but  the  isometric  perspective should not be considered a quintessential game view since it has a history 'in other realms, such as Chinese art and architectural drawings' (2006: 21-22).\n\nCourtesy of the 'overhead imagery' people, 897 movable-type blocks and the 897 performers underneath them are perfectly in sync. Looking again, I thought: wow, games (not just the Games) are definitely big in China; this must be, by far, the most spectacular and  massive  display  of  game  aesthetics  in  visual  culture  history,  if  not  'culturalist rejoicing'. 2 It  is  no  coincidence  how  at  the  same  time  China's  56  officially  recognized\n\nethnic  groups  are  seen  'performing'  their  connectedness  to  the  world,  the  country  has emerged  as  an  increasingly  significant  content  producer,  with  developments  in  online gaming among the leading factors in this new media globalization. By extension and from the perspective of a national strategy on media technologies, new media art too has its 'nurtured'  part  to  play  in  accelerating  and  sustaining  the  economic  development  of China's creative and cultural industries.\n\nAccording  to  Forbes,  'the  video  game  industry  is  one  of  the  largest,  most  profitable entertainment industries in the world with a global market that is expected to reach about $82 billion in 2017, from an estimated volume of $67 billion in 2012' (Münch 2013: 1). Raking in $13 billion in 2013, China 'is predicted to overtake the US as the world's biggest video-game market by  2016,  generating  more  than  $25  billion  a  year  in  revenue'  (Harwell  2014).  Since  China's Ministry of Culture banned the selling of game consoles in 2000, temporarily relaxing restrictions in 2014 for 'foreign-invested enterprises' (such as Microsoft, which scored the lead on market penetration), its 'gaming culture has been dominated by free-to-play, online multiplayer games', or MMORPGs in Internet cafes, with gamers only paying for add-ons such as weapons or extra lives (Harwell  2014). Intra-Asian online gaming  networks  were  created  particularly via MMORPGs in the late 1990s and early 2000s (Hjorth and Chan 2009: 6).\n\nBy the time Feng's Long March: Restart premiered at the Third Guangzhou Triennial in September 2008, '58.3% of Chinese netizens play[ed] online games - or 78.15 million players' (Chan 2009: 146). Using a media archaeological approach, it would not be a big leap to make affective connections and formal associations between the spell-binding 'Games' scenario and the prosaic return, in Feng's game installation one month later, to the representational spaces of earlier, vintage 'side-scroller' video games where characters in profile move in a long horizontal scrolllike space. To trace the scroll aesthetics further, one can also make correspondences with how the familiar historical narratives of traditional Chinese landscape painting have long been presented a screen form that Feng, who started out as a painter, is as well-versed in as his knowledge of game aesthetics. Feng's  8-bit  two-dimensional  Red  Guard  may  be  no  match  for  the  long-legged Olympian, but both can be accredited for loading up on visually charged historical and cultural references - propaganda. In fact, Long March: Restart could be said to be a Pixel Mao Goes Pop remake in  a style  of  the  16-bit  tactical  simulation  game The Romance of the Three Kingdoms\n\n(Nintendo, 1988), which in turn is based on the classic fourteenth-century novel by the same name that is said to have been highly influential on Mao's views on imperialism.\n\nScenario 2: After its premiere at the Third Guangzhou Triennial, Long March: Restart was shown the following summer (26 July to 30 August 2009) at the new private Ullens Center for  Contemporary  Art  (UCCA)  in  the  now  trendy  798  Art  District  in  Beijing  and subsequently acquired by MoMA New York the year after. The presentation, marketing (plates, scarves, laminated prints) and acquisition of this work by these prestigious, and some might say elitist, venues may seem incongruous, if not conformist, especially since the artist considers this work to be the culmination of his fourteen-year-old plan to turn his 1994 Game Over: Long March painting  series,  or  'game  snapshots'  as  he  called  them (each approximately 34 by 43 inches, and in the Ullens collection), into a 'made-to-order' video game that could be distributed freely; Feng has lamented that his was a generation that explored computer technology 'as a way to break away from the mainstream or the established art traditions', only to find their 'work confined to an even narrower circle of elites' (Feng 2008: 104). On the other hand, he has also repeatedly disavowed any political agency for his work, arguably relegating the Long March: Restart project rather innocuous than critical (albeit very lucrative): 'I'd rather be considered a game artist than a Political Pop  artist.  This  doesn't  mean  that  I  don't  care  about  history,  simply  that  I  can't  be responsible for it' (Feng 1995:5).\n\n\n## GAME ART WORLDS\n\n\nLondon's Saatchi Gallery marked the end of 2014 with the gargantuan survey exhibition 'Post Pop: East Meets West', celebrating Pop Art's legacy and influence on 250 works by 110 artists from China  ('political  pop'),  the  Former  Soviet  Union  (SOTS  Art,  or  Soviet  Pop  Art),  Taiwan,  the United Kingdom, and the United States.  The exhibition included one of Feng's 2012 customized arcade game console versions of Long March: Restart (Figure 6) along with works by blue-chip Chinese Political Pop artists Wang Guangyi, Fang Lijun and Yu Youhan, making it is all the more pressing to consider the conditions under which the glam rather than the political side of popular visual imagery has been exploited, critiqued or both at the same time by artists in recent decades. While Feng has expressed no qualms about the market success of his works, 'earnestly believ[ing]\n\nartists should not avoid discussing their relationship to the market, which, as he sees it, is integral to being a professional artist nowadays', speaking of his series of custom-made-to-order paintings 'following the logistics of online shopping' where 'we find a situation in which the customer is in control' (Krischer 2009), what I have become interested in is how the very diversity of not only Feng's  work  but  game  art  'coming  out'  of  China  (as  they  are  for  the  most  part  presented  at international exhibitions or art fairs targeted for foreign consumption) 'emphasize the importance of maintaining interpretive approaches that are equally attentive to both the nature and actual sites' of their production (Chan 2009: 144).\n\nFigure 6: Feng Mengbo, Long March: Restart (arcade console edition), 2012, customized arcade game console. Three arcades in the artist's home studio, 2015. Image credit: Feng Mengbo.\n\n<!-- image -->\n\nThe year 2012 marked a significant decade that witnessed the breakthrough for game art on the international art scene beginning with Feng's participation at the 2002 'Documenta 11' with Q4U , the 2004 Whitney Biennial in New York, and culminating with MoMA's acquisition in 2012 of fourteen video games on their wish list of about 40 ( Super Mario Brothers is  on the  list) to be acquired  in  the  future  for  their  permanent  collection  'as  outstanding  examples  of  interaction design', according to MoMA Architecture and Design curator Paola Antonelli, though not without controversy (Antonelli quoted in Maeda 2012; Moore 2013). Notably, the classic Super Mario\n\nClouds (2002), one of the first game artworks associated with the 8-bit movement, was a mod of Super  Mario  Brothers ; hacking  the  cartridge  by  hand,  Brooklyn-based  artist  Cory  Arcangel removed all of the game's graphics except for its iconic backdrop of blue sky and clouds. The recent release by Nintendo in 2014, however, of Mario Maker for Wii U GamePad controllers, which allows 'players to customize their own 2D Super Mario courses from scratch', basically legitimizes 'a practice already developed by hardcore modders and artists alike' (Weiner 2014). Art world playbour remains no more lucrative for the entrepreneurial artist than it is for the game player, precisely because it is the dominant currency of a 'participatory culture' (Jenkins 2006) that repeatedly tags user labour on digital platforms as a form of 'co-creative labour' (Banks and Deuze 2009). As Justine Humphry (2013) writes, 'Only very few of the vast majority of modders, glitch artists and other user-producers receive formal recognition and monetisation for the work on their media platforms'. This is of course not the case in the context of corporate management strategies favouring 'fun and games' in the workplace (or, enforced and 'managed culture of fun') as a means of increasing creative innovation and improving productivity and worker satisfaction (Goggin 2011: 358).\n\n\n## ONLINE PARTICIPATORY MEDIA: NOT ALL FUN AND GAMES\n\n\nFar away from this but not unrelated, making headlines at the same time Feng was restarting his Long March project  was  the  plight  of  the  Chinese  Gold  Farmer  with  the  discovery  of  'virtual sweatshops' located in a number of countries including Mexico, Romania and predominantly in China. Workers are paid in real money, to work long shifts on computers in 'gaming workshops' to earn and collect virtual loot, in whatever currency, that the actual, presumably time-strapped or patience-lacking players/clients can use to pay for virtual gear to fight monsters to reach the next level of the online game with which they are obsessed: for all parties involved in RMT (RealMoney Trading), 'play  has  begun to do real work' (Dibbell 2007). China rules the  illicit realmoney economy in the game World of Warcraft (Blizzard Entertainment, 2004); Chinese virtual sweatshop  labourers are well aware of their place  in WoW -  in  contrast to  players:  'They  are playing. And we are making a living' (Goggin 2011: 365). The latest is that, in China, prisoners and  labour  camp detainees  are  forced  to  work  hard  and  unpaid  in  virtual  sweatshops  (Vincent 2011), blurring previous understandings of 'precarious playbour' as 'simultaneously voluntarily given and unwaged, enjoyed and exploited' (Terranova quoted in Kücklich 2005).\n\nCritical analysis of game art can ill afford to ignore the implications of different forms of 'precarious playbour', be it in the context of the art world or virtual sweatshops, because these are essentially two sides of the same coin. In the concomitant extraction of value from play, be it about leisure being co-opted as labour or labour being performed in video games for low wages, both have become affective realities of the playbour condition where 'work is play and play is work' (Dibbell 2006: 294). Game technologies are not the only 'affective' technologies where playbour takes place in an age of personal and pervasive social media.\n\nScenario 3: Ai Weiwei, renowned contrarian artist, human-rights activist, architect (he codesigned the Bird's Nest, although he disavowed his role as artistic consultant before it was  completed)  and  curator  (among  others,  in  2000,  he  curated  the  notorious  protest exhibition called 'Fuck Off') and committed political blogger since 2005, takes a selfie. Two months prior to the opening of Long March: Restart in Beijing on 28 May 2009, a week before the twentieth anniversary of the Tiananmen Incident, Ai woke up to discover that two of his five blogs had been shut down by government censors, with the content cleared (Wines 2009). Just days prior, Ai had allegedly suffered a brutal punch to the head by the police while in Chengdu (the capital of Sichuan province) hours before he was to testify for a fellow political activist (Tan Zuoren) investigating the school disaster from the Sichuan earthquake exactly a year before in 2008 that killed thousands of children in their classrooms. The two incidents, the censorship and the beating, are not unrelated: Ai had posted photos of his hospitalization on his blog. A month after his injury in June 2009, Ai had to be rushed into surgery to drain a pool of blood from his brain  while he was in Munich setting up his provocative exhibition 'So Sorry'. This included the commemorative work Remembering ,  reproaching  the  Chinese  government's  near-silence  on  the  same school disaster he and his colleague in Chengdu were investigating.\n\nThe Chinese Internet, or more specifically China's so-called 'Great Firewall', as its elaborate Internet censorship system is called, has been all over the news since January 2010, starting with reports of Google taking concrete steps to pull out of China in protest over state restrictions and hacking attempts to access information about Chinese humanrights activists stored on its systems. On 15 January, last year, five days after Google's announcement  of  'a  'highly  sophisticated'  cyber  attack'  in  December  2009,  Ai  came\n\nforward reporting his Gmail account had been hacked into, although 'he had no proof that the Chinese government' was behind it (Moore 2010). Apparently, in China, art modding is permissible as long as it falls within socially acceptable - that is, 'legal' - limits, but art blogging is definitely not. So why does this paradox - between hacking and chatting - exist?\n\nThe so-called 'Great Firewall' of China refers to the country's 'comprehensive Internet content filtering and blocking system that serves as a censorial device and functions as a statecontrolled bulwark against unwarranted external influence' (Chan 2009: 141). This last scenario underscores the ambivalences in the status quo concerning 'the technological determinist view and teleological  assumption  that  China  is  being  fundamentally  democratized  by  and  through  the Internet'  (Chan  2009:  142).  By  27  June  2011,  for  example, The Globe and Mail reported that according to Chinese human-rights groups and Amnesty International, 'For the first time, China's public security  budget has outstripped its  military  budget. Scores of  human rights  lawyers and bloggers have been rounded up and made to 'disappear', at least temporarily'. As Dean Chan argues, on the one hand, 'in-game protests and virtual world mass mobilizations that have taken place in China since 2005' with World of Warcraft players staging dramatic virtual suicides are 'ultimately constitutive of a 'new field of struggle''; on the other hand, 'a key trope in emergent Western Techno-Orientalist discourses about gaming in China' that understands 'Chinese ludic space  as  always  already  inscribed  by  and  co-extensive  with  government  control'  continues  to substantiate  'the  moral  imperative  to  judge  and  castigate  China's  governance  in  the  name  of upholding liberal definitions of democracy and individual freedom' (Chan 2009: 144).\n\nCoined by David Morley and Kevin Robins in 1992, the term 'techno-Orientalism' refers to  an  Orientalist  discourse  from  the  sixties  onwards  that  was  first  used  to  describe  western perceptions  of  the  economic  threat  of  Japanese  technology  and  its  cornering  of  the  consumer electronics goods market by propagating stereotypes of Japanese identity as hyper-technological, dehumanized robots operating in a futuristic materialist society (Morley and Robins 1992). In the 1980s and 1990s, techno-Orientalist images began to be projected on other East Asian populations (Taiwan,  Singapore,  South  Korea  and  China),  subsuming  the  entire  region  into  a  single universalizing  entity,  but  at  the  same  time  also  entertained  more  positive  connotations  as  the popularity of Japanese media products such as anime and video games and promotion of Asian values and aesthetics increased, primarily aided by a self-Orientalist discourse that reversed the\n\npolarized discourse. By the millennium, however, techno-Orientalism had turned to predominantly target a rapidly modernizing China steadily climbing up the financial superpower ladder (LozanoMéndez 2010: 191), reverting back to negative techno-Orientalist associations of the country as the  world's  factory  producer  of  shanzai  (fake)-manufactured  brands  and  substandard,  shoddy cheap goods in utter disregard for hazardous environmental waste and in the absence of rights for exploited workers - all of which have gained for China clearly an illegitimate competitive edge over their western counterparts. In this context, the high profile case of Ai Weiwei and censorship of social media was taken as yet another sign of China's oppressive and authoritarian regime, poor human-rights record and basic lack of freedom of expression (Jim 2014).\n\nSuch rhetoric, which has certainly dogged unofficial art in China for a long time, can be seen  to  be  acutely  operational  in  emergent  discourses  concerning  Chinese  new  media  arts. Discussions  about  Chinese  game-related  art  can  hardly  avoid  dovetailing  with  indictments  of China's  position  on  Internet  censorship.  At  issue  here  is  unproblematically  eliding  art  world playbour in relation to the paradoxes of new media arts practices that occupy the liminal spaces of gaming and participatory media technologies under authoritarian circumstances. When we get to, for  example,  Cao  Fei's Second  Life online  art  world  of RMB City (with  its  pretence  of  Rem Koolhaas's CCTV tower as a blazing inferno), it becomes rather explicit that art worlds online or off,  like  game  worlds,  are  incontrovertibly  shaped  by  the  whole  systems  that  produce  them  networks, rules, internal politics and tensions (Bittanti 2006: 7). As Matteo Bittanti argues drawing from Howard Becker, art worlds are like game worlds: they involve collective activity, and their products, be they artworks or games, are shaped by the whole systems that produce them: 'The rules of this particular game are called 'conventions' and they 'cover all the decisions that must be made with respect to works produced'' (Bittanti 2006: 7)\n\n\n## CONCLUSION\n\n\nThese scenarios have attempted to denote three different kinds of spaces that Chinese game art finds itself embedded in: the ubiquity of visual, popular and political culture; the relatively safe haven  -  if  not  disconnect  -  of  the  international  art  world;  and,  especially  as  compared  to  the precarious  nature  of  virtual  spaces  and  blogospheres,  whether  they  are  run  by  artists  or multinational  corporations.  This  article  has  been  concerned  with  how  these  spaces  represent contentious  sites  where  the  ways  in  which  not  only  national  history  but  also  global  media  art\n\nhistories are written must contend with different formulations of playbour that have risen out of online gaming in the context of East Asia as well as emergent techno-Orientalist discourses about media art and technologies in China. To do this has meant taking into consideration the broader contexts for such activities, of which there are many. These include the increasing internationalization of contemporary art and the growing interest of the art world in networked cultures and participatory media in general; the rise of gaming in Asia (as elsewhere); the current debates  surrounding  Internet  censorship  in  China;  art  and  cultural  policy  in  China  concerning media technologies; and the  legalization and economic privatization processes that have taken place  since  the  late  1970s  and  that  have  transformed  conceptions  of  public  spheres  and  social freedoms in China. Neither the thrill of gaming nor the futuristic dazzle of virtual creation in works such as Cao's Second Life projects or Feng's Long March: Restart , with their whimsical blend of social  capitalist  and  propagandistic  iconography,  should  dissuade  from  a  reflection  on  the Internet's questionable democratizing impulse in China in relation to a morphing media archive that attends to holding fundamental, if ambiguously 'localized', cultural values. It is within this charged context that Chinese new media arts may be at a precarious cusp of a new emergent field of struggle that warrants further examination by transnational cultural critics.\n\n",
         "Among the most significant examples of new media art in China to first receive critical attention are those that tend towards re-engineering early video games while riffing off on aspects of the 1990s’ ‘political pop’ movement. Are these works the product of, or interventions into, the current parameters established for Chinese media, political censorship and game worlds? How might they reflect the fault lines of the growing interest in networked cultures and participatory media in contemporary art and in general? Through personal vignettes and playful moments, this article argues that one of the politico-cultural implications of the Mao Goes Pop art movement going digital concerns the link between digital art’s ‘precarious playbour’, the rise of gaming in Asia, and emergent techno-Orientalist discourses about media art and technologies in China. Since the 1990s, game art by Feng Mengbo (b. 1966) and other artists is introspective of not only the transnational art world but of global media convergence as well.",
         ""
        ],
        [
         "39",
         "39",
         "## 1 Introduction\n\n\nInterest in early warning systems and predicting conflict intensity has recently increased in both research and policy circles (Hegre, Vesco and Colaresi, 2022; Gleditsch, 2022). However,\n\n† Center for Crisis Early Warning, University of the Bundeswehr Munich, christian.oswald@unibw.de\n\nwhile this development has no doubt had a positive impact on researchers, practitioners, and decision-makers, and the interactions between these groups, current practices are mostly limited in one important way: they focus on one main outcome variable which is battlerelated deaths. While important, there are several other variables of interest related to conflict intensity such as casualties from violence against civilians and violence between nonstate actors, or a more general category of security-related incidents which may or may not result in casualties but are still indicative of conflict intensity in a country. Furthermore, most publicly available conflict prediction efforts on the subnational level focus on PRIO-GRID cells as unit of analysis. However, a sizable share of conflict event data does not have the necessary level of geoprecision to reliably allocate events to these cells (Cook and Weidmann, 2022). This paper, in contrast, seeks to predict conflict intensity at the province-level to avoid geoprecision issues while keeping a meaningful subnational unit of analysis. Lastly, finding new and innovative data sources to increase our collective ability to predict conflict intensity is of high priority since they can help increase ensemble performances by detecting signals which other models and variables capture to a lesser extent (Hegre, Vesco and Colaresi, 2022; Vesco et al., 2022). This paper contributes to the literature by introducing openly available and real time-updated data sources in the form of Google Trends and Wikipedia data for conflict forecasting, using these data sources to predict four continuous variables of interest which capture conflict intensity, and predicting them on the country- and province-month level. It answers the research question: Do Google and Wikipedia search data increase our ability to predict conflict intensity on the national and subnational level ?\n\nEarly efforts of conflict forecasting focused on predicting conflict onset, operationalized by passing thresholds of 25 or 1,000 battle-related deaths (Ward, Greenhill and Bakke, 2010; Goldstone et al., 2010). More recent research has mostly focused on battle-related deaths as outcome variable (Vesco et al., 2022). 1 However, focusing solely on battle-related deaths resulting from encounters between government and rebel forces ignores the amount of casualties from violence against civilians perpetrated by any conflict actor and it likewise ignores violence between different non-state actors such as rebels which undoubtedly influence and shape the security situation and conflict intensity in a country. In addition, the abovementioned variables are purely concerned with casualties whereas many conflict- or securityrelated incidents do not necessitate casualties. Examples may include various forms of sexual violence, mutilations, looting, non-fatal assaults and explosions, and the list could go on and on. Turning a blind eye to such incidents in our efforts to predict conflict intensity paints an incomplete and possibly misleading picture of a conflict situation and its intensity. In\n\ncontrast, this paper predicts the number of security-related incidents and of casualties from state-based, non-state, and one-sided violence as outcomes of interest.\n\nFurthermore, most current efforts to predict conflict intensity subnationally are at the PRIO-GRID level (Rød, G˚sste and Hegre, 2023). There are good reasons for doing so such a as stable geographical units over time and apolitical border design (Tollefsen, Strand and Buhaug, 2012). However, the strong imbalance in grid cells which experience conflict makes prediction tasks more challenging (Vesco et al., 2022). In addition, PRIO-GRID cells are too fine-grained for the spatial accuracy of a substantial share of conflict event data which oftentimes only provide reliable information on the provinceor district-level, leading to either incorrectly attributing events to the wrong cells or omitting events with insufficient geoprecision (Cook and Weidmann, 2022). This paper predicts at the subnational level of first-level administrative regions which will be referred to as provinces. In addition to the above-mentioned possibility of geolocation error, the main motivation to use provinces is that reporting about events, be it in traditional or more modern outlets, oftentimes evolves around country and province names. The conflicts in Tigray and more recently in Amhara, both located in Ethiopia, have received international attention by frequently referring to the province names. Other examples include Benghazi in Libya, Bamako or Timbuktu in Mali, or South and North Kivu in the Democratic Republic of the Congo. There are thus sound theoretical and empirical reasons to focus on provinces as subnational unit of analysis.\n\nLastly, a key argument in the literature is that we need new and innovative data, alongside increasing the quality of existing data sources and methodological advances, to increase our ability to predict conflict intensity more successfully. The aim of this paper is to propose new and refined data sources for conflict forecasting on the national and subnational level. Previous research showed that using Wikipedia data can help improve our ability to predict changes in battle-related deaths on the country-level, and that such variables are able to deliver unique insights which other data sources provide to a lesser extent (Oswald and Ohrenhofer, 2022; Hegre, Vesco and Colaresi, 2022). The interests of the crowd, similar to the wisdom of the crowd, can be a powerful predictor of conflict intensity. This paper builds on this work and both extends the scope of previously used Wikipedia data and adds Google Trends as a new and important data source to capture international interest. Both Wikipedia and Google Trends search data are sourced in seven major languages: English, Spanish, French, German, Portuguese, Russian, and Chinese. 2 In addition, Google Trends are used for web and news searches for each language. 3 These variables have meaningful subannual\n\nvariation over time and are thus expected to reflect developments related to conflict intensity. They may also be better able to predict cases where past violence, traditionally the strongest predictor of intensity, is not a suitable indicator (Hegre, Vesco and Colaresi, 2022). The data used in this paper are also fully transparent and open. Covariate data used for comparison are publicly and openly available and can be downloaded with open source software. Likewise, Google Trends, although there are some caveats which will be explained later, and Wikipedia data are openly available, updated in real time, and can be extracted with relative ease with existing open source software. The paper thus contributes to wider efforts of both improving conflict prediction and making it more open and transparent (Rød, G˚sste and Hegre, 2023). a\n\nIn sum, this paper makes three contributions to the conflict forecasting literature. First, it expands the set of outcome variables of interest. In addition to the number of battlerelated deaths between a government and a rebel group, this paper predicts the number of security-related incidents and of casualties resulting from both violence against civilians and violence between non-state actors. This is vital to get a full picture of the conflict situation and intensity in a country or any spatial unit of analysis of interest. Second, it presents results for the country- and province-month level as units of analysis. The models predict globally, and for Africa with additional covariates comparisons, at the country-month level and for Africa, also with covariates comparisons, at the province-month level. Provinces have both theoretical and empirical appeal and are of substantive importance for practitioners and users of forecasts, and are less prone to suffer from imprecision of geolocated conflict event data than other alternatives. Third, it introduces data sources that reflect international interest in, or salience of, a country or province in the form of Google Trends and Wikipedia page views. Data for seven major languages are tested for their predictive performance. Importantly, both Google Trends and Wikipedia data can overcome common data problems such as missing values and irregular or delayed updating which makes them attractive for near-real time forecasting efforts. Given that the main independent variables are updated in real time and the main dependent variables are regularly updated as well, the approach presented in this paper can be used to produce forecasts with monthly updating schedule. The paper is structured as follows: After reviewing previous efforts to predict conflict and violence, I show how Google Trends and Wikipedia have been used in different disciplines to predict various phenomena and explain how it can be useful to predict conflict intensity. I describe the data and methods in more detail before presenting both aggregated and disaggregated out-of-sample results using various performance metrics and test windows. The final section outlines limitations of this approach and avenues for future research.\n\n\n## 2 Predicting conflict and violence\n\n\nEarly models of civil war onset distinguished between greed and grievances as groups of explanatory factors. However, they turned out to be of limited predictive capacity (Ward, Greenhill and Bakke, 2010). Others likewise predicted civil war onset and adverse regime change onsets (Goldstone et al., 2010). While these early efforts were based on regression techniques, machine learning algorithms such as random forest were shown to outperform regression models when predicting onset (Muchlinski et al., 2016; Colaresi and Mahmood, 2017) and have since taken over. More recently, a number of different models and variables were used and tested to predict civil war onset and incidence. These studies also sought to investigate the influence of structural, i.e. relatively slow-moving country or regime characteristics, and procedural, meaning developments related to dissent, mobilization, and repression preceeding civil war onset, variables and debated the value of theory for forecasting civil war onset (Blair and Sambanis, 2020; Beger, Morgan and Ward, 2021; Blair and Sambanis, 2021). This paper seeks to contribute to this discussion by adding salience variables in the form of internet search data to the discussion and the forecaster's toolkit.\n\nThere has likewise been a shift to predict the number of battle-related deaths over binary or categorical conflict variables (Hegre et al., 2019, 2021). 4 This has been done using a variety of algorithms and data sources (Vesco et al., 2022; Hegre et al., 2024). Data sources which tended to add information to commonly used indicators such as GDP, population size, or conflict history, have been for example news sources (Mueller and Rauh, 2022 b ) and internet search data from Wikipedia (Oswald and Ohrenhofer, 2022). Such quickly changing features which can capture rising tensions are well suited to predict both conflict incidence and numbers of battle-related deaths and outbreaks of violence in previously peaceful settings (Hegre, Vesco and Colaresi, 2022). Predicting new outbreaks of violence is a particularly challenging task, even with atypically fine-grained local-level data at hand (Bazzi et al., 2022; Mueller and Rauh, 2022 a ). Using Google Trends and Wikipedia data seeks to contribute to these efforts by expanding the previous use of internet search data and complementing news sources as predictors.\n\nLastly, a recent review and comparison of different academic, commercial, and operational conflict early warning systems highlighted several important points regarding transparency and accessibility, key parameters, and forecasts (Rød, G˚sste and Hegre, 2023). a One take-\n\naway from this overview is that the data source for operationalizing the outcome of interest varies mostly between the Uppsala Conflict Data Program (Sundberg and Melander, 2013, UCDP) and the Armed Conflict Location and Event Dataset (Raleigh et al., 2010, ACLED) while none of the systems seem to use both simultaneously. 5 This may risk fine-tuning models and variable selection too much on the respective dataset in use. This paper will use both these datasets to operationalize different outcomes of interest. Another illuminating aspect is the units of analysis, which range from week to month to quarter to year on the temporal dimension whereas the spatial dimension is dominated by country while three systems have provinces and two have PRIO-GRID cells as subnational. 6 Importantly, systems serving both country and province as spatial units of analysis are rare (Rød, G˚ asste and Hegre, 2023). 7 This paper thus contributes to current forecasting efforts by using more than one distinct data source to operationalize various outcomes of interest and by predicting on both the country- and province-month level.\n\n\n## 3 Forecasting with Google Trends and Wikipedia data\n\n\nGoogle search volumes have been used in relation to cryptocurrency returns and volatility. While, much like previous financial research, Google searches did not help predict returns, it did on average increase predictive performance regarding hourly, daily, and weekly volatility levels (Bleher and Dimpfl, 2019). It has further been used to nowcast GDP which tended to increase accuracy even when contrasted to official statistics (Ferrara and Simoni, 2023). Others used Google Trends to foreand nowcast influenza-like illnesses during influenza season in the Netherlands. These online search data were able to predict the onset, peak, and end of influenza episodes between one and three weeks earlier than other commonly used data sources (Schneider et al., 2020). Google searches have also been used to predict shortterm monthly tourist arrivals in popular German vacation spots (Bokelmann and Lessmann, 2019). Lastly, using Google Trends to detect and forecast protests in major US cities and metropolitan areas delivered promising results (Timoneda and Wibbels, 2022). Thus Google Trends have previously been used to forecast various phenomena with encouraging results.\n\nOthers looked at Google Trends to determine changes in user interest and behavior. Previous research looked at for example public interest expressed via Google searches in pes-\n\nticides and plant protection products in Switzerland. Between 2011 and 2019, and especially since 2017, interest in pesticides increased considerably whereas it remained relatively stable throughout the time for plant protection products. Thus online searches are important to detect current environmental discussions which do not take place in public or the open (Schaub, Huber and Finger, 2020). Others investigated how Google searches changed after mass shootings in the United States. Issues such as the number of victims, amount of news coverage, shootings at schools as opposed to other venues, and the use of certain weapons increase general interest in gun control laws and gun rights (Semenza and Bernau, 2022). Overall, Google Trends can and do reflect public interest, and this interest is affected by news coverage (Nghiem et al., 2016). It has further been shown for conservation biology that the impact of news reporting about relevant events on internet searches is very much instantanous (Anderegg and Goldsmith, 2014). Such attributes are particularly useful for predicting conflict intensity.\n\nWikipedia data have likewise been used to predict various topics of interest such as changes in battle-related deaths, influenza cases, stock market changes, or European Parliament elections. It has been shown that views of English Wikipedia country pages pick up patterns that other, commonly used data sources and algorithms pick up to a lesser extent and thus provide unique insights into conflict dynamics (Oswald and Ohrenhofer, 2022; Vesco et al., 2022). It has further been shown that Wikipedia, alongside Google Trends, can help anticipate Influenza season in the US by several weeks (Liu, Srinivasan and Meyers, 2019). Wikipedia data also helped predict changes in overall turnout and parties' vote shares in European Parliament elections but were less helpful regarding overall election outcomes (Yasseri and Bright, 2016). Finally, using Wikipedia traffic can help discover stock market changes early on (Moat et al., 2013). Wikipedia page views thus likewise reflect public interest and have resulting predictive power. There is therefore evidence that both Google Trends and Wikipedia searches reflect public international interest and are influenced by news cycles and current events which makes them suitable for conflict prediction.\n\n## 4 Google and Wikipedia data for predicting securityrelated incidents and conflict fatalities\n\nPrevious research has used keyword counts from vast amounts of newspaper articles to forecast conflict. Journalists give informed accounts about conflict events without leaving interpretations to the readers which makes them suitable sources for prediction since they report about increasing tensions (Chadefaux, 2014). Others have used newspapers and\n\nnews aggregators such as the New York Times, the Economist, the Washington Post, BBC Monitor, Associated Press, and LatinNews to estimate topic distributions over time and subsequently predict conflict onset and intensity on the country- and PRIO-GRID cell-level (Mueller and Rauh, 2018, 2022 a b , ). There is also research utilizing more recent natural language processing tools to analyze large text corpora, including numerous news sources and reports from organizations, think tanks, and governments to predict conflict (Hu et al., 2022; H¨ffner et al., 2023). a What all these efforts share is a focus on English language sources and on published pieces of reporting to predict conflict. 8\n\nHowever, it has been shown that news media reflect 'reporters' locations, identities, capacities, relationships, outlet priorities, and [a] need to place stories in competitive media markets, rather than a representative or systematic sample of ongoing events' (Parkinson, 2024, 1527). Media also tend to underreport for example violent conflict events in African countries and in countries with relatively low internet coverage or trade volume (Dietrich and Eck, 2020), and journalists in particularly conflict-ridden countries tend to use less specific language while trying to uphold quality reporting (Dorff, Henry and Ley, 2023). Using reader- or consumer- rather than writer- or publisher-driven forms of public interest may add an additional dimension to our forecasting efforts not captured by text news sources to the same extent. Google Trends and Wikipedia page views reflect public interest while being influenced by news cycles and current events (Semenza and Bernau, 2022; Nghiem et al., 2016; Anderegg and Goldsmith, 2014). However, internet searches are influenced by many more additional recent media outlets and websites not included in the above mentioned sources. They may, of course, still be influenced by these traditional media reports, but not exclusively. Google Trends and Wikipedia page views reflect what readers and news consumers are interested in whereas the above news sources reflect what editors and journalists deem newsworthy. Internet searches can thus be regarded as a complement to media text sources rather than a filtered or watered-down version of text sources. Individual-driven internet searches can be thought of as the interest of the crowd, analogous to the wisdom of the crowd (Tetlock, Mellers and Scoblic, 2017; Atanasov et al., 2017). The data reflect international interest, since I focus on global searches, in a country or province. Such increased international attention can be indicative of political instability and violent developments.\n\nWhy the focus on Google and Wikipedia over other alternatives? Google is the dominant search engine globally, accounting consistently for around 90% or more of the market share since at least 2015, with Bing following in second place with 2-3%. 9 It is therefore the\n\nideal search engine to measure global public interest. 10 Meanwhile, Wikipedia has evolved to a highly accurate and complete open encyclopedia. Research has shown that the level of factual information is comparable to reputable sources such as the Encyclopedia Britannica or the Dictionary of American History (Holman Rector, 2008), that political information is correct and consistent (Brown, 2011; Herrmann and D¨ring, 2023), and that historical o information is likewise highly accurate, with more emphasis on wars and violent events compared to e.g. the Encyclopedia Britannica (Samoilenko et al., 2018). The incorporation of information from for example non-profit, research, and government sources and updates based on new information means that Wikipedia articles are oftentimes more rounded and give a more complete picture than media sources (Gildersleve, Lambiotte and Yasseri, 2023). As a result of all this, Wikipedia's image has improved over time and individuals regard it as trustworthy source to consult (Gildersleve, Lambiotte and Yasseri, 2023). Helpfully, Google returns the Wikipedia article as first item when searching for countries or provinces which further exemplifies the argument that Google Trends reflect user interest while Wikipedia views mirror user intent to read (K¨mpf et al., 2015). a\n\nThe proposed mechanism is as follows: countries feature in traditional, social, and other, more recent, media outlets due to for example protests, coups, violent behavior, or other ongoing political, economic, or social developments mostly associated with negative aspects. Searches are valuable for conflict intensity because a substantial share of internet searches relate to reporting of negative aspects about a country. As a result of this reporting, individuals in search for more information about that country use Google and might read the accompanying Wikipedia article. However, not everyone googling a country will automatically read the corresponding Wikipedia article, too, and individuals might consult a Wikipedia page directly without using Google. The main difference in general is that Google Trends show what individuals are interested in whereas Wikipedia page views show what they actually read (K¨mpf et al., 2015). a It is therefore conceptually and empirically important to use both rather than using one over the other since they are not overlapping perfectly. The observable implications of this proposed mechanism are shifts in both Google Trends scores and Wikipedia page views as a result of conflict- or stability-related developments. I argue that the same mechanism applies to first-order administrative regions (provinces). In some instances, especially if developments are regionally concentrated, province rather\n\nthan country names feature more prominently in reporting. Recent examples include Tigray and Amhara in Ethiopia or Crimea, Donetsk, and Luhansk in Ukraine. Other examples are Benghazi in Libya, Bamako and Timbuktu in Mali, and North and South Kivu in the Democratic Republic of the Congo.\n\nFigure 1: Google Trends and Wikipedia page views for Ukraine in English and Russian.\n\n<!-- image -->\n\nFigure 1 illustrates the mechanism looking at Ukraine which attracted considerable international attention prior to fighting and hostilities taking place. The solid vertical lines indicate the annexation of Crimea in March 2014 and the invasion of Russian troops in February 2022. The colored lines indicate Google Trends web (solid) and news (dash-dotted) searches and Wikipedia page views (dotted). Orange lines show values for Russian whereas red lines show them for English. Y-axes were rescaled for ease of comparability. Notice first that there is evidence for differences between languages. There is much more variation in Russian searches compared to English searches in the case of Ukraine. This is the main motivation to use internet search data in seven major and widely spoken languages to account for geographical and linguistic variation in public interest. Notice further that there are distinct peaks at the vertical lines, and that we can observe a certain buildup in interest preceeding these events. This is more pronounced for Google Trends compared to Wikipedia page views. While for example Russian troops crossed the Ukrainian border on 24 February 2022, first troop movements and warnings of possible incursions were noticed and voiced in November 2021. In early December, US President Biden warned Russian President Putin\n\nfrom invading Ukraine. 11 In February 2022, including just a few days prior to the invasion, French President Macron and German Chancellor Scholz separately visited Putin in Moscow and sought to prevent a possible invasion diplomatically. 12 These troop movements and high-level political visits as well as political statements by Putin questioning Ukrainian statehood attracted widespread media coverage and international attention. There is thus evidence that using both types of internet search data using several languages is most likely to detect tensions prior to hostilities, and that variation over time may mirror variation in conflict intensity. Internet searches in the form of Google Trends and Wikipedia page views can thus constitute a valuable source to predict conflict intensity.\n\n\n## 5 Data and methods\n\n\nData for the outcome variables of interest come from the UCDP Georeferenced Event and Candidate Events Datasets (Sundberg and Melander, 2013; Hegre et al., 2020, GED) and the Armed Conflict Location and Event Database (Raleigh et al., 2010, ACLED). UCDP GED provides data on the number of battle-related deaths (state-based violence, SBV), casualties from violence against civilians (one-sided violence, OSV), and casualties from violence between armed groups (non-state violence, NSV) attributed to specific conflicts between named actors which account for at least 25 fatalities per years. ACLED, in contrast, provides data on both lethal and nonlethal conflict events which makes it ideal for operationalizing the more general category of security-related incidents (SRI). These incidents include all events in the ACLED categories Battles, Explosions/Remote violence, and Violence against civilians. I subsequently aggregate the numbers of the above mentioned variables by month and spatial unit of analysis, i.e. either country or province. I use CShapes for country and GADM for province boundaries for maps and for geolocating events (Schvitz et al., 2022; GADM Database of Global Administrative Areas, Version 4.1 , 2024). Table 1 provides descriptive statistics for the target variables. In addition to measures of central tendency and dispersion, Pct indicates the percentage of non-zero observations.\n\nI use raw numbers of country and province pages on Wikipedia. Daily page views are aggregated to the monthly level for subsequent analyses. Google Trends data, in contrast, have a few idiosyncrasies to be aware of (Ficetola, 2013; Timoneda and Wibbels, 2022). Data obtained from Google Trends are based on a sample rather than the full search history of a\n\nTable 1: Descriptive statistics (target variables)\n\nparticular term. It is unknown which sampling method is used by Google but it introduces difficulties regarding replicability since each query will deliver values from different samples. In addition, Google does not provide raw search numbers like Wikipedia does. Instead, it normalizes data from the sample such that values range between 0 and 100 where 0 refers to the minimum value of searches in the sample and 100 to the maximum. This means that two countries cannot be compared directly as with Wikipedia data, since both have the same minimum and maximum values but we do not know whether one had many more searches than the other. Lastly, the time frame for Google Trends queries matters, too. For example, the maximum for Ukraine between 2008 and 2015, the Crimea annexation in 2014, is different from the time frame between 2008 and 2023, the full-scale invasion in 2022. However, previous research has shown that differences between for example trendsor average-divided data over raw data are minimal (Bokelmann and Lessmann, 2019), also providing evidence that the sampling issue mentioned earlier is not severe, which is why I use raw values. 13\n\nThe Google Trends and Wikipedia model ( gtw ) contains the number of Wikipedia page views and the values for Google Trends hits for both web and news searches for seven languages: English, Spanish, French, German, Portuguese, Russian, and Chinese. 14 Table 2 shows summary statistics for Africa on the country-level. 15 We can observe that the English Wikipedia version is by far the most used and popular in terms of monthly page\n\nviews, surpassing Spanish, French, and German by a margin. Portuguese, Russian, and Chinese have much lower mean and median values whereas, interestingly, maximum values for Russian are larger than for the French and German language editions. These patterns are similar on the global level with some slight variations. On the province-level, however, the differences are stark and the English language version dominates in popularity, followed by the Spanish, French, Russian, and Chinese versions. The Portuguese and German versions were the least popular or active ones. Turning to Google Trends, the mean and median values are indicative of activity since the minimum and maximum values are identical and the standard deviations are by and large comparable across languages, ranging between 9 and 22. The most active languages were English, Spanish, French, and German. This pattern is similar on the global level. However, Portuguese is the most popular language with regards to province searches by a large margin, followed by English.\n\nTable 2: Summary statistics for all Google trends and Wikipedia model variables (Country - Africa)\n\nThe covariate model ( cov ) includes several commonly used predictors for political violence such as the Correlates of War Military Capabilities index and its constituent components,\n\npopulation and economic data from the World Bank, the V-Dem polyarchy democracy index, and ethnic and religious fractionalization and polarization. It also includes several geographical variables such as the shares of farmland, forest, open and rugged terrain, mean elevation, the number of petroleum resources, and road length and density. Political variables include the number of leaders per year, whether there was an irregular leadership change, the number of built-up areas and excluded ethnic groups, and information about state membership in international organizations. The covariate model on the province-level contains overall fewer but also some additional variables, focusing on variables which vary at the province- rather than country-level. It also includes the share of farmland, forest, and open terrain, mean elevation, road length and density, number of built-up areas and excluded ethnic groups, the number of petroleum resources, and population size. It additionally includes GDP ppp, nighttime light emissions, rainfall and temperature. 16 Lastly, the benchmark models ( bm ) include lagged values for the number of fatalities from state-based, one-sided, non-state violence, and security-related incidents, and the number of security-related incident events.\n\nI use random forests to test the predictive power of Google Trends and Wikipedia data. Random forests have been used frequently in conflict forecasting and beyond and showed satisfying performances and efficiency (Muchlinski et al., 2016; Colaresi and Mahmood, 2017; Hegre et al., 2019; Grinsztajn, Oyallon and Varoquaux, 2022; Rød, G˚sste and Hegre, 2023). a In brief, a number of decision trees are grown using bootstrapped samples of the training data. Any individual decision tree randomly chooses one independent variable after the other to best predict the outcome until there is no performance gain by adding another variable. The random forest takes the average of all decision trees to improve predictive performance and mitigate overfitting (Breiman, 2001). I grow random forests of 1,000 trees for each model using time-series cross-validation predicting twelve months ahead. The models are trained globally while predicting countries and provinces individually. Whereas others use the full time-series of available data to train models using time-series cross-validation, I only use a relatively small window of the previous three years. The main reason is that, given the relative recency of Google Trends and Wikipedia, I expect user behavior and the amount of users to be (very) different in 2006 or 2008 compared to e.g. 2020. I repeat this procedure for each outcome of interest and each spatial unit of analysis and scope combination for four held-out test windows, the years 2020 through 2023, respectively, to evaluate out-of-sample performance. I evaluate the three models mentioned above - Google Trends and Wikipedia, covariate, and benchmark - as well as their combinations for comparative purpose.\n\n\n## 6 Results\n\n\nI focus first and foremost on the target variable security-related incidents while also discussing the other outcomes. I expect the proposed mechanism to be strongest or most visible for a more general category such as security-related incidents whereas the more specific categories of state-based, one-sided, and non-state violence may, on their own, attract relatively less attention than a category which includes all of them and additionally non-lethal events. After all, one aim of this paper also is to investigate whether internet search data help us predict certain types of violence more than others. In addition to the root mean squared error (RMSE) and mean absolute error (MAE), I evaluate the accuracy coefficient (AC), Concordance correlation coefficient (CCC), and Robinson's Agreement Coefficient (RAC) to measure individual model performances. 17 RMSE and MAE measure both precision and accuracy, but RMSE is more sensitive to outliers. Values closer to 0 indicate better predictive performance and there is no upper bound. AC measures accuracy while both CCC and RAC measure agreement, or both precision and accuracy. 18 Values range between 0 and 1 and values closer to 1 indicate better predictive performance.\n\n\n## 6.1 Country-level analysis\n\n\nFigure 2 shows results for models and model combinations for security-related incidents in Africa on the country-month level. The orange dots indicate the models of particular interest: bm , gtw , and bm+gtw . Notice first that the benchmark model, which only includes lagged conflict variables, expectedly tends to perform well since these variables are traditionally considered to be the best predictors for future violence. In addition, the gtw model consistently outperforms the cov model across all test windows and metrics. Notice further that the cov and cov+gtw models perform worst across all test windows and metrics, indicating that the covariate model itself is not adding too many unique insights to our efforts to predict security-related incidents. Indeed, comparing the bm+gtw to the bm+cov+gtw model indicates that adding the cov model decreases precision and accuracy. This conclusion holds true for all performance metrics and test windows. It is worth reiterating that the covariate model includes mostly variables on the annual level with delayed updating schedules which also makes them more challenging to use for near-real time forecasting, or more prone towards the need of imputing missing values. Meanwhile, the gtw model is not among the best performing models looking at RMSE and MAE, but the bm+gtw model outper-\n\nforms all other individual and combined models in two out of four test windows, indicating that Google Trends and Wikipedia data add important information to the benchmark model to increase predictive performance. The gtw model likewise performs well when evaluated against the remaining metrics, and the bm+gtw model is either the best or second-best performing model. Figure 2 thus provides evidence that Google Trends and Wikipedia data help improve our ability to predict the number of security-related incidents on the country-month level.\n\n<!-- image -->\n\nPerformance\n\nTurning to the other target variables, it is first noteworthy that all models struggled with predicting state-based violence in 2022; a pattern we observe across all unit of analysis and scope combinations. Likewise of note is that the bm , gtw , and bm+gtw models were, compared to other models, less performant in 2023 compared to 2020 and 2021, where they were performing best across almost all metrics. Looking at one-sided violence, all models performed less well for 2020 compared to the other test windows, but the bm+gtw model was still consistently among the best performing. Google Trends and Wikipedia helped improve the benchmark model predictions across most metrics and test windows. Lastly, Figure 3 shows performance metrics for non-state violence. Models performed well with regards to RMSE, MAE, AC, and RAC despite the relatively low prevalence of non-state violence. Recall from Table 1 that only 13% of observations saw non-state violence compared to more than 20% for state-based and one-sided violence and 62% for security-related incidents. The\n\nbm+gtw model is again among the best-performing while the gtw model on its own is likewise doing well and performs better than the cov and cov+gtw models across test windows and metrics. There is thus evidence that Google Trends and Wikipedia data help improve our collective efforts to predict different types of violence as well as security-related incidents as a more general category of interest. It is further noteworthy and encouraging that it tends to do well for different types violence with varying levels of prevalence. We next investigate whether there are country differences where salience variables tend to do better or less well.\n\nFigure 3: Out-of-sample performance metrics for countries in Africa (non-state violence).\n\n<!-- image -->\n\nFigure 4 aggregates the mean absolute error to the country-year level for the 2022 out-ofsample predictions of security-related incidents and plots them on a map. 19 We can observe that the bm and gtw models perform quite well and comparable whereas the cov model performs less well for a number of countries, including Nigeria, Somalia, and the Democratic Republic of the Congo (DRC). 20 We can further observe that the performance of the cov and cov+gtw models is very similar, and that there is no discernible difference between the bm+gtw and bm+cov+gtw models. This is a pattern we observe across all test windows, and at times the bm+cov+gtw model is doing worse than the bm+gtw model. The models perform surprisingly consistent for one-sided and non-state violence, all struggling or doing well for similar sets of countries, albeit at times at different levels. Countries such as South\n\nSudan, Ethiopia, Mali, Nigeria, and the DRC show the highest mean absolute errors. In contrast, all models struggled for example predicting state-based violence in Ethiopia in 2021 and 2022, and some still in 2023. Looking at 2020, we can observe neatly how Google Trends and Wikipedia data help adjust predictions from the bm model to decrease the MAE for countries such as the DRC, Nigeria, Niger, Mali, and Burkina Faso. We can furthermore see that the bm+cov+gtw model seems to do worse than the bm+gtw model, decreasing performance for countries such as South Africa, Algeria, Chad, and South Sudan. There is thus evidence that salience variables help improve predictions on aggregate and at more disaggregated levels.\n\nModel performances predicting security-related incidents\n\nFigure 4: Out-of-sample mean absolute error by country in Africa (security-related incidents, 2022 held-out).\n\n<!-- image -->\n\nFigure 5 shows out-of-sample predictions of security-related incidents for Nigeria in 2023 as line plots while the dots indicate the actual values. We can observe that the gtw model looks the most dynamic and shows the most variation. It further helps make the bm model less conservative in its predictions, mostly coming closer to the actual values. This pattern of making the benchmark model predictions less conservative can be observed for many countries and types of violence. It further exemplifies how Google Trends and Wikipedia data in combination with past violence indicators can help improve our ability to predict.\n\n<!-- image -->\n\nThe plot shows the actual number of security-related incidents as dots and the predicted number of security-related incidents for the models as lines.\n\nWith this proof-of-concept in hand, we turn to global predictions without covariate comparison. Figure 6 shows the performance metrics for three models: bm , gtw , and bm+gtw . The two models of particular interest are colored in orange. We observe here, similar to the analysis confined to Africa, that the gtw model does relatively well on its own but shows its full potential and strength in combination with past conflict and violence variables. There can be a number of reasons for relative and absolute increases in international interest, and combining this international interest with past violence can help adjust for these situations. Looking at security-related incidents for 2020, the gtw model tends to produce higher annually aggregated MAE values for generally much-googled countries such as the United States, Mexico, Brazil, or China for example. 21 The largest error values are for Ukraine and Yemen. The benchmark model also struggled somewhat with Ukraine but not to the same extent as the gtw model. The two individual models largely struggle with the same countries. In both 2020 and 2021, for example, they over- or underpredicted Ukraine, Afghanistan, and Myanmar. Still, the gtw model adds to our predictive capabilities and does so at relatively low computational cost to source data and it can be used in near-real time, which makes it exceedingly attractive for live early-warning systems.\n\nTurning to other outcome variables, all models struggled to similar degrees with Afghanistan, Ethiopia, Ukraine, and Yemen across test windows with regards to state-based violence while\n\nFigure 6: Out-of-sample performance metrics for countries globally (security-related incidents).\n\n<!-- image -->\n\nSudan, Ethiopia, Mali, and the DRC showed to be most challenging for the outcome of onesided violence. All models predicting non-state violence struggled the most with Mexico. While some metrics show higher values compared to the previous Africa predictions, it is notable that some show equal or, at times much, smaller values for the global analysis looking at standard metrics such as RSME and MAE. The models tend to generally perform better for security-related incidents than for casualties from specific types of violence. They are both more precise and accurate and show more agreement between predictions and observations.\n\n\n## 6.2 Province-level analysis\n\n\nFigure 7 shows performance metrics for all models, and their combinations, and test windows for Africa. Notice first that the gtw model scores worst on its own across all metrics and test windows. In contrast, the bm+gtw model almost always scores best across all metrics and test windows. This underscores the point made in the previous section that combining internet search data, or salience variables, with past violence helps adjust predictions and bring them more on target to correct for the possibility that internet searches increase unrelated to events or precursors of political instability. It is noteworthy that for AC, CCC, and RAC, which are bounded between 0 and 1, we still obtain values well above 0.8 across all test windows, which suggests that the proposed approach also works well on the province level.\n\nFigure 7: Out-of-sample performance metrics for provinces in Africa (security-related incidents).\n\n<!-- image -->\n\nResults for other target variables are more mixed. All models struggled considerably with state-based violence in 2022. It is furthermore interesting that the cov model did better in comparison to the country-level in Africa. Still, the bm+gtw or at times the gtw model tended to perform best, alongside the bm model. However, the results are more mixed for different test windows, such that we achieve accuracy values of well above 0.9 for 2023, just around 0.8 for 2020, and values around 0.5 or lower for 2021. CCC and RAC values likewise remained on comparatively low levels but the bm+gtw model performed best in two out of four test windows. Turning to one-sided violence, the gtw model tended to do worst on its own, similar to security-related incidents as outcome. The bm+cov model performs surprisingly well on the province level and achieves almost always top performance looking at AC, CCC, and RAC. Still, the bm+gtw model performs well and at times reaches top performance. It should be kept in mind here that many variables in the covariate model do not have subannual variation which is why we should treat this performance with some caution. Of note, the performance varied considerably between test windows, showing its overall worst performance for 2020 with the highest RMSE and the lowest AC, CCC, and RAC values.\n\nLikewise noteworthy is that the RMSE and MAE values were on average lowest for the non-state violence out-of-sample predictions compared to the other target variables, shown in Figure 8. We observe for non-state violence as well that, with the exception\n\nFigure 8: Out-of-sample performance metrics for provinces in Africa (non-state violence).\n\n<!-- image -->\n\nof AC in 2022 and RMSE in 2020, Google Trends and Wikipedia data help improve the benchmark model in its predictive capability. While the bm+cov model oftentimes seems to perform well for this outcome variable, it should be taken with a grain of salt again for the same reasons mentioned earlier. Overall noteworthy is that if the bm+cov+gtw model achieves top performance, it never does so with a considerable advantage over other combined models ( bm+gtw or bm+cov ). There is thus evidence that Google Trends and Wikipedia help improve predictions on the province-month level as well, although it seems to be most pronounced with regards to security-related incidents. The evidence for state-based and one-sided violence showed considerable variation across all models for certain test windows. All models struggled the most predicting non-state violence. This is to be expected since non-state violence is the rarest of outcomes considered and only appears in about 1.7% of observations, compared to e.g. 18.2% regarding security-related incidents.\n\nFigure 9 provides further disaggregated evidence with the example of Borno state in Nigeria in 2023, showing line plots of individual model predictions and dots indicating actual values. The figure conveys two key pieces of information. First, while the gtw model is not particularly close to actual values with its predictions, its trend line comes close to the actual trend observed. Second, the bm+gtw model tends to be less conservative in its predictions compared to the benchmark model, similar to the evidence presented on the country-month level. Taken together, this is important information and encouraging. Google Trends and Wikipedia search data seem to be a valuable data source to add to our conflict forecasting\n\nBorno Prediction error of different models\n\nFigure 9: 2023 out-of-sample prediction for Borno state (Nigeria).\n\n<!-- image -->\n\nefforts since overly conservative predictions are a common criticism regarding the usefulness of forecasts. There is thus evidence that salience variables can contribute in our efforts to improve conflict predictions on both the country- and province-level.\n\n\n## 7 Discussion and conclusion\n\n\nConflict forecasting has received increased attention recently from scholars and practitioners alike. The need for early-warning systems has been voiced by heads of states as well as leaders of international organizations. This paper sought to make three contributions to this fast-growing field. First, it introduces data sources which can be sourced and updated in real time and are thus valuable for near-real time forecasting: Google Trends and Wikipedia data. One particular advantage of these data sources is that they have the potential to predict increased conflict intensity in hitherto peaceful settings, since they can pick up increasing tensions in a country or province which other data sources struggle to capture due to their more static nature. Second, it expands the set of target variables and goes beyond battlerelated deaths. I also predict casualties from violence against civilians and violence between armed groups, as well as a more general category of security-related incidents. This has two advantages: it avoids tuning models too narrowly to a particular target variable and it helps provide a more complete picture of the conflict and security situation in a country. Third, the paper presented models and results on the country- and province-month level. To the best of my knowledge, only ACLED CAST currently serves the country- and province-level while other publicly available early warning systems predict at the countryand PRIO-GRID\n\ncell-level. One advantage of the province- over the PRIO-GRID cell-level as subnational unit of analysis is that it is less prone to the problem of geoprecision in conflict event data (Cook and Weidmann, 2022). Provinces also suffer less from zero-inflation than grid cells. Lastly, reporting is oftentimes done using country and province names which provides sound theoretical and empirical grounds for the analyses in this paper.\n\nUsing Google Trends and Wikipedia page views to predict conflict intensity delivers promising results. The gtw models are about as good or better than traditionally used data in conflict forecasting efforts. This has been shown on the province- and country-level for Africa and globally. Especially noteworthy are the increases in precision and accuracy across the board when combined with the benchmark models containing information about past violence. Google Trends and Wikipedia data help make past violence predictors less conservative and oftentimes gets them closer to the actual values. Another main takeaway of the paper is that a pure focus on battle-related deaths ignores the effect other types of violence may have on the conflict and security situation in a country or province. Taking one-sided violence against civilians and violence between non-state actors into account is likewise of great importance and interest to both academics and practitioners. Recall that models struggled with different countries with regards to different types of violence, e.g. Mexico regarding non-state violence and Sudan regarding state-based violence. In addition, looking at the number of security-related incidents is also of particular interest to practitioners and policymakers, and the models tend to perform well on these incidents and better than on casualties from specific types of violence which are by definition less prevalent. Many incidents do not necessarily lead to casualties but can still lead to politically unstable environments. This is as much of interest as casualties assigned to named conflicts between recognized groups, the traditional focus of UCDP datasets. Lastly, the gtw models did likewise well on the subnational level of provinces in Africa. There are good theoretical and empirical reasons to focus on them. Provinces oftentimes feature prominently in reporting on traditional and more recent media, and using this fact for prediction while keeping a meaningful subnational unit of analysis is of scholarly and practical value.\n\nThe approach outlined above could also be applied to provinces outside Africa, for example in Southeast Asia, and to districts, i.e. second-level administrative regions, in areas of interest. These could be specific continents or particular regions such as the Sahel or others. However, the expectation would be that names of districts are mentioned much less frequently when ongoing events are discussed online or offline than names of provinces. Still, future research may seek to reproduce this paper's approach to lower-level administrative regions and evaluate performance on more spatially disaggregated levels. This may, however, come at the expense of having fewer relevant conflict observations due to a lack of\n\ngeoprecision in conflict event data (Cook and Weidmann, 2022). Furthermore, this paper exclusively uses searches for country and province names. There can be many reasons for why individuals search these names, but the results seem to indicate that these searches are frequently related to developments detrimental to political stability. Future research may seek to refine search terms by including security- or violence-related terms. However, this may also introduce the problem that search terms are not available as pages on Wikipedia. One option may thus be to have different search terms for Google Trends and for Wikipedia pages. The setup in this paper was explicitly chosen to be simple and transparent to indicate what is possible, but the terms and combinations can be constructed in much more complex ways to test whether predictive performance increases. The potential of using Google Trends and Wikipedia page views for predicting conflict intensity and various other social phenomena is far from exhausted.\n\n",
         "Conflict forecasting has seen two recent developments: a shift to predicting continuous variables and a debate about the value of structural and procedural variables. This paper contributes to these efforts and proposes the category of salience variables in the form of Google Trends and Wikipedia data. Internet searches can be precursors of conflict intensity as a result of e.g. an increase in protests, violent behavior, or public announcements. Data are readily and openly available, updated in real time, and provide global coverage which makes it ideal for near-real time forecasting. Prediction targets are the number of security-related incidents and battle-related, non-state, and civilian casualties. I demonstrate the value of salience variables using various out-of-sample windows and performance metrics on the country- and province-month level. I find evidence that salience variables have considerable predictive power, outperform other commonly used variables, and are thus a valuable addition to the conflict forecasting toolkit.",
         ""
        ],
        [
         "40",
         "40",
         "### INTRODUCTION\n\n\nUnderstanding tourist behaviour stands at the core of tourism research and guides managerial decisions in the tourism industry. Motivation – a construct known to predict behaviour – has been investigated extensively to improve the understanding of tourist behaviour (e.g., Crompton, 1979; De Guzman et al., 2006; McKercher et al., 2021; Vidon &amp; Rickly, 2018). One of the key theories linking travel motivations with travel behaviour is the travel career pattern. The travel career pattern was inspired by Maslow’s hierarchy of needs theory (Maslow, 1970) and originally conceptualised as a travel career ladder (Pearce &amp; Caltabiano, 1983). According to the travel career ladder, tourists – as their travel experience increases – move up a sequence of travel motivations, comprising of “relaxation needs, safety/security needs, relationship needs, self-esteem and development needs”, and “self-actualization/fulfilment needs” (Pearce &amp; Caltabiano, 1983, p. 18). Tourists ascend from the bottom-level (relaxation) via safety/security, relationships, self-esteem and development, to the highest-level motivation of self-actualization/fulfilment (Pearce &amp; Caltabiano, 1983, p. 19).\n\nThe travel career ladder was later refined and renamed the travel career pattern (Pearce &amp; Lee, 2005). The main difference is that tourists are not proposed to ascend a ladder from step to step, but rather to change within middle level motivations. These core motivations at the centre of the model (escape/relax, novelty and relationships) are equally important across all levels of travel experience. Tourists move from these core motivations outwards towards middle layer motivations. Two types of middle layer motivations exist. The first group (self-actualisation and self-enhancement) is postulated to be associated with low travel experience (Pearce, 2011; Pearce &amp; Lee, 2005; Wu et al., 2019). The second group (kinship, nature and self-development) is postulated to be associated with high travel experience. With increasing travel experience, tourists are assumed to move from the first group of self-actualisation and self-enhancement being important travel motivations, towards the second group of kinship, nature and self-development being important travel motivations. The outer layer motivations of isolation, stimulation, social status, autonomy and nostalgia are considered least important across all levels of travel experience (Pearce, 2011; Pearce &amp; Lee, 2005; Wu et al., 2019). In 2019, this was again revised to posit that increasing travel experience relates to increased self-development and nature, and kinship and self-enhancement decreasing with increased travel experience (Pearce, 2019a). Together, the travel career ladder and the travel career pattern are referred to in 584 research studies investigating tourist behaviour.\n\nContrary to the travel career pattern’s crucial feature of change with experience, habits are behaviours that increase in rigidity with repetition (Lally &amp; Gardner, 2013). Habits are learned behaviours acquired by repetition, consisting of a cue, a routine, and a reward (Lally &amp; Gardner, 2013). Over time, the reward for performing the routine in response to the cue may transfer from something external to the mere satisfaction of following this sequence (Lally &amp; Gardner, 2013). The key component of habit is automaticity – once learnt and solidified, the routine is performed outside of awareness, on presentation of the cue (Gardner et al., 2012; Lally &amp; Gardner, 2013). Habits can therefore form intentionally or unintentionally (Gardner et al., 2012), with the combination of cue, routine, and reward with repetition.\n\nDisruption of any of these three factors can lead to the breaking of a habit, a theory formally known as the habit discontinuity hypothesis (Bamberg, 2006;Verplanken et al., 2008; Wood et al., 2005). The first field experiment investigating the habit discontinuity hypothesis concluded that behaviour change interventions are more effective when targeting people who have recently moved house (Verplanken &amp; Roy, 2016). When controlling for past behaviour, habit strength, intentions, perceived control, biospheric values, personal norms and personal involvement, study participants who had recently moved home exhibited greater behaviour change across 25 environmentally sustainable behaviours than those who had not recently moved, illustrating the power of disruption to creating behaviour change (Verplanken &amp; Roy, 2016). This idea is mirrored by the life course paradigm, suggesting that changes in circumstances or life events can lead to changes in behaviour (Mochis, 2019).\n\nFig. 1 illustrates how the travel career pattern and habit theory lead to contradictory predictions about the mechanisms driving adult tourist behaviour. The core arguments of the travel career pattern are that (1) travel motivations drive travel behaviour and (2) travel motivations change with experience. The change in travel motivations must therefore lead to a change in travel behaviour. In contrast, habit theory predicts that much of human behaviour is driven by habit. If driven by habit, travel behaviour should not change much over time and with increased travel experience. The two theories, therefore, make opposing predictions of adult travel behaviour (see Fig. 1). The aim of this study is to assess empirically whether the travel motivations and behaviours of adult tourists align better with the predictions made by the travel career pattern or habit theory.\n\n<!-- image -->\n\nFig. 1. Comparison of theoretical predictions derived from the travel career pattern \nand habit theory and study hypotheses.\n\nWe test three hypotheses relating to the travel career pattern (hypotheses 1.1 – 1.3) and one hypothesis (H2) relating to habits as the primary explanatory variable:\n\nH1.1\tTravel motivations are associated with travel behaviour as an adult.\n\nH1.2\tHigher travel experience is associated with lower levels of kinship and self-enhancement.\n\nH1.3\tHigher travel experience is associated with higher levels of self-development and nature.\n\nH2\tPast travel behaviour is associated with travel behaviour as an adult.\n\nThis study makes a significant contribution to the theoretical understanding of tourist behaviour by putting to the test two competing theories, which both predict travel behaviour either directly (habit theory) or via evolving motivations (travel career pattern). The managerial value of our study lies in offering guidance to tourism marketing managers on how to best influence travel behaviour. If empirical evidence supports the validity of the travel career pattern, tourism marketers should target evolving travel motivations to influence travel behaviour. If, however, travel habits formed in childhood drive adult travel behaviour, tourism marketers should identify market segments with travel habits most compatible with their offer, then trigger and reinforce those habits.\n\n\n### LITERATURE REVIEW\n\n\nThe travel career ladder and the travel career pattern\n\nThe travel career ladder proposes that motivations for travel change with tourists’ accumulated travel experiences (Pearce, 2005). Considered one of the key motivation theories in tourism (Hsu &amp; Huang, 2008; McKercher &amp; Prideaux, 2020), the concept has changed from a linear, hierarchical framework to a broader, more dynamic pattern and adapted from tourism to the event context in recent years, with the most recent work by Pearce being published in 2019 (Getz, 2007; 2008; Pearce, 2019).\n\nThe travel career ladder, inspired by Maslow’s hierarchy of needs, postulates that tourists seek higher order travel needs as they gain travel experience (Pearce, 1988; Pearce &amp; Moscardo, 1985). The travel career ladder implies ordinal scaling in travel career levels, with travellers progressing through “relaxation, safety/security, relationship, self-esteem/development” and “self-actualisation or fulfilment needs” as forms of motivation (Pearce &amp; Caltabiano, 1983, p. 19; Pearce, 1988) as they gain more travel experience throughout their lives. The original conceptualisation of the travel career ladder – as illustrated in Fig. 2 – differentiates between self-directed and other-directed motivations (Pearce, 1988).\n\n<!-- image -->\n\nFig. 2. Travel career ladder (modified from Ryan, 1998).\n\nThe travel career ladder has been widely adopted by academic researchers and industry consultants (Ryan, 1998) because it represents an easy-to-understand conceptual framework to present travel motivations. It has also been applied in relation to other life progression concepts, such as the travel life cycle (Wu et al., 2019) and the family life cycle (Lin &amp; Lehto, 2006). However, despite its popularity, the travel career ladder has also attracted critique, leading to its refinement. Pearce (1993), who developed the travel career ladder, acknowledged its limited predictive validity, while Ryan (1998) discussed several methodological issues, including the fact that studies purporting to show linear progression were not longitudinal in design. Its hierarchical nature, implying progression from one level to the next, has also been heavily discussed (Kim et al., 1996).\n\nIn response to this, the travel career pattern was developed and dissociated from the hierarchical implications of a ladder. The travel career pattern reclassifies motivations into fourteen key types for leisure travel, listed by decreasing importance: “novelty, escape/relax, relationship strengthening, autonomy, seeking nature, self-development through involvement with hosts or the site, stimulation, self-enhancement, kinship (enjoying being with similar others), self-actualisation (getting a new life perspective), isolation, nostalgia, romance and social status (prestige of travelling)” (Pearce, 2005, p. 61; Pearce, 2019). Three of the most important common motivations (escape/relax, novelty, and relationships) form the backbone of the travel career pattern, supporting the notion that travel career patterns are anchored in core motivations applicable across most leisure travel experiences (Pearce &amp; Lee, 2005). The other types of motivations are rearranged in an outward radial pattern of decreasing importance to travellers (Pearce &amp; Lee, 2005), with motivations in the outer rings influencing motivation in the inner rings (see Fig. 3). Contrary to the linear progression implied by the travel career ladder, empirical studies using the travel career pattern identify higher-level motivations – such as self-actualisation – as the focus of lower-travel-experience groups (Pearce, 2019; Pearce &amp; Lee, 2005).\n\n<!-- image -->\n\nFig. 3. Travel career pattern (modified from Lee, 2004).\n\nIn 2019, the travel career pattern was further revised to suggest that self-development and nature increase in importance with increasing travel experience, and kinship and self-enhancement decrease in importance with increased travel experience (Pearce, 2019a).\n\n<!-- image -->\n\nFig 4. Updated travel career pattern (modified from Pearce, 2019).\n\nThe travel career pattern, as a development of the original ladder, is also not without critique. The initial reliance on the concept of psychological development and maturity as a ladder to be ascended was the impetus for the development into a pattern, replacing the concept of a hierarchical ladder with a multi-level approach. The construct of travel experience is also ambiguously defined, which often results in the use of proxies to empirically measure, including age, life stage and self-reported experience measures (Lin &amp; Lehto, 2006; Pearce, 2005; Wu et al., 2019). Without clear agreement on how travel experience is defined, operationalising the concept of a travel career via proxies is precarious. For example, the assumption that age is an appropriate proxy for travel experience presupposes a level of consistent travel over the course of a lifetime. This may not be an accurate assumption given the democratisation of travel in recent decades, which has made it more accessible to younger people. In an attempt to resolve an ambiguous definition and varying operationalising of travel experience, three indicators have been proposed to rectify this problem (Filep &amp; Greenacre, 2007): “(1) The number of times a person has travelled (overseas or domestically); (2) the number of destinations a person has travelled to (overseas or domestically); and (3) the amount of time a person has spent travelling (overseas or domestically)” (Filep &amp; Greenacre, 2007, p. 35). While this proposal may assist in a more unified approach to measuring travel experience, it remains unclear whether tourists are able to accurately recall the required travel frequencies and has not been consistently adopted across studies.\n\nPast empirical research into the travel career ladder and the travel career pattern is based on one-off cross-sectional data sets, although it is generally understood that longitudinal studies are required to prove or disprove the assumptions underlying both the travel career ladder and the travel career pattern (Wu et al., 2019). One-off cross-sectional snapshots fail to provide insights into the aspect of change, which is so integral to both concepts (Oktadiana et al. 2017; Paris &amp; Teye, 2010; Song &amp; Bae, 2018).\n\nHabit theory\n\nHabit is a strong predictor of human behaviour (Wood et al., 2002) but has been largely ignored in tourism. A habit is defined as an automatic behaviour acquired by repetition and prompted by a cue (Lally &amp; Gardner, 2013). With as much as 43% of daily behaviour driven by habit (Wood et al., 2002), it is recognised in most social science disciplines as a critically important driver of behaviour (Habeat Consortium, 2017; Kjønniksen et al., 2008; Simpkins et al., 2020). The role of habit may have been neglected in the field of tourism because its integral features (repetition and stable cues) seem incompatible with tourism, which is inherently performed irregularly and in novel contexts. Despite this, habit is an important component to consider in tourist behaviour, due to its resistance to change. When trying to change habits, most existing behaviour change techniques are likely to fail, because the behaviour is performed without awareness and typical behaviour change techniques rely on attention (Bargh, 1994; Orbell &amp; Verplanken, 2010). In prior tourism research investigating habit, one study has preliminarily investigated the repetition of vacation types from childhood to adulthood (Lazar &amp; Gabruè, 2017), another linked the use of smart phones while on vacation to habit (Wang et al., 2014), and transformative tourist experiences are theorised to have the ability to create habits at home (Pung et al., 2020). Despite these studies into facets of habit within tourism, it remains unclear whether adult travel behaviours are repeated from childhood and if they are - which behaviours and to what degree. The effect of habit in the hospitality industry and hedonic space has also been investigated, but prior work does not focus on the transfer of behaviour from childhood to adulthood. Instead, these studies operationalise habit as habituation (the reduction of a response resulting from repeated exposure), rather than a learnt automatic response to a specific cue (Chugani &amp; Irwin, 2020; Choi et al., 2021). Another study has investigated the consistency with which participants repeated holidays in childhood and adulthood, which found weak associations of adults repeating childhood-type holidays (Lazar &amp; Gabruč, 2017). The automatic component of habit is also associated with green behaviours of adult tourists (MacInnes et al., 2022). These studies point to some role of habit in adult tourist behaviour, but the current literature fails to comprehensively identify or characterise childhood travel habits as drivers of adult travel behaviour, and to determine which specific behaviours may be most driven by childhood travel habits. Therefore, in the pursuit of understanding and influencing tourist behaviour, it is vital to investigate the existence of habits formed in childhood as a driver of tourist behaviour.\n\nIn the current study we propose that tourists learn travel behaviour in childhood and create travel habits through repetition across one’s life. Childhood is a prime time for habit formation because of the neuroplasticity of children’s still-developing brains (Willis, 2019). For this reason, new connections develop much easier than in adulthood. In adulthood, brains are more rigid and have pruned back connections (Willis, 2019). Additionally, children’s brains are “blank slates”. As a result, new habits are easy to form. This process does not require breaking or modifying existing habits, processes which are difficult in adulthood (Lally et al., 2011). While there is evidence of childhood experiences being formative in many areas of life and extending into adulthood – including physical activity, food choices, work ethic and spending habits (Habeat Consortium, 2017; Kjønniksen et al., 2008; Otto, 2013; Simpkins et al., 2020) – we do not know whether childhood travel experiences are also formative in determining adult travel behaviour. If childhood travel behaviours become habitual, repetition leads them to become automatic, explaining repetition throughout a lifetime with very little cognitive effort. Such lifelong travel habits would be difficult to change without appropriate infrastructural disruption that interrupts the cue triggering the habit (Habeat Consortium, 2017; Jensen &amp; Larsen, 2021; Kjønniksen et al., 2008; Wood, Tam &amp; Witt, 2005). In the tourism context, this could be a reduction in plate size at the breakfast buffet (Kallbekken &amp; Sælen, 2013), reducing the ability to automatically overfill one’s plate. Infrastructural disruptions do not reduce consumer choice. Instead, they trigger an alternative automatic behaviour or force people to make conscious choices. Understanding the impact of childhood travel experiences therefore may have profound implications for understanding and influencing adult travel behaviour.\n\n\n### METHOD\n\n\nWe collected survey data from 300 members of the crowdsourcing platform Prolific Academic. Prolific Academic maintains a panel of survey respondents for academic research. The nature of this platform could bias the sample, but comparative studies conclude that data quality is superior to other platforms (Peer et al., 2017; 2021). Prolific Academic respondents are more naïve to scientific design and more honest than the popular alternative MTurk (Peer et al., 2017; 2021). We recruited half of the respondents from the UK and half from Australia to ensure geographical diversity while avoiding potential bias resulting from surveying in multiple languages. Because a representative sample of the travelling population is not currently established and because habit and motivation are not known to be linked with socio-demographics, we do not implement quota sampling, but ensure that half of the respondents are male and half female (Table 1). Because we investigate travel behaviour over time for each study participant, we adopt a survey design to elicit people’s childhood and adult travel experiences, motivations, and behaviours. This means that we capture self-reported travel details within participants across the two time points examined (in childhood and adulthood). While some degree of error is unavoidable with self-report measures, particularly for childhood, the ability for reliable recall past the age of six is considered acceptable (Newcombe et al., 2000). Absolute values are difficult to remember from childhood, but recall is sound for general memories (Henry et al., 1994).\n\nTable 1. Demographic details of sample\n\n| Country of origin        | Gender                             | Age                                                          |\n|--------------------------|------------------------------------|--------------------------------------------------------------|\n| UK (50%) Australia (50%) | Male (51%) Female (48%) Other (1%) | Mean: 33  Standard deviation: 11.30  Minimum: 18 Maximum: 74 |\n\nThis research complies with all relevant ethical regulations. Each stage of data collection was approved by the university’s human ethics committee of the corresponding author (approval number 2020003021) and complies with the relevant National Statement on Ethical Conduct in Human Research. All study participants have given their written consent to participate in the study. The survey took, on average, 11 minutes to complete. Participants who answered all questions received £1.78 to compensate them for their efforts. We set the amount to be in the average range recommended by Prolific Academic.\n\nWe measured travel motivations using 13 of the 14 categories from the travel career pattern. The original item battery containing 72 motivations (Pearce, 2011; Pearce &amp; Lee, 2005) was too long to ensure high data quality in view of fatigue effects (Dolnicar, 2013). We excluded the travel motivation romance because it is unlikely to drive travel behaviours as a child. For all other motivation groups, we selected the highest loading individual item and included it in brackets to clarify the listed travel motivation, asking participants to answer the degree to which each motivation prompted their travel as children and as adults. This is a common approach taken by many researchers using the travel career patterns in their empirical investigations (Filep &amp; Greenacre, 2007; Song &amp; Bae, 2018), including Pearce, who developed the original 72 motive test-battery (Oktadiana et al., 2017).\n\nThe number of domestic and international holidays taken as a child under 12 years of age (childhood) and as an adult served as empirical measure of travel frequency. Travel frequency and respondent age combined lead to the empirical measure of travel experience as conceptualised in the travel career pattern (Pearce, 2005; 2011). Because of concerns that respondents may not be able to accurately report the number of trips taken, we asked how confident they felt responding to the travel frequency questions. Participants rated their confidence on the number of holidays they had been on for childhood and adulthood on a 100-point visual analogue scale, on which the endpoints are verbally described as “not at all confident” (0) and “completely confident” (100).\n\nStudy participants reported specific features of their typical holidays as a child (until the age of 12) and as an adult (from age 12 onwards). We primed them to imagine their typical childhood holiday and asked about the typical travel motivation, travel frequency, confidence in providing an accurate frequency, and their typical travel behaviours. Travel behaviours included how often they went on holiday annually, holiday duration, distance from home, accommodation, transport, food, motivation, and activities. Upon completion of the childhood holiday questions, we primed respondents to imagine their typical adult holidays, and asked them to answer the same questions again. Respondents recorded their answers on a 100-point visual analogue scale on which the endpoints were verbally described as “never” (0) and “always” (100).\n\nThe key dependent variable in this study is travel behaviour from age 12 onwards (see Fig. 1). We use a range of different travel behaviours as empirical measures of that dependent variable: proportion of domestic holidays, proportion of international holidays, duration of holidays, annual frequency of holidays, holiday accommodation (friends/family, backpacker’s/hostel, camping site, RV/motor home, motel,  mid-range hotel, bed and breakfast, resort, luxury hotel, holiday home, private home stay), transport to destination (bus, train, plane, car, motorbike, RV/motorhome), transport navigating destination (walking, cycling, bus, train, plane, car, motorbike, RV/motorhome), food choices (restaurants, cafes, bought groceries, street food, accommodation eatery, fast food, food preference), and activities (spending time with friends/family, historical sites, being in nature, trying food and drink, adventure activities, rest and relaxation, cultural experiences, shopping, meeting new people, education). These factors represent typical features of adult and child holidays, enabling comparison.\n\nThe key explanatory variables for the travel career pattern are travel motivations (see Fig. 1). We measure the following motivations: escape/relax, novelty, relationships, self-actualisation, self-enhancement, isolation, stimulation, social status, autonomy, nostalgia, kinship, nature and self-development. For the hypotheses relating to the travel career pattern (H1.1), we calculate 11 independent multiple regression analyses using, in each of those regressions, all 13 travel motivations. We report how many and which travel motivations are significantly associated with each of the travel behaviours under study.\n\nTo derive the travel experience measures as conceptualised in the travel career pattern, we combine the number of domestic holidays, number of international holidays and age. For adult travel experience we use the number of domestic holidays a person has undertaken in their life, the number of international holidays a person has undertaken in their life and their age. We combine the number of domestic and international holidays and age. We follow the same procedure for the travel experience as a child, relying on respondents’ reports of the total number of domestic and international trips they had undertaken during their childhood years. For lifetime travel experience we combine the number of trips as a child and the number of trips as an adult. By observing respondents’ ratings of confidence for these measures, we see that the number of domestic holidays for childhood (M = 65.86, SD = 27.16) and adulthood (M = 65.41, SD = 28.42) could not be confidently estimated. International holidays had higher ratings of confidence estimation for both childhood (M = 80.79, SD = 23.90) and adulthood (M = 84.72, SD = 23.66).\n\nThe key explanatory variables for hypotheses relating to the travel career pattern are the adult travel motivations. For H1.1 this entailed entering all motivations into a multivariate regression model, with adult travel behaviours as the outcome variables. For H1.2 and H1.3, we enter the increase in travel experience as conceptualised by Pearce into a bivariate correlation with the distance calculated between childhood and adulthood travel motives.\n\nThe key explanatory variables for the habit theory hypothesis (H2) are holiday behaviours as a child. We run bivariate correlations for each pair of childhood and adult behaviours for all ten behaviours available from the survey.\n\n\n### RESULTS\n\n\nTravel career pattern related hypotheses\n\nHypothesis H1.1 posits that travel motivations are associated with travel behaviour as an adult. This was supported by the regression analyses performed for travel activities in adulthood, where each activity significantly predicts at least one motivation, with the exception of nostalgia (see Table 2). While all motivations are associated with at least one activity, there is a range of how many activities each motivation predicts. Autonomy, for example, predicted only one activity: “trying new food and drink”. Relationships, by contrast, predicted eight of the ten possible activities: “spending time with friends and family”, “visiting historical sites”, “being in nature”, “trying food and drink”, “adventure activities”, “shopping”, “rest and relaxation” and “cultural experiences”.\n\nTable 2. Regression coefficients per significant predictor and dependent variable\n\n|   Motive           | Behaviour                             | Behaviour                 | Behaviour       | Behaviour             | Behaviour            | Behaviour    | Behaviour          | Behaviour   | Behaviour           | Behaviour            |\n|--------------------|---------------------------------------|---------------------------|-----------------|-----------------------|----------------------|--------------|--------------------|-------------|---------------------|----------------------|\n| Motive             | Spending time with friends and family | Visiting historical sites | Being in nature | Trying food and drink | Adventure activities | Shopping     | Meeting new people | Education   | Rest and relaxation | Cultural experiences |\n| Escape/relax       | β = .138**                            | -                         | -               | β = .204**            | -                    | β = .151*    | -                  | -           | β = .563**          | -                    |\n| Novelty            | -                                     | -                         | -               | β = .174**            | β = .243**           | -            | -                  | -           | -                   | -                    |\n| Relationships      | β = .675**                            | β = .138*                 | β = .095*       | β = .143**            | β = .136*            | β = .119*    | -                  | -           | β = .123*           | β = .156**           |\n| Kinship            | β = .141**                            | -                         | -               | -                     | -                    | -            | -                  | -           | -                   | -                    |\n| Nature             | -                                     | β = .185**                | β = .696**      | -                     | β = .158*            | -            | -                  | -           | -                   | β = .169**           |\n| Self-development   | -                                     | β = .208*                 | β = .134*       | -                     | -                    | -            | β = .457**         | β = .188*   | -                   | β = .263**           |\n| Self-actualisation | -                                     | -                         | -               | -                     | -                    | -            | -                  | β = .137*   | -                   | β = .162*            |\n| Self-enhance       | β = -.123*                            | -                         | -               | -                     | -                    | -            | -                  | β = .231**  | -                   | -                    |\n| Isolation          | -                                     | -                         | -               | -                     | -                    | -            | -                  | -           | -                   | -                    |\n| Stimulation        | -                                     | -                         | -               | -                     | β = .431**           | β = .-.185** | -                  | -           | β = -.168**         | -                    |\n| Social status      | -                                     | -                         | -               | -                     | -                    | β = .329**   | β = .143*          | -           | -                   | -                    |\n| Nostalgia          | -                                     | -                         | -               | -                     | -                    | -            | -                  | -           | -                   | -                    |\n| Autonomy           | -                                     | -                         | -               | β = .153**            | -                    | -            | -                  | -           | -                   | -                    |\n\nCore motives, middle layer motivations external, middle layer motivations internal, outer layer motivations.\n\nNote. * p &lt; .05, ** p &lt; .01\n\nHypothesis H1.2 posits that travel experience is associated with lower levels of self-enhancement and kinship. Table 1 contains information about travel motivations as a child and adult and travel experience as a child and adult. The travel career pattern postulates that, as travel experience increases, the middle layer motivations self-enhancement and kinship become less important. To test this, we calculated the difference in travel motivation from childhood to adulthood, the difference in travel experience from childhood to adulthood and correlated these values. We expect, in line with the travel career pattern, to see significant negative correlation coefficients, as travel experiences increases – these motivations become less important. As shown in Table 2, this is not the case: both correlations are non-significant. These findings therefore do not support the predictions made by the travel career pattern.\n\nHypothesis H1.3 posits that travel experience is associated with higher levels of nature and self-development. The travel career pattern postulates that, as travel experience increases, the middle layer motivations nature and self-development become more important. To test this, we correlated the change in each motivation from child to adult and the chance in travel experience from child to adult. We expect, in line with the travel career pattern, to see significant positive correlation coefficients, showing that – as travel experience increases – so do these travel motives. As shown in Table 3, this is the case for one of the three motives: nature. The correlation for self-development is non-significant. This finding does not support half of the relevant predictions made by the travel career pattern.\n\nTable 3. Pearson’s bivariate correlations between increase in travel experience and difference in travel motivations.\n\n| Motivation       |   Average childhood motivation value (Cm) |   Average adulthood motivation value (Am) |   Average difference (Dm = Am-Cm) | Average childhood travel experience (Ce)   | Average adulthood travel experience (Ae)   | Average difference (De = Ae-Ce)   | Correlation with travel experience (Dm and De)   |\n|------------------|-------------------------------------------|-------------------------------------------|-----------------------------------|--------------------------------------------|--------------------------------------------|-----------------------------------|--------------------------------------------------|\n| Self-enhance     |                                     10.58 |                                     22.67 |                             12.09 | -                                          | -                                          | -                                 | .07                                              |\n| Kinship          |                                     25.76 |                                     31.6  |                              5.84 | 22.57                                      | 68.35                                      | 55.57                             | .02                                              |\n| Nature           |                                     36.02 |                                     49.11 |                             13.09 | 22.57                                      | 68.35                                      | 55.57                             | .17**                                            |\n| Self-development |                                     11.93 |                                     25.6  |                             13.67 | 22.57                                      | 68.35                                      | 55.57                             | -.03                                             |\n\nDecreasing motives, increasing motives.\n\nNote. * p &lt; .05, ** p &lt; .01\n\nHabit theory related hypotheses\n\nHypothesis H2 posits that childhood travel behaviour is positively associated with travel behaviour in adulthood. Table 4 shows, the average engagement as a child and as an adult. To test H2 we calculated correlations between the childhood and the adulthood values for each respondent. In line with habit theory, we expect a substantial number of significantly positive correlations. Table 4 shows that this is indeed the case. With the exception of traveling to the destination in a recreational vehicle, the (non)occurrence of every single travel behaviour measured on a holiday as an adult is significantly positively associated with the (non)occurrence of this same travel behaviour as a child. We find that motives, food choices and activities are particularly positively associated between childhood and adulthood, suggesting that adults repeat the motives, food choices and activities they experienced during childhood travel. These findings suggest that childhood travel behaviour cannot be excluded as a predictor of adulthood travel behaviour.\n\nTable 4. Pearson’s bivariate correlations between childhood and adulthood travel experiences\n\n| Variable                             | Childhood mean   | Adulthood mean   | Adulthood mean   | Correlation   | Correlation   |\n|--------------------------------------|------------------|------------------|------------------|---------------|---------------|\n| Proportion of domestic holidays      | 67.45            | 52.66            | 52.66            | .26**         | .26**         |\n| Proportion of international holidays | 31.83            | 49.68            | 49.68            | .35**         | .35**         |\n| Duration                             | 10.05            | 11.02            | 11.02            | .11*          | .11*          |\n| Frequency                            | 4.28             | 4.56             | 4.56             | .25**         | .25**         |\n| Motivation                           |                  |                  |                  |               |               |\n| Escape/relax                         | 61.56            | 70.65            | 70.65            | .38**         | .38**         |\n| Novelty                              | 53.66            | 62.39            | 62.39            | .45**         | .45**         |\n| Relationships                        | 63.60            | 58.72            | 58.72            | .39**         | .39**         |\n| Kinship                              | 25.76            | 31.60            | 31.60            | .55**         | .55**         |\n| Nature                               | 36.02            | 49.11            | 49.11            | .53**         | .53**         |\n| Self-development                     | 11.93            | 25.60            | 25.60            | .37**         | .37**         |\n| Self-actualisation                   | 13.82            | 35.85            | 35.85            | .37**         | .37**         |\n| Self-enhance                         | 10.58            | 22.67            | 22.67            | .51**         | .51**         |\n| Isolation                            | 19.10            | 34.63            | 34.63            | .46**         | .46**         |\n| Stimulation                          | 17.30            | 34.00            | 34.00            | .44**         | .44**         |\n| Social status                        | 8.22             | 15.20            | 15.20            | .55**         | .55**         |\n| Nostalgia                            | 24.21            | 30.93            | 30.93            | .53**         | .53**         |\n| Autonomy                             | 14.09            | 38.34            | 38.34            | .36**         | .36**         |\n| Accommodation                        |                  |                  |                  |               |               |\n| Friends/family                       | 44.92            | 40.99            | 40.99            | .31**         | .31**         |\n| Backpacker’s/hostel                  | 2.00             | 12.78            | 12.78            | .19**         | .19**         |\n| Camping site                         | 21.34            | 14.55            | 14.55            | .33**         | .33**         |\n| Recreational vehicle/Motor home      | 8.76             | 4.22             | 4.22             | .27**         | .27**         |\n| Motel                                | 14.94            | 13.75            | 13.75            | .51**         | .51**         |\n| Mid-range hotel                      | 29.38            | 40.30            | 40.30            | .40**         | .40**         |\n| Bed and breakfast                    | 14.71            | 19.00            | 19.00            | .42**         | .42**         |\n| Resort                               | 24.23            | 22.87            | 22.87            | .45**         | .45**         |\n| Luxury hotel                         | 12.57            | 21.13            | 21.13            | .42**         | .42**         |\n| Holiday home                         | 20.67            | 15.20            | 15.20            | .48**         | .48**         |\n| Private home stay                    | 9.22             | 28.98            | 28.98            | .25**         | .25**         |\n| Transport to destination             |                  |                  |                  |               |               |\n| Bus                                  | 9.29             | 14.90            | 14.90            | .43**         | .43**         |\n| Train                                | 10.92            | 23.03            | 23.03            | .36**         | .36**         |\n| Plane                                | 37.98            | 58.23            | 58.23            | .39**         | .39**         |\n| Car                                  | 70.17            | 52.59            | 52.59            | .33**         | .33**         |\n| Motorbike                            | 0.73             | 1.48             | 1.48             | .15**         | .15**         |\n| Recreational vehicle/motorhome       | 2.93             | 2.69             | 2.69             | .27**         | .27**         |\n| Transport navigating destination     |                  |                  |                  |               |               |\n| Walking                              | 57.65            | 63.94            | 63.94            | .48**         | .48**         |\n| Cycling                              | 5.28             | 8.59             | 8.59             | .38**         | .38**         |\n| Bus                                  | 20.23            | 30.92            | 30.92            | .57**         | .57**         |\n| Train                                | 14.86            | 30.69            | 30.69            | .45**         | .45**         |\n| Plane                                | 7.66             | 15.37            | 15.37            | .39**         | .39**         |\n| Car                                  | 68.63            | 56.72            | 56.72            | .32**         | .32**         |\n| Motorbike                            | 1.84             | 3.38             | 3.38             | .43**         | .43**         |\n| RV/motorhome                         | 1.93             | 2.63             | 2.63             | .08           | .08           |\n| Food choices                         |                  |                  |                  |               |               |\n| Restaurants                          | 41.66            | 52.95            | 52.95            | .49**         | .49**         |\n| Cafes                                | 29.88            | 43.51            | 43.51            | .55**         | .55**         |\n| Bought groceries                     | 53.25            | 46.50            | 46.50            | .30**         | .30**         |\n| Street food                          | 21.57            | 36.77            | 36.77            | .58**         | .58**         |\n| Accommodation eatery                 | 31.43            | 33.69            | 33.69            | .39**         | .39**         |\n| Fast food                            | 33.20            | 39.35            | 39.35            | .60**         | .60**         |\n| Adventurous eater                    | 41.01            | 65.80            | 65.80            | .52**         | .52**         |\n| Activities                           |                  |                  |                  |               |               |\n| Spending time with friends/family    | 72.60            | 62.24            | 62.24            | .37**         | .37**         |\n| Historical sites                     | 38.15            | 48.70            | 48.70            | .49**         | .49**         |\n| Being in nature                      | 43.15            | 50.06            | 50.06            | .53**         | .53**         |\n| Trying food and drink                | 33.51            | 52.82            | 52.82            | .47**         | .47**         |\n| Adventure activities                 | 37.97            | 37.64            | 37.64            | .45**         | .45**         |\n| Rest and relaxation                  | 58.83            | 67.96            | 67.96            | .43**         | .43**         |\n| Cultural experiences                 | 34.40            | 51.66            | 51.66            | .40**         | .40**         |\n| Shopping                             | 28.95            | 35.53            | 35.53            | .65**         | .65**         |\n| Meeting new people                   | 19.75            | 26.03            | 26.03            | .53**         | .53**         |\n| Education                            | 18.62            | 25.49            | 25.49            | .49**         | .49**         |\n\nNote. * p &lt; .05, ** p &lt; .01\n\n\n### CONCLUSION\n\n\nThe current study introduces an alternative theory to explain adult travel behaviour; that of travel habits formed in childhood repeating throughout adult life. This theory extends the currently dominant view that tourist motivations change during a person’s travel lifetime and that these ever-changing motivations lead to changes in travel behaviour. Recognising habits as drivers of adult travel behaviour represents a paradigm shift in our understanding of adult travel behaviour. The present study investigates the comparative predictive validity of these two opposing conceptualisations using a within subject design across two time periods recalled during the survey study.\n\nResults indicate that motivations are indeed predictive of adult travel behaviour. Thirteen of Pearce’s travel motivations – all except nostalgia – significantly predict travel activities. Most motives do not, however, change in accordance with travel experience from childhood to adulthood. Only the motive of nature changes in dependence of travel experience. These findings have important implications. According to the travel career pattern, travel experience changes travel motives, which, in turn, change future travel experience. The present empirical results do not supply evidence of this mechanism occurring. While motivations are associated with behaviour, they do not change as predicted with experience, thus not explaining changes in future travel behaviour. Further, by re-examining the travel experience measure of the travel career pattern, findings show that respondents are not confident in reporting the number of domestic holidays they have taken. This uncertainty calls into doubt conclusions initially drawn by the travel career pattern because the measure of travel experience is integral to the predictions of the theory.\n\nThe alternative theory of travel habits formed in childhood being associated with adult travel behaviour was supported by the present empirical investigation. All childhood travel behaviours measured in this study were significantly positively associated with adult travel behaviours, except one single behaviour: travelling to the destination in a recreational vehicle/motorhome. This finding aligns with previous conclusions that behaviours can be formative in childhood and create habits extending long into adult life (Habeat Consortium, 2017; Kjønniksen et al., 2008; Simpkins et al., 2020). The present study adds to this body of literature by including travel behaviours in childhood as those which can extend into adulthood.\n\nThese findings have major theoretical and practical implications. Theoretically, results from this study suggest that the role of motivations as drivers of adult travel behaviour may be overestimated, while the role of travel habits formed during childhood travel is underestimated. This represents a fundamental change in our understanding of drivers of adult travel behaviour, which translates into revised practical recommendations for the tourism industry. When industry attempts to influence travel behaviour, targeting ever-evolving travel motivations may not be the most promising approach. Rather, the importance of habit means that tourism industry could benefit from understanding adult travellers’ “travel roots” and designing marketing activities accordingly.\n\n",
         "This study investigates a popular theory of tourist motivation – the travel career pattern – and contrasts it against an alternative explanation – that childhood travel habits repeat throughout life. The key distinction is that the travel career pattern predicts change, whereas habit predicts repetition. This study tests competing hypotheses using self-reported childhood and adulthood travel experiences, behaviours and motivations. Results point to childhood travel behaviour driving adult travel behaviour, supporting the key role of habit as a driver of travel behaviour. These findings represent a paradigm shift in our theoretical understanding of determinants of travel behaviour, which implies that habits could be used as leverage points for behavioural change in tourism.",
         ""
        ],
        [
         "41",
         "41",
         "## 1. INTRODUCTION\n\n\n\n## 1.1 The flood risk management (FRM) approach in England\n\n\nThe major UK summer floods in 2007 led to over 46,000 homes and up to 6,000 businesses being flooded, and around £3 billion in insurance claims (Marsh and Hannaford, 2007; Environment Agency, 2010). The scale of the flood impacts led to the commissioning of the Pitt Review that aimed to learn lessons from the 2007 flood events and make a series of recommendations to improve flood risk management approaches. The eventual Pitt recommendations, amongst many other things, called for greater national coordination of flood risk management via a 'unifying Act' alongside enhanced local responsibilities to manage flood risk (Pitt, 2008). However, and as summarised by Benson et al. (2018), the subsequent Flood and Water Management Act 2010 (HM Government, 2010; hereafter F&amp;WMA2010) failed to deliver on the unifying Act recommendation and, rather, addressed only the 'immediate legislative requirements' (Defra, 2012).\n\nThe resultant, and still current, overarching approach to flood risk management (FRM) in England 1  that followed the F&amp;WMA2010 is determined by a suite of overlapping legislation, strategies, plans and guidance that each cover different spatial areas, timeframes and sources of flooding (i.e. river, coastal, surface water and groundwater). This is further complicated by legislation and policies linked to climate change adaptation, land-use planning and environmental protection that cover elements of FRM from different perspectives. Table 1 provides a summary of some of the key elements of England's FRM framework.\n\nAlongside the F&amp;WMA2010, England also has a separate framework for addressing climate change risks. The Climate Change Act 2008 (HM Government, 2008; hereafter CCA2008) set out a process of assessing climate change risks every 5 years (known as the Climate Change Risk Assessment, or CCRA) and of responding to the CCRA risk within a National Adaptation Programme (NAP). Flood risks are a major part of the CCRA and, therefore, should be addressed in NAP with adequate plans to manage those risks. The CCA2008 also set up a statutory, independent body - the Committee on Climate Change - to report every 2 years on progress towards adequate risk management.\n\nWithin this legislation, the most central element of the FRM framework is the National Flood and Coastal Erosion Risk Management (FCERM) Strategy (Environment Agency, 2020), which was updated and significantly improved (CCC, 2021) in 2020 as compared to the original 2011 version. The F&amp;WMA2010 dictates that the Environment Agency must provide a 'strategic overview' for all risk management authorities (RMAs) which includes Lead Local Flood Authorities (LLFAs), district councils, relevant highways agencies, internal drainage boards and water companies. However, the Agency, as outlined above, does not directly manage the activities of those RMAs. This is particularly relevant as the Agency has taken an integrated FRM (e.g. van der Most and Marchand, 2017) approach to the strategy, which relies on all stakeholders acting in line with the overarching strategy. Therefore, as good as the national strategy may be, it still cannot address the failure of the F&amp;WMA2010 to unify the FRM approaches of different RMAs who can choose to act on different spatiotemporal scales and in different ways with differing levels of commitment.\n\nWhilst such a 'patchwork' framework to FRM is not necessarily a poor approach, it has been highlighted by England's statutory climate change adaptation advisor - the Committee on Climate Change (CCC) - that some elements of FRM have no clear strategy because of this structure (CCC, 2019). With many different actors involved, this particularly applies to surface water flooding (SWF). The analysis of the potential 'policy gap' (i.e. the difference between risk magnitude and the magnitude of risk that could be managed by the planned SWF interventions) is, therefore, the focus of this paper.\n\n\n## 1.2 Managing surface water flood (SWF) risk\n\n\nThis SWF issue arises because of the framing of the F&amp;WMA2010, which gives the Environment Agency responsibility for developing a national Flood and Coastal Erosion Risk Management (FCERM) Strategy. However, as per the Water Resources Act (1991), the Environment Agency only has authority to manage flood risk from main rivers and the sea whilst the F&amp;WMA2010 gives responsibility for developing strategies for SWF risk management to England's 152 LLFAs (Figure 1). The LLFAs were provided with guidance for developing their local flood risk management strategies (LGA, 2011) and tools to assess future changes in future flood risk (Environment Agency, 2014), and given a requirement within the F&amp;WMA2010 that their strategies should be consistent with the National FCERM Strategy. However, this approach means that SWF risks have been assessed and addressed in different ways across England's LLFAs.\n\nAgain, this does not necessarily mean that there is an inadequate approach to SWF risk management. It has meant that, to date, the CCC has not fully assessed England's strategy for SWF risk management, which the CCC has a statutory responsibility to do, because there is no clear, overarching articulation of the approach or a complete compilation of the LLFA actions. In other words, it is not straightforward to define and assess adaptation planning and progress that is spread across 152 LLFA strategies (CCC, 2021). The CCC have referred to Maiden et al. (2017) who identified that only 55 of the 90 LFRMSs available at that time included a costbenefit analysis of proposed actions and that 35 of the 90 LFRMSs did not specify when or how actions would take place, both factors required by the F&amp;WMA2010 (CCC, 2017). Furthermore, and because of the delegation of responsibility for SWF risk management to the LLFAs, the CCC raised the criticism that the impact of climate change on SWF risk was not properly addressed in the National Adaptation Programme, as it should be under the CCA2008 (CCC, 2019). In response to this CCC assessment, the government did not agree that climate change was not considered in relation to SWF but the response did not point to any analysis or evidence that such considerations existed in the LLFA strategies (HM Government, 2019). Instead, the government referred to the Surface Water Management Action Plan (Defra, 2018) as addressing this, which the CCC had already assessed as containing no actions that directly aim to reduce the risk of SWF.\n\nIn addition to the Maiden et al. (2017) assessment of LFRMSs, Benson et al. (2018) have also assessed a sub-set (n=43) of the strategy documents for the 81 LLFAs that had published an LFRMS at the time of their research. Their analysis focused on the legal requirements for the strategies as dictated by the F&amp;WMA2010 and on implementation criteria outlined by the Local Government Association (LGA, 2011). The authors developed 16 evaluation criteria to test alignment with the F&amp;WMA2010 and LGA guidance and these were assessed on a 3-point 'scorecard' scale based on Fritsch and Kamkhaji (2016). The key result from the analysis was that the 43 LLFAs were generally producing strategies that met the minimum legal requirements. More than 75% of the strategies assessed fully met one or more of the following 5 criteria: a summary was included; RMAs were specified; objectives for managing flood risk were included; local flood risk was assessed; and/or a Preliminary Flood Risk Assessment was specified. However, more than 50% of the strategies assessed failed to fully meet one or more of these 6 criteria: costs and benefits of the FRM measures proposed were presented; the review process of the strategy was outlined; alignment with the Water Framework Directive is specified; contribution to the Habitats Directive is specified; the public consultation process was specified in the strategy; and/or consistency with the National FCERM Strategy is specified.\n\nHowever, neither Maiden et al. (2017) or Benson et al. (2018) directly assess the elements of climate change risk in the SWF risk management assessments or actions in the LFRMSs. Therefore, this is a key aim of the current study as this remains a gap in the literature and is an important risk.\n\n\n## 1.3 Climate change and SWF\n\n\nIn addition to the SWF risk management issues relating to FRM processes described above, we must also consider the scale of the SWF risk and how this is likely to increase as a result of climate changes in the UK. For this, we can look to the research underpinning the UK's 2022 Climate Change Risk Assessment (Sayers et al., 2020; Russell and Sayers, 2022) which shows that under assumptions of high population growth and a continuation of current levels of adaptation the, annual cost of expected damages from SWF would approximately double by the 2080s. This is, therefore, a major physical risk as well as a potential risk assessment failure point. It should be further noted that projections of the high-intensity, convective rainfall that tends to drive SWF are challenging to produce (e.g. Kendon et al., 2021) and, therefore, the uncertainty inherent in these projections adds further urgency to production of robust and adequate FRM plans at the local scale.\n\n\n## 1.4 Aims and structure\n\n\nGiven these issues relating to SWF risk management and climate change in England, this paper aims to develop an audit framework for Local Flood Risk Management Strategies (LFRMSs) and to apply that audit framework to the published LFRMSs produced by England's LLFAs. Our ultimate goal is to assess whether England has an adequate strategy for managing increasing surface water flood risk in a changing climate. There will be some consideration of quite general attributes of the LFRMSs but, given the work of Maiden et al. (2017) and Benson et al. (2018), there will not be a detailed assessment of whether the strategies meet their requirements under the F&amp;WMA2010.\n\nSection 2 describes the audit method that will be applied in this paper with a focus on the questions that will be asked of the LFRMSs and how they will be assessed. Section 3 presents the results of the audit in terms of the scores across all LFRMSs as a whole. Section 4 will discuss the results in the context of the national FRM framework and the climate change adaptation approach in England as well as looking to individual LFRMSs for lessons to be learnt, and draw conclusions from the analysis.\n\n\n## 2. METHOD\n\n\n\n## 2.1 General approach\n\n\nWhilst Maiden et al. (2017) and Benson et al. (2018) developed their evaluation criteria from the legal requirements listed in the F&amp;WMA2010 and the guidance points developed by the LGA (LGA, 2011), the study here will look at a range of 'audit' questions that will indicate the extent to which the LFRMSs are appropriately assessing and managing local flood risk and how they are accounting for climate change. The audit questions fall into 3 categories:\n\n- 1. Audit of the LFRMS document attributes - using the F&amp;WMA2010 and LGA (2011) as a guide to how LFRMSs should be produced, these questions will look at the publication date, version, length, authorship and review process. The aim here is to assess whether the process of producing the LFRMS is sound and not whether the F&amp;WMA2010 requirements were being met.\n- 2. Audit of the LFRMS approaches - using CCC assessment processes as a guide, these questions will focus in on the nature of the LFRMS objectives and measures, how they are evaluated, whether they are based on a risk assessment, whether climate change factors are incorporated into the risk assessment and/or LFRMS, and whether the LFRMS is consistent with the National FCERM Strategy.\n- 3. Audit of specific terms that sound LFRMS should include - using the National FCERM Strategy and CCRA (HM Government, 2022) as a guide, these questions look to assess\n\nthe extent to which the LFRMS in referring to key datasets, risks, resilience-focussed FRM approaches (i.e. not hard infrastructure defences) and legislation.\n\nThese questions will be assessed in different ways as appropriate but all fall into these categories: year or date range; count/number; yes/no; or A/B/C scorecard grading as per Benson et al. (2018). The assessment of the questions, up to a point, is subjective but to ensure consistency and accuracy as much as possible a single researcher was used to make these assessments and a subset of the judgements were re-assessed by a second researcher to corroborate the classifications and raise any inconsistencies. In these subsets, the context of the assessment was also analysed to ensure that the scores are indicative of the LFRMS contents.\n\n\n## 2.2 Specific audit questions\n\n\nTable 2 presents the audit questions applied to the LFRMSs alongside the assessment metric. These questions were applied to all available LFRMSs, which are discussed in Section 2.4.\n\nQuestions 1-7 were used to examine the relatively simple document attributes, as described in 1) in Section 2.1. Questions 8-20 take a more detailed look at key LFRMS approaches, as described in 2) in Section 2.1. Questions 21-25 took a direct, quantitative approach to assessing the extent to which the LFRMS refers to specific FCERM approaches and relevant datasets to support flood risk analyses,  as described in 3) in Section 2.1. The calibration of the 'scorecard' indicators for the more in depth questions is described in Section 2.3.\n\n\n## 2.3 Calibrating the audit question 'scorecard' indicators\n\n\nMost of the indicators linked to 'scorecard' questions (i.e. the questions with A, B, C responses) can be structured using a fairly simple model e.g. A: Yes, x is outlined in detail, B: Yes, x is outlined with limited detail, C: No, x is not outlined. This applies to questions 2-4, 6, 10, 15, 1718 and 20. Some of the audit questions, however, are more complicated yet also fundamental to the value of this analysis so they require some extra discussion.\n\nQuestion 11 asks 'Are the objectives SMART (Specific, Measurable, Achievable, Realistic, Time-bound)?', with the assessment criteria 'A: Yes, they mostly meet the SMART criteria, B:\n\nYes, they partially meet the SMART criteria, C: No, they are not SMART'. SMART is widely used and understood, even in similar contexts to this analysis (e.g. CCC, 2019, 2021), so it is reasonable to assume that the authors of LFRMSs are likely to be aware of the concept and might apply it knowingly or otherwise in their plans. However, it is a concept that has been questioned (Day and Tosey, 2011) and it is not always defined or applied in a universal way. Given this, it is worth focusing on the way that each element was interpreted for this analysis.\n\n- ● Specific , in this case and in addition to being well-defined, concerns whether an objective or action relates to the overall aim of the LFRMS initiative, which, from the F&amp;WMA2010, is to \"manage local flood risk\". In our assessment, therefore, we looked for objectives that directly manage flood risk rather than objectives that are tangential, such as those related to operational processes or organisational structures that, whilst useful, don't necessarily lead to a reduction in flood risk.\n- ● Measurable relates to whether the objective or action is theoretically measurable quantitatively. We did not look for the metric or assessment process here (this is the focus of Question 12) but rather whether the objective is articulated in a way that makes it practical rather than aspirational, say.\n- ● Achievable was approached in a broad sense: it was assessed whether the objectives or actions were within the power of the LLFA (i.e. in line with the responsibilities set out in the F&amp;WMA2010) and if achieving the objective was broadly conceivable.\n- ● Realistic relates to any discussion around the resources and skills available to the LLFA and whether, in board terms, these appear sufficient to meet the objectives. (Note that the R in SMART is sometimes defined as Relevant but this would overlap with the definition of Specific used here.)\n- ● Time-bound is quite straightforward but important: is there a target or completion date associated with the objective or action?\n\nWithin our analysis, we placed the most emphasis on Specific, Measurable and Time-bound as these elements are distinct and most reliably assessed within the approach applied here. These elements are also prioritised by an analysis of how to practically use climate change risk assessments to develop effective adaptation policy (Brown et al., 2018). Achievable and Realistic are clearly important but are more challenging to assess and overlap with the other three elements so the threshold to meet these criteria was lower.\n\nQuestion 12 asks 'Are the objectives accompanied by monitoring and evaluation approaches?'. This aims to identify if clear metrics and assessment processes are outlined alongside the SMART objectives discussed above.\n\nQuestions 13 and 14 looked to understand if the LFRMS discussed climate changes in a sophisticated way with the former looking for evidence of the uncertainty of climate change projections informing the objectives and the latter looking for consideration of the impacts of specific climate risks.\n\nAll other questions have either yes/no or number assessment criteria and require no further explanation. In all cases where names have changed (e.g. Highways England to Highways Agency) or it is known that some stakeholders use different names (e.g. Property Level Resilience and Property Level Protection) we searched for all terms and summed the results.\n\n\n## 2.4 The Local Flood Risk Managements Strategies (LFRMSs)\n\n\nThe research team searched the relevant LLFAs' website and/or contacted the LLFAs for their LFRMSs during January and February 2022. Of England's 152 LLFAs, 147 had a complete LFRMS (i.e. a Strategy document with an incorporated or separate Action Plan) that was found online or was provided via email after contacting the LLFA. It was not possible to acquire a complete LFRMS from 5 LLFAs despite multiple attempts to contact them throughout January to March 2022. These LLFAs were Doncaster, Greenwich, Merton, Somerset and Wandsworth.\n\nIn addition, three small groups of LLFAs had produced a joint LFRMS, these are:\n\n- ● Dudley, Sandwell, Walsall, and Wolverhampton (4 LLFAs combined)\n- ● Blackburn with Darwen, Blackpool, and Lancashire (3 LLFAs combined)\n- ● Shropshire and Staffordshire (2 LLFAs combined)\n\nThis resulted in a total of 141 LFRMS documents that were available to be analysed, which covered 147 of the 152 LLFAs.\n\nAs mentioned above, some LFRMSs incorporated the Action Plan into the main document and some had it as a separate document. Where it was separate, we conducted our analysis on the main document and the separate Action Plan and combined the results to ensure that our analysis was examining consistent material.\n\n\n## 3. RESULTS\n\n\nThis section provides an analysis and contextualisation of the complete dataset of results, which is available at the Queen Mary Research Online (QMRO, 2022).\n\n\n## 3.1 LFRMS attributes and planning approaches\n\n\nThe first section of Fig. 2 shows that, in general, LFRMSs are being produced in line with guidance. A relatively small number have been updated (Q2: 22/141, 16%; Fig. 3a shows the rate of publication and update of LFRMSs) but this is likely to increase following the publication of the updated National FCERM Strategy in 2020 with which LFRMSs are supposed to align.\n\nThere is evidence in the documents that most LFRMSs are viewed as living documents to some extent by the LLFAs (Q3: 120/141, 85%) and that they have been implicitly or explicitly assigned an active period (Q4: 111/141, 79%; Fig. 3b visualises those active periods). However, many of the LFRMSs with an active period have now gone beyond the end of that period (Q4: 60/141, 43%) and, therefore, require an urgent update. (It is likely that the intense response to the COVID-19 pandemic throughout 2020 and into 2022 by local authorities diverted resources from FRM and has delayed some of the LFRMS updates.)\n\nFewer than half of the LFRMSs have a cover sheet (Q6: 59/141, 42%), making it impossible to identify whether the Strategy has been peer reviewed and formally signed off. A small number of LLFAs indicated that they commissioned external consultants to develop their LFRMS (Q7: 25/141, 18%). These commissions were spread across a range of companies - WSP (5), ch2m (2), Peter Brett (2), JBA (3), Parsons Brinckerhoff (1), AECOM (5), Balfour Beatty (1), Capita (5), URS (6), Environment UK Ltd (1), Metis Consultants (1) - with no clear dominant consultancy (some LLFAs instructed multiple consultancies). Whilst the use of a consultancy does not imply the LFRMS will be higher quality, it does indicate that some LLFAs invested capital in their LFRMS. The range of consultants used suggests a missed opportunity for LLFAs to have issued combined tenders for single consultancies to produce multiple (consistent) LFRMSs, which could have increased cost efficiency and comparability across LLFAs.\n\nA key result of this analysis is that nearly all LFRMSs included clear objectives (Q10: 140/141, 99%) and the same number can be classified as including some elements of SMART objectives (Q11: 140/141, 99%). When objectives fell short of being fully SMART, it tended to be the time bound element that was lacking. Some degree of monitoring and evaluation is included in the majority of LFRMSs (Q12: 104/141, 74%) but there is room for improvement in most of those plans (i.e. the B score is dominant for Q12).\n\nClimate change scenarios were rarely considered in LFRMSs (Q13: 49/141, 35%) and this number reduced even further when looking for evidence of scenarios informing actions i.e. the A score for Q13 (7/141, 5%). Nonetheless, the majority of LFRMSs did discuss examples of potential climate change impacts (Q14: 135/141, 96%) despite not using projections. Given the importance of climate changes to these Strategies, the examination of these, and related, results is expanded in Section 3.3. Also considering future risk, population change was incorporated into less than one third of LFRMSs (Q19: 38/141, 27%). Furthermore, in response to these uncertainties influencing long term planning, dynamic adaptation pathways were only evident in a very small number of LFRMSs (Q16: 2/141, 1%) despite their very successful use in the Thames Estuary 2100 strategy (Environment Agency, 2012).\n\nDespite these criticisms, there is further evidence that the majority of LFRMSs are meeting their basic requirements in terms of direct consideration of SWF risk management measures (Q15: 140/141, 99%), references to the Strategic Risk Assessment (Q17: 138/141, 98%) and Asset Register (Q18: 132/141, 94%), and alignment with the National FCERM Strategy (Q19: 135/141, 96%).\n\n\n## 3.2 LFRMS coverage of FRM approaches, data and other policies\n\n\nFigure 3c shows that the length of LFRMSs is remarkably varied, with the longest at almost 50,000 words and the shortest at under 3,300 words. The peak of the approximately normal distribution lies around 16,000-24,000 words. In the discussion, the links between word count and performance in this audit exercise will be considered.\n\nFigure 3d shows the prevalence of references to a selection of resilience-focused FRM interventions that the research team considered to be important elements of a good LFRMS.\n\nRemarkably, 100% of LFRMSs refer to SuDS - this is a higher proportion than included objectives or referred to surface water flooding or climate change. It appears clear that the existence and use of SuDS has been picked up universally by the LLFA community. There was also a high incidence of using the term in the LFRMSs with a mean of over 29 references to SuDS in each LFRMS. That said, there was a huge range in the number of references to SuDS in individual LFRMSs, from a single reference in one LFRMS to over 100 in another, so the depth of consideration appears to vary greatly. Other interventions, however, were referred to much less: PLR/PLP - 75%; spatial planning - 55%; natural flood management/nature-based solutions - 27%; flood warnings - 86%; and land management/upland water storage - 58%. There were some instances where individual LFRMSs had very few references to any of these interventions and this will be examined more in the discussion. Some of this variability can be explained by the different local contexts but there are, nonetheless, insights of value in these findings.\n\nReferences to 'consult' or 'consultation' were found in the vast majority of LFRMSs (137/141, 97%; not shown), with a mean of 13 references per LFRMS, which suggests LLFAs are consulting with relevant stakeholders. To elaborate on this, Figure 3e shows how many times individual LFRMSs referred to important stakeholder groups. Water companies dominate the number of references here (140/141 LFRMSs, 99%), which is understandable given their role in SWF risk management. RFCCs (131/141, 93%) and the public (135/141, 96%) are referred to in the vast majority of LFRMSs. IDBs and riparian landowners are referred to in fewer LFRMSs (78% and 88%, respectively) but when they are included there is a high number of mean references per LFRMS (14 and 11 references, respectively). Indeed, there are several instances of LFRMSs that have a very high number of references to the IDBs.\n\nFinally, on references to underpinning legislation, policies and data, it is unsurprising the nearly all the LFRMSs refer to the F&amp;WMA2010 (138/141, 98%) and the National FCERM Strategy (140/141, 99%) as these represent the primary legislation that requires the LFRMS to be produced and the national strategy with which the LFRMSs must align. There is also a high level of engagement with the National Planning Policy Framework (126/141, 89%) and the Local Plans (127/141, 90%), which implies that LLFAs are considering the FRM implications for housing development. There is a relatively low rate of reference to the national data products 2 that could be used to underpin an LFRMS (116/141, 82%) and, similarly, references to Strategic Environmental Assessments are not high (117/141, 83%).\n\n\n## 3.3 Climate change\n\n\nIn Section 3.1, some initial analysis showed that climate change scenarios and tools to plan under uncertainty were very rarely used. In this section, the examination of climate change factors will be expanded.\n\nThe term 'climate change' was used in all but one of the LFRMSs examined (140/141, 99%) and was referred to, on average, 20 times in each LFRMS. However, once more specific climate change legislation and policy is considered, this prevalence rapidly decreases: the Climate Change Act (2008) is referred to in fewer than half of the LFRMSs (61/141, 43%), the Climate Change Risk Assessment in fewer than one fifth of the LFRMSs (26/141, 18%), and the National Adaptation Programme (NAP) in fewer than one sixth of the LFRMSs (19/141, 13%). However, whilst theoretically it would appear necessary for LFRMSs to refer to the NAP, it has been consistently noted by the Committee on Climate Change that the NAP has repeatedly failed to address flood risk in any meaningful way. This points to a clear failing in the delegated and top-down approach to SWF risk management in England: if the NAP is inadequate then there is no (statutory) direction or target for long-term, evidence-based adaptation plans nationally or locally. If LFRMSs develop adequate (or better) plans in relation to climate change, this is in spite of the NAP and not because of it.\n\nIt was also found that ranges of climate change scenarios were rarely considered in the LFRMSs, with as few as 5% using scenarios to inform actions. This is a key shortcoming in the plans. It implies that the range of potential impacts are not being considered and, therefore, there will not be adaptation plans put in place to prepare for the full range of possibilities.\n\nOverall, though, it is clear that the consideration of climate change impacts across the LFRMSs is weak and should be addressed to avoid increasing exposure to flood risk, particularly SWF risk, in the future,\n\n\n## 4. DISCUSSION AND CONCLUSIONS\n\n\n\n## 4.1 Achieving the research aims\n\n\nThe key aim of this analysis was to identify whether the LFRMSs are, as a whole, adequately addressing SWF risk in England, particularly in the context of a changing climate. Using a systematic method of quantifying elements of the LFRMSs that are indicative of important factors being included in the Strategies, it was shown that there are significant shortcomings in the LFRMS portfolio. Whilst nearly all the LFRMSs were shown to address SWF risk, very few were shown to address important aspects of climate change and increasing risk in the future. Of most concern:\n\n- ● Only 35% considered climate change scenarios in any way;\n- ● Population change in the future was only considered in 27%;\n- ● The Climate Change Risk Assessment was only referred to in 18%;\n- ● The National Adaptation Programme was only cited in 13%; and\n- ● Only 1% referred to the dynamic adaptation pathway approach (and none present this method in the LFRMS).\n\nThere are, therefore, significant opportunities for LFRMSs to address SWF risk in a changing climate in a much more sophisticated way - the knowledge, data and the tools are rapidly developing but they need to be implemented more widely. Encouragingly, some of the more recent LFRMSs that now align with the 2020 version of the National FCERM Strategy are using more sophisticated approaches and are referring to a wider range of resilience measures (e.g. City of London, Devon). This opportunity should be seized to disseminate good practice and to capitalise on the improvements in the new National FCERM Strategy.\n\nDespite the issues around climate change adaptation planning, our analysis is largely consistent with Benson et al. (2018) and Maiden et al. (2017) that the LFRMSs are broadly meeting their statutory requirements. Indeed, Figure 2 shows that, more or less, the overall LFRMS portfolio is meeting the minimum requirements from the F&amp;WMA2010.\n\n\n## 4.2 Examining individual LFRMSs\n\n\nIt was identified in Section 3.2 that some of the LFRMSs had very few references to resiliencefocused interventions. This included Southend-on-Sea Unitary Authority, which at over 49,000 words, is the longest of the LFRMSs. Examination of this LFRMS, and other Strategies with similarly low references to interventions, highlighted that they included very few, if any, actions that directly reduce flood risk. They tended to focus on actions that improve risk characterisation, raising awareness and encouraging stakeholders to act. Whilst these aims are in line with objectives from the old, 2011 National FCERM Strategy, there were no actions in line with the 'building, maintaining and improving flood and coastal erosion management infrastructure and systems' from that Strategy that would have addressed flood risk. In these cases, there is little reason to refer to any interventions, least of all the resilience-focused ones that have been highlighted here.\n\nAt the other end of the LFRMS length scale, many of the shortest LFRMSs refer to other plans that include actions to address flood risk. In the case of Essex, Durham, Leicester City UA and Poole (all under 5,500 words), they refer to the Surface Water Management Plan (SWMP) rather than developing new actions themselves that will directly reduce flood risk. These short LFRMSs have other issues as well: Essex was the single LFRMS that did not refer to climate change; none of the four refer to any of the key datasets identified in Section 3.2; none of the four refer to refer to more than two of the resilience-focused FRM interventions; and Durham, Leicester and Poole do not refer to the NPPF or Local Plan, which implies that the potential impact on housing development has not been considered at the necessary depth. Whilst LFRMS length is not necessarily a negative, in these cases of short documents it does appear to indicate a delegation of planning to another plan or strategy, which is not the role of the LFRMS as set out in the F&amp;WMA2010.\n\nThe issues raised here appear to be common across FRM. Indeed, both the NAP and Defra's Surface Water Management Action Plan have been criticised for similar issues by the CCC for delegating planning and acting on flood risk (CCC, 2019). As discussed in Section 1, this is the result of the lack of a unifying Act for FRM - there is no clear, overarching objective so individual plans and strategies often refer back to each other and delegate responsibilities without ever developing a clear approach or set of actions that reduce flood risk. That many LLFAs have not used the opportunity to develop an LFRMS to take a strong lead on SWF risk management is entirely reasonable in the FRM system as it exists.\n\nHowever, there is a group of LFRMSs that scored very highly in the audit. The Newcastle City Council LFRMS scored highest, followed by Leeds City Council, East Riding of Yorkshire Council and Norfolk County Council. It is worth examining why these were ranked highest and to identify lessons that can be applied to other LFRMSs as they are updated. Newcastle's LFRMS responded well to the standard elements required by the F&amp;WMA2010 (i.e. objectives, actions, responsibilities) and it was also underpinned by the relevant datasets, including climate projections. The buy-in from stakeholders and consideration of impacts and responses was clear (e.g. integration of local planning and the NAP). The Norfolk LFRMS demonstrated widespread engagement with stakeholders as well as extensive consideration of the resiliencefocused interventions. Leeds - an updated version and a WSP commission - made excellent use of the UKCP09 dataset and the Strategic Environmental Assessment. The East Riding of Yorkshire LFRMS, similarly, demonstrated good engagement with stakeholders, informed consideration of the resilience-focused interventions and good use of underlying datasets. It is worth noting that these 4 LLFAs have long histories of FCERM issues and were almost certainly in good positions (and had clear motivation) to compile good LFRMSs.\n\n\n## 4.3 Reflecting on the method\n\n\nThere are some shortcomings to the method applied in this research. Whilst some of the audit questions required an examination and classification of text from the LFRMSs (e.g. Q10-15 from Table 2) a large part of this analysis involved the somewhat blunt approach of searching for key terms that were chosen to identify valuable characteristics of each LFRMS. This approach allowed the research team to examine all the LFRMS, which has not been done before, in a reasonable time frame but it did not allow for the nuance within each LFRMS to be examined. A more detailed examination was undertaken for a sub-set of LFRMSs (some of which is reported above) to ensure that the method was uncovering results of value - and it was assessed that it did - but this cannot be guaranteed for the whole portfolio. Nonetheless, with a degree of error that cannot be calculated, this examination provides valuable insights into the nature of the SWF risk management framework in England.\n\nThe analysis did not consider whether the plans had actually been implemented on the ground. This is a key element of the climate change adaptation assessment process but, as a first step, the current work only focussed on whether adequate plans are in place. This is logical as it is unlikely that LLFAs are doing more than they set out in their LFRMS but, if the plan is inadequate then it is almost certain that actions are also inadequate. Nonetheless, assessment of implementation of interventions is planned for future work.\n\n\n## 4.4 Conclusions\n\n\nThe conclusions of this research are:\n\n- ● The findings corroborate previous work that LFRMSs are generally meeting their minimum statutory requirements.\n- ● There is a widespread issue across LFRMSs with inadequate consideration of increasing climate change risk. We therefore conclude that the plans in place in England to manage surface water flood risk are not describing adequate actions.\n- ● There is some evidence of good practice within the LFRMS portfolio and effort should be made to disseminate this as LLFAs update their LFRMSs in line with the new National FCERM Strategy.\n\n",
         "The flood risk management policy and implementation framework in England is overseen by complex layers of governance bodies via a range of overlapping legislations, policies and strategies. Within this, responsibility for surface water flood management is largely delegated to 152 local authorities. In this research, the local flood risk management strategies (LFRMSs) produced by these local authorities were audited using a systematic, largely objective method to identify alignment with a range of factors that good strategies should include. The aim was to determine if the strategies were meeting their minimum statutory requirements and whether they were developing robust climate change adaptation plans. The findings show that LFRMSs are, in the main, meeting their minimum statutory requirements. However, there is a widespread issue across most LFRMSs regarding inadequate consideration of increasing surface water flood risk from climate changes. Therefore, we conclude that surface water flood risk plans are not adequate in England largely because of the range in quality across the local authorities. Nonetheless, there is some evidence of good practice within the LFRMS portfolio, which is discussed in the context of the ongoing update process of these strategies. This research is the first examination of the full suite of LFRMSs and, therefore, is the first time that the complete approach to surface water flood management has been assessed in England.",
         ""
        ],
        [
         "42",
         "42",
         "## Introduction\n\n\nBeliefs  are  essential  in  every  human  activity  and  behavior  to  help  individuals  know themselves and their surroundings (Nikitina &amp; Furuoka, 2006). Beliefs are fundamental tools for determining behavior (Cephe &amp; Yalcin, 2015; Parsi, 2017). Nikitina &amp; Furuoka (2006, p. 2010) state that 'Belief is a way of perceiving the world that generates the confidence to act upon matters accepted as true but may be questioned in the future. Beliefs in such a contextual approach are dynamic, socially constructed, situated, paradoxical, and related to action.'\n\nHorwitz  (1999)  confirms  that  beliefs  about  language  learning  form  the  students' perceptions and affect their performance in the classroom (as cited in Nikitina &amp; Furuoka, 2006; Bidari, 2021). Teachers must understand their students' beliefs to know their context better and deal with it. They should be aware of the learners' views to decide on their language learning techniques and employ appropriate learning strategies to help them enhance their language skills. Educational psychology considers learner beliefs as  essential factors of learning behavior. For example, students interested in their studies and consider it significant engage more actively in the learning process and work harder. Teachers must be familiar with their audience to design their materials in the most efficient manner possible for learning.\n\nIt is essential to understand language learners' beliefs for two reasons; first, these beliefs may influence language learners' expectations. Second, compared with attitude and motivation, these  beliefs  can  be  more  easily  changed  (Horwitz,  1987,  as  cited  in  Diab,  2006;  Jafari  &amp; Shokrpour, 2012).\n\nMoreover, research in this field has shown that language learners' beliefs have a massive impact on their learning process and even affect many other aspects of language learning (Mohebi &amp; Khodadady, 2011; Abdi &amp; Asadi, 2015). Victori &amp; Lockhart (1995, p. 224, cited in Meshkat &amp; Saeb, 2014, p. 211) defined beliefs about language learning as 'general assumptions that students hold  about  themselves  as  learners,  about  factors  influencing  language  learning,  and  about  the nature of language learning and teaching.' Hayati (2015) defined beliefs as learners' opinions about language learning. They determine the learners' actions. Rokeach (1968, p. 113), cited in (Nikitina &amp; Furuoka, 2006), states that 'Beliefs are predispositions to action.' Beliefs and actions help language learners to know themselves better and recognize their own identity in language learning (Kalaja et al., 2015).\n\nForeign language learners have different perspectives on the way languages are learned. Some learners think this process is easy, while others believe the opposite. Some others believe that children learn languages more easily and quickly than adults. Many believe that it does not need much time and others think it does. Several learners consider language learning a unique gift that  some people have. There are many other such beliefs among language learners, and each learner has their own set of beliefs when s/he starts language learning and even during the process. These beliefs affect their language learning behavior and experience positively or negatively. In addition,  these  beliefs  help  them  choose  suitable  learning  approaches  and  strategies  (Horwitz, 1988, 2008). Moreover, the views of language learners are affected by their past language learning experiences and cultural background (Hong, 2006; Saeb &amp; Zamani, 2013; Azar &amp; Saeidi, 2013; Cephe &amp; Yalcin, 2015).\n\nMany linguists and scholars have studied language learners' beliefs in different contexts. They  discovered  that  these  beliefs  have  a  significant  role  in  learning  a  language  successfully (Horwitz, 1999). Most of them used Horwitz's (1988) BALLI questionnaire tool to explore foreign language learners' beliefs on language learning in their contexts. The purpose of this study is to explore and learn more about the ideas of Kurdish EFL university students about learning the English language. The study addresses the following research questions: What are the opinions of Kurdish EFL university students about learning English? Do Kurdish EFL university students have the same beliefs as the participants of Horwitz's (1988) study? The study adopts Horwitz's (1988) approach to data collection and analysis and descriptive statistics, but in a different context and with another research community.\n\n\n## Literature Review\n\n\nSince  the  mid-1980s,  researchers  have  been  increasingly  interested  in  the  function  of individual  learners  in  language  learning.  Due  to  this  curiosity,  they  were  interested  in  learner variables  as  a  technique for  assessing  students'  performance in foreign language learning. The beliefs regarding language learning examined in foreign language learning are factors (Meshkat &amp; Saeb, 2014).\n\nHorwitz (1988) was the first  researcher  who  practically  researched  second  and  foreign language learning beliefs. She works at the University of Texas as a professor. She investigated the language learning beliefs of French, German, and Spanish university students in the United States  by  developing  the  Beliefs  About  Language  Learning  Inventory  (BALLI).  The  study's findings revealed that many students held opposing views to language educators. The participants in the research, for example, thought the language they were learning was simple and that they could  acquire  it  in  two  years.  They  believed  that  learning  a  foreign  language  mostly  entailed memorizing  many  new  vocabulary  words,  grammatical  rules,  and  translation.  Horwitz  (1988) concluded that language learners come to class with preconceived notions about language learning, some of which prevent language learning successfully. One of the aims of Horwitz was to inform teachers  about  their  students'  beliefs  and  perceptions  (Horwitz,  1987,  1988,  as  cited  in  Riley, 2006).\n\nAs mentioned earlier,  Horwitz  researched  the  beliefs  of  students  and  instructors  at  the University of Texas at Austin. Later, other researchers used her tool worldwide. For example, Yang (1992) examined students' beliefs about language learning at six Taiwanese universities; Park (1995) studied learners' beliefs at two universities in Korea; Truitt (1995) explored Korean University students' beliefs about learning English (Nikitina &amp; Furuoka, 2006).\n\nMeshkat  and  Saeb  (2014)  state  that  there  have  been  many  other  studies  on  language learners' beliefs that employed Horwitz's instrument (1987), Beliefs about Language Learning Inventory  (BALLI),  for  different  purposes.  Some  of  these  studies  looked  at  the  relationship between beliefs and other factors that influence language learning, such as strategies (Wenden, 1986; Yang, 1999); gender (Bernat &amp; Lloyd, 2007; Tercanlioglu, 2004); language proficiency (Abedini  et  al.,  2011);  foreign  language  anxiety  (Jee,  2014;  Oh,  1996),  (Truitt,  1995;  Young, 1991); culture (Horwitz, 1999); and the secrets of beliefs (Sakui &amp; Gaies, 1999). Moreover, Jafari and Shokrpour (2012) state that  the  BALLI  has  been  broadly  used  in  different  ESL  and  EFL contexts and cultures to evaluate or explore the beliefs of ESL and EFL students. For example, in\n\n## Arab World English Journal (AWEJ) Volume 13. Number 2. June 2022\n\nExploring Kurdish EFL University Students' Beliefs\n\nGhafor, Ahmad &amp; Mustafa\n\nChina (Zhang &amp; Cui, 2010); Hong Kong (Peacock, 2001); Hungary (Rieger, 2009); Korea (Park, 1995) and (Truitt, 1995); Lebanon (Diab, 2006); Malaysia (Nikitina &amp; Furuoka, 2006); Thailand (Fujiwara, 2011); Turkey (Altan, 2006) and (Ariogul et al., 2009); and Vietnam (Bernat, 2004).\n\nDiab (2000) modified the BALLI and used it to explore the beliefs of 284 students learning English  and  French  as  foreign  languages  at  three  Lebanese  universities.  He  realized  that  the students learning English had the following viewpoints: integrative motivation, the difficulty of speaking and learning English, the importance of accuracy in speaking English, and English in Lebanon. While the students learning the French language had the following beliefs: 'motivation/ confidence  in  speaking  French,  the  nature  of  learning  French,  the  importance  of  French  in Lebanon,  and  the  importance  of  accuracy  in  speaking  French.'  In  terms  of  language  learning difficulty,  most of the participants believed that English is an easy or very easy language, but French is difficult. More French learners than English thought of learning a foreign language in a native country.\n\nApart from English language learners, the BALLI tool was also used to explore learners' beliefs  in  the  other  languages.  For  example,  Horwitz  (1988)  researched  the  learners'  French, German, and Spanish views at the University of Texas at Austin. Kuntz (1996) looked at Arabic and  Swahili  learners.  Smith  (1989)  and  Tumposky  (1991)  investigated  the  views  of  Russian language  learners.  Kern  (1995)  discovered  French  language  learners'  beliefs.  Bacon  and Finnemann (1990) researched Spanish language students' beliefs. Mori (1999) explored Japanese learners' ideas (Nikitina &amp; Furuoka, 2006). Furthermore, Oh (1996) used the BALLI questionnaire with 195 first and second-year Japanese learners at the University of Texas at Austin to explore their language learning beliefs and anxiety in learning foreign languages.\n\n\n## Methods\n\n\nThe researchers used a quantitative method, which is a questionnaire, in conducting this study because it is a suitable way to achieve the aim of the study. The participants of the study reflected  on  the  items  of  the  questionnaire  based  on  a  Likert-type  linear  scale  (Likert,  1932); strongly  disagree,  disagree,  neutral,  agree,  and  strongly  agree,  as  it  is  a  reliable  rating  scale to measure attitudes and gives more freedom to the participants in showing their agreement or disagreement with the statements than usual yes/no responses. The results of such scales are more precise and can be analyzed better.\n\n\n## Participants\n\n\nThe participants of this study are the Kurdish EFL university students studying English as a foreign language at the English language department during the academic year 2021/2022 in seven public and private universities located in different areas of the Iraqi Kurdistan Region. They are five public universities: the University of Halabja, the University of Sulaimani, Salahaddin University, Koya University, and Soran University. And two private universities; the University of Human Development and Tishk International University in Sulaimani. The overall number of the students who participated in filling out the questionnaire was 420. Their age is between 18-25 years, as shown in table one.\n\nTable 1. Students' ages\n\nTable two shows the frequencies and percentages of the students' genders. As seen in the table, more female students participated in filling out the questionnaire than males.\n\nTable 2.  Students' genders\n\nTable  three  indicates  the  distribution  of  the  students  according  to  their  stages.  The  first-year students participated more, followed by the third, second, and fourth-year students.\n\nTable 3. Stages of the students\n\nFurthermore, the participant's responses to the three background questions are shown in table four below.\n\nQ1. How much do you usually study the English language outside the classroom daily?\n\nThe table shows that (27.4%) of the participants spend less than 30 minutes studying English outside class per day, (25.7%) spend 30 minutes to 1 hour, (26.4%) spend 1 to 2 hours, (and 11.7%)\n\nGhafor, Ahmad &amp; Mustafa\n\n## Arab World English Journal (AWEJ) Volume 13. Number 2. June 2022\n\nExploring Kurdish EFL University Students' Beliefs\n\nGhafor, Ahmad &amp; Mustafa\n\nspend 2 to 3 hours, and only (8.8%) spend more than 3 hours. Most students spend less than two hours per day studying the English language outside class.\n\nConcerning the participants' main reason for studying and learning the English language, only (7.1%) of them study to get a degree. While (67.6%) study it for future careers and education, and (22.4%) are interested in the English language and culture. This means that most students have a relevant aim in studying and learning the English language, not just to get a degree.\n\nRegarding  the  students'  preferred  language  for  communication  with  their  colleagues; (36.2%) use only Kurdish, (15.5%) use only English, (25.7%) use both equally, and (21.9%) use either  English  or  Kurdish  with  various  portions.  Only  (0.7%)  use  other  languages,  especially Arabic. This means that all the participants are Kurdish nationals and are learning English as a foreign  language.  In  addition,  they  do  not  use  the  English  language  only  for  everyday communication outside the classroom.\n\n\n## Research Instrument\n\n\n\n## Questionnaire\n\n\nThe researchers intended to investigate the language learning beliefs of EFL students in Kurdish universities. To achieve this aim, they adapted Horwitz's (1988) questionnaire 'Beliefs About Language Learning Inventory (BALLI).' They distributed it among the target group at the English language departments in seven universities in Iraqi Kurdistan Region.\n\nThey  divided  the  questionnaire  into  two  parts;  part  one  asks  about  demographic information of the participants and three background questions concerning their own language learning experience. The second part is devoted to the items of the BALLI questionnaire, which consists  of  34  statements.  According  to  Horwitz  (1987),  the  statements  are  grouped  into  five categories: 'the difficulty of language learning, foreign language aptitude, the nature of language learning, learning and communication  strategies (learning strategies and communication strategies), and motivation and expectations.'\n\nThey have modified or restructured some items in the original BALLI questionnaire to adjust to the present study's aim and setting. For example, they changed expressions referring to 'foreign language' in general to 'English language' or 'English as a foreign language.'\n\nAccording to the Likert-type linear scale, they asked the students to show their agreement with the statements (Likert, 1932; McLeod, 2019). The rankings are referred to as follows: ((1) Strongly Disagree, (2) Disagree, (3) Neutral, (4) Agree, and (5) Strongly Agree). However, the fourth and fourteenth items have different scales. The fourth item has the following scales: ((1) a very difficult language, (2) a difficult language, (3) a language of medium difficulty, (4) an easy language, and (5) a very easy language). While the fourteenth item has the following scales: ((1) you can't learn a language in 1 hour a day, (2) 5-10 years, (3) 3-5 years, (4) 1-2 years, and (5) less than a year).\n\n## Arab World English Journal (AWEJ) Volume 13. Number 2. June 2022\n\nExploring Kurdish EFL University Students' Beliefs\n\nGhafor, Ahmad &amp; Mustafa\n\n\n## Procedure\n\n\nThe researchers used the 'Google Forms' platform to collect the research data and sent the online questionnaire link to the students of the English language departments to fill. The link was active during January 2022 to let the target students access it. They described the paper's topic to the students and instructed them to complete the questionnaire correctly. They allowed them to ask questions if they needed clarification on any item to ensure they understood everything before answering it.\n\nThey analyzed the quantitative data using Google Sheets, Microsoft Office Excel, and IBM SPSS  Statistics  Software.  They  determined  percentages,  averages,  and  modes  of  all  the questionnaire items and shaped them into the form of a table, see the Appendix. Based on the data, they made  discussions,  outlined  the most  significant conclusions, and  provided  specific recommendations  to  show  the  importance  of  language  learners'  beliefs  and  how  language educators consider them.\n\n\n## Results and Discussion\n\n\nThis section presents the questionnaire results and discussions that address the research questions  and  attain  the  study's  goal.  The  table  in  the  appendix  illustrates  the  results  of  each statement and category of the questionnaire and summarizes all the information provided by the respondents. Moreover, it demonstrates the percentages, means, and modes of all the responses for the questionnaire items. In addition, it shows that the beliefs are five categories.\n\nThe first category is the difficulty of language learning. The average of the beliefs of this category is (3.3), and its mode is (4). Learning a foreign language in general and English is of medium difficulty to the study participants. This category has the lowest mean score among the five categories of the BALLI questionnaire. It consists of six beliefs; 3, 4, 6, 14, 24, and 28. Half of  the  participants  agree  that  some  languages  are  more  accessible  to  learn  than  others.  While (16.9%) strongly agree and (20.7%) neither agree nor disagree with this belief. Over half of the participants (52.9%) regard English to be a medium-difficult language. While (20.5%) of them consider it a complicated language, and (17.9%) of them consider it an easy language. This finding is  opposite to the results of Diab (2000), in which the participants think of English as an easy language, and it is in line with the findings of Horwitz (1988). Most of the participants believe that they will eventually learn to speak English very well; (45.2%) of them agree, (26.2%) strongly agree, and (19%) neither agree nor disagree with this belief. Concerning the time needed for a learner to become fluent if s/he spends an hour day when it comes to learning English, (40.2%) of the participants think that it takes (1-2) years, (29.3%) of them believe that it takes (3-5) years and (19%)  believe  that  it  takes  less  than  a  year.  This  finding  is  in  line  with  (Horwitz,  1988).  In comparison between speaking and understanding, (40.5%) of the participants disagree with the idea that speaking English is more accessible than understanding it, (16.7%) strongly disagree, (18.6%)  neither  agree  nor  disagree,  and  (20.5%)  agree.  Most  of  the  participants  think  that understanding English is more accessible than speaking. When comparing reading and writing to speaking  and  understanding,  many  participants  (37.6%)  agree  with  the  idea  that  reading  and writing English are more accessible than speaking and understanding, (18.3%) strongly agree, (20.5%) are neutral, and (18.8%) disagree. This indicates that most participants believe reading and writing English is simpler than speaking and comprehending it.\n\nwww.awej.org\n\nISSN: 2229-9327\n\n## Arab World English Journal (AWEJ) Volume 13. Number 2. June 2022\n\nExploring Kurdish EFL University Students' Beliefs\n\nThe  second  category  is foreign  language  aptitude .  The  average  of  the  beliefs  of  this category is (3.4), and its mode is (4). It means that the participants' anticipation level of language learning ability, in general, is high. This category consists of nine beliefs; 1, 2, 10, 15, 22, 29, 32, 33, and 34. Most participants believe that learning a foreign language is easier for children than adults; (45.5%) strongly agree, and (36.4%) agree. Concerning foreign language learning ability, (45.7%) of the participants agree that some people have a special ability for foreign language learning, (17.4%) strongly agree, and (21.9%) are neutral. Most of the participants believe that learning another language is simpler for someone who has already learned one; (48.6%) of them agree  with  this  belief,  (16.2%)  strongly  agree,  and  (22.4%)  are  neutral.  Regarding  their  own foreign language learning ability, (38.6%) of those polled are undecided about having a remarkable talent to learn other languages, (38.1%) agree, and (14.5%) disagree. Concerning gender, (34.3%) disagree with the belief that says women are better than men at learning foreign languages, (31.7%) are  neutral  and  (16.7%)  agree.  Most  of  the  participants  do  not  see  any  relationship  between language learning and mathematics and science subjects; (41.4%) disagree with the belief that 'people who are good at mathematics and science are not good at learning foreign languages,' and (16.9%) strongly disagree, (19.8%) neither agree nor disagree and only (15.2%) agree. Most of the participants feel that persons who are fluent in many languages are extremely brilliant; (40.7%) agree with this belief, (27.4%) strongly agree, (18.3%) are neutral and only (10.7) disagree with it. Moreover, (37.4%) of the participants neither agree nor disagree with the belief that 'people from my country are good at learning foreign languages.' While (26.4%) disagree and (25.2%) agree with this belief. The study participants are not certain about Kurdish people's ability to learn foreign languages. However, many of the participants feel that everyone can acquire a foreign language; (49.8%) agree with this belief, (26.9%) strongly agree, and only (14.5%) are neutral.\n\nThe nature of language learning is the third category. The average of this category's views is  (3.7),  with  a  mode  of  (4),  indicating  that  most  respondents  agree  with  the  questionnaire's opinions regarding language learning. This category carries six beliefs: 8, 11, 16, 20, 25, and 26. Concerning  the  relevance  of  culture  in  acquiring  the  English  language,  (47.4%)  believe  that knowing English-speaking cultures is necessary to be able to communicate effectively in English, (17.1%) strongly agree, and (23.1%) neither agree nor disagree. Most of the participants felt that learning English in an English-speaking nation is the best way to learn it; (43.1%) agree with this belief,  (34.8%)  strongly  agree,  and  only  (13.3%)  are  neutral.  This  finding  is  opposite  to  the conclusions  from  Diab  (2000)  about  the  nature  of  English  language  learning.  Regarding vocabulary, (48.3%) agree with the importance of vocabulary in mastering the English language, (20.7%) strongly agree, and only (18.8%) neither agree nor disagree. However, (38.6%) agree with the role of grammar rules in mastering the English language, (12.4%) strongly agree, (25.5%) say they don't agree or disagree, and (19.5%) say they oppose. The results of these two beliefs, the role of vocabulary and grammar in language learning, are in line with the results of (Horwitz, 1988). Many participants felt that studying English is not the same as learning other academic topics; (52.9%)  agree  with  this  belief,  (13.6%)  strongly  agree,  and  (21.9%)  are  neutral.  Concerning translation, most of the participants believe that learning English is typically a matter of translating to/from their native language; (44.5%) agree with this belief, (13.6%) strongly agree, (26.7%) are neutral and only (12.4%) disagree. This result is also in line with (Horwitz, 1988).\n\n## Arab World English Journal (AWEJ) Volume 13. Number 2. June 2022\n\nExploring Kurdish EFL University Students' Beliefs\n\nThe fourth category is learning and communication strategies . It consists of two parts. The first  part  is  learning  strategies,  which  includes  two  beliefs;  17  and  21.  The  second  part  is communication strategies, which comprises seven ideas; 5, 7, 9, 12, 13, 18, and 19. The average of the beliefs of this category is (3.6), and its mode is (4). The first belief in this category is about the role of practice in mastering the English language. (45%) of the participants strongly believe that  it  is  critical  to  practice  and  repeat  in  learning  the  English  language,  and  (40.2%)  agree. Moreover, (48.8%) agree that 'it is important to practice in the language laboratory (or with CD players or headphones),' and (29.5%) strongly agree. Most of the participants would like to have friends  who  are  native  English  speakers;  (47.4%)  of  them  strongly  agree  with  this  belief,  and (37.9%) agree. Regarding accent, (40%) of the participants agree that it is essential to speak with an excellent accent, (32.6%) strongly agree, and (16.7%) neither agree nor disagree. In terms of saying things correctly, (31.9%) disagree with not saying anything until you can say it correctly, (26.2%) strongly disagree, (19.3%) agree, and (15%) neither agree nor disagree. There is no need to worry about making mistakes, especially during communication activities. More than half of the participants would like to go and speak when hearing somebody speaking English. In addition, (47.1%) of the participants agree with the belief that says: 'If you don't know a term in English, it's fine to guess,' (19.5%) strongly agree, and (22.4%) neither agree nor disagree. When it comes to feeling self-conscious when speaking English in front of others, (35.2%) of the participants agree that they feel conscious, (14%) strongly agree, (31.9%) neither agree nor disagree, and (15%) disagree. Moreover, (28.8%) of the participants disagree that if you're permitted to make mistakes at first, it'll be challenging to get rid of them afterward, (14.5%) strongly disagree, (28.1%) agree, and (19.8%) neither agree nor disagree. The participants believe that mistakes should be allowed to achieve fluency at the beginning of language learning and it does not harm the process. This finding is opposite to the conclusions from Diab (2000).\n\nThe  fifth  category  is motivation  and  expectations .  The  average  of  the  beliefs  of  this category is (4.2), and its mode is (4). This is the highest average among the five categories of the questionnaire. It consists of four beliefs; 23, 27, 30, and 31. The participants believe that if they could speak English very well, they would have many opportunities to use it; (44.5%) of them agree, and (36.9%) strongly agree with this belief. Moreover, (56%) of them strongly agree that learning  English  helps  them  get  a  good  job,  and  (32.6%)  agree.  Among  the  34  beliefs  in  the questionnaire, this belief had the highest average (4.4). Learning English is crucial in getting an excellent job in the Iraqi Kurdistan Region's job market. In addition, (41.9%) of the participants agree  that  Kurdish  people  think  that  knowing  the  English  language  is  essential,  and  (40.5%) strongly agree. Finally, (46.2%) of them agree with the belief that says, 'I would like to learn English to know native English speakers and their culture better,' and (32.6%) strongly agree.\n\n\n## Conclusion\n\n\nThe main aim of this study is to explore the beliefs of Kurdish EFL university students about  learning  the  English  language.  The  questionnaire  results  show  that  the  mean  score  for language learning difficulty is the lowest, and motivation and expectations is the highest among the  five  categories  of  the  BALLI  questionnaire.  Furthermore,  most  of  the  study's  findings  are parallel or close to Horwitz's (1988) study. At the same time, there are apparent differences.\n\n## Arab World English Journal (AWEJ) Volume 13. Number 2. June 2022\n\nExploring Kurdish EFL University Students' Beliefs\n\nGhafor, Ahmad &amp; Mustafa\n\nThe study's findings reveal that language learners enter the process of language learning with certain, sometimes unexpected, beliefs that affect the way they behave during the process. Below are the most significant views of the Kurdish EFL university students about mastering the English language:\n\n- 1. English is a language of medium difficulty.\n- 2. Typically,  a  learner  takes  (1-2)  years  to  become  fluent  if  s/he  spends  an  hour  a  day mastering the English language.\n- 3. Understanding the English language is more straightforward than speaking it.\n- 4. Children have an easier time learning a foreign language than adults.\n- 5. A foreign language, such as English, may be learned by anyone.\n- 6. To master the English language, repetition and practice are essential.\n- 7. Mistakes are expected and expected at the beginning of language learning.\n- 8. Learning English helps EFL students in getting a good job.\n\n## Recommendations\n\nThe researchers recommend the following based on their inquiry into the issue of this article and the results reached:\n\n- 1. EFL teachers should be acquainted with their students' beliefs to understand their needs and design their modules accordingly.\n- 2. Mistakes should be allowed at the beginning of language learning for fluency.\n- 3. When EFL students hear someone speaking in  English, they should  practice speaking. They may also have pals who speak English as a first language.\n- 4. EFL students can make educated guesses if they are unfamiliar with a word in the English language.\n- 5. EFL students learn the language better in an English-speaking environment.\n- 6. EFL students should learn new vocabulary to use the language better.\n\n7.\n\n\n## Research Limitations and Suggestions for Further Studies\n\n\nThis study is aimed to look at the beliefs of Kurdish EFL university students in seven institutions' English language departments. The researchers chose a sample of students rather than all of them since the study's goal and scope are restricted, and it's challenging to obtain the opinions of all EFL students from all universities. They also wanted to learn about the perspectives of a definite number of EFL students from each university.\n\nSimilar  studies  on  the  following  issues  can  be  conducted  by  researchers  interested  in examining language learners' beliefs:\n\n- 1. Choosing the same target group at all the region's institutions.\n- 2. Increasing the number of participants from all or some of the region's universities.\n- 3. Finding out the correlation between language learners' beliefs and other factors affecting language learning, such as strategies, approaches, methods, and techniques.\n- 4. Examining the effect of language learners' beliefs on foreign language learning.\n\n",
         "This paper is an attempt to deal with language learners’ beliefs. Researchers used Elaine Kolker Horwitz’s model (1988), Beliefs about Language Learning Inventory, and they applied it to explore the views of Kurdish EFL university students concerning language learning. The study aims to investigate and expose their opinions regarding language learning generally, then English language more precisely. Its significance lies in exploring the beliefs of Kurdish EFL university students about language learning. It mainly answers the question, “what are the beliefs of Kurdish EFL university students about learning English?”. The researchers administered a   Beliefs about Language Learning Inventory (BALLI) questionnaire to seven universities to achieve this aim. The questionnaire includes several viewpoints regarding the difficulty of language learning, foreign language aptitude, the nature of language learning, learning and communication strategies, and motivation and expectations. They collected and analyzed the questionnaire results and found out that the first category, the difficulty of language learning, has the lowest mean score among the five categories. In contrast, the fifth category, motivation and expectations, has the highest mean score. They ended the study with suitable beneficiary recommendations.",
         ""
        ],
        [
         "43",
         "43",
         "## ESTIMATING THE PREVALENCE OF GANG MEMBERSHIP\n\n\nGangs are a public policy priority globally, but especially in the United States where nearly every state and the federal government have enacted anti-gang legislation (Decker et al., 2022). The FBI, at the direction of Congress, established the National Gang Intelligence Center in 2005, partly because about one out of every seven U.S. homicides was gang-related (Egley, et al., 2014). Even outside the United States, however, the consequences of gangs on communities and the contemporaneous and cascading effects of gang membership on individuals are welldocumented by researchers (Decker et al., 2022). One might expect this would attract sustained interest and investment from policymakers and researchers to paint national portraits of gang\n\nactivity. Yet our interpretation of five decades of efforts to do just that leads us to an alternative conclusion.\n\nFigure 1 charts 13 attempts to generate national estimates of gang activity, delineating the sources of data and types of gang activity measured. We arrive at five main conclusions. First, and perhaps most glaringly, all but one of these efforts (i.e., OCJS) were based in the United States.  Second, the bulk of these attempts rely on information provided by law enforcement, 1 from the early work of Miller (1975, 1982), Needle and Stapleton (1983), and Curry (Curry et al., 1994, 1996; Spergel &amp; Curry, 1993), to the most recent efforts of the National Youth Gang Survey. Third, many existing efforts focus on indicators of gang activity other than gang membership, such as the number of gangs, gang-related homicides, or the presence of gangs in communities or schools (e.g., the Maxson-Klein survey: Klein, 1995; Maxson, 1998). Fourth, the past decade has seen no published attempts to generate estimates of gang membership; the most recent data collection and publication on the topic occurred in 2012. Finally, longitudinal or repeated cross-sectional data collection is exceedingly rare in a field largely characterized by one-off efforts to estimate gang activity.  The only ongoing data collection effort is found in the 2 National Crime Victimization Survey's School Crime Supplement. While the data have incredible potential, and are underutilized in the gang literature, the survey instrument does not include a measure of gang membership, instead focusing on the presence of gangs in school.\n\n<!-- image -->\n\nNote: LE = Law enforcement survey data source; SR = Self-report survey data source; GP = gang presence; G = gangs; GM = gang members; GH = gang homicide (or gang incidents); GS = gangs in school.\n\nJust three of these data collection efforts are consistent with our interests in providing population-representative information on gang membership in the United States. These include National Youth Gang Survey (NYGS), National Longitudinal Survey of Youth 1997 (NLSY97), and National Longitudinal Study of Adolescent to Adult Health (Add Health). Each data collection effort has its benefits and drawbacks, which we elaborate upon to (1) draw a contrast to online, opt-in sampling methodology, and (2) serve as an imperfect benchmark against which we compare our findings.\n\nThe NYGS, conducted by the National Gang Center from 1996 to 2012 (Cahill et al., 2024), sampled all police departments serving cities with populations exceeding 25,000 residents\n\n(N=1,216), all suburban county police and sheriff's departments (N=661), a random sample of police departments serving populations between 2,500 and 49,999 residents (N=398), and a random sample of rural county police/sheriff's departments (N=492). An agency representative, typically someone knowledgeable about gangs, reported the number of gangs, gang members, and gang homicides in their jurisdiction, among other issues. This information was then aggregated across agencies for a national snapshot of gangs; for example, an estimated 30,700 gangs, 850,000 gang members, and 2,363 gang homicides in 2012 (Egley et al., 2014). The NYGS consistently achieved a high response rate (85%), and independent reliability and validity testing was generally positive, despite considerable variation across agencies in how they defined and tracked gangs (Decker &amp; Pyrooz, 2010; Jensen &amp; Thibodeaux, 2013; Katz et al., 2012). Accordingly, these data have been cited extensively in the literature, but primarily to 'set the context for work in a specific study area' (Cahill et al., 2024, p. 232). There have been relatively few attempts to leverage these data to inform policy, guide practice, or address substantive issues. 3\n\nHowever, the NYGS is expensive and at least somewhat contentious. The survey was discontinued in 2013, but revived in 2020, after the National Institute of Justice, the research arm of the U.S. Department of Justice (Wyrick et al., 2024), committed $1m USD to generate a single wave of data (Cahill et al., 2024). Police data are also criticized for not measuring gangs and gang membership accurately and for producing racial/ethnic and gender disparities that far exceed those observed in survey research (Meehan, 2000; Pyrooz &amp; Densley, 2024). Amid fervent calls to 'erase the gang database' (Trujillo &amp; Vitale, 2019), this project explores whether\n\nthe prevalence of gang membership in the United States can be understood independently of law enforcement.\n\nThe two additional data sources-NLSY97 and Add Health-are based on surveys of youth, which we consider a better benchmark, yet they are outdated and constrained by age. The NLSY97, funded by the Bureau of Labor Statistics, is representative of youth born between 1980 and 1984 and living in the United States in 1997. A sample of 8,984 youth was generated based on the sampling of housing units, including an oversample of Black and Latino youth. Respondents were asked to self-report membership in a gang in waves 1 through 9, which corresponded (roughly) with annual interviews. By the final wave, 8% of respondents claimed they had ever been a member of a 'group that hangs out together, wears gang colors or clothes, has set clear boundaries of its territory or turf, and protects its members and turf against other rival gangs through fighting or threats.' Add Health, funded by the National Institute of Child Health and Human Development, was representative of youth attending grades 7-12 in the 199495 school year. The 1996 wave of Add Health asked 14,738 youth if they had 'ever been initiated into a named gang,' and 5% of respondents said yes.\n\nNLSY97 and Add Health avoid several criticisms levied at law enforcement data. By asking youth to self-nominate as gang members, it avoids any biases and/or organizational priorities of law enforcement (Esbensen et al., 2001). Moreover, over one dozen studies indicate sound measurement properties of self-nomination in survey research (Pyrooz et al., 2020, p. 634). However, both surveys include unnecessary prompts and wordings (e.g., 'initiated' and 'territory') rooted in stereotypes of gangs. Despite evidence of adulthood-onset gang membership (Decker et al., 2022), they also constrain measures of gang involvement to adolescence and emerging adulthood. Add Health, now in Wave V, stopped asking gang\n\nquestions in Wave III, and NLSY97, now in Wave 19, stopped asking them in Wave 9. Nevertheless, both datasets have been used productively to address a wide range of methodological and substantive research questions on gangs.\n\nIn sum, the most recent estimates of gang membership from law enforcement and selfreport survey data sources are outdated, raising questions about their current relevance to practitioners, policymakers, and researchers. This is particularly problematic given that gangs are constantly evolving, shaped by culture, history, technology, and public policy (Pyrooz et al., 2024). Both data sources also suffer from limitations in scope: law enforcement data underrepresent juvenile gang members, while self-report surveys overlook adult gang members (Pyrooz &amp; Sweeten, 2015; Watkins &amp; Moule, 2014). Furthermore, both methods are costly to administer, with survey being especially limited-a factor that contributed to the removal of Eurogang questions to minimize crowding in the ISRD-3 survey instrument. This study aims to explore whether an alternative methodology can complement the existing data inventory. Can online opt-in panels serve as a valid source of data for a hard-to-reach population like gang members? To answer this, we evaluate whether the population and relational inferences drawn from such panels comport with the existing literature on gangs.\n\n\n## METHOD\n\n\n\n## Data\n\n\nWe contracted with YouGov, a market research firm, to field surveys with four representative samples of U.S. adults in the United States between January 2023 and January 2024. YouGov uses multistage matched design sampling with an online opt-in panel of around one million Americans. A target population is enumerated using a synthetic sampling frame based on age, education, gender, and race/ethnicity, derived from several national sources,\n\nincluding the American Community Survey public use microdata. YouGov uses sample matching by first generating a random target sample from the target population and then selecting individuals from its pool of panelists who match the target sample. Interviewed respondents were assigned weights using propensity scores derived from a logistic regression model with age, education, gender, region, and race/ethnicity, to estimate inclusion in the sampling frame. Poststratified weights were generated based on the 2020 presidential vote and sociodemographics, and used in all analyses to produce nationally representative values.\n\nYouGov's panel data comes from custom (i.e., single client) and omnibus (i.e., multiple clients) surveys, both of which include stock items (e.g., sociodemographics). We examined population and relational inferences using both survey types, as follows:\n\n- ∞ Omnibus-1 included a single item of lifetime gang membership as part of an omnibus survey fielded in January 2023 to 948 respondents.\n- ∞ Custom-1 was a custom survey, titled 'Social Groups and Public Opinion,' fielded September 2023 to 1,000 respondents. It included measures of lifetime gang membership along with several known correlates. Owing to funding requirements, this survey was limited to individuals ages 18 to 60 years, whereas the other three surveys included adults of all ages.\n- ∞ Omnibus-2 was fielded October 2023 to 1,200 respondents as part of an omnibus survey and included a measure of lifetime gang membership and four known correlates.\n- ∞ Custom-2 was a custom survey, titled 'Exposure to Gun Violence in the United States,' and fielded January 2024 to 10,000 respondents. It included measures of lifetime gang membership, along with known correlates. 4\n\nIn total, 13,148 respondents completed the four surveys, all of which included a measure of gang membership.\n\nYouGov uses a similar procedure for omnibus and custom surveys. Panel members receive an access link in an email invitation that explains the incentive 'points' they would earn for completing the survey. Respondents who completed custom surveys provided their consent as outlined in study protocols approved by blinded University (#XXXX) and University (#XXXX), but consistent with YouGov practices, not in omnibus surveys. No personal identifying information was gathered except geographic-associating information in the custom surveys (i.e., zip codes). YouGov shared information about sample construction (see Appendix A), including cases exceeding demographic quotas, partial completes, or failed quality checks (e.g., speed throughs, attention checks, non-sensical answers, and duplicate IP addresses). However, like other online panel data providers, we received only the final datasets, precluding further inquiry into the characteristics of non-respondents.\n\n\n## Measures\n\n\nThe core measure of interest is gang membership . Self-nomination was used to operationalize lifetime gang membership, consistent with an established line of research with incarcerated, neighborhood, population, and school samples (Decker et al., 2022). Respondents were presented with the question: 'Have you ever been a member of a gang on the street or in prison?' In three surveys, response categories were listed as 'yes,' coded 1, or 'no,' coded 0. The Custom-1 survey, however, also included a 'don't know' option, which for analytic purposes, we treated as missing at random.\n\nSeveral correlates were included to assess the relational inferences attained with the online panel. Some measures were included in all four surveys, while others were limited to specific surveys. Appendix B contains the precise wording and response options for the items, along with the survey in which they appeared.\n\nAge was measured in years and adjusted for the month the survey was administered. Sex included male , coded 1, where female, coded 0, was used as the reference group. Black race and Hispanic ethnicity were included, respectively coded 1, where White, Asian, multiple, and other races/ethnicities were used as the reference group, coded 0. Married , coded 1, included domestic/civil partnerships, while respondents without or no longer with partners were coded 0. Sixteen categories of annual family income (in thousands), ranging from less than $10,000 to $500,000 or more, were converted to mid-point dollar amounts. Respondent education and parental education were based on six response categories, ranging from no high school to postgraduate degree completion, of the highest level of education completed, converted to years; parental education was averaged for respondents with two parents.\n\nNeighborhood fear is based on the Gallup and General Social Survey item: 'Is there any area near where you live - that is, within a mile - where you would be afraid to walk alone at night?' One-parent household captures whether a respondent indicated having grown up in a household with one parent, coded 1, or two parents, coded 0, present. Respondents were asked if they had grown up in an area with neighborhood gangs or neighborhood gunshots . For the former, 'yes' was coded 1, 'no' was coded 0. For the latter, respondents who stated they heard gunshots 'somewhat often' or 'often' were coded 1, while 'almost never' or 'never' were coded 0. Three final measures captured whether the respondent had in their lifetime experienced violent victimization (i.e., physically injured with violence), been arrested by the police, or incarcerated in a county jail and/or state/federal prison; those who responded 'yes' were coded 1 and 'no' were coded 0.\n\nAnalytic Strategy\n\nWe aim to evaluate the merit of online opt-in panel surveys for studying hard-to-reach populations-specifically, people currently or formerly involved in gangs. First, we examine population inferences to determine if the prevalence of lifetime gang membership approximates findings derived from two high-quality probability samples: NLSY97, which sampled housing units, and Add Health, which sampled school students. Having drawn four samples from YouGov's panel, we expect to generate a reliable estimate of lifetime gang membership.\n\nSecond, we examine relational inferences, partitioning the sample by self-reported gang and non-gang respondents to discern differences across demographic, ecological, economic, legal, and social characteristics. These items were chosen a priori based on the literature on gangs, which reveals they are sturdy correlates of gang membership (Decker et al., 2022). As an initial test of proof of concept, we are concerned less with temporal ordering than statistical significance; some factors should precede the onset of gang membership, while others should be the result. We provide univariable and bivariable statistics to accomplish this, supplementing these findings with multivariable logistic regression (see Appendix C).\n\n\n## FINDINGS\n\n\n\n## POPULATION INFERENCES ON GANG MEMBERSHIP\n\n\nFigure 2 presents the prevalence of self-reported gang membership in six different U.S. representative samples. By the final wave in which gang membership was asked in the NLSY97, when respondents were between ages 21 to 25 years in 2005, 8% of the sample self-reported lifetime gang membership. The Add Health data from 1996 reveal that 4.8% of students in grades 8 to 12 self-reported lifetime gang membership. How did respondents from an online opt-in panel compare to these benchmarks?\n\nFigure 2. Prevalence of Self-Reported Gang Membership in Representative Surveys\n\n<!-- image -->\n\nAmong the 911 respondents with valid self-reports in Omnibus-1 , 6.2% reported having ever been a member of a gang on the street or in prison (95% confidence interval [CI] = 4.298.03%). In the Custom-1 survey, in contrast, only 2.0% (95% CI = 1.04-2.99%) of respondents self-reported lifetime gang membership, a marked departure from Omnibus-1 . This prompted fielding two additional surveys. The first, Omnibus-2 , included 1,200 respondents and produced an estimated 5.3% lifetime gang membership (95% CI = 3.85-6.82%), aligning more closely with the first omnibus survey. The second, Custom-2 , comprised 10,000 respondents, 2.4% of whom self-reported lifetime gang membership (95% CI = 2.05-2.76%).\n\nGiven our benchmarks, as well as historical context for gang proliferation the United States, it is useful to provide addition comparisons of lifetime gang membership. In terms of the former, we focused on respondents across 10 birth years that overlapped with the sample eligibility criteria of the Add Health and NLSY97 surveys (1975 to 1984), which corresponded to lifetime gang membership of 5.7% in Omnibus - 1 (95% CI: 1.4-10.0%, n =137), 3.3% in Custom - 1 (95% CI: 0.8-5.8%, n =278), 7.2% in Omnibus - 2 (95% CI: 2.5-12.1%, n =169), and 3.2% in Custom - 2 (95% CI: 2.2-4.2%). In terms of the latter, we compared the prevalence of lifetime gang membership across generations. On the whole, the Baby Boomer / Silent generations were the least likely to report lifetime gang membership. In Omnibus - 1 , the percentage who reported lifetime gang membership was 8.9 for Generation Z (born 1997 or more recently), 13.6 for Millennial (born 1981 to 1996), 4.2 for Generation X (born 1965 to 1980), and 1.4 for Baby Boomer / Silent Generations (born 1964 or earlier). Excluding the Custom - 1 sample, owing to age restrictions, the remaining surveys reveal a similar generational gradient. For Omnibus - 2 , those estimates are 8.8%, 7.9%, 5.6%, and 1.2%. For Custom - 2 , those estimates are 3.8%, 3.4%, 2.6%, and 0.8%.\n\nIn sum, people who have been gang members in their lifetimes take part in online opt-in panels. They self-report membership at a rate comparable to prior studies using probability sampling. However, the prevalence of gang membership appears sensitive to the type of survey administered. Omnibus surveys produce estimates similar to high-quality probability samples, although they likely underrepresent gang membership when considering the wider age distribution of these samples. Custom surveys, in contrast, produce estimates that systematically underrepresent gang membership. Both types of surveys produce higher estimates among younger generations, which is what we would have expected to observe given the proliferation of\n\ngangs in the 1980s and 1990s (Klein &amp; Maxson, 2006). Still, any population inferences would be severely undermined if the relational inferences do not comport with the literature on gangs. Do gang and non-gang respondents differ across demographic, ecological, economic, legal, and social characteristics?\n\n\n## RELATIONAL INFERENCES ON GANG MEMBERSHIP\n\n\nTable 1 provides descriptive statistics of self-reported gang and non-gang respondents in the four samples. In the three samples where age was not capped, lifetime gang members were younger than respondents who had never been in a gang-13.8 years (0.79 standard deviations) in Omnibus - 1 , 9.2 years in Omnibus-2 (0.52 standard deviations), and 9.4 years in Custom-2 (0.52 standard deviations). Men were more likely to self-report lifetime gang membership than women in all four samples by anywhere from 20 ( Omnibus-2 ) to 29 ( Custom-2 ) points. These differences were even more pronounced than those observed in school-based studies (Esbensen &amp; Carson, 2012) and even in representative studies (Decker et al., 2022), though they were less stark than those found in law enforcement data (e.g., Pyrooz &amp; Densley, 2024).\n\nRacial and ethnic differences were mixed. We expected Black and Hispanic overrepresentation, consistent with survey and law enforcement data. Hispanic respondents were more likely to self-report lifetime gang membership in two of the four samples (differences between 7.5 to 19.7 percentage points). Black respondents were only overrepresented in the Custom-2 sample, by nearly 10 percentage points. Despite developmental and life-course criminological research demonstrating consequences of gang membership that cascade to economic, education, and family domains, we found less evidence consistent with the literature (Pyrooz et al., 2024). Lifetime gang members fell about one year short of educational attainment than non-gang respondents in the Omnibus-1 and Custom-2 samples, 0.35 and 0.38 standard\n\nTable 1. Descriptive Statistics by Self-Reported Lifetime Gang Membership in Four U.S. Representative Surveys\n\nNote : All estimates are weighted to achieve representativeness. Statistical differences in means/proportions were determined by separately regressing each variable within each sample on lifetime gang membership using ordinary least squares and logistic regression.   refers to adolescent neighborhood. a b refers to current neighborhood. c refers to lifetime occurrence. * p &lt;.05\n\ndeviations, respectively. Rates of marriage and family income were indistinguishable between gang and non-gang respondents, except for a single sample.\n\nAdolescent risk factors consistently differentiated respondents with and without histories of gang membership. Respondents raised in one-parent households were more likely to selfreport lifetime gang membership than those who were not (between 26.7 and 30.1 percentage point differences). Lifetime gang members were also more likely than non-gang members to report growing up in gang neighborhoods and hearing gunshots; these differences were larger in magnitude-45.2 to 59.0 percentage points for gangs and 36.7 to 42.5 percentage points for gunshots.\n\nViolent victimization and criminal justice contact also consistently differentiated lifetime gang and non-gang respondents. Anywhere from 42 to 80% of lifetime gang members reported being victimized violently in their lifetime, compared to 15 to 21% of non-gang respondents. Around 22% of non-gang respondents indicated they had been arrested in their life, whereas 47% ( Custom-1 ) to 78% ( Custom-2 ) of lifetime gang members reported the same; while statistically significant, a striking difference in magnitude. Just 10 to 13% of non-gang respondents reported incarceration in their lifetime, compared to 34 and 58% of lifetime gang members; again, statistically significant with wide variation in magnitude. Lastly, neighborhood fear varied between lifetime gang and non-gang respondents.\n\n\n## GENERALIZABILITY CHECKS\n\n\nThompson and Pickett (2020, p. 926) argued that researchers must subject online opt-in samples to provisional generalizability checks. This involves including test questions related to core variables of interest that also appear in a 'high-quality, probability-based survey, such as the GSS [General Social Survey].' To this end, we included a measure of neighborhood fear into our\n\ntwo custom surveys, asking respondents, 'Is there any area right around where you live-that is, within a mile-where you would be afraid to walk alone at night,' into our two custom surveys. In our samples, 39.7% ( Custom-1 ) and 39.8% ( Custom-2 ) responded 'yes,' figures that align closely with Gallup polling, where 37% (2021) and 40% (2023) answered 'yes,' and from the General Social Survey in 2022, where 37% stated 'yes.' 5\n\nArrest and incarceration could also be compared to estimates derived from probability samples. For the full samples in the Custom - 1 and Custom - 2 surveys, 22.0% (95% CI: 19.224.8%) and 24.0% (95% CI: 23.1-24.9%) self-reported arrested in their lifetime, respectively. Estimates of arrest are 30% for respondents in the Add Health survey by ages 24 to 34 (Barnes et al., 2015) and 30% for respondents in the NLSY97 by age 23 (Brame et al., 2012). Lifetime estimates of incarceration in a county jail or federal or state prison were 13.0% (95% CI: 10.715.3%) in Custom - 1 , 12.0% (95% CI: 10.0-14.0%) in Omnibus - 2 , and 13.5% (95% CI: 12.714.2%) in Custom - 2 . Estimates of incarceration vary widely in prior research, depending on birth cohort and measurement, ranging from 6% to 19% (Bovell-Ammon et al., 2021; Enns et al., 2019; Nakic et al., 2022; Roehrkasse &amp; Wildeman, 2022). But our findings most closely approximate Nakic et al.'s (2022) lifetime incarceration estimate of 11.4% from the National Epidemiological Survey on Alcohol and Related Conditions-III, a probability sample of 36,309 adults.\n\n\n## DISCUSSION\n\n\nTwenty-five years ago, in Schmitten, Germany, an interdisciplinary group of about 40 researchers began meeting to discuss an issue that cut across large cities in Europe: the emergence of troublesome youth groups that resembled American street gangs (Klein et al.,\n\n2001). At the time, theoretical and empirical knowledge on this topic was found primarily in the United States, but this group sought to change that by forming the Eurogang Program of Research. The program has accomplished much, assembling over 250 international scholars spanning the humanities to the behavioral sciences; organizing 22 international workshops; developing five working groups; designing, pretesting, and translating several open-access research instruments; publishing six edited volumes; and, critically, advancing the first consensus definition of a gang (https://eurogangproject.com) (Esbensen &amp; Maxson, 2018). Yet one of the central aims that unites Eurogang has never truly materialized: cross-national, comparative research.\n\nTo be fair, there are strong examples of cross-national comparative research undertaken in the spirit of Klein's (2005) call for it (e.g., Esbensen &amp; Weerman, 2005; Urbanik et al., 2020). The problem is that this work entails post-hoc rather than a priori comparative research designs, meaning scholars piece together overlapping themes or harmonize items across survey instruments from distinct sites instead of deliberately coordinating and simultaneously executing a research agenda from the onset; as Maxson and Esbensen (2016, p. 9) described it, the raison d'etre of the Eurogang Program of Research. These issues are particularly acute when it comes to population-representative data on gang activity at the national level. To illustrate with an exaggerated example, we cannot confidently assert that the United States has more gang activity than the United Kingdom-or any other country, for that matter.\n\nEnter the online opt-in panel research design. From the outset, we did not expect this methodology to serve as a panacea. However, it was worth investigating its potential to gather data on gang membership, especially given that the three leading U.S. data sources-Add Health, NLSY97, and NYGS-benefit from probability sampling but are also biased, costly,\n\nobsolete, outdated, or restricted in scope. The current study was designed to assess the viability of generating national estimates of gang activity in the United States using an online opt-in panel survey research design. Samples drawn from online opt-in panels offer criminologists several advantages, including flexibility, accessibility, customizability, timeliness, and affordability (Shi &amp; Roche, 2024). Over 13 months, we contracted with YouGov to field four surveys to over 13,000 respondents. Each survey was completed-from project setup and programming to the delivery of the codebook and dataset-within four weeks. Costing approximately $1 per personminute and targeting specific demographic groups with customized questions, this research design presents clear benefits. But are online opt-in panels capable of yielding trustworthy population and relational inferences?\n\nOur conclusion is one of cautious optimism. There is clear evidence that online opt-in panels capture the hard-to-reach population of lifetime gang members-381 respondents selfreported across the four surveys. This methodology provides a novel source for uncovering knowledge about a potentially wide range of gangs and gang activity in the United States, bypassing law enforcement biases and limitations baked into traditional survey methods.\n\nHowever, the population and relational inferences reached in these four surveys are reasons to exercise caution. We interpret these findings as providing mixed evidence. Estimates of the prevalence of lifetime gang membership ranged from 2.0-6.2%, lower than anticipated from the literature, particularly the NLSY97, which includes lifetime estimates through emerging adulthood and uses a more restrictive definition of a gang in its prompt; the wider age range in our study offered the opportunity to capture later-life gang onset. Still, cohort and period effects are likely at work because gangs proliferated during the 1980s and 1990s (Klein &amp; Maxson, 2006). Across all four samples, consistent with expectations, lifetime gang membership was\n\ngreater among more recent than later generations. These findings quell some concerns that online opt-in panels produce lower rates of lifetime gang membership.\n\nYet, the observation that custom surveys systematically underestimate lifetime gang membership compared to omnibus surveys gives us pause. Additional panels beyond the four presented here are required to determine if this is truly an empirical regularity. Several studies have leveraged YouGov's services to infer the prevalence of issues such as victimization, sex crimes, and non-fatal gun use (Adhia et al., 2021; Hamilton-Moseley et al., 2023; Henry &amp; Umbach, 2024). While these studies acknowledged the potential for selection bias, they nonetheless produced estimates consistent with prior research in their respective domains.\n\nStill, if custom surveys-which include a consent page with disclosure the survey themes-lead to systematic non- participation among hard-to-reach populations, this raises valid questions about their utility for population-level inferences. This issue appears to stem from sampling selection rather than survey methodology. To address concerns about item placement, for example, we randomized the gang membership question in Custom - 2 to appear either at the beginning or end of the survey. The probabilities were statistically indistinguishable (beginning = .0265, end = .0216; p = .175), suggesting item placement had no significant effect. Ultimately, researchers must weigh the cost-efficiency tradeoffs of survey design. Based on our findings, we recommend criminologists with comparable interests allocate resources to support a more extensive custom survey while simultaneously embedding a smaller set of key behavioral or social items in an omnibus survey.\n\nWhile online opt-in panels capture lifetime gang members, even if underestimated, the relational inferences align closely with findings in the gang literature. Demographic disparities were mixed across surveys. Males were overrepresented in gangs in all four surveys, consistent\n\nwith qualitative and quantitative research on gangs (Decker et al., 2022). Racial/ethnic differences were inconsistent in the omnibus and first custom surveys; however, the prevalence of White, Black, and Hispanic gang membership observed in the second custom survey was in line with NLSY97 and Add Health (Decker et al., 2022, p. 36). Except for growing up in a single-parent household, which performed as expected, socioeconomic correlates were generally in the right direction, but not consistently different statistically. If anything, the self-reported gang members were more affluent than expected, perhaps indicative of survivorship bias in the samples. All ecological and legal correlates operated as expected, whether conceptualized as causes or consequences of gang membership. Self-reported lifetime gang members were more likely to grow up in gang neighborhoods and where gunshots occurred; they also reported greater lifetime rates of victimization, arrest, and incarceration. Equivalencies in these known correlates would have otherwise undermined confidence in using online opt-in panels for hard-to-reach populations.\n\nOnline opt-in panels have offered the field of criminology incredible value, perhaps best realized in the context of public opinion (e.g., Burton et al., 2020; Densley et al., 2024; Graham et al., 2021; Schutten et al., 2022). Researchers have begun to address questions concerning population and relational inferences with these data (Schutten et al., 2024; Semenza et al., 2023), illustrating their strengths and drawbacks. Our contribution to this field is determining whether online opt-in panels can effectively capture hard-to-reach populations. This is important because criminologists aim to understand and respond to many specialized groups that are difficult to observe in population-representative surveys, such as individuals involved in domestic extremism, drug trafficking, outlaw motorcycle groups, organized crime, and other collectives. Survey methodology has been a boon for gang research, from the Causes and Correlates\n\nlongitudinal studies to the first and second evaluations of the Gang Resistance Education and Training program (Gravel, 2024).\n\nDespite mixed findings, we remain cautiously optimistic. Online opt-in panels should not supplant high-quality probability samples derived from housing units, schools, or police, but they do provide a low-cost, flexible, timely, and valid complementary source of information. By demonstrating a representative survey of gang involvement is achievable, we hope this research encourages future comparative proposals to pursue similar goals and challenges, driving innovation and progress in criminology. We suspect that such methodology can be especially valuable to advance the core aims of the Eurogang Program of Research, given that YouGov's panel spans dozens of countries, including in Europe and Latin America.\n\n",
         "Criminologists maintain a vested interest in hard-to-reach populations, such as active offenders, former prisoners, and affiliates of criminal enterprises. For five decades, policymakers and researchers have sought national estimates of gang activity. Traditional methods, such as surveys sampling law enforcement agencies or youth populations, have provided valuable insights into gang activity in the United States. However, these approaches face limitations, including bias, obsolescence, high costs, outdated data, and restricted scope. This study examines the potential of online opt-in panels to studying gang populations. Contracting with YouGov, we administered four surveys to 13,148 respondents between January 2023 and January 2024, measuring lifetime gang membership and its correlates. Lifetime gang membership estimates ranged from 2.0% to 2.4% in custom surveys and 5.3% to 6.2% in omnibus surveys. While demographic and socioeconomic correlates showed mixed results, ecological and legal correlates consistently aligned with expectations based on prior research. Our findings suggest cautious optimism about the utility of online opt-in panels for studying hard-to-reach populations like gang members and advancing cross-national, comparative research in line with the Eurogang Program of Research. These panels offer advantages such as cost-efficiency, accessibility, and timeliness, but further validation is necessary to establish their reliability and validity for population-level estimates.",
         ""
        ],
        [
         "44",
         "44",
         "## Introduction\n\n\nWhich body weight is viewed as ideal? Which range of body weight is socially accepted? Who is seen as 'too thin' and who is seen as 'too heavy'? The desire to be perceived by others as healthy and attractive is near universal. But these questions are not only private concerns that individuals have about their own body weight. These questions are also relevant to policymakers and practitioners concerned with public health, eating disorders, and large population groups that are overweight and obese, but also underweight.\n\nIn light of their personal and societal relevance, media, research, and policy have been occupied with these questions for decades. 1, 2, 3, 4, 5 Answers to these questions invoke social body weight norms (BWN) as a societal phenomenon: Normative evaluations about what body weight is commonly considered ideal and what body weight is within the socially accepted range, i.e., commonly considered neither too thin nor too heavy. Although different terms are used across disciplines, social BWN are typically understood as an aggregation of individual beliefs about how thin or heavy individuals (ideally) ought to look like. Those who comply with BWN are socially rewarded. Those who deviate are socially sanctioned. 6, 7\n\nThe unit of aggregation is commonly denoted as a reference group representing a context in which individuals engage in social comparisons and form assumptions about body weight that is empirically common (descriptive norm) and considered ideal and accepted (injunctive norm).  Most commonly, individuals compare themselves to others of their own 7 age and sex, to others of the opposite sex, and to others with similar visible characteristics such as ethnicity. 8, 9 Social BWN have been studied in specific and restricted social contexts, including school classes, colleges, and friendship networks. The individual and social importance of BWN at a more general, societal level is widely acknowledged, but not yet sufficiently addressed in empirical research. Extant knowledge about social BWN relies on selective and non-representative data sources, such as mass media, 10, 11 surveys among undergraduate students and in other convenience samples, 12, 13 and ethnographies conducted\n\nin the United States and European countries. 14, 15, 16 Although it is well-known that results from non-representative data can differ strongly from results found in population-based probability samples, previous studies commonly elevate their construct of interest - social BWN - and their conclusions to the societal level,  evident from common claims about 'thin and possibly underweight' 13 body weight ideals and a strict 'thinness norm' 7, 17, 18 especially for women in Western societies (i.e., US and Europe). Such claims are largely unquestioned in the literature and are commonly used as a starting point, main motivation, and as prominent explanatory factors in studies on causes and consequences of eating disorders and obesity.\n\nAs these claims are not based on representative population data, it remains unclear whether they accurately reflect contemporary societal beliefs and expectations about body weight. Is it true that social BWN are 'thin and possibly underweight'? 13 Is it true that social BWN are strict and hence exclude large population groups from the accepted range of body weight?\n\nIn this study, we draw on representative population data that allow us to empirically evaluate these claims and their underlying narrative of a strict thinness norm governing ideal and accepted body weight . We obtained these data from a showcase-winning project funded by the Open Probability-Based Panel Alliance (OPPA), which yielded established and novel measures of social BWN in three large-scale probability-based samples representative of the adult population in the US (UAS; age 18-84), Germany (GESIS Panel; age 24-74), and the Netherlands (LISS; 18-84). In the present study, we present the first national and crossnationally comparative profile of social BWN. .\n\n\n## Results\n\n\nWe present population-based profiles on two dimensions of social BWN. First, the ideal BWN denote the body weight that is commonly considered beautiful, attractive, healthy, desirable, and socially rewarded. Second, the accepted BWN denote the range of body weight that is commonly considered as neither too thin nor too heavy, and hence not socially sanctioned. Within both dimensions, we distinguish between actual and perceived BWN. Actual BWN denote respondents' own views about what body weight is ideal and what range of body weight is within the accepted range (i.e., who is not too thin and not too heavy). Perceived BWN denote respondents' views about what body weight others find ideal and what range of body weight others find acceptable. Although actual and perceived BWN are related, distinguishing both components is important. Research on the psychological consequences of BWN has found perceived BWN to be even more relevant than actual BWN. 7, 18, 19, 20 Conversely, actual BWN may be more relevant than perceived BWN when it comes to social consequences, as individuals are unlikely to sanction (i.e., treat unequally or disapprove of) those whom they actually consider ideal or within the accepted range.\n\nFor all survey questions capturing these types of social BWN, respondents rated linedrawn silhouettes on a figure rating scale (FRS), an extended version of the most commonly used FRS initially developed by Stunkard, Sørensen, and Schulsinger in 1983 (Figure 1). 21, 22 .\n\nWe first present results for ratings of ideal body weight (Figures 2-5), followed by results for the accepted range of body weight (ratings of figures looking too thin or too heavy) (Figures 6-9). For both dimensions, we show age-specific distribution-plots of actual BWN for women and men along with distribution-plots of the differences between actual and perceived BWN. Each of the figures shows predicted probabilities estimated by linear probability models described in S1.\n\nFigure 1: Original and Extended Figure Rating Scales. The initial 9-silhouette scale was extended to 11 silhouettes by adding one silhouette representing higher level of underweight and one representing higher level of overweight. We extended the scale with permission and approval of the author of the initial scale (T. I. A. Sørensen). Extending the initial FRS was necessary to capture the full range of body weight that has become prevalent across the globe after the initial scale had been published in 1983. In addition to the 11 categories, respondents could also select the option 'None'.\n\n<!-- image -->\n\n## Ideal BWN for female figures\n\nFigure 2 summarizes the results on actual-ideal BWN by sex, age, and country. As visible from the ratings of own ideal figures, there is no evidence for a strict thinness norm on female body weight. Underweight- and very slender looking female figures (#F1, #F2, and even #F3) are rarely chosen as ideals by women, rarely chosen as ideals by men, and rarely chosen as ideals across all age groups and in all countries. Instead, actual-ideal BWN for females are concentrated in figures #F4, #F5 and #F6, corresponding to BMI levels of approximately 21.5, 24.5, and 27.5 (see Table S3a). Taken together, figures #F4, #F5 and #F6 have a cumulative probability of more than 85% of being rated as the ideal female figure in each of the countries, sexes, and age groups.\n\nFigure 2. Predicted probabilities of rating one of the 11 female figures as actual ideal (i.e., own ideal) by age for women and men. Source: GESIS Panel, LISS, UAS. Predicted probabilities were calculated in linear probability models, controlling for survey device, survey mode (in the German sample only) and for order of the figures on the FRS (see S1).\n\n<!-- image -->\n\nActual-ideal BWN for females are slenderer in Germany, especially when rated by women, slightly heavier in the U.S., and noticeably heavier in the Netherlands. In all countries, women tended to choose slenderer female ideal figures than men, and younger age groups tended to choose slenderer female ideal figures than older age groups. Yet, the probability of selecting\n\nvery slender and underweight figures (#F1 and #F2) remained close to zero in all groups. The same is true for very heavy figures corresponding to strongly overweight or obese levels of BMI. As a result, the variance of actual-ideal BWN for females is rather small. A small variance is consistent with the idea of a strict norm. Yet, this variance is spread across normal-weight and slightly overweight female figures - inconsistent with the idea of a strict thinness norm.\n\nFigure 3 contrasts actual-ideal with perceived-ideal BWN for female figures. On the graphs, the bars point upward if figures where more frequently chosen as perceived-ideals than as actual-ideals; the bars point downward if figures were less frequently chosen as perceived-ideals than as actual-ideals. In terms of upward and downward directions, the resulting picture is almost fully consistent across sexes, countries, and age groups: People's perceived ideals are slenderer than people's actual ideals. In terms of mean differences, the largest contrast appears in the US where the difference between actual and perceived ideal BWN approaches 1 SD . The contrast is smaller in Germany and smallest in the Netherlands. Our data do not allow us to assess whether the prevailing narrative of a strict thinness norm has influenced people's perception. Yet, the data demonstrate a bias in perception: Norms on ideal female body weight appear slenderer to people than they are. Nevertheless, very slender or underweight-looking figures are rarely perceived as ideal in most subgroups.\n\nFigure 3. Difference between predicted probabilities of rating one of the 11 female figures as perceived ideal (i.e., most people's ideal) and actual ideal (i.e., own ideal) by age for women and men. The bars point upward if figures where more frequently rated as perceived-ideals than as actual-ideals; the bars point downward if figures were less frequently rated as perceived-ideals than as actual-ideals. Source: GESIS Panel, LISS, UAS. Predicted probabilities of rating most people's and own ideal figures were calculated in linear probability models, controlling for survey device, survey mode (in the German sample only) and for order of the figures on the FRS (see S1).\n\n<!-- image -->\n\n## Ideal BWN for male figures\n\nFigure 4 and Figure 5 show the equivalent set of results for actual-ideal male BWN and the contrast to perceived-ideal male BWN.\n\nFigure 4. Predicted probabilities of rating one of the 11 male figures as actual ideal (i.e., own ideal) by age for women and men. Source: GESIS Panel, LISS, UAS. Predicted probabilities were calculated in linear probability models, controlling for survey device, survey mode (in the German sample only) and for order of the figures on the FRS (see S1).\n\n<!-- image -->\n\nFigure 5. Difference between predicted probabilities of rating one of the 11 male figures as perceived ideal (i.e., most people's ideal) and actual ideal (i.e., own ideal) by age for women and men. The bars point upward if figures where more frequently rated as perceived-ideals than as actual-ideals; the bars point downward if figures were less frequently rated as perceived-ideals than as actual-ideals. Source: GESIS Panel, LISS, UAS. Predicted probabilities of rating most people's and own ideal figures were calculated in linear probability models, controlling for survey device, survey mode (in the German sample only) and for order of the figures on the FRS (see S1).\n\n<!-- image -->\n\nThe overall picture is similar to that obtained for women: no evidence for a strict thinness norm on male body weight ideals; very slender and very heavy figures are rarely chosen as ideals; the same sex (here: men) tends to choose slenderer ideals and younger age groups tend\n\nto choose slenderer male ideals than older age groups (sex and age differences are somewhat smaller than for female ideals); and perceived male ideals are slenderer than actual male ideals - a contrast that is once again most pronounced in the US.\n\nThe cross-national gradient in female ideals is not replicated in male ideals: Mean ideals are similar across the three countries. Actual-ideals are even slightly thinner in the Netherlands, a result that contrasts with heavier BWN on actual-ideal female figures. A further notable difference is the larger variance of male ideals. In all countries and subgroups studied, actual-ideal BWN for male figures are less strict than for female figures, as indicated by larger SD s.\n\n## Accepted BWN for female figures\n\nBWN are not only defined by which body weight is considered ideal, but also by which range of body weight is socially accepted. This range is defined by figures that are commonly rated as neither too thin nor too heavy. Figure 6 and Figure 7 show the results for actual-accepted female figures and the contrast to perceived-accepted female figures.\n\nOur previous findings on strict but not overly thin norms on female body weight are corroborated by the narrow valleys in the bar graphs of Figure 5. Narrow valleys indicate that only a small range of female figures is commonly accepted as neither too thin nor too heavy. Very slender female figures #F1, #F2, corresponding to BMI levels of less than 19.5, are rated 'too thin' by the vast majority in each country and in each subgroup. This rating extends to figure #F3 (BMI ~ 20.5) and partly even to figure #F4 in the Netherlands. U.S. and German raters are less decided over figure #F3, with one-third to one-half considering this figure 'too thin', and overwhelmingly consider #F4 within the accepted range.\n\nTurning to figures considered 'too heavy', we observe that starting from figure #F7, heavy and very heavy figures are consistently excluded by a majority from the accepted range of female body weight. Female figure #F6, corresponding to a BMI level of about 26, is\n\nconsistently rated within the accepted range by a majority, although substantial shares of\n\nGerman and U.S. raters (only one-fifth to one-third) consider this figure 'too heavy.'\n\nFigure 6. Predicted probabilities of rating each of the 11 female figures as actual too thin/ too heavy by age for women and men. Source: GESIS Panel, LISS, UAS. Predicted probabilities were calculated in linear probability models, controlling for survey device, survey mode (in the German sample only) and for order of the figures on the FRS (see S1). Predicted probabilities of rating figures F#1-F#4 as too heavy and figures F#5-F#11 as too thin as well as predicted probabilities of rating 'none' of the figures as too thin or too heavy are not displayed for better readability of the results. These probabilities were very small and usually close to zero in each subsample.\n\n<!-- image -->\n\nFigure 7. Difference between predicted probabilities for rating each of the 11 female figures as perceived too thin/ too heavy figures (i.e.,  most  people's  too  thin/too heavy  figures)  and  actual  too  thin/  too  heavy  figures  (i.e.,  own  too  thin/too heavy figures) by age for women and men. The bars point upward if figures where more frequently rated as perceived too thin/heavy than actual too thin/ heavy figures; the bars point downward if figures were less frequently rated as perceived too thin/too heavy than actual too thin/too heavy. Source: GESIS Panel, LISS, UAS. Predicted probabilities of rating most people's and own too thin/ too heavy figures were calculated in linear probability models, controlling for survey device, survey mode (in the German sample only) and for order of the figures on the FRS (see S1). Predicted probabilities of rating figures F#1-F#4 as too heavy and figures F#5-F#11 as too thin as well as predicted probabilities of rating 'none' of the figures as too thin or too heavy are not  displayed  for  better  readability  of  the  results.  These  probabilities  were  very  small  and  usually  close  to  zero  in  each subsample.\n\n<!-- image -->\n\nCompared to actual-ideal BWN, age and sex differences in actual-accepted BWN are similar in direction but less pronounced. Similar to measures of body weight ideals, actual ratings of 'too thin' and 'too heavy' figures are related to individuals' body weight, while perceived ratings are not (see Figure S2).\n\nFigure 7 shows the contrast between actual-accepted and perceived-accepted BWN on female figures. Once again, this contrast is most pronounced in U.S. raters, and most noticeable to the left and right of figure #F4. To the left, downward bars indicate that the slenderer figures #F2 and #F3 (corresponding to BMI ~ 18 and ~ 19.5, respectively) are more often perceived as located within the accepted range than the higher actual ratings of 'too thin' reveal. To the right, upward bars indicate that the heavier figures #F5, #F6, and #F7 (corresponding to BMI ~ 24, ~26 and ~29) are less often perceived as located within the accepted range than the lower actual ratings of 'too heavy' reveal. When moving towards the edges of underweight and obesity, actual and perceived ratings converge. Overall, the U.S. pattern is consistent with the previous conclusion: Accepted BWN on female body weight appear thinner to people than they are. In Germany and in the Netherlands, actual-accepted and perceived-accepted BWN differ less.\n\n## Accepted BWN for male figures\n\nFigure 8 and Figure 9 show the equivalent set of results for the actual-accepted range of male figures and the contrast to the perceived-accepted range of male figures. The most obvious contrast to female figures are broader valleys. This finding corroborates the conclusion that norms on male body weight are less strict, a conclusion that applies in all countries and in all subgroups studied. The picture is notable for the absence of major differences between countries, between sexes, and across age groups.\n\nFigure 8. Predicted probabilities of rating each of the 11 male figures as actual too thin/ too heavy by age for women and men. Source: GESIS Panel, LISS, UAS. Predicted probabilities were calculated in linear probability models, controlling for survey device, survey mode (in the German sample only) and for order of the figures on the FRS (see S1). Predicted probabilities of rating figures F#1-F#5 as too heavy and figures F#6-F#11 as too thin as well as predicted probabilities of rating 'none' of the figures as too thin or too heavy are not displayed for better readability of the results. These probabilities were very small and usually close to zero in each subsample.\n\n<!-- image -->\n\nFigure 9. Difference between predicted probabilities for rating each of the 11 male figures as perceived too thin/ too heavy figures (i.e., most people's too thin/too heavy figures) and actual too thin/ too heavy figures (i.e., own too thin/too heavy figures) by age for women and men. The bars point upward if figures where more frequently rated as perceived too thin/heavy than actual too thin/ heavy figures; the bars point downward if figures were less frequently rated as perceived too thin/too heavy than actual too thin/too heavy. Source: GESIS Panel, LISS, UAS. Predicted probabilities of rating most people's and own too thin/ too heavy figures were calculated in linear probability models, controlling for survey device, survey mode (in the German sample only) and for order of the figures on the  FRS (see S1). Predicted probabilities of rating figures F#1-F#5 as too heavy and figures F#6-F#11 as too thin as well as predicted probabilities of rating 'none' of the figures as too thin or too heavy are not displayed for better readability of the results. These probabilities were very small and usually close to zero in each subsample.\n\n<!-- image -->\n\nSimilar to the other results, ratings of the actual-accepted range of male body weight are related to individuals' body weight, while ratings of the perceived-accepted range are not (see Figure S2). Yet, when comparing Figure 7 and Figure 8, we observe relatively small differences between actual-accepted and perceived-accepted BWN. For the U.S., this pattern contrasts with the gradient found in female figures, leading to a nuanced conclusion: For female body weight, but less so for male body weight, accepted BWN appear thinner to people than they are.\n\n\n## Discussion\n\n\nThis study presents nationally representative and cross-nationally comparative profiles of social body weight norms (BWN). Data collected from large-scale probability samples in the US, Germany, and the Netherlands offer new answers to pertinent questions of high individual and societal relevance: Which body weight is viewed as ideal? Which range of body weight is socially accepted? Who is seen as 'too thin' and who is seen as 'too heavy'?\n\nPrevious answers to these questions relied on non-representative data collected from mass media, convenience samples, and ethnographic sources, mainly concluding that social BWN in modern societies are strict and thin. The notion of a strict and possibly underweight thinness norm - particularly on the female body - remains largely unquestioned in the research literature and has become firmly entrenched in the media and in the public discourse.\n\nOur representative population data allowed us to examine if the notion of a strict thinness norm accurately reflects beliefs and expectations about body weight: Is it true that social BWN are strict, allowing for only a narrow range of socially accepted body weight? And is it true that social BWN are thin, endorsing body ideals that are very slender and possibly underweight?\n\nOur answer to the first question is yes, but our answer to the second question is no. Hence, our main conclusion is that social BWN are strict, but not thin. This conclusion\n\napplies for female and male raters, for female and male bodies, in all age groups, and in all countries. The prominent notion of a very thin female ideal is not supported by populationbased data. The probability of selecting very slender and underweight figures as female ideals is small in all countries and in all subgroups studied. The range of female figures considered by a majority as not too thin but also not too heavy, however, was narrow: Not only underweight but also slender female bodies at the lower bond of normal BMI are commonly rated as 'too thin'; not only very heavy or obese but also moderately overweight female bodies are commonly rated as 'too heavy.' This means that although the notion of a thin norm is not supported, the notion of a strict norm on female body weight is supported at population level.\n\nFor norms governing male body weight, results are similar regarding the uncommonness of thin ideals. A notable difference is that social BWN are less strict for men than for women. In all countries and all subgroups studied, actual-ideal and accepted-ideal BWN are less strict for male bodies.\n\nConsidering the contrast between our results and the results of previous research based on non-representative samples, we find that a key descriptive conclusion - namely the central tendency of 'thin' social BWN - does not replicate in our representative samples. Several relational conclusions from previous research, however, do replicate: men's female ideal is heavier than women's female ideal; social BWN are stricter for women than for men; and social BWN are thinner and stricter for younger age groups. 13, 15, 16, 29, 24 The contrast between convenience-sampled data and population-representative data found in our study is consistent with findings from survey methodology, showing that in non-representative samples, descriptive distributions are often strongly biased, whereas relational conclusions about two or more variables are often robust. 25\n\nUnderstanding social BWN requires us to distinguish between what people believe the actual BWN - and what people believe others believe - the perceived BWN. Our findings\n\ndemonstrate that people perceive body weight ideals to be thinner than they are. This contrast between actual and perceived BWN was most pronounced in the U.S. and concentrated in questions about the ideal female body weight.\n\nWe cannot explain the discrepancy between actual and perceived BWN with our data, but the evidence is suggestive: The ubiquitous notion of a strict thinness norm governing body weight ideals, and especially ideals about female bodies, may influence people's perception. Even if a strict thinness norm is not real, it might be perceived as real and therefore entail real consequences, as stipulated by the Thomas theorem. 26 This applies particularly to the perception of a strict thinness norm on female body weight in the U.S. If women perceive this norm as real, it may entail consequences for the risk of eating disorders, body dissatisfaction and psychological distress. However, we note that although differences between the actual BWN and perceived BWN were substantial, only a minority - albeit substantial in size perceived very slender or underweight-looking figures as 'most people's ideal.'\n\nOur results demonstrate the relevance and contribution of population-based research on social BWN to establish a representative baseline against which the dominant narrative can be evaluated. Our findings question this narrative and call for further population-based research to improve our understanding of social BWN, their representation in the media, and their perception in the public. An improved scientific understanding of social BWN can potentially reduce harmful consequences, in particular those associated with biased perceptions of a thinness norm that may not be real.\n\nWe recommend that public debates about social BWN draw on research findings pertaining to entire populations and reflect prevalent views, rather than on those pertaining to selective groups who endorse thin ideals that are shared by few and unattainable to many.\n\nWith the present study, we took initial steps towards uncovering body weight ideals and beliefs about body weight as population-level phenomena. Future research needs to continue mapping out social BWN across the globe using representative and comparative data\n\nconsidering entire populations but also relevant demographic, economic, and cultural distinctions, such as socioeconomic status and ethnicity. Longitudinal data are needed to understand the origin of age differences found in the cross-sectional data of the present study, in particular to separate age effects from cohort effects. Do social BWN change as individuals age or do younger cohorts embrace thinner BWN than older cohorts? Future studies also need to refine the assessment of social BWN with greater attention to further factors related to body weight, such as muscularity, physical fitness, and the distribution of body fat (e.g., waist-tohip ratio and shoulder-to-waist ratio). Finally, research needs to assess individual and societal consequences of social BWN. What are the shares of a population that conform to or deviate from the social BWN? What are psychological and social consequences of belonging to those who are considered 'too thin' or 'too heavy'?\n\n\n## Materials and Methods\n\n\nThe study was preregistered at Open Science Framework. Anonymized registration for the review purposes can be viewed under the following link:\n\nhttps://osf.io/26dj8/?view\\_only=bf3203400f7b4136b5141f7bafa9bb13\n\n",
         "What body weight is viewed as ideal and socially accepted? This study presents the first population-based profile of social body weight norms, drawing on data from the US, Germany, and the Netherlands (N = 7,715). Measurements of norms are based on ratings on a validated figure rating scale. Across all study populations, male and female figures representing the range of normal weight to slight overweight were commonly rated ideal and neither too thin nor too heavy. Heavier norms were found in older people, in men, and more commonly in the Netherlands than in Germany and the US. People generally perceived social body weight norms to be thinner than what actual ratings showed. This perception bias was most pronounced in the US. These results establish a population-representative baseline of social body weight norms, contradicting the narrative of a thinness norm pervading Western societies.",
         ""
        ],
        [
         "45",
         "45",
         "## 1 Introduction\n\n\nEurope is at a 'now-or-never' moment in the global AI race, squeezed between the United States' massive venture-capital ecosystem and China's scaleoriented, top-down drive. At this crossroads, as AI is rapidly converging with complementary and synergistic technologies, such as quantum computing, biotech, VR/AR, 5G/6G, robotics, advanced materials, and high-performance computing, industries andgeopolitical balances can be radically reshaped . Drawing on Europe's collaboration frameworks (such as Horizon Europe) and established regulatory instruments, such as GDPR, AI Act, DSA, Data Governance Act [1, 2, 3, 4], as well as its industrial backbone of 'hidden champions', this article offers a targeted, executable roadmap for Europe's technology lead in AI. We believe now is the time to accelerate as European industries push for swift AI adoption [5] and the AI Action Summit in Paris sparked record investments of = C150billion from private companies plus another = C50 billion from the InvestAI Initiative [6, 7].\n\nWeemphasizethree urgent pillars for Europe's competitiveness:\n\nSemiconductor Capacity and GPU-Accelerated HPC. Europe's share of global semiconductor production is under 10%, while its GPU resources significantly trail those of the US and Asia [8]. Ac-\n\n<!-- image -->\n\ncording to recent HPC rankings, Europe's presence in the TOP500 is commendable but still considerably overshadowed by both the US and China [9, 10, 11]. Rapidly bridging this gap via new foundry investments, strategic foreign partnerships, and open-source hardware consortia is indispensable for technological sovereignty. We advocate for market-based incentives and competitive frameworks rather than direct state control.\n\n## Integrate and Strengthen Existing Frameworks.\n\nModeled on the successful coordination practices of leading innovation hubs, an innovation-focused European AI Coordination Council would serve as an advisory body to unify standards, tackle fragmentation, and pilot light-touch regulatory sandboxes for quick prototyping. Leveraging the AI Act, it would also promote a voluntary and incentive-driven AI Trust Certificate through third-party certifications, upholding safe and responsible systems.\n\nCompetitive, Market-Facilitated Support for SMEs and Mid-Sized Innovators. Europe's highimpact growth potential depends on bridging the 'Valley of Death' [12] through competitive incentives such as tax credits, matching funds, and innovation vouchers rather than heavy direct subsidies. By linking universities and academic research to SMEs in realworld 'living labs', and leveraging privileged access to sandboxes under the EU AI Act, Europe can convert its academic excellence into global market results.\n\nTalent retention and recruitment are equally decisive in achieving full competitive power in AI and related fields. We propose university-industry programs , e.g., incentivized through matching funds, flexible R&amp;D career paths, and targeted immigration reforms to secure a pipeline of world-class talents and AI experts. Meanwhile, dynamic but practical governance , covering sector-specific AI audits, labeling of high-risk systems, and sector-specific compliance sandboxes, ensures that rigorous standards do not stifle Europe's ability to innovate swiftly.\n\nFinally, Europe must forge global alliances to shape rules and guardrails around generative AI (AI systems that create content such as text, images, or audio) and foundation models (versatile, large-scale models that can be adapted to multiple downstream tasks), quantum, and next-gen connectivity. By weaving together these elements, ambitious legislation, robust infrastructure, smart regulation, and a unifying vision, Europe can transcend its role as a 'regulatory first mover' and become the definitive global catalyst for responsible AI.\n\nMoreover, by emphasizing Europe's own strengths, this strategy demonstrates how Europe can differentiate itself from US venture-capital-driven rapid iteration and from China's top-down scale deployments.\n\n\n## 2 The Global AI Landscape and Europe's Position\n\n\n\n## 2.1 Comparative Dynamics\n\n\nThe pursuit of AI leadership is at a genuine tipping point: advancements in Generative AI, Quantum Computing, VR/AR, 5G, 6G, and Robotics increasingly amplify one another, raising global stakes. For Europe, this is not an optional race but a strategic imperative . The United States and China together pour hundreds of billions into scaling AI research and deployment, exemplified by the $500 billion Stargate private-joint venture [13], fully aware that AI's economic and geopolitical impact will be pivotal for decades. Europe must match this with bold, targeted, and urgent commitments and unwavering resolve .\n\nUnited States. Since 2022, the US AI landscape has evolved dramatically. In 2022, federal spending on AI reached $3.3 billion while private investments hit $47.4 billion, and by 2023 these investments had surpassed $67 billion. This surge spurred a vibrant startup ecosystem, raising nearly $50 billion [14, 15, 16]. The deployment of the Frontier supercomputer in 2022, e.g., achieving 1.1 exaflops, set the stage for nextgeneration systems like Aurora and El Capitan that are now revolutionizing high-performance computing for AI research [9]. Concurrently, landmark regulatory actions, including the NIST AI Risk Management Framework and a comprehensive executive order on AI safety, established robust guidelines for ethical and secure AI development [17, 18]. Together, these initiatives have reinforced the US position as a global leader in AI and set international standards for investment, innovation, and governance.\n\nChina. Since 2022, China's AI landscape has experienced rapid expansion fueled by significant state-led investments and a vibrant private sector. Just recently, China unveiled a 1 trillion yuan ( ≈ $140 billion) financing plan to boost AI development, while private funding in 2023 reached roughly $7.8 billion [19, 20]. Major tech giants such as Baidu, Alibaba, Tencent, and Huawei have advanced homegrown AI models, e.g., Baidu's ERNIE Bot, Alibaba's Tongyi Qianwen, and Tencent's Hunyuan, which are transforming indus-\n\ntries from autonomous driving to e-commerce. Concurrently, China has bolstered its high-performance computing infrastructure with exascale systems such as Sunway OceanLight and Tianhe-3, spurring robust domestic AI chip development in response to US export controls [21]. Comprehensive regulatory measures, including algorithmic recommendation rules, deep synthesis regulations, and generative AI service controls introduced since 2022, have established a governance framework aligning AI growth with national priorities [22]. Together, these initiatives have cemented China's position as a serious global competitor in AI, narrowing the gap with the US while advancing its own innovation ecosystem.\n\nEurope. Europe's HPC and semiconductor deficits, compoundedbyscalingchallenges and the initial funding bottlenecks for flagship projects and startups like Mistral and AlephAlpha, threaten to undercut its regulatory leadership, e.g., GDPR, AI Act, DSA [23]. Annual AI-related venture capital investment in the EU is approximately eight times less than in the US and around 50% of China's investments [24, 12, 25].\n\nEurope's high-performance computing capacity (such as the LUMI system in Finland and Leonardo in Italy) is indeed considerable [11, 9]. Still, it is not sufficient for the requirements of cutting-edge AI training [26]. This shortfall is partly due to a fragmented infrastructure and a lack of investment in HPC resources over the years [27]. However, initiatives are underway to bridge this gap: the EuroHPC Joint Undertaking [10], national exascale projects like the JUPITER supercomputer [28], and new 'AI factories' are aimed at significantly boosting Europe's computing capabilities [11]. Furthermore, the recent introduction of DeepSeek-V3 [29], China's cost-effective AI model that has upended market expectations by delivering impressive performance at only a fraction of the investment, vividly demonstrates that breakthrough innovations in AI need not rely on enormous budgets. This disruptive development currently reinforces the AI race and offers Europe a renewed opportunity to capitalize on its strengths, thereby facilitating marketdriven innovation and private-sector leadership.\n\n\n## 2.2 Europe's Strengths are Europe's Dilemmas in the Age of AI\n\n\nRegulatory Pioneering. The GDPR showed Europe's capability to influence global data protection. Together with the AI Act, Europe is well-positioned to lead on responsible AI standards. However, Europe's AI governance model is increasingly being put to the test. Mario Draghi's 2024 report on the economic competitiveness of Europe warned that excessive regulation, unclear enforcement mechanisms, and burdensome compliance cause AI talent and investment to migrate out of the EU; while the AI Act aims to establish trust and accountability, critics argue that unclear enforcement mechanisms and complex compliance processes could deter smaller companies from using AI at scale [30, 31].\n\nHuman-centric Leadership &amp; Societal Commitment. European institutions spotlight algorithmic transparency, bias mitigation, and privacy [32], a stance increasingly valued worldwide. Transforming discussions into actionable measures necessitates standardized auditing protocols and industry-specific checklists, supported by a European AI Coordination Council and third-party auditing agencies following sector-specific best-practice frameworks.\n\nSimilarly, social responsibility, sustainability, and inclusion are ingrained in European business and governance models. Still, these ideals must manifest in large-scale pilots, living labs , and accessible AI tools for SMEs to translate high-level objectives into everyday economic gains.\n\nResearch Leadership. Europe is a research powerhouse and home to some of the world's leading universities and research institutions, which have been at the forefront of groundbreaking AI research. Innovations like Stable Diffusion [33], and transformative projects led by HuggingFace [34] and Mistral [35] exemplify Europe's extraordinary potential in artificial intelligence. However, despite these high-impact research achievements, the translation of academic breakthroughs into scalable, industrially relevant innovations remains marginal and slow. The gap between research and market application is widened by fragmented funding mechanisms, regulatory hurdles, and a lack of cohesive technology transfer frameworks [30, 31]. Consequently, while foreign tech giants rapidly commercialize cutting-edge AI innovations, Europe risks underutilizing its academic excellence and losing some of its brightest minds to more dynamic markets abroad. Over time, this disconnect between groundbreaking research and real-world application could significantly erode Europe's competitive edge in AI research.\n\nHidden Champions in the SME Landscape. Europe's Mittelstand (99% of businesses, employing twothirds of its workforce) often dominates niche global markets (e.g., industrial robotics, agritech). However,\n\nAI adoption among SMEs remains low, with barriers including:\n\n- · Lack of expertise : Many SMEs lack in-house AI specialists [36] and depend on external AI service providers.\n- · Cost constraints : AI implementation requires significant upfront investments, which most SMEs struggle to finance.\n- · Fragmented access to AI tools : Unlike in the U.S., where AI-as-a-service models dominate, European AI solutions remain sector-specific and less integrated.\n- · Lack of AI-related governance regulatory expertise : There is an urgent need for agile, forwardthinking governance models that balance regulatory and ethical imperatives, real-time risk management, and cross-border harmonization, enabling SMEs to adopt and scale AI solutions confidently.\n\nTo address these issues, the EU has initiated several actions:\n\nAI Scale-Up Fund: Grants and low-interest loans to overcome the 'Valley of Death' [12, 37].\n\nRegulatory Sandboxes: Sector-specific prototyping environments for high-risk AI use cases (e.g., healthcare, financial services) with accredited auditors overseeing reduced bureaucracy [38].\n\nLeverage Local Strengths and Regional Diversity: Identify strategies to encourage SMEs to localize AI solutions (e.g., advanced robotics for mid-sized factories), capitalizing on Europe's regional plurality [39].\n\nHowever, to fully unlock these possibilities, Europe must secure data and infrastructure sovereignty, underpinned by robust, GPU-accelerated high-performance computing that is readily accessible to SMEs and research institutions, alongside streamlined, forwardthinking compliance frameworks - all of this underlined with first-class educational and talent retention strategies. The reward: empowered 'hidden champions' that could propel Europe's AI-driven economic transformation in line with Europe's regulations.\n\n\n## 3 Strategic Imperatives for European AI Governance\n\n\nDespite world-class research, Europe lags behind the US and China in the commercialization, funding, and fundamental models of AI. While the US is leading with platforms like OpenAI and China is supporting large AI megaprojects, Europe's late start in largescale generative AI requires urgent reform . To secure its potential for trusted AI governance, Europe must streamline regulation to increase development agility and reflect sector-specific challenges and needs. In addition, Europe must boost investment and considerably expand access to computing power. Below, we propose concrete action points integrating prior regulatory frameworks with urgent on-the-ground needs.\n\n\n## 3.1 Integrate and Strengthen Existing Frameworks\n\n\nThough the EU has introduced holistic digital regulations (GDPR, AI Act, DSA, Data Governance Act), coherence, adaptability, and above all, the empowerment of large-scale industrial applications are paramount:\n\nInteroperable, Sector-Focused Rules. We believe it is crucial to have guidelines tailored to verticals such as healthcare, manufacturing, and creative industries, as each of these verticals comes with sector-specific challenges and needs. These vertical guidelines need to work together more efficiently with horizontal regulations. Risk and quality analysis, as well as corresponding measures for AI solutions, vary vastly across sectors and use cases. Therefore, and consistent with the AI Act, it is important to incentivize interoperability, including adoption of standards and industry best practices, by offering co-funded AI projects to Member States.\n\nTargeted Coordination Mechanisms. There is a need not only for investment in technological innovation, but also innovation in new types of institutions. Modeled after the successful coordination practices of leading innovation hubs, we propose the formation of a European AI Coordination Council (drawing inspiration from DARPA in the US) to serve as an advisory body to derive meaningful interoperability among the broad range of AI norms and standards (in close collaboration with industry experts) and unify them where possible, tackle fragmentation, and pilot light-touch regulatory sandboxes for quick prototyping in highrisk domains. Leveraging the AI Act, this Council would also promote a voluntary and incentive-driven AI Trust Certificate through third-party certifications and drive sector-specific best-practice frameworks for safe and responsible systems.\n\nRegulatory Learning In particular, we recommend recalibrating definitions and risk levels in 18-month regulatory review cycles for rapidly changing areas such as generative AI, AI- and quantum-computing-\n\nempowered search algorithms. By integrating structured feedback from industry, academia, and regulatory experts, and systematically synthesizing insights from distributed regulatory sandboxes, such an agile approach could help minimize lag, reduce uncertainty for innovators, and ensure that oversight keeps pace with technological change.\n\nGlobal Capacity-Building. We propose to engage not only with international bodies such as the OECD, G20, and specialized standard-setting organizations, but also to intensify collaborations with majority world countries. This can be achieved through university partnerships and initiatives facilitated by regional development banks and national development agencies to enhance bilateral knowledge exchange and build robust networks and communities of practice, such as current efforts to establish and connect AI Safety Institutes globally. This approach will help position European values and frameworks as de facto global benchmarks as we move from a technological to a regulatory arms race in the realm of emerging technologies.\n\n\n## 3.2 Achieve Technological Sovereignty through Industrial Policy\n\n\nEuropean AI success rests on hardware autonomy and dynamic R&amp;D:\n\nClosing the Semiconductor Gap. Via the Chips Act [40], Europe must aim to boost its share of global semiconductor production to at least 20%, relative to its economic scale, potential, and needs. The focus should be on GPUs and AI accelerators through opensource hardware consortia, new fabrication plants, and strategic alliances (e.g., joint ventures with non-EU foundries).\n\nHPCAcceleration. EuroHPC [11] remains crucial and an excellent initial example of Europe's commitment to developing world-class HPC infrastructure. However, Europe must considerably expand its GPUcentric computing capacity. As of 2024, Europe's representation in the TOP500 list of the world's most powerful supercomputers stands at roughly 28%, trailing the US and China [9]. For future-proof AI development and scale, it is crucial to encourage exascale and GPU-centric investments and regionally distributed HPC clusters accessible to SMEs and research institutions.\n\nFederated Data Platforms. Building on the practical insights from the Gaia-X Project [41], Europe should incentivize the development of federated data platforms that enforce open standards and userfriendly APIs to enable secure, real-time data sharing.\n\nThese platforms must integrate HPC frameworks for distributed training on local datasets, ensuring data sovereignty and privacy while providing advanced AI capabilities to SMEs and research institutions.\n\n\n## 3.3 Competitive, Market-Facilitated Support for SMEs and Mid-Sized Innovators.\n\n\nWe believe that Europe's high growth potential depends on effectively bridging the 'valley of death' through competitive, market-based financial mechanisms rather than high direct subsidies. To achieve this, we recommend the following targeted measures to reduce barriers to early-stage investment and promote breakthrough innovations.\n\nTax credits. Tax-related incentives can lower the effective costs of innovation by reducing the financial burden on companies investing in advanced AI research and development. These credits reduce risk and incentivize both startups and established companies to allocate resources to breakthrough technologies, thus accelerating progress and market impact.\n\nMatching funds. Such co-investments could play a crucial role by leveraging public investment with private capital. They can ensure that public funds are used efficiently and serve as a catalyst for projects with high market potential, thereby not only boosting the confidence of private investors but also helping to secure the capital needed to bring innovative ideas from research prototypes to market maturity.\n\nInnovation vouchers. This kind of support could serve as a practical policy tool, granting SMEs direct access to specialized expertise and essential resources. By funding short-term or high-impact projects, such vouchers can be used to mitigate regulatory or financial risks of early-stage innovation, enabling firms to test and refine their ideas cost-effectively and fostering sustainable growth.\n\nLinking universities and academic research to SMEs. Fostering academic-industry collaborations through specific funds and real-world living labs would establish a dynamic platform for rapidly translating theoretical findings and research breakthroughs into market-ready applications. A close collaboration between academia and industry not only aligns research with practical needs and competitive market conditions but could also catalyze the commercialization of academic excellence towards a resilient innovation ecosystem in Europe. Furthermore, fostering a venture-friendly ecosystem by streamlining IP transfer rules from universities to industry could spur the\n\ntimely commercialization of AI breakthroughs. The establishment of strong startup and AI factories in leading university ecosystems around Europe would accelerate the creation of new AI companies. On top, European or national initiatives like WIN in Germany or Tibi in France could help unlock private venture and growth capital for the next generation of AI scaleups [42, 43, 44].\n\n\n## 4 Other Crucial Considerations\n\n\n\n## 4.1 Education, Reskilling, Talent Retention, and Public Engagement\n\n\nThe rapid evolution of AI necessitates continuous talent cultivation [45] and robust public engagement. To this end, we propose the development of industryaligned and interdisciplinary curricula through strategic partnerships with organizations such as EIT Digital [46] and leading universities, offering intensive AI as well as interdisciplinary degrees and fellowships that provide private-sector sponsors with priority access to emerging talent. Complementary reskilling initiatives (delivered both online and in-person) and upskilling programs should target sectors vulnerable to automation, such as manufacturing and logistics, with small grants available to support workforce retraining. Furthermore, streamlining visa pathways, offering competitive research grants, and establishing flexible 'talent bridging' tracks from academia to industry are essential to attracting and retaining top talent.\n\nSimultaneously, public trust in AI must be cultivated through transparent communication and active civic participation. Regular citizen assemblies, including town halls and online forums, should be organized to discuss pressing issues, such as the implications of fake content generation, and incorporate community insights into policymaking. Additionally, partnerships with broadcasters to rigorously label AIgenerated content (including deepfakes) will enhance media and AI literacy, while targeted educational campaigns in schools and adult learning programs will ensure that the broader public remains well-informed and engaged with AI developments.\n\n\n## 4.2 Global Alliances and Standard-Setting for Future Technologies\n\n\nEurope must leverage its regulatory influence to shape global AI norms and standards. Europe can promote frameworks that embody transparency, accountability, and human-centricity by actively engaging with international bodies such as the OECD, G20, ITU, and specialized standard-setting organizations, and advancing partnerships and initiatives such as the Global Network of AI Safety Institutes and Policy Clinics. Initiatives like establishing a 'G10 for Responsible AI' [47] would position European models as global lodestars. In parallel, science diplomacy efforts aimed at bridging the global digital divide, including multistakeholder initiatives such as GESDA [48], will help share Europe's balanced vision of AI governance worldwide, ensuring that its standards resonate across borders.\n\n\n## 4.3 Future-Proofing Against Emerging Technology Paradigms\n\n\nEurope must proactively adapt its policies and infrastructure to remain competitive amid rapid technological evolution. For generative AI and foundation models, measures should include mandating transparent disclosure, such as clear labeling and watermarking of AI-generated content as stipulated by the AI Act, and funding multilingual large language models that reflect Europe's diverse linguistic heritage. In the realm of quantum computing, integrating quantum accelerators with existing HPC resources and developing adaptive cyber-defense standards will be essential to harness its exponential potential while mitigating dual-use risks. Equally, advancing next-generation connectivity requires closing 5G deployment gaps, investing in 6G research, and establishing edge computing testbeds to support real-time AI applications. Finally, by harnessing synergies with complementary fields such as VR/AR, robotics, and biotechnology, Europe can unlock new markets and strengthen its strategic autonomy. Together, these measures will ensure that Europe's regulatory and technological frameworksremainagile and resilient in the face of emerging paradigms.\n\n\n## 5 Europe's Path to AI Leadership - A Balanced Vision for the Future\n\n\nEurope stands at a pivotal crossroads. The global AI race is not merely a contest of technological prowess but a battle for values, sovereignty, and societal resilience. While the U.S. and China dominate through scale and speed, Europe's unique opportunity lies in\n\nharmonizing its regulatory foresight, industrial ingenuity, and human-centric ethos into a cohesive strategy. This paper has outlined a roadmap to transform Europe from a reactive rule-setter into a proactive, innovation-driven leader capable of shaping the AI era on its own terms.\n\nEurope's strengths, its world-class research ecosystem, globally influential regulatory frameworks, and network of agile 'hidden champions', are formidable foundations. Yet these alone are insufficient. To thrive, Europe must urgently bridge critical gaps in semiconductor sovereignty, high-performance computing, and SME empowerment while fostering a culture of agile experimentation. The proposed European AI Coordination Council offers a blueprint for harmonizing standards without stifling innovation, marrying accountability with agility through sector-specific sandboxes and risk-calibrated audits. By prioritizing market-driven incentives over heavy-handed subsidies, Europe can unlock the latent potential of its SMEs, turning niche excellence into global leadership.\n\nEqually vital is the cultivation of talent and public trust. Europe's workforce must be equipped not only with technical skills but with the ethical literacy to navigate AI's societal implications. Strategic immigration reforms, industry-aligned education, and lifelong reskilling programs will ensure a steady pipeline of innovators. Concurrently, transparent governance through AI labeling, citizen assemblies, and global partnerships will reinforce Europe's role as a beacon of responsible innovation.\n\nCritically, Europe must embrace multi-technology convergence as a strategic imperative. AI's synergy with quantum computing, biotechnology, and next-gen connectivity will define future industries and geopolitical power. By embedding interoperability into its infrastructure and policies, Europe can lead in crosscutting domains like green tech, precision medicine, additive manufacturing, and resilient supply chains.\n\nThe stakes could not be higher. Hesitation or fragmentation risks relegating Europe to a regulatory island that is respected but irrelevant in shaping the technologies reshaping our world. Conversely, decisive action anchored in Europe's values, democratic accountability, privacy, and sustainability, can position it as the global standard-bearer for AI that empowers.\n\nThis vision demands more than ambition; it requires political courage, cross-border collaboration, and a willingness to rethink outdated paradigms. By uniting its regulatory clout with industrial agility, Europe can transcend the false dichotomy between innovation and ethics. The result will be a competitive, values-driven AI ecosystem that fuels economic growth, reinforces strategic autonomy, and exports a model of inclusive progress worldwide.\n\nThe time for incrementalism has passed. Europe must act with the urgency this moment demands, not merely to compete in the AI race, but to redefine its rules and strategy. By doing so, it will secure not just technological leadership but a future where innovation serves humanity, anchored in the principles that have long defined Europe's identity.\n\nAcknowledgements. The authors acknowledge the insights from governmental bodies, industry experts, andacademicinstitutions across Europe who have contributed to shaping this holistic AI governance vision.\n\n",
         "Europe is at a make-or-break moment in the global AI race, squeezed between the massive venture capital and tech giants in the US and China’s scale-oriented, top-down drive. At this tipping point, where the convergence of AI with complementary and synergistic technologies, like quantum computing, biotech, VR/AR, 5G/6G, robotics, advanced materials, and high-performance computing, could upend geopolitical balances, Europe needs to rethink its AI-related strategy. On the heels of the AI Action Summit 2025 in Paris, we present a sharp, doable strategy that builds upon Europe’s strengths and closes gaps.",
         ""
        ],
        [
         "46",
         "46",
         "## Introduction\n\n\nThe field of education research is increasingly affected by socio-technical challenges. In recent years, a combination of increased digitization of educational offerings and world-spanning crises such as the global COVID 19 pandemic have had profound consequences both for the surrounding support structures for and content of educational research. Topics in education research have moved towards a concern with digitization, psychological and medical factors and the impact of these on curriculum development and instruction (Polat 2022) . There is also a rising interest in questions of inclusivity in education, particularly in situations of social change (Pak and Ravitch 2021) . This context, coupled with an increasing demand for rapid dissemination of empirical evidence in times of crisis (Gorbea Díaz et al. 2023) , means the conditions for systematic appraisals of new research in the field have shifted. Simultaneously, the landscape of scientific publishing has undergone dramatic changes in the last few decades, both in terms of the volume of publications and in new forms of dissemination and the emergence of new fields and subfields in most disciplines. These changes have a bearing on the practice of reviewing and summarizing large corpora of academic texts.\n\nEven as changing conditions bring new challenges, there are developments within the practice of systematic knowledge summarization which might help meet these. Concurrently with the evolution of the publishing landscape, new developments in the capabilities of machineassisted analyses of lexical and semantic content ('ML/AI techniques' from now on) have given rise to new methods for conducting large-scale review and summarization. In fields with a high degree of standardization in reporting results, such as medicine, the use of ML/AI techniques in research synthesis is already common (Marshall and Wallace 2019; van Dinter, Tekinerdogan, and Catal 2021) . The practice is also spreading to other quantitatively oriented fields where standardized protocols for statistical meta-analysis can be developed (Ioannidis 2022) . In fields with a higher degree of heterogeneity in reporting practices, such as education research, the use of ML/AI techniques for textual analysis is still limited, although growing (Ayanwale, Molefi, and Oyeniran 2024) .\n\nIf used properly, ML/AI techniques can present one way to at least partially address new challenges arising from the intensification of academic publishing. At the same time, it is important to be aware of the tradeoffs that come with increased automation of text analysis, particularly in terms of validity and trust in the results.\n\nIn this article, I will discuss how new computational techniques can assist in all phases of the systematic review process, from text retrieval and screening to analysis of the content within publications using machine learning and contextual analysis of the relations between documents using bibliometric methods. The article does not present original research utilizing these tools. Instead, it aims to provide three things: 1) a description of the current challenges and opportunities presented by the rise of ML/AI techniques in systematic reviews related to the field of education, 2) a typology of review tasks where such techniques can be utilized, and 3) an appraisal of the tradeoffs inherent in the adoption of these techniques. I present a set of promising avenues for the automation of manual tasks that are proving untenable when met with corpora above a certain size. This avoids having to limit the number of publications eligible for reviews without first considering their fit for the review. Rather than supplanting the expert assessments of reviewers, the aim is to provide reviewers with a solid conceptual foundation for understanding the parts of the review process that can be supplemented by quantitative methods, and which considerations must be taken when sampling, filtering, mapping, and summarizing research fields.\n\n\n## Challenges in systematic reviews\n\n\nThis section will briefly discuss two of the main challenges facing systematic publication analysis today: explosive growth in scientific literature and increased fragmentation of scientific fields. These have developed against a backdrop of changing expectations from policy makers and society at large for more comprehensive and more rapidly produced reviews of relevant research in the face of disruptive events such as the recent global COVID 19 pandemic (W.-T. Wang and Wu 2021). Increased demand and shorter turnaround place an onus on the systematic reviewer to combine more efficient methods with rigorous quality control to ensure reliability in their work (Buhagiar and Anand 2023).\n\n\n## Explosive growth in publications\n\n\nIn the latter half of the 20th century and well into the 21st century, the global output of research articles has been doubling roughly every fifteen years (Bornmann, Haunschild, and Mutz 2021;\n\nThelwall and Sud 2022) . Such rapid expansion of the scientific corpus has serious implications for systematic reviews, especially in what might be called text-interpretative fields such as education research, where literature is highly heterogeneous in form and content and dispersed across more numerous but smaller journals (Bearman et al. 2012) . Traditional methods of literature analysis, often involving manual sifting and vetting of articles, become increasingly untenable as the volume of publications continues to rise.\n\nThe sheer volume of publications poses a logistical challenge to review projects that rely on manual identification and classification of publications for inclusion. The main problem, however, is the increased risk of low validity that results from attempting to implement stringent search constraints to limit eligible search results (Cian 2021) . Missing out on pivotal studies can compromise the integrity and findings of the review. As the volume of scientific outputs mushrooms, ensuring thorough validation becomes difficult (Lefebvre et al. 2019) . A vast corpus means a greater number of studies to scrutinize, methodologies to understand, and results to interpret. It is imperative, therefore, to consider how systematic reviews can maintain rigor, depth, and breadth facing such an abundance of potentially relevant information.\n\n\n## Field fragmentation\n\n\nThe proliferation of scientific literature has been accompanied by the increasing fragmentation and specialization of scientific fields (Q. Wang and Waltman 2016; Sjögårde and Ahlgren 2020) . While indicative of the maturation and refinement of scientific disciplines, this presents substantial challenges for systematic reviews. Concurrent with this is an increased focus on interdisciplinary collaboration, resulting in more collaborative publishing across fields (Glänzel and Debackere 2022) . This trend is present in education research, which exhibits tendencies towards both increased fragmentation and multidisciplinarity (Huang et al. 2020) .\n\nFrequently, systematic reviews are undertaken to gain understanding of questions that cut across disciplinary boundaries. Synthesizing insights across multiple sub-disciplines requires generalized knowledge of the process of systematic reviews combined with domain-specific knowledge (Park et al. 2021) . There is a constant tension between depth and breadth. Ensuring a comprehensive review across several fragmented subfields often means wading through disparate terminologies, methodologies, and even epistemologies, which can be an arduous and intricate task.\n\nExpecting reviewers to possess deep expertise across all relevant sub-disciplines covered by a systematic review is in many cases unrealistic. This limitation raises questions about the proficiency with which reviewers can validate findings from subfields outside their core expertise. Nuances in methodologies, terminologies, or theoretical frameworks that are specific to a sub-discipline might be misconstrued or oversimplified by someone unfamiliar with that specialization (Shahjahan et al. 2022) . This is particularly true in cases where the literature under review has fewer standardized reporting elements and data suitable for rigorous meta-analysis (M. Campbell et al. 2020; Tong et al. 2012) , such as is the case with education research.\n\n\n## Possibilities in publication analysis\n\n\nThe challenges posed by the growth and diversification of scientific literature underscore the need for expanding the toolbox of systematic review, in both literature retrieval (Gusenbauer and Haddaway 2020) , relevance filtering (Rethlefsen et al. 2021) , and content summarization (El-Kassas\n\net al. 2021) . Traditional search methods, reliant on keyword-based querying and manual filtering, are becoming less feasible and efficient given the vastness and complexity of today's academic databases (Harari et al. 2020) .\n\nHowever, the rise and fragmentation of scientific publishing is not the only significant trend in the last decades. In the same period, there have been major advances in the development of computer-assisted tools for handling the content within and relations between text documents (Khurana et al. 2023) . These developments open new opportunities for the systematic analysis of scientific texts, aided by better language models and better access to computing hardware and literature metadata. Together, machine learning techniques and relational bibliometric analysis can alleviate some of the pains of attempting systematic synthetization of the research literature (Pan et al. 2024) , and potentially reduce the effects of human error in various parts of the review process (Bannach-Brown et al. 2019; Kusa et al. 2023) .\n\n\n## Natural Language Processing\n\n\nML/AI techniques present promising solutions to the challenges that have long plagued the systematic review process, offering both enhanced efficiency and depth of analysis. Whereas computational text analysis techniques were somewhat esoteric and highly specialized fields twenty years ago, three developments have combined to make ML/AI techniques available to researchers outside of computer science or specializing in language processing tasks: text models have vastly improved, the cost and task complexity of text analysis has dropped, and mature software support systems have appeared.\n\nFirst, there have been clear improvements in text models. Unlike earlier models that relied heavily on manual feature engineering and could only capture surface-level patterns (Raffel et al. 2020) , contemporary models like transformers can understand context, semantics, and even nuances in texts (Min et al. 2021) . The ability of modern language models to consider contextual information makes them adept at tasks like identifying sentiment in text (Wankhade, Rao, and Kulkarni 2022) , identifying and classifying topics (Vayansky and Kumar 2020) and clustering documents based on their semantic content (Ghosal et al. 2020) . For systematic reviews, this can translate into more accurate literature categorization, richer extractions of insights, and even the potential to identify overarching themes across disparate studies.\n\nSecond, the last decade has seen tremendous growth in specialized hardware and software designed to handle large-scale text processing tasks (Lauriola, Lavelli, and Aiolli 2022) . Assuming the technical competency is there, even vast corpora can be processed locally, reducing dependency on costly cloud services or high-end data centers.\n\nThird, the support systems for doing ML and NLP analysis has matured over the same period (Hewage and Meedeniya 2022) . The ML and NLP landscape is not just defined by its algorithms and hardware but also by the ecosystems that support them. There has been a proliferation of user-friendly software tools tailored for text analysis (Qi et al. 2020; Gkevrou and Stamovlasis 2022) and off-the-shelf solutions providing pre-trained models and easy-to-use APIs (Gamieldien 2023) . Researchers with access to the right technical competencies can also train their own models with open-source access to the underlying language models (Shen Wang et al. 2024) . Extensive support documentation and training material is readily available. Together, these developments point towards a maturation point for the inclusion of ML and NLP techniques in their review workflow.\n\n\n## Stages of a systematic review\n\n\nTo better understand how computational techniques can fit into well-established workflows for systematic reviews, it helps to understand the distinct stages of the review process. The rest of this paper will describe the review process, where computational techniques can be employed in such a workflow, and new challenges that may arise from the use of automation that reviewers must be aware of and able to answer satisfactorily.\n\nWe can divide the workflow of reviews into four distinct phases (Newman and Gough 2020) :\n\n- 1) Operationalization of research questions and conceptual framework\n- 2) Identification of potentially relevant literature and document retrieval\n- 3) Analysis and summarization of the content of publications\n- 4) Analysis and visualization of metadata and content\n\nThis paper will focus on the last three stages, as the operationalization and conceptualization steps criteria lean heavily on domain expertise and are still reliant on manual design decisions.\n\n\n## Identifying relevant publications\n\n\nMost systematic reviews start their literature identification and retrieval phase with a keyword search, using the resulting publication set either for bounding the corpus or as a starting point for various forms of snowballing and/or corpus supplement strategies (Polanin, Maynard, and Dell 2017) . Within the context of structured databases such as Web of Science or Scopus this will continue to be the most common method, meaning there is little scope for computational techniques to play a large role in this step in the process.\n\nHowever, most keyword-based search techniques result in a large share of publications of low relevance to the review topic or research question. Some review tasks start with a corpus of publications connected through other criteria than topical or field similarity. This means that being able to quickly assess large numbers of publications for eligibility or clustering and classification can provide major benefits, especially when the corpus size expands beyond what is feasible to manually handle.\n\nFor example, rather than rely on relevancy criteria defined through the search strategy (e.g., only publications from a certain geographic area, or from a very limited time period), computational techniques can be used to exclude or include publications based on criteria related to relational (Bellis 2009) or semantic characteristics (van de Schoot et al. 2021) of the publications.\n\nExpanding beyond the citation signal, NLP techniques can be employed to match publications based on lexical patterns and semantic content (Chandrasekaran and Mago 2022) . This ensures that even articles that do not explicitly use the predefined keywords but discuss the topic in question or adjacent, pertinent topics, have a chance of being captured. Making use of such techniques can also improve recall of document retrieval (Kuzi et al. 2020) .\n\nOther techniques involve text classification algorithms for relevancy scoring. Systematic reviews in education research have made use of such algorithms when they have been predefined and implemented in existing review software such as Leximancer (Thomas 2014) , Covidence (Jackson et al. 2022) or Rayyan (Bhatti et al. 2023) , but the ability to fine-tune models for sensitivity towards domain-specific terms has been shown to yield good results in the field of education (Z. Liu et al. 2023) . The most basic method is to use ML models trained to classify texts based on predefined relevancy criteria. By feeding these models a training set of relevant and non-relevant\n\narticles, they can learn to discern the characteristics of pertinent publications. Once trained, they can process large volumes of literature, efficiently categorizing them as relevant or not. Automated classification speeds up the initial filtering process, reduces manual labor, and ensures consistent application of relevancy criteria across a large corpus. However, validity concerns necessitates pre- and post-application manual validation of these techniques (Song et al. 2020) ,  meaning that reductions in time and effort only manifest at larger scales.\n\nMore complex filtering techniques involve using a clustering or multiclass classification algorithm to identify clusters based on their semantic and topical similarities, in order to identify sub-corpora of higher relevance for inclusion in the review process (Weisser et al. 2020) . Similarly, experiments with large language models (LLMs) have shown good performance on clustering tasks (Keraghel, Morbieu, and Nadif 2024) .\n\n\n## Analyzing and Summarizing the Content of Publications\n\n\nAfter defining the set of eligible publications for a review and validating the resulting corpus, the next step in most review processes is analyzing and summarizing the content of the publications. Traditionally, this step could only be done by the reviewer reading and summarizing the content in a manual fashion. The benefit of this is that human judgment can be attached to the resulting analysis, but the obvious drawback is that it scales very poorly with corpus size.\n\nComputational text analysis offers far superior scalability. Modern NLP architectures using word embeddings or transformers have been shown to achieve human-level classification and summarization scores, meaning human evaluators agree with the algorithmic classification about as often as they agree with other humans completing the task (Bird, Ekárt, and Faria 2023; Occhipinti, Rogers, and Angione 2022) . For some tasks, sentiment analysis can be used to understand the valence of a publication, particularly in identifying supporting or detracting citations to other literature (Shiyun Wang et al. 2022) .\n\nIn addition to identifying conceptual relationships through semantic similarity, some models can be used for automatic summarization or data extraction tasks (Jethani et al. 2023; Wagner, Lukyanenko, and Paré 2022) . LLMs, with their large context windows and fine-tuning for extractive tasks, offer a promising avenue for automated text summarization (S. Liu et al. 2024; Bianchini et al. 2024) . This is particularly useful when identifying specific sections of publications, for example extracting descriptions of methodologies, or other clearly delimited summarization tasks (de la Torre-López, Ramírez, and Romero 2023). For whole-document summarization, current models have been shown to struggle with summarization of long-form texts (El-Kassas et al. 2021) , particularly if the task is of an abstractive (i.e. generating new sentences that capture semantic meaning) rather than an extractive kind. This can be alleviated by introducing indicators of domain knowledge or additional metadata in the training process (Xie et al. 2022) , but careful thought must go into integrating these techniques into the review workflow. Still, the largest providers of LLMs all currently provide ways to define sets of documents that can act as a knowledge base for the model, reducing their tendency for hallucinations and increasing validity of the summarization (S. Liu et al. 2024).\n\nThe tradeoff in utilizing these techniques is ceding some control to the algorithms (Kasneci et al. 2023) . It is usually possible to inspect the weighting scores of individual records in classification tasks, and some variable importance measures can be computed to identify which terms contribute the most to a particular classification. However, providing this in a meaningful way for thousands if not tens of thousands of publications can be challenging. The effect is that the\n\nreviewer will have to draw validity from the strength of the pre- and post-validation steps undertaken earlier in the process (Susnjak et al. 2024) .\n\n\n## Metadata Analysis and Visualization\n\n\nConcurrent with content analysis, relational analysis can help in understanding the research context of a set of publications (F. Campbell et al. 2023) . Situating research in time and place adds contextual information and can itself be used to identify clusters of researchers or topics. In many cases, one of the goals of the review process is to gain an understanding not only of what is covered in the corpus, but also who is contributing.\n\nThe most common techniques of relational analysis are used for domain mapping, with the goal of mapping out the underlying structure of networked relations that can be inferred from the metadata. These include co-authorship networks, influence lineage through citation networks or mappings of publication channels for any given topic. Biographical metadata can be used to construct profiles of the academic milieus of the corpus, to understand geographical or institutional distribution (Rungta et al. 2022; Higham, Contisciani, and De Bacco 2022) . Temporal network analysis can be used to trace the development of topics and scientific domains (Jiang and Liu 2023; Vital and Amancio 2022) .\n\nIn the overlap between relational and contextual analysis, topic modelling using title and abstract text has been shown to produce good results, albeit often requiring supervised training and manual validation to ensure good reconstruction of topics (Held, Laudel, and Gläser 2021) .\n\nWhile relational analysis is often used as a context-providing supplement to content analysis, its methods are more mature in terms of tested validity and offer more in the way of interpretability of results. Because of this, they can also serve as extra steps towards validation of the content analysis techniques. Using topic modeling in combination with text classification can be part of a comparative validation step. In addition, relational analysis lends itself well to visualization. Network visualizations of citation, co-publication or topic similarity graphs offers a way to manually inspect and validate the output of the algorithms (Kossmeier, Tran, and Voracek 2020) . This has the potential to increase the validity of the review project.\n\n\n## The integration continuum\n\n\nAs should be evident from the discussion so far, there are multiple phases in the systematic review process where ML/AI techniques can be integrated. This integration is not a binary choice, but rather a continuum with varying degrees of implementation. One can envision moving along this spectrum, from minimal to full integration, depending on the complexity, size, goals, and available resources of the project. As the use of computational methods intensifies in a project, scaling in terms of corpus size and analytical methods can be achieved, but not without incurring added costs in terms of project complexity and introducing extra validation steps. Integrating new techniques requires different skillsets and the ability to work in a crossdisciplinary fashion, both of which have project size and complexity costs related to them. Table 1 summarizes the characteristics of the various degrees of integration and gives some hints as to when it makes sense to apply them.\n\nTable 1. Characteristics of and applicability of various computational integration modes.\n\nThe choice of where a review falls on this spectrum should be strategic and driven by the unique requirements and constraints of the project. While the allure of advanced computational techniques is undeniable, it's crucial to remember that the goal of a systematic review is to provide accurate, insightful, and actionable analysis for policy makers. The tools employed, be they manual or computational, should always serve this primary objective.\n\n\n## Challenges with the integrated approach\n\n\nOne of the primary concerns with employing automated systems, particularly complex machine learning models, is the \"black box\" nature of their operations (Yan et al. 2024) . While ML models can efficiently process vast amounts of text and identify patterns beyond human capability, their\n\ndecision-making processes can often be opaque (Tao, Zhou, and Hickey 2022) . Also, while much work is done on testing models on various text analysis tasks, the field still lacks rigorous, transparent benchmarks for model evaluation (O'Connor et al. 2019) . This lack of transparency poses challenges in the validation of the selection, classification, and summarization steps. If reviewers cannot understand or explain why certain texts were selected or categorized in a particular manner, it can lead to skepticism regarding the model's decisions. This opacity can thereby undermine the perceived validity and trustworthiness of the entire review process.\n\nSystematic reviews traditionally rest on domain expertise, where review validity is based on the reviewer's expert assessment. As noted in the introduction, this can already pose a problem for more fragmented fields such as education research, where there is a higher heterogeneity in terminology used (Newman and Gough 2020; Coe et al. 2021) . The integration of quantitative text analysis introduces a technical dimension that might be alien to many reviewers. A review project must now introduce rigorous training, testing and validation cycles to the process, particularly for the more integrated procedures. The need to understand and sometimes tweak algorithms, validate model outputs, or interpret complex network graphs can be daunting for those without a background in computational methods. This mismatch can result in a reluctance to adopt these tools or, worse, their misuse due to a lack of understanding.\n\nGiven the technical challenges of custom-building and maintaining ML/NLP models, using offthe-shelf software or proprietary platforms might be the only feasible road to integration. While these offer user-friendly interfaces and promise comprehensive analysis, they come with their own set of challenges. First, they can be costly, limiting access for researchers with constrained budgets. Secondly, proprietary systems further exacerbate the \"black box\" problem, as their internal workings and algorithmic implementations are often hidden from users. This can create a dependency where reviewers are making crucial decisions based on tools that they neither fully understand nor control. Similarly, the efficiency of automated tools might lead reviewers to overly depend on them or lead to review projects being undertaken by people who lack the necessary understanding of the systematic review process.\n\n\n## Conclusion\n\n\nThis paper has presented some ways in which computational methods can be integrated into systematic review projects to deal with the challenges of increased size and specialization of scientific corpora. While the uncertainty connected to parsing semantic content algorithmically means extra care must be taken in the design and implementation phases of a project, it is probable that most review projects in the future will have to integrate ML/AI techniques to plausibly claim that most or all relevant literature has been included and made part of the analysis. Gaining experience with such techniques can help in increasing understanding for how computational text analysis works, and how to ameliorate some of the drawbacks of introducing quantitative text analysis into an analysis practice which relies on meaning and interpretation. There is still much to learn.\n\n",
         "The speed and volume of scientific publishing is accelerating, both in terms of number of authors and in terms of the number of publications by each author. At the same time, the demand for knowledge synthesis and dissemination is increasing in times of upheaval in the educational sector. For systematic reviewers in the field of education, this poses a challenge in the balance between not excluding too many possibly relevant studies and handling increasingly large corpora that result from document retrieval. Efforts to summarize and synthesize knowledge within or across domains manually are increasingly running into constraints on resources or scope, but questions remain about the coverage and quality of automated review procedures.\nThis article makes the case for integrating computational text analysis into current review practices in education research. It presents a framework for incorporating computational techniques for automated content analysis at various stages in the traditional workflow of systematic reviews, in order to increase their scope or improve validity. At the same time, it warns against naively utilizing models that can be complex to understand and implement without devoting enough resources to implementation and validation steps.",
         ""
        ],
        [
         "47",
         "47",
         "## Introduction\n\n\nTranslation  is  not  just  an  exchange  of  words;  it  is  also  an  important  element  of communication between cultures. It helps to create an image in the target readers' minds that allows them to build up an idea of how others behave and think. To facilitate this communication, the translator needs to be aware of the context of the Source Language (SL) text so that it can be recreated,  in  line  with  the  translation  purpose,  in  the  Target  Language  (TL).  The  translator's awareness of the source's cultural context helps them to choose procedures to serve the purpose of the translation. One of the phenomena that complicate the task for the translator is the use of conversational dialects in writing, such as literature, or what is referred to in this paper as Literary Dialectal Dialogue (LDD).\n\nThe Arab region is a diglossic speech community, where more than one dialect is used to communicate. The traditional existence of diglossia in the region takes the form of two or more dialects  in  the  same  Arabic  speech  community,  where  according  to  Ferguson  (1959)  the superposed dialect is the one used in formal education and formal writing or spoken purposes whereas the other is used mostly in ordinary conversation.\n\nConcerning Arabic literature, the literary scene in the Arab world changed from the mid1940s onwards, and there was a transformation in the themes and structure of creative writing. These changes coincided with and may have been the result of several political and social changes in the region (Abu-Deeb, 2000). Holes (2004) states that the need to use the dialect in the Arab world spread in the 1950s after World War II and the political independence in the region.\n\nThis change has had a significant impact on how novels have been written, and changes have occurred  in  the  type  of  language,  themes,  and  settings  of  the  novel  (Abu-Deeb,  2000).  The phenomenon of using dialect in novels has grown in recent decades, and the new forms of dialectal novels have become more prominent in the Arab literary scene in recent years. In addition to the sociopolitical factors, the rise of digital technology and social media platforms has significantly contributed to familiarising readers with dialect as a written form.\n\nThis diglossic situation will pose a translation problem for the translator who needs to reflect the nuances of the dialogue that not only exist for linguistics purposes but also to reflect the many sociopolitical layers and other factors for the use of LDD in the first place.\n\nThis paper aims to understand how LDD in contemporary Saudi and Egyptian novels is recreated in English and to examine whether the change of the dialects plays a role or influences the dialogue in the English translations of the novels. This primary focus can be subdivided into two interrelated questions that structure the research. The questions can be formulated as follow:\n\n- 1. What are the procedures that translators have employed to translate LDD in the corpus? Are there frequent procedures that translators have applied more than others?\n- 2. Do the translation procedures shift with changes in dialect?\n\nThis paper is divided into six sections. Following this introduction, the literature review will be concerned  with  discussing  the  literature  on  translating  dialects,  an  overview  of  the  issue,  and procedures to deal with such an issue. Then, the discussion will move to the method part where the  macro  methodological  approach  will  be  discussed  and  the  specific  micro  methods  will  be explained. To answer both questions, quantitative and qualitative analysis will be conducted to gain a holistic overview of the procedures and frequency of using them in English translations. The result section maps the translation procedures used to tackle LDD in the corpus of Egyptian\n\nand Saudi novels. Then, the paper will present the discussion and findings that emerge from the results and end with the conclusion.\n\n\n## Literature Review\n\n\nNovelists incorporate the voices of ordinary people. These voices may derive from many different regional and social dialects, and novelists employ these dialects as the voices of their characters. However, these representations are not a transliteration of oral speech, because using a full real dialect may pose a challenge to the flow of the novel and make it difficult to read. Giving too  many  details  and  representations  may  hinder  the  reading  process  and  affect  the  reader's comprehension of the storyline and the author's message (Fine, 1983). In analysing how writers render  the  characteristic  of  spoken  conversational  language,  it  can  be  observed  that  when conversation is used for literary purposes it distances itself from the raw spoken word in reality (Leech &amp; Short, 2007). Hence, the process involves selecting representative linguistic features that can demonstrate the spoken language in that speech community. Such changes are intended to make a spoken dialect fit with the rhetorical style of the novel, taking it from the ordinary dialect zone to what Ives (1971) has called 'literary dialect'. According to Ives (1971) literary dialect can be defined as an 'attempt to represent in writing a speech that is restricted regionally, socially, or both' (p. 146). It is crucial to use the adjective 'literary' when referring to the dialectal dialogue in the novel, because it indicates that this dialect exists within the piece of fiction and is not a real entity in the way that regional or social dialects are (Azevedo, 2000).\n\nTranslation scholars have paid attention to the issue of translating dialect in general and dealing with Literary Dialectal Dialogue (LDD) in particular (Catford, 1965; Hatim &amp; Mason, 1990; Fawcett, 1997; Sánchez, 1999 a, b; Berthele 2000; Määttä 2004). Many procedures have been proposed to tackle this  issue,  but  scholars  all  agree  that  there  is  no  clear-cut  solution  to managing this problem and that it depends on the translator's understanding of the social and cultural  context  of  the  SL  and  TL,  the  intention  behind  the  use  of  dialect  in  the  ST,  and  the translator's goals for the translation.\n\nLefevere  (1992a)  has  noted  that  language  is  never  used  in  isolation;  rather,  the  use  of language  is  related  to  the  situation  in  which  a  particular  language  is  considered  appropriate. Authors elevate the communicative effect of their text, or what calls 'the illocutionary power', by utilising  'all  kinds  of  discrepancies  between utterance  (the use of language) and situation (the particular context in which language is used)' (p. 58). That might help to create the communicative effect  of  the  meaning  for  the  readers.  According  to  Lefevere  (1992a),  translators  should  pay attention to whether the register or type of utterance in the TT is appropriate for the specific context and also to whether a particular situation is similar, to some extent, in different culture. Translating needs to capture this communicative effect and explain the source's cultural situation rather than apply a literal translation of the text or  'the illocutionary power of the source text will not be heightened by a mere literal translation of the words on the page in what amounts to a cultural vacuum' (p. 58). He argues that choosing a variety from TL to replace the variety in ST is not the best strategy to deal with a dialectal text and 'is likely to sound artificial and may even make the translation less intelligible' (p. 69).\n\nTranslating dialect cannot be isolated from associated political and cultural considerations. Hatim and Mason (1990) have commented on that when dealing with a dialect in a text, it is not always just the linguistic aspect that differentiates a regional dialect, but those political and cultural\n\nconsiderations also contribute to set these boundaries. Understanding the ideological, social, and political implications of the source and target dialects is vital knowledge for the translator when dealing  with  a  dialectal  text  since  such  knowledge  helps  to  produce  a  translation  that  avoids problematic misconceptions by its readers.\n\nCatford (1965), like Hatim and Mason (1990), has thought that the translator should keep in mind that the source and target dialects extend beyond the limit of language and the location of the dialects. The translator should also be careful about the impact that the translation and the chosen procedures have on the target reader. Catford (1965) has given an example of replacing the southern British cockney dialect with the northern French Parigot dialect, based not on the location but on social implications. Therefore, unwanted messages will be associated with the text where the mark of the dialect in ST may be formally quite different from those of the ST. Another point regarding translating based on the linguistic aspects, not the social or cultural implications have been shared in a very recent study by Jiménez (2021) who analysed the Spanish translation of Yaa Gyasi's Homegoing (2016), a novel that focuses on slavery and the history of a black family from the beginning eighteenth-century in Ghana to the early twenty-first century in the United States. Jiménez (2021) has noted that sometimes the inconsistency in applying the translation procedures to represent the purpose of LDD in the character voices could affect the social and cultural role that this character is meant to serve; such as the case with the major Ghanaian character in the story,  the  maid  Esther,  whom  their  broken  English  was  used  to  reflect  their  otherness  was standardised in the TT.\n\nThe importance of understanding the functions of dialect in the ST has highlighted by Sánchez  (1999b)  who  has  thought  it  is  crucial  to  choose  the  best  possible  procedures  for translation.  Fawcett  (1997)  has  demonstrated  that  a  dialect  in  a  text  poses  a  problem  to  the translator to the point where translation becomes impossible. He thinks that 'dialect translation is by no means as simple and straightforward as one might think, especially since it often relates to questions of status and repression' (p. 76). For him, this form of translation is more representation than a translation of the ST.\n\nThis is a point that Määttä (2004) has agreed with him on it as he has stated that the novel is a medium to express the ideologies of the language. However, in the translation, the 'sociolinguistic stratification' cannot be produced in translation. Accordingly, the emphasis on the role and intention of using the dialect in the 'polyphonic structure' of the novel might give the readers an understanding of the ideological framework of the novel (Määttä, 2004). The focus in translation should be on the general of the novel and its macro context, including the literary dialect, and not on reflecting every single dialectal word or utterance.\n\nIn the field of Arabic literary translation studies, a few research studies have addressed the issue  of  translating  dialects  from  dialectal  Arabic  literature  into  English.  One  of  these  is Rosenbaum's  (2001)  research,  which  has  highlighted  the  issue  of  translating  diglossia  from Egyptian literature into Hebrew and English. She has noted that when a text is written mainly in dialect,  there  will  be  no  problem  in  identifying  the  dialect.  However,  she  has  stated  that  the problem becomes more complicated and challenging to the translator when some dialect elements in a text are mainly written in Modern Standard Arabic (MSA), i.e. elements that uniquely belong to dialect; elements that have the same form in dialect, and MSA but are different in meaning; and dialect elements that look like MSA where the words have been modified to comply with MSA grammar.  Rosenbaum (2001) has claimed that failing to identify these elements of dialects in the\n\ntranslation process may result in problems in the translation, such as literal translation of figurative expressions, translation shifts, and non-equivalent translation.\n\nConcerning the practice of translating Saudi dialectal novels, Daoudi (2011) has outlined the challenges of translating the two e-Arabic novels Banāt al-Rīyāḍ ( Girls of Riyadh ) and Barīd Mistaʿjil (Bareed Mista3jil) . She has argued that the emergence of e-Arabic has led to the rise of a new way of writing the novel in Arabic, and she has suggested that these new forms of novelwriting are challenging the MSA elite literary language and offering a more diverse multilingual space for the expression of the self. However, she maintains that when these novels are translated into English, the co-mixture of dialects in the ST loses its cultural and linguistic effects, especially in  the  case  of Girls  of  Riyadh where  the  author  intervened  in  the  translation.  She  stated  that changing the intended readers could lead to the loss of e-Arabic dynamics in translation.\n\nFurther, a very interesting point was raised in a recent study conducted by Shmasnh (2022) where he compared the work of an Egyptian and a British translator for Mourid Barghouti's novels to English. He has stated that sharing a very similar cultural and linguistic background like the case with the Egyptian translator Ahdaf Soueif, might not have a great influence on translating the text; the translator may still fail in conveying the pragmatic implication of some cultural and LDD dialogues in the text. Shmasnh (2022) has stressed the importance of understating the intended purpose of the novel's cultural and social significance in these kinds of novels and does not rrely much on the hypothesis that the translator mastering the source text culture is more faithful and adequate in reflecting the source text than the translator who does not.\n\nOn a different note, in the discussion of translating dialect several specific procedures have been suggested that can help the translator to overcome this challenge and which may help to fulfill the function of the ST (whether a novel, play, poem, and so on). These suggested procedures are using pseudo-dialect translation which  is  creating  a  literary  dialect  and  changing  the  standard grammar of the language with the standard linguistic features, and making it sound like a dialect (Hatim &amp; Mason, 1990). However, Wekker and Wekker (1991) has stated that creating a literary dialect may invent a non-existent, broken language. Azevedo (1998) also has noted that using a creation or ad hoc literary dialect might mask or misrepresent the sociolinguistic variables of the ST. Parallel dialect translation which is translating the literary dialect into another target dialect that has a similar connotation or functions could result in it serving the same functions in the TL (Sánchez, 1999b). Lefevere (1992b) has criticised this procedure by stating that it may have a negative impact on the TL readers, because it may awaken unwanted connotations that are different from the intended function of the source target. Standardisation which is using a standard formal variety  in  the  TT  and  removes  all  dialectal  elements  from  the  TT  novel  (Leppihalme,  2000). However, replacing the literary dialect with the standard form could affect the representation of the characters and might substantially alter their relationship with each other and with the reader (Azevedo, 1998). Dialect compilation is translating the dialect into a mixture of target dialects and using this mixture in the idioms and dialectal expressions (Perteghella, 2012).\n\nIt is in the end up to the translator to use one or a mix of these procedures or other applicable procedures to achieve the desired stylistic and semantic impact. With the characters' LDD in the text, the role of constructing the characters' speech is crucial. The translator is in the first place a reader of the author's words and their novel; she or he is one of the implied readers who is supposed to  decode  the  markers  of  the  chosen  dialects  and  try  to  fill  the  gap  with  their  background\n\nknowledge. ST readers are supposed to pick up these signifiers and turn these words into voices and images that might help them to create a visual scene in their minds while reading. These images can be clear or vague depending on the reader's imagination and their familiarity with the context of the text (places, sound, characters, smells, and so on). Thus, we can think of the translator first as a reader who translates the text before taking it to a different language. She or he translates it in a way that evokes certain images, sounds, and, perhaps, smells. This might help to comprehend the  context  and  to  make  sense  of  the  narrator's  internal  dialogue  or  the  characters'  dialectal dialogue. Then comes the mission of creating a parallel story in a different language.\n\nThis parallel text to translate LDD will be produced based on several internal and external factors  relating  to  the  purpose  of  the  translation,  which  in  turn  will  determine  the  translator's procedures in dealing with such a linguistic challenge. It is obvious that translation is a process that cannot be isolated from the environmental factors surrounding its production. When shifting from a focus on the language to the culture, it is important to pay attention both to the cultural power of the target context that influences the translation and to the special purposes the text will serve in the target culture. Bassnett and Lefevere (1990) argue that these cultural powers lead translators to manipulate the text and attempt to imitate a certain discourse to be accepted by the target readers. The ideology and power of the target culture quite often play an important role in the  translation  process,  according  to  the  'manipulation  school'  (Lambert  &amp;  van  Gorp,  1985; Hermans, 1985). Under these circumstances, the translation, and specifically the translation of literature, reconstruct the representations of SC, authors, and text.\n\nThe  concept  of  'rewriting'  in  translation  was  coined  by  Lefevere  (1992b).  He  draws attention to how the text is rewritten in various ways to serve certain purposes, such as political or cultural interests. He suggests that the factors that control the acceptance or rejection of the literary text in any translation system are ideology, patronage, poetics, and the universe of discourse. He argues  that  ideological  consideration  is  the  most  important  -  even  more  so  than  linguistic consideration - when it comes to the translation process (1992b). The ideology comes from society to show what is and what is not acceptable in the literary and social norms. According to Lefevere (1992b), ideology serves as the basis of the translation strategy when dealing with the text in the primary stages: it is the guidance the translator follows to shape the translation. The translators themselves, according to their ideology, can also enforce the ideology of those who impose upon the translators themselves, such as the patrons who are responsible for publishing the translation. Moreover, translation is also influenced by regulatory forces, whether from within literary systems, such  as  the  professionals  (for  example,  translators  themselves,  critics,  and  reviewers)  or  from factors  outside  the  literary  system,  such  as  patrons  (persons,  institutions).  Powerful  people,  a religious  body,  a  political  party,  a  social  class,  the  media,  a  publisher,  or  an  educational establishment are all examples of (potential) patrons.\n\nIn  addition,  other  'intra-systemic'  constraints  affect  the  rewriting  of  literature,  such  as poetics and the universe of discourse. Poetics refers to the aesthetic principles that control the literary system at a certain time. Lefevere (1992b) claims that poetics consists of two components: literary devices, which comprise genres, motifs, symbols, characters and situations; and functional components, which concern the relation of the literature to the social system, the role this literature should play in a certain society, and the way it should play this role. An example of this is the rewriting that was done by Fitzgerald to Rubáiyát , the work of the Persian poet Omar Khayyam to make it  come  close  to  the  target  literary  conventions  (Lefevere,  1992b);  this  resulted  in  huge\n\nchanges to the ST. This kind of rewriting manipulates the text to work by the literary system of the  target  society.  On  the  other  hand,  the  functional  component  can  be  influenced  by  the ideological constraints from outside the domain of poetics, such as the contextual environment surrounding the literary system. Certainly, professionals and patronage can also play a role in determining and supporting the dominant poetics in a certain literary system. However, poetics is subject to change, and they have a variable nature.\n\nThe final factor that plays a crucial role in rewriting the literature is, according to Lefevere (1992b),  the  universe  of  discourse  that  can  also  act  as  an  intra-systemic  constraint  in  literary systems. The universe of discourse refers to 'the knowledge, the learning, but also the objects and the customs of a certain time, to which writers are free to allude in their work' (Lefevere, 1985, p. 233). Each culture is unique in the way it expresses itself, and elements like costumes, concepts, and ideologies are different from one culture to another. This is, in turn, a challenge for translators. The attitude of the translator's patron, and the social forces relating to the universe of discourse in the ST and the other universe of discourse of their target society, are the factors that determine the rewriting that occurs in the target literary system. This attitude is influenced by many factors, such as the status of ST, the self-image of the target culture, what type of texts are acceptable in the TC, and the intended audience (Lefevere, 1992b).\n\nWhen the rewriting is put in the context of LDD it could be seen that there is a strong emphasis on the target culture, but little has been said about the author and SC, the importance of the  function  of  the  ST,  and  how  this  might  be  decided  by  the  translator  to  be  reflected  in  the translation.  Nord  (200)  has  pointed  out  the  importance  of  understanding  the  communicative function of the ST and how this is important as a basis for determining the choice of translation method and strategy. Furthermore, she argues that 'the translation purpose justifies the translation procedures' (p. 35) and that this purpose can be identified in part by the translator analysing the communicative function of the ST. Nord (200) has maintained that the purpose depends on the translator's evaluation of the impact of their translation:\n\nthe translator acts as a responsible mediator in the cooperation developing between the client, the target audience and the source-text author. This does not mean that translators always have to do what the others expect - this may even be impossible if the three parties expect different translational behaviours. It just means that the translator has to anticipate any  misunderstanding  or  communicative  conflict  that  may  occur  due  to  different translational concepts and find a way to avoid them. (p. 3)\n\nNord (2002) has introduceed to the functionalist theory the concept of 'loyalty', which refers to the social relationship between the translator, on the one hand, and the client (or patron [Lefevere, 1992b]), author, and TT readers on the other. In particular, she highlights the relationship of the translator with the author, which is based on respecting the latter's 'individual communicative intentions' (p. 4). According to Nord, this might lead to the author accepting any changes that happen in the process of the translation. The translator's loyalty towards her or his partner performs a helpful role in the 'powerplay' between the client (or patron), author, and reader expectations. Thus, according to the translator's evaluation, the purpose of the translation of LDD will affect the chosen procedures. The purpose of the translation could determine that little attention should be paid to the LDD, so the translator will be less concerned about creating LDD in the TT and more concerned about fitting the text within his or her evaluation of the TT's literary translation norms\n\nand readers' expectations. However, if the translator's purpose is to recreate the style of the ST and focus on the LDD, that might change the translator's procedures in this matter.\n\nLastly, it could be argued that LDD especially in relation to Arabic novels and more precisely to Saudi novels still an under-researched area that needs to be analysed. The most important research angle, which will be addressed in this paper, is that analysing the translation of both Saudi and Egyptian novels by the same translators might be still a gap in the field. These research gaps will be  studied  in  this  paper  with  a  combination  of  descriptive  quantitative  and  qualitative  textual analysis that will be discussed in the following section, in order to understand the translation of LDD across and within novels.\n\n\n## Methods\n\n\n\n## Descriptive methodological Approach\n\n\nTo investigate the phenomenon of the use of LDD in Egyptian and Saudi novels, and how LDD has  been  translated,  a  descriptive  approach  was  adopted  as  the  general  methodological approach  to  data.  The  descriptive  approach  was  undertaken  by  conducting  a  quantitative  and qualitative comparative analysis of contemporary Saudi and Egyptian novels.\n\nToury's  descriptive  analysis  emphasises  the  need  to  move  from  a  source-orientated approach  to  a  target-orientated  approach  to  examine  and  explain  the  nature  of  the  translation product  and/or  process.  Toury  (1980)  argues  that  source-oriented  theories  are  abstract  and insufficient as a point of departure for research since they are mainly preoccupied with the source text  and  protecting  it.  Toury  (1985)  stresses  the  empirical  nature  of  a  descriptive  study  of translation:\n\nSince the object-level of translation studies consists of facts of 'real life' - whether they be actual texts, intertextual relationship, or models and norms of behavior - rather than the merely  speculative  outcome  of  preconceived  theoretical  hypotheses  and  models,  it  is undoubtedly, in essence, an empirical science. (p. 16)\n\nTranslation, according to Toury (1995), is a product of the host culture, so the function, process and product of translation according to him are studied in consideration of the target culture (TC). The main aim is to understand and explain the translation product rather than to suggest or present the right or correct translation. This approach does not neglect ST, but it shifts the attention to studying the relation between the TT, the TC, and the process of the TT's production. Toury (1995) believes that such an approach is the 'best means of testing, refuting, and especially modifying and amending the very theory, in whose terms research is carried out' (p. 1).\n\nAs  mentioned  above,  this  target-oriented  approach  does  not  exclude  the  ST  or  the translation  relationship,  but  it  changes  the  priority  and  level  of  attention.  It  begins  with  an observation from where the translation activities end, which is the translated text and its position in the social and literary system of the TC. Then the observations go back to study the process, which involves comparing segments from the ST and the TT to identify regularities. Ultimately, it will formulate a generalisation of norms and establish implications for decision-making in future research (Toury, 1995).\n\nOne of Toury's central  sociological notions is the concept of translational norms. This concept  was previously  discussed by Even-Zohar (1971), but it was  Toury who expanded the concept  and  took  it  further  (Brownlie,  1999).  The  exploration  of  norms  in  a  broader  sense  in\n\ntranslation studies began with his article, published in the 1980s, and was then expanded in his 1995 book Descriptive Translation Studies and Beyond (Malmkjær, 2008). Toury (1995) argues that norms are socio-cultural phenomena that lie and move on a scale between two extremes of absolute rules and individual idiosyncrasies. He claims that, by their nature, norms are unstable: they can appear, change and disappear over time. They are formed through socialisation, which involves  individuals  shaping  these  norms  or  other  kinds  of  sanctions  through  their  activities (Toury, 1995). Norms, according to Toury, can be defined as 'the translation of general values or ideas shared by a community - as to what is right and wrong, adequate and inadequate - into performance instructions appropriate for and applicable to particular situations' (Toury, 1995, pp. 54-55). Toury states that norms exist in translation practice, but that they are not just limited to the translation process; rather, they are involved at every level of the translation experience. The norms of translational  behavior  can  be  identified  by  studying  the  text  and  identifying  regular patterns in the translation. Regularities of the behavior in the data can indicate the existence of translational norms.\n\n\n## Comparative Textual Analysis\n\n\nComparative textual analysis was conducted as the major method to collect and categorize the data for the paper. A key initial stage in the comparative analysis involved analysing LDD in the STs. The source textual analysis was concerned with confirming the diglossia in the novels and then locating the LDD in the diglossic texts. This aimed to understand the differences between the LDDs that were used in the novels, such as which Saudi or Egyptian dialects are presented in the text. In particular, this stage focused on providing evidence as to why the selected novels can be considered LDD novels, how the LDD in the novels is represented, how it is semantically and syntactically different from the spoken dialect in everyday life, and, finally, what changes authors have made to the spoken dialect when they write their dialectal dialogue. To identify the LDD, the researcher used my knowledge of the dialects, consulted with other native speakers, studied the profile of the  characters in the novel, and make use of the oral (podcast, radio and, television shows) and written (such as dictionaries, forums and social media) media material. It should be noted  that  the  transliteration  of  the  LDD  in  the  discussion  chapters  also  made  use  of  these resources.\n\nAfter completing the identification process of the STs, the researcher then identified the availability of the English translations of the selected texts. After confirming the availability of the TTs, the researcher started to create unidirectional parallel corpora. To obtain satisfactory results that covered the procedures that were used in the English translations of the selected novels, the researcher worked on each novel with its translation individually. LDD and its translation were mapped  into  a  series  of  paired  segments.  This  series  of  paired  segments  were  organised  by following two steps. First, the data were compared, by identifying LDDs in the STs and analysing all  of  the  LDDs and their translation. After this, each paired segment was divided into several categories depending on the adopted translation procedures. The program that was used to organise the paired segments was Microsoft Excel. Each novel had its own Excel file that was divided into several sheets, with each sheet representing a translation procedure. In a word document, and while the researcher was doing the analysis for each novel and its translation, the researcher added her comments and analysis for a substantial number of examples to assist me in the description. It is important to clarify that the Microsoft Excel program was used only as a management tool for\n\nclearly organising the data. After that, the data was turned by Excel into visual charts to facilitate understanding. Where relevant, the quantitative data will be included in the data analysis chapters in the form of percentages. Due to the overlap between procedures, where several procedures were used simultaneously for the same sentences, the percentage will be an approximation. The main expected outcome from the quantitative method was to give only an indication or estimation of the frequencies of procedures in the translations. In addition, the quantitative evidence was intended to strengthen the validity of the observations, especially about stylistic features, and to highlight the significance of stylistic features that might be overlooked in the first descriptive chapter.\n\n\n## Selections\n\n\nIt is impractical and impossible to include the whole selected translations in the analysis, so a sample from the texts should be selected. The selection technique used in this research was inspired by purposive sampling, which 'involves selecting a sample based on pre-defined critical parameters' (Saldanha &amp; O'Brien, 2013, p. 34). A focus on the characteristics of the population might  help  in  serving  the  aim  of  the  paper.  The  selections  were  made  in  two  stages  when conducting the comparative textual analysis. The focus was on mapping the translation procedures adopted to translate LDD in Arabic diglossic novels regardless of who the translator of the text was. The selection method was applied across each novel by choosing a sample from several chapters. The chosen chapters were from those that include more LDD, whereas those chapters that include more narrative than dialogue were excluded. However, due to the variation of length between each novel - which meant that a chapter in one novel could equal in length three chapters in another - no maximum of 15 chapters from any one novel were included in the selection. Within the  selected  chapters  I  divided  each  paired  segment  in  each  novel,  as  stated  previously,  into separate  categories,  where  each  category  represents  a  translation  procedure.  Next,  I  select examples  from  each  category  to  represent  each  procedure  in  the  discussion  chapters.  The representative examples were chosen based on internal and external factors. External factors that are related to the context for example the regional varieties. The internal factors are linguistically representative of each procedure.\n\n\n## Results\n\n\nThe reason behind this paper is mainly to explore how the translators have dealt with LDD by examining a selection of ten dialectal novels (five Saudi and five Egyptian). The aim is to give a quantitative and qualitative overview of how LDD has been translated into English and what the frequent procedures used in English translations are when one of the Saudi or Egyptian dialects is used in the dialogue. What are the changes that the LDD undergoes in the translation process?\n\nThe data included in the following analysis is extracted from: 1. Mūdan Al Mīlḥ  Cities of ( Salt ); 2. Dunqulah: Riwāyah Nūbīyah ( Dongola ); 3. alShamīsī  Shumaisi ( ); 4. Matāhat Maryam ( Maryam's Maze ); 5. Dhāt  Zaat ( ); 6. al-Qārūrah  Munira's Bottle ( ); 7. Banāt al-Rīyāḍ  Girls of ( Riyadh ); 8. al-Bāb al-Maftuḥ  The Open Door ( ); 9. al-Ḥamām lā yaṭīr fī Buraydah  Where Pigeons ( Don't Fly ); 10. al-Fā'il  A Dog with no Tail ( ).\n\nTwo points require clarification concerning the writing of Saudi and Egyptian novels. First, the use of diacritic markers plays a crucial role in the Arabic writing system as it shows how a word is pronounced. In most of the LDD in the ST, diacritic markers are partially absent, so it is sometimes difficult in short sentences to classify whether the words in the selected data should be\n\npronounced in MSA or according to the pronunciation of the dialect used in the novel. I used my knowledge of the dialects, in addition to the contextual and dialogue information surrounding the LDD and the background information of the character that is speaking, to judge the sentence. Any sentence that in my judgment leans more towards Modern Standard Arabic (MSA) was discarded. Second, the letter ( ق qāf ) is realised as a glottal stop in the Cairo and the Delta spoken dialects but as a hard 'g' in upper Egypt. However, Egyptian writers retain MSA phonological realisation for the letter ( ق qāf) as ( قا qā ) when writing LDD.\n\nOverall, the comparison of parallel corpora reveals that the procedure used by translators can be classified into three categories. First, the most frequent procedures, which are evident in almost all translations of the novels in the corpus, include using marked form, standardisation, borrowing,  substitution,  and  paraphrasing.  The  second  category  comprises  the  semi-frequent procedures which do not score a high percentage in the novels and are apparent in only halves of them, such as semi-literal translation, omission, addition, explication, and paratextual procedure. The third category contains the least frequent procedures; these procedures, which only appear in less than a quarter of the corpora i.e. changing the narrative to dialogue, using broken English. These findings, especially with only the first two categories, will be expanded and described in more detail, with examples from the translations, in the subsequent sections.\n\nIt is important to note that the procedures do not function separately and that there is an overlap  between  several  procedures;  for  example,  marked  style  can  exist  with  borrowing  and paraphrasing  in  the  same  sentence.  However,  the  procedures  are  considered  separately  in  the analysis stage and here for the purposes of description and illustration, even if several procedures may occur in the same sentence. Particularly with procedures such as borrowing and substitution, the focus will be on the part of the sentence that represents that procedure to clarify how these are presented in the translated novels. The frequency percentages represent the percentage of those procedures  out  of  the  overall  percentage  in  each  novel.  Procedures  in  the  novels  will  not  be compared here based on percentage; these figures are provided here only to show the frequency of each procedure related to LDD in each novel.\n\n\n## Using the Marked Form\n\n\nThe use of a marked writing style to tackle the LDD in TTs is one of the most frequent ways that translators choose to approach LDD in the ST. By marked writing style, I mean a style of writing that imitates spoken conversation. It includes contractions, slang, incomplete syntax, abbreviations, and the use of short or incomplete sentences. The marked writing style is presented in the selected translations thro as the use of contractions, phrasal verbs, idioms, incomplete syntax (such as removing subject and auxiliary verb), slang, and colloquial words. The marked writing style was either a direct representation of the dialect or compensation to present the conversational style of the dialogue.\n\nThis procedure was the most frequent in all of the translated novels, with high frequency in the corpora, as shown in Figure One.\n\nFigure 1. Using marked form\n\n<!-- image -->\n\nThe selected novels include a substantial number that uses marked writing style. This striking result stems mostly from the prevalence of contractions and phrasal verbs in dialogue to illustrate the marked style of the dialogue in the translated novels. However, there are different preferences for using marked writing styles in each novel.\n\nThe most frequent procedure to represent the marked writing style in the translations is the use of contractions. The translators try to represent the dialect in the STs by using contractions as a means to create in the TTs a marked style that resembles the conversational writing style. Most of the contractions are the common contracted forms that occur between the subject and the verb 'to be' or that come with interrogative or negative sentences. The following example is from The Open Door :\n\n## Example One (ST, p. 4; TT, p. 6)\n\nماتخافيش ياماما، ماتخافيش، أنا عارفه ان محمود بخير. دلوقتي ييجي، ضرورى ييجي ضرورى ضرورى، الصبح .. 'Don't be afraid, Mama. Don't worry, I know Mahmud is fine. He'll come now, he must, he'll come. This morning…'\n\nThe representation of the Cairene dialect in this example is presented in the following way: (1) omitting the glottal stop in the emphasising particle / إن ʾinn / and the dot below the letters / ي yā / in the  repeated  word /  ضروري ḍaruwwrī / which  means  'must';  (2)  negative  marker  / mā / and inflectional negation marker / -sha / in the verb / ماتخافيش matkhāfīsh / which means, as translated in this  example,  'do  not  worry'  or  'do  not  be  afraid  or  scared';  (3)  the  Egyptian  adverb دلوقتي / dilwa'ti /, which means 'now', although it can be noticed that the letter / qāf / is kept in MSA. The translator has chosen to render the dialects in the sentence through contractions of the negation and the subject with modal auxiliary verb 'will', along with using repetition.\n\nThere are some cases where the translator has used a less common contraction, that is, one that is more a spoken than a commonly written form. An example from the novel in Munira's Bottle :\n\nExample Two (ST, p. 39; TT, p. 24)\n\n.بدت الحرب\n\n'the war's started.'\n\nThe verb / بدت bīdat / is pronounced and written in the central Najdi dialect with the omission of the glottal stop after the letter د /d/, in contrast to its MSA counterpart. It is presented with the short vowel /i/ at the beginning and the absence of the phonological feature أ /ʾa/ , which occurs in the\n\nmiddle of the MSA counterpart verb /  بدأت badʾat /. This central Najdi verb is rendered through the omission of the 'h' and the vowel in the verb 'has' and the use of contraction.\n\nAs seen from the above examples, contraction is sometimes used as the only means to reflect the whole dialectal sentence in the translation of the dialogue, and where there is no other compensation for the dialectal representations in the ST.\n\nThe second representation is the use of phrasal verbs and idiomatic expressions, which were used by the translators to give a conversational style to the translated parts of the LDD. A phrasal verb is a combination of a verb and a particle that can function in a sentence as a single verb. When combined, both words give a different lexical meaning. Although phrasal verbs are more accepted nowadays in formal writing and settings, a number of the phrasal verbs in the translations are mostly used in spoken and conversational settings or sometimes in marked writing styles. This procedure has been used as a substitute for the dialectal verb in the STs. Consider the following example from A Dog with No Tail :\n\nExample Three (ST, p. 26; TT, p. 20)\n\nهي نقلة رمل، سبع متر، هتطلع الدور السابع، وانت حر، هتطلعها لوحدك طلعها، هتقاول عليها وتجبلك نفرين م السوق .معندناش مانع\n\n'It's a load of sand: seven meters. You'll carry it up the seventh floor. Do what you want. If you want to contract it out and bring a couple of other guys with you, I don't mind.'\n\nThe LDD in the ST example has been presented by the following means: (1) prefixal conjugation / هـ ha / before verbs, which indicates the future tense in Egyptian dialects; (2) the omission in the preposition  to  refer  to  the  speaker  as  someone  who  lives  in  Cairo  but  is  from  outside  Cairo (probably the Delta); (3) negative marker /  مـ mā / and inflectional negation marker /  ـش -sha/ after the verb. The dialect form has been reflected in several ways. As the focus here is the phrasal verb and idiomatic expressions, the sense of the prefixal conjugation / ha / has been replicated through the use of 'Carry it up' and 'contract it out'.\n\nAnother example of capturing the marked form of the dialectal verb through the use of phrasal verb and idiomatic expression in Cities of Salt is:\n\nExample Four (ST, p. 50; TT, p. 47)\n\nً\n\n<!-- formula-not-decoded -->\n\nHe added, almost in a whisper, 'He should be roaming about with the sheep or playing with children.'\n\nIn  this  example,  the  collocation /    يسرح  بالغنم yasraḥ  balghanm /  means  'to  freely  graze sheep'. This collocation is used in the Saudi Bedouin dialect to refer to a shepherd who takes his/her sheep and goats in the early morning to search for food. The verb /  يسرح yasraḥ/ means to 'proceed freely or without restraint', but it also has a temporal dimension that implies going out in the early hours of the morning. In the TT, the markedness of the collocation has been considered, and the translator uses of the idiomatic expression 'roaming about', which means to wander or range  about  freely,  which  may  also  imply  doing  an  activity  with  no  restraint.  The  temporal dimension of the verb has not been replicated, probably because the focus of the speaker was more on the effect of the activity rather than on the time.\n\nThe third representation of the marked writing style is through using TT colloquial and slang words. Here is an example from The Open Door : Example Five (ST, p. 9; TT, p. 11)\n\nمالك يا بنى، طمنى؟\n\n'What's wrong my boy? Tell me …'\n\nIn this case, the character addresses her son using / يا بنى yā bni /, which translates as 'my son'. The dialect is shown through the omission of the vowel at the beginning of the  un / بنى bni / after the vocative particle يا / yā /, as well as the omission of the dot under the letter / yā / at the end. The use of the colloquial phrase 'my boy' as a translation of /yā bni/ reflethe cts intimacy and a close relationship in English dialogue.\n\nThe same colloquial expression is used to translate the synonym for the word / يا بني yā bni / from the Saudi dialect, which is / ياوليدي yā wlīdī /. Consider the following example from Cities of Salt :\n\nExample Six (ST, p. 22; TT, p. 16)\n\n..يكفي ..  ياوليدي\n\n'that's enough, my boy.'\n\nThe word / ياوليدي yā wlīdī / is an eastern Bedouin dialectal diminutive form of the word /  ولدي wlādī/ , which means 'my son'. Again, the translated word 'my boy' captures the informality and the caring and intimate feeling implied by the dialectal diminutive.\n\nFinally, short sentences are also used in the translations to indicate LDD, as can be seen in the following examples:\n\nExample Seven (ST, p. 133; TT, p. 114, my underlining)\n\n.نائمة لكن ليه تسأل كذا؟ ماتثق بي\n\n'Asleep. Why are you asking all this? Don't you trust me?' ( Munira's Bottle )\n\nExample Eight (ST, p. 4; TT, p. 6, my underlining)\n\n.ماتخافش يابابا ، دي مظاهرة سلمية\n\n'nothing to worry about, Papa. It's to be a peaceful demonstration.' ( The Open Door ) The subject and the verb 'to be' in these two examples were not presented, thereby shortening the sentences and making them less unmarked and more conversational.\n\n\n## Standardisation\n\n\nStandardisation is when dialectal words are substituted by unmarked forms. Specifically, this procedure involves the translator choosing to omit all the dialectal references in the original text and to opt for more standard terms words. In this situation, the translator does not heavily include any marked writing style, such as the examples mentioned above - contractions, phrasal verbs, and colloquial or slang words. It is important to highlight that standardisation occurs mostly for sentences that do not have strong cultural references. The focus is not on the presentation of the  sentence  but  the  translation  of  the  LDD  words  themselves.  As  Figure  two  indicates, standardisation is a frequent procedure that is present throughout the entire corpus.\n\nFigure 2. Standardisation\n\n<!-- image -->\n\nHowever, the results obtained from the preliminary analysis of standardisation also show that the frequency  percentage  varies.  Particularly  worth  noting  is  the  wide  disparity  between  the application of standardisation in the translations. Standardising the dialect is below 15% of the total procedures in more than half of the novels, and in some cases, such as Shumaisi and A Dog with No Tail , standardisation accounts for less than 2%. The highest score for standardisation was in Zaat and Munira's Bottle , both translated by Calderbank.\n\nThe following example of standardisation comes from the translation of Zaat :\n\nExample Nine (ST, p. 127; TT, p. 117)\n\n<!-- formula-not-decoded -->\n\nyour servant Kamal, car clearance. What can I do for you?\n\nThe phrase أي خدمة /āyy Khidmah/ ' any service' means the offer of any service to someone, usually in providing service settings. It implies a sense of informality and causality when it is used in the conversation. The auxiliary verb and subject are again omitted here, as is the case in the Cairene dialect, and the sentence has been shortened. In the translation, the question has been presented in its full formal form as a direct wh-question. Moreover, instead of a series of very short sentences, the translator has used a comma as a pause before clarifying the job description.\n\nAnother example of standardising LDD in the translation can be found in Girls of Riyadh : Example Ten (ST, p. 47; TT, p. 30)\n\n<!-- formula-not-decoded -->\n\n'what are you doing, Mother?'\n\nَ\n\nThe Najdi LDD is shown in this example through: (1) the Najdi interrogative particle / وش wish /, which is used to request specific information where it means 'what'; (2) the verb / تسوين tsawiyyn /, a second-person feminine singular non-past active indicative of / س َ و ِي sawiya /  which means 'what , are you doing' or 'what you are up to'; (3) the word / اميمتي amimtī /, which means 'my mom' and is a diminutive form of the standard word / أمي 'ummī /.  This is an expression used in the Najdi region  to  show  unconditional  love  and  respect  for  the  mother.  The  whole  sentence  was standardised; the effect of showing love and respect to the mother by using a diminutive word in the ST has changed in the TT by the unmarked form.\n\nThe data analysis also reveals that some translators standardised a few dialectal terms or expressions and used the generic translation of source terms. The generic word can be defined here as the general word or phrase that is used to describe a group or a class of something without referring to a specific individual thing from that group or class. An example from Cities of Salt is:\n\nExample Eleven (ST, p. 50; TT, p. 47)\n\n( .واذا جاء الوسمي وكانت الامطار كثيرة تتغير حياة الناس ويتغير الوادي\n\n50)\n\n'If we get good rains, everything will change - the wadi will be a different place.' (47) The word /  الوسمي al-wasmī / means the rain that falls at the beginning of spring. It is derived from the word / الوسم al-wasm /, which means the marks left on the skin after cauterisation. The Bedouin use al-wasmī to refer to the rain that comes after the dry season. It is a metaphor for the effect of the rain on the land when the crops start to grow, and it reflects the obvious signs of the rain after the dry season. The translator has standardised the word and used the generic term to describe this rain as 'good rains'. This retains the sense of joy and hope after the arrival of this rain, but it does not reflect the temporal aspect of this rain.\n\n\n## Substitution\n\n\nSubstitution is here used to describe the translation of ST concepts by using a substituted referent from the TT that performs a similar function. Concerning the topic of this research, and based on the  results  obtained  from  the  data  analysis,  substitution  was  used  mainly  when  translating linguistically specific expressions from the SC or with some culturally specific expressions, such as jokes, religious expressions, or idioms.\n\n<!-- image -->\n\nFigure 3. Substitution\n\nFigure three shows that substitution constituted no more than 14.49% of procedures in the corpus novels except Shumisi in which it constituted approximately 27% of all procedures. Despite its fairly low frequency, this procedure was consistently found throughout the whole corpus.\n\nAn example of substitution from the data is the following idiomatic expression uttered by one of the main characters in the novel Girls of Riyadh :\n\nExample Twelve (ST, p. 16; TT, p. 8)\n\n! لا يا تِنحة! قصدي التفتي يسارك زي عقارب الساعة لما تكون على الحدعشر ... عمركو ماحتتعلموا أصول الحش 'No, you idiot, I mean, turn to your left like the hands of a clock when it's eleven - you will never get it, will you - you'll never pass Gossip 101!'\n\nThe word / أصول الحش ʾuṣol alḥash / is a collocation used in general in Saudi dialects to mean the basic knowledge of gossiping. This collocation is translated as 'Gossip 101'; the number 101 is a colloquial expression usually used in the university context to mean an introductory course, often with no prerequisites, and, outside the university context, it can also mean an introduction to the basics  of  something.  It  is  usually  combined  with  another  word  that  denotes  what  is  being introduced. The collocation 'Gossip 101' performs the same function as the ST terms and is a\n\nmore accessible referent in the receptor culture. Moreover, it preserves and reflects the humour in the original collocation.\n\nFrom The Open Door , consider the following:\n\nExample Thirteen (ST, p. 78; TT, p. 86)\n\nتعبان ولاجيت تلبس وتستوجه عشان ال حفلة ؟\n\n'Tired  -  or  was  it  just  so  you  could  come  and  get  dressed  and  make  yourself  dandy  for  the reception.'\n\nHere, the character is mocking his friend for coming to the party by saying to him تستوجه /tīstawjāh/ which means literally ' to make yourself a noble'.  He means to tell him that 'you come here to us you are dressing fancy clothes just to make yourself noble'. In the translation, the expression 'make yourself dandy' has been used. What is interesting in this translation is the relevancy of the word to TC. According to the Cambridge dictionary, the word 'dandy' refers to a man, especially in  the  past,  who  dressed  in  expensive,  fashionable  clothes  and  was  very  interested  in  his appearance. Connecting this historical connotation to the word could help the readers to understand how the character is mocking the other for being an extravert and for his attempt to create this noble image for himself.\n\n\n## Borrowing\n\n\nBorrowing is a procedure used to transfer a word from the SL into the target culture. Vinay and Darbelnet (1958/95) state that this procedure is usually used to create 'a stylistic effect' for the text and to introduce some of the source's local style into the TC (Shuttleworth &amp; Cowie, 1997, p. 17). Following such a procedure will keep the SC present in the translation (Fawcett, 1997). Borrowing has always helped to introduce many loan words into other languages, which could become accepted over time as part of the TL.\n\n<!-- image -->\n\nFigure 4. Borrowing\n\nAs Figure four shows, most of the translators in the corpus used the procedure of borrowing, with the highest frequency of 7.69% and the lowest of 2.33%. Although the procedure does not occur in the dialogue in Maryam's Maze , that does not mean that it is not used. A quick analysis shows that it is present in the narrative through the borrowing of several words which were explained in the glossary included in the novel.\n\nA closer look at the selected novels reveals that this procedure is used more with terms relating to clothes, cultural expressions, religious expressions, places, honorific titles, celebrations,\n\nor  public  figures.  The  use  of  borrowing  is  consistent  in  the  corpus;  however,  translators  have approached it in many different ways. First, some translators include in the dialogue borrowed words with no explanation in the translation or even in a glossary. This is mainly the case in three novels: Cities of Salt , Shumaisi , and Where Pigeons Don't Fly . In other novels, borrowed words are combined with other procedures or followed by an explanation to help the reader grasp the sense of the borrowed words.\n\nFew translators mainly rely on in-text explanations, such as in Booth's translation of The Open Door and in a few cases in Girls of Riyadh , where she adds a parallel concept in English after the borrowed word to help the reader understand the borrowed cultural terms. For example: Example Fourteen (ST, p. 8; TT, p. 12)\n\n.زي القمر\n\n' Zayy al-qamar , he's as gorgeous as a full moon.'\n\nThe expression / زي القمر Zayy al-qamar/ , which is in Egyptian Arabic and means literally 'like a moon', is usually used to praise someone and to comment on their beauty. As can be seen from the translation, an explanation was added in the sentence next to the borrowed word.\n\nA similar example of this procedure of borrowing with an explanation, but where the latter is not included in the dialogue but after the quotation marks, can be found in the translation of Dongola :\n\nExample Fifteen (ST, p. 99; TT, p. 68)\n\n<!-- formula-not-decoded -->\n\n'My son is dead, people! Dead! Ya badailli.' This meant, what a loss! 'My dear Awad!' The  meaning  of  the  Nubian  expression /  يابادللي Ya  badailli /  in  the  above  dialogue  has  been explained  in  the  ST  in  a  footnote  as  meaning  'what  a  loss';  however,  in  the  translation,  that footnote is included as an explanation after the borrowed word.\n\nThe case of Dongola is interesting for the variation in opting for an explanation or not. The translator varied between in-text explanation and no explanation at all, even for Nubian words that would be unfamiliar to readers of the English translation. On the other hand, in the translations of A Dog with No Tail , Munira's Bottle , and Zaat , the translators choose to treat the borrowed words as a natural part of the English dialogue. They include the borrowed words in the TT, with no intext explanation or footnote, but they do include a glossary at the end of the novel to explain all the cultural terms included in the translation. One interesting case in Calderbank's translations is the  consistent  appearance  of  the  vocative  particle /  يا ya /,  which  can  be  considered  a  new  and experimental addition in the target English context. For example, in Munira's Bottle :\n\nExample Sixteen (ST, p. 119; TT, p. 111)\n\n<!-- formula-not-decoded -->\n\n'How am I the criminal, ya Munira?'\n\nThe two letters / يا Yā / are a grammatical structure called the vocative. The vocative usually consists of two parts: the first is the vocative particle, which is / يا ya /, which is followed by the second part (noun  or  phrase)  for  the  one  who  is  being  addressed.  It  is  usually  used  to  attract  someone's attention.\n\n\n## Paraphrasing\n\n\nThe use of paraphrasing procedure in the context of translating dialect is the omission of the  dialectal  denotative  meaning  of  the  word,  followed  by  the  addition  of  amplification  or\n\nexplanation of the connotative meaning. It has been used with culturally specific expressions or dialectal proverbs.\n\n<!-- image -->\n\n## Figure 5 . Paraphrasing\n\nThe results obtained from the preliminary analysis of paraphrasing show that it is a procedure that translators in the study preferred to use as an option to balance and not overload the text with cultural references. However, as is also the case with substitution, the procedure in most of the novels in the corpus does not exceed 15% of the overall procedures in each novel, as shown in Figure  five  with  the  lowest  frequency  of  4.4%  in Girls  of  Riyadh. In Shumaisi and Dongola , dialectal  cultural  reference  phrases  are  frequently  naturalised  and  paraphrased.  This  is  largely because, at least in these two novels, the translator tends to reflect the communicative nature of the phrase within the dialogue rather than give a literal meaning or borrow the whole phrase. The following is an example from Dongola :\n\nExample Seventeen (ST, p. 44; TT, p. 29)\n\n<!-- formula-not-decoded -->\n\n## 'And I'll give you all the money you want.'\n\nThe dialectal idiomatic phrase وأنا من جنيه لألف /wāna mn janīah lāʾalf /  is  used  in  the  Egyptian context in general, and in this excerpt from the dialogue in particular, to mean that the speaker will support the other man financially no matter what the amount of money needed. It means: 'I am ready to give you from one pound to one thousand.' In the translation, the communicative meaning of offering financial support is rendered as 'I'll give you all the money you want'.\n\nParaphrasing procedures are also used with culturally specific collocations, such as in the following example from Girls of Riyadh :\n\nExample Eighteen (ST, p. 14; TT, p. 5)\n\n<!-- formula-not-decoded -->\n\n'Ma shaa Allah* God willing, no envy touch her, she's so pretty.'\n\nThe collocation / ملح وقبلة milḥ wi qablah/ means 'pretty' and 'accepted'. This collocation is usually used in the Najdi and northern Saudi dialects to comment on the attractiveness of someone who has a charismatic character that makes people accept them. The translation captures the meaning of the collocation that relates to facial attributes since the word 'pretty' means someone attractive; however, the part relating to character has been dismissed.\n\nA final  example of paraphrasing is the following idiomatic expression from The Open\n\nDoor :\n\nExample Nineteen (ST, p. 70; TT, p. 78)\n\n.مواصفات ابن الحلال، انه يكون ابن ناس وكويس ومريش ومقطوع من شجرة ولايسكرش  ولايدخن\n\n'And the goods on the lovely man. Son of a good family, a real plum, seemly and solid and reeking with money, no relatives alive to come sniffing around, don't get potted, doesn't smoke.' Here are a few cases of paraphrasing concerning the traits the speaker uses to describe the potential husband. First, the expression ابن حلال /ībn ḥalāl / means 'legitimate'; however, it is used culturally to positively refer to someone as a 'kind good person'. This is fairly paraphrased as 'lovely man'. The other expression is ومقطوع من شجرة /wimʾtooʿ min shajarāh /, which has the literal meaning 'he was cut from a tree' and is used in Egyptian culture mainly to refer to the fact that someone has no living relative, or more precisely that one or both parents have passed away and that there is no sibling or extended family. The character says this to imply that she wants to marry a man who does not have any relatives, since then she can live in peace without relatives bothering the couple or trying to create problems. The translator has explained this metaphorical expression by translating the expression to 'no relatives alive to come sniffing around'.\n\n\n## Literal Translation\n\n\nThe  literal  and  semi-literal  translation  is  a  procedure  used  to  'convey  the  content unchanged while observing TL norms' (Shuttleworth &amp; Cowie, 1997, p. 95); in other words, it keeps the same lexis by following TL grammar (Newmark, 1988). It can be seen, by some, as a useful way to remain close to the source expression by keeping its meaning. With the data analysis, the literal translation is used with dialectal cultural words or expressions (for example, proverbs) that have a metaphorical nature.\n\n<!-- image -->\n\n## Figure 6. Literal translation\n\nIt  is  apparent from Figure six that literal translation is not present in all the selected data. The results show that around two-thirds of the novels in the study include literal translation with a frequency below 6%. This percentage demonstrates that translators in the corpus are not totally in favour of literal translation when it comes to translating LDD. Further analysis shows that literal translation is mostly used to translate proverbs in The Open Door and Cities of Salt .\n\nThe following is an example of a literal translation from Munira's Bottle :\n\nExample Twenty (ST, p. 74; TT, p. 32)\n\n.عشب الحديقة مات، مانفع السيل\n\n'The grass in the garden is already dead, see. The rain won't make any difference.'\n\nThis is a Najdi dialectal proverb that indicates that sometimes there is no point in responding after something has happened because it will not make any difference. Although it has a meaning based on its metaphorical nature, the expression can be guessed from the literal translation.\n\nA literal  translation  may,  however,  sometimes  fail  to  capture  the  functionalism  of  the expression. Ivir (1987) argues that 'when the extralinguistic realities of the two cultures differ at a particular point, the literal translation of an expression will not in itself be sufficiently transparent to fill the gap' (p. 41). In other words, when there is no shared extralinguistic reality, the use of the literal translation may sound odd to the target readers and may provide an abstract expression. Here is an example from Girls of Riyadh :\n\nExample Twenty-one (ST, p. 16; TT, p. 8)\n\n.المهم شوفي البنت هادي... أما عليها مواهب\n\n'Anyway, check out that girl - she's got 'talent', all right!'\n\nThe word / مواهب mawahib / this word is street slang with a cultural connotation in Saudi Arabia. The meaning is more related to a description of a woman's physical attributes, or what is rendered in English slang as 'assets' rather than 'talent'.\n\nAnother case of not fully capturing the meaning through literal translation is the following proverb from Cities of Salt :\n\nExample Twenty-two (ST, p. 78; TT, p. 76)\n\n.إلحق العيار لباب الدار\n\nPursue the scoundrel to the door of his house.\n\nThis Bedouin proverb إلحق العيار لباب الدار / ʾalḥak al-ʿayar labāb eldār/ which means 'follow the wicked to the door of his house' is used here to warn the people to be aware of a wicked human but at the same time to be patient to see whether the situation will end or not. In this case, the character is impatient with the Emir and he does not believe the excuse that is given to him. The character implies through this proverb that there is something not right here but that they should be patient and wait to see where this is going to take them. This is not clearly captured through the semi-literal meaning of the proverb.\n\nUnderstanding the elements of the dialectal expression is important for clearing up any pragmalinguistic  misunderstanding  when  rendering  the  literal  meaning  of  the  words.  As  these expressions  have  a  metaphorical  nature,  the  denotative  meaning  of  the  ST  words  should  be considered  when  deciding  which  synonym  to  choose  to  avoid  any  loss  of  meaning  and awkwardness in the context.\n\n\n## Omission\n\n\nThere are cases where translators omit a dialectal word or expression without compensation. This procedure has been used with some of the dialectal words in sentences within the dialogue.\n\nFigure 7. Omission\n\n<!-- image -->\n\nFigure seven shows that omission is not present in almost half of the data. The frequency is lower than that of other procedures, with the highest frequency of 8.6% in Where Pigeons Don't Fly and the lowest of 0.2% in The Open Door . In Where Pigeons Don't Fly the omission is surprisingly not limited to sentences, as in other novels; instead, the translator chose to omit an entire song that a  character  was  chanting  in  dialogue  as  well  as  a  few  dialectal  conversations.  The  following example  presents  such  omission  from  the  translation  of Where  Pigeons  Don't  Fly :  dialectal conversations at the end of chapter three, where there is introductory information about why the father of the main character Fahd has been jailed and how that has affected his family, particularly his sisters, have been omitted:\n\nExample Twenty-three (ST, p. 3; TT, p. omitted)\n\nَ فلم يكن هناك أكثر قسوة من أن يقول أهل بريدة(( ولدهم مسجون بقضية جهيمان!)) كم كانت الجدة صارمة حين جاءت أم :شاب خطب أصغر العمات، وهي تعتذر بخجل عن إتمام زواج ولدها من العمة الصغرى حصة -!مادرينا أن ولدكم مسجون\n\n!مسجون بقضية سياسية، ماهو بقضية أخلاق ولاشرف، أو قلَ دين-\n\nهكذا حسمت الجدة نورة الأمر، وهي توصي المرأة قبل أن تخرج من باب المنزل في حي القويع غرب بريده، بأن تقول للناس ...))!ولحريم القيل والقال بأن (( بيت السفيلاوي بيت شرف ومراجل\n\nIn this conversation, the narrator talks about how life has been harsh on the family of Fahd's father because of his involvement in the seizure of the Grand Mosque led by Juhayman in 1979, which was a turning point in Saudi history that resulted in the Sahwa movement taking control. The above dialogue hints at how the people in Saudi Arabia have regarded and reacted to this event, and how it not only affected the father who is in jail but also brought shame to his family. The dialectal conversation is between Fahd's grandmother and a lady whose son is engaged to Fahd's aunt. After the incident, she visits the family to tell them that they will call off the wedding because 'we didn't know that your son is in jail!' The grandmother firmly replies, 'he was imprisoned in a political issue,  not  an  issue  related  to  morality,  honour,  or  religion!'  The  grandmother  gives  a  strict instructions to the woman to tell everyone this, saying that 'the house of Saflawy's family is the house of honour and manhood'. The frustration of the grandmother in these sentences indicates her realisation of how stigma will be attached to her and her house because of her son, and how she should be firm about it. Although this is a brief conversation, this detail shows how the family of anyone involved in the event will be judged by society. The strict character of the grandmother and how she firmly deals with this scandal are not shown in the translation here or later.\n\nAnother example of omission occurs in Maryam's Maze :\n\nExample Twenty-four (ST, p. 20; TT, p. 10)\n\n:صرخت رضوى فردت عليها المرأة -احمدي ربنا إني ساكته عليك. دا أنا قانية في بيتي مرة. دى جزاتي إني مافضحتكيش؟ .. وقعت الجملة على مريم كالصاعقة خاصة مع تصاعد المرأة وهو يسرد تفاصيل علاقات رضوى بآخرين 'You should thank God that I've kept quiet about you,' replied the woman. 'Is this my reward for not exposing you?'\n\nThis last sentence struck Maryam like a thunderbolt, especially when the woman's voice got even louder, and she started reeling off the details of Radwa's relationships with other people… The translator has omitted the second sentence in the conversation دا أنا قانية في بيتي مرة /da ʾana qaniā fī  bītī  marah/ which means 'I keep in my house a prostitute'. The owner of the house describes Radwa as / مرة marah / which according to an explanation by a native speaker, is used in Egypt, especially in the local context of Cairo, as an extremely strong insult to a woman to indicate that she has had multiple relationships or to imply that she is not a virgin. In the ST, this is what might shock Maryam, as the word is strong and scandalous in the Egyptian context of the novel. Although it can be guessed from the translation that there has been a scandalous conversation, the strong insult itself has been omitted.\n\nA final example of omission at the word level is from Cities of Salt :\n\n\n## Addition and Explicitation\n\n\nThe addition in the corpus involves either adding new information that was not in the LDD in the ST or adding syntactic additions that explicate the implicit information in the LDD which is obvious to the ST readers but not to the TT readers.\n\n<!-- image -->\n\nFigure 8. Addition\n\nThe addition of new information not in the ST occurs in six of the ten novels, as shown in from Figure eight, with a frequency that does not exceed 3.5%. It is used in some cases to add emphasis to the translation, such as in the following example from Girls of Riyadh :\n\nExample Twenty-five (ST, p. 14; TT, p. 6)\n\nأحلى من العروس بكثير! تصدقين أنا سمعت أن الرسول دعا للشينة؟\n\nShe's a good deal prettier than the bride. Can you believe it, I heard that Prophet Mohammed used to send up prayers for the unlovely ones!\n\nISSN: 2550-1542 | www.awej-tls.org\n\nIn this example, the translator has added the expression 'a good deal' to emphasise the attractive traits of the girl compared to the bride. The idiom is an American spoken expression that is used when the speaker thinks something is good. The superlative statement is in the original; however, the expression has been added in the TT for emphasis. However, according to an American English speaker, this expression seems unusual to be used by a person, since it is usually used with objects.\n\nIn other cases, new information, not present in the ST, is added to the sentence in the TT for reasons either of characterisation or censorship. In the following example from A Dog with No Tail , the curse word has been omitted from the ST sentence حمدي العبيط بيقولك .. أمك /Hamdi alʿabīṭ bīʾwlak ... ʾumak/ which means 'fool Hamdi says … your mother'. The omission could be because of censorship, at the publisher's request, or because the author felt the readers would get the curse without openly voicing it in the written text. However, the removed curse in the ST can be guessed by readers from the sentence, as the following example shows:\n\nExample Twenty-six (ST, p. 29; TT, p. 22)\n\n<!-- formula-not-decoded -->\n\nHamdi the Fool says to you, 'Your mother's cunt.'\n\nIn the TT, the translator has decided to complete the sentence and make the curse obvious to the readers. The word 'cunt' has been added. The offense becomes visible in the translation, unlike in the ST.\n\n<!-- image -->\n\nFigure 9. Explicitation\n\nBesides the addition of new information, Explicitation is also used to introduce new information in the TT that is implicit in the ST (Vinay and Darbelnet, 1958/95). Figures eight and nine reveal markedly lower rates of addition and explication compared to other procedures applied in the translations.\n\nAs an example of clarifying new information to explicitate what is implicit in ST, consider the following example from The Open Door :\n\nExample Twenty-seven (ST, p. 73; TT, p. 82)\n\n<!-- formula-not-decoded -->\n\n'When's the big day, God willing.'\n\nHere the aunt is asking her nephew when they should plan to set a date for his sister's wedding by saying ونويتوا أمتى ان شاء الله / wanīatū ʾamtaa ʾin shāʾ Allāh/. She does not ask the question directly; instead, her question means 'when are you having the intention, God willing'. In the Egyptian or general  Arab  cultural  context,  particularly  in  Islamic  families,  it  is  usual  to  attach  the  word\n\n## AWEJ for Translation &amp; Literary Studies Volume, 6 Number 4.  October 2022\n\n'intention' نويتوا /nīatū/, which here refers to the wedding with the willing of God. This is mainly in the hope that God will bless the act. The word 'wedding' is not mentioned in the conversation, and the aunt mainly asks this question to shift the conversation. In the TT, the translator makes this implicit information about the date of the wedding explicitate to the readers by adding the expression 'the big day' that refers to weddings.\n\nAnother example comes from Dongola :\n\nExample Twenty-eight (ST, p. 33; TT, p. 20)\n\n.سيبك منه جا با ين زملكاوي عبيط، أصل كل البوابين زملكاوية\n\n'Leave him alone - he's just a stupid Zamalek supporter. All the servants are for Zamalek.' In this example, the character is trying to make fun of the other person by saying he is a زملكاوي /Zamālkāwi /, which means he is a supporter of the Al Zamālk football team, the rivals of his team. Zamālk or calling someone Zamālkāwi can be used either to refer to an area in Cairo or to the famous Egyptian football team. As the fact that he is talking about a football team is implicit in the ST, the translator has added the word 'supporter' to make this explicit for TT readers.\n\n\n## Peritexts and Dialects\n\n\nPeritexts are the other texts supplied by the translator to give the reader more information about the text or the cultural and historical references in the text. Genette (1997) describes peritexts as  'liminal  devices  and  conventions,  both  within  and  outside  the  book,  that  form  part  of  the complex mediation between book, author, publisher and reader: titles, forewords, epigraphs and publishers'  jacket  copy  are  part  of  a  book's  private  and  public  history'  (p.  xvii).  Paratextual intervention  is  an  important  aspect  of  translation  in  general  and  in  studying  the  translation  of dialogue it is frequently 'metatranslational in nature, reflecting on the problems of translation in the text in question' (Hermans, 2014, p. 287). Pym (2011) argues that studying peritexts 'can reveal  a  great  deal  about  the  social  context  in  which  translations  are  carried  out,  especially concerning target audiences' (p. 87). The paratextual presence in the data has been examined to indicate  if  the  dialect  was  presented  in  these  paratextual  procedures  or  not.  It  was  found  that paratextual data varies between translators. Paratext in the selected novels is presented through three types of peritext: translator's introduction/note; glossary; and footnotes.\n\n\n## Speech and Sound Representation\n\n\nIn  a  few  translations,  the  translators  use  a  number  of  compensation  procedures  that  are  not necessary for translating LDD, but which give a sense of conversational style that is usually already in the ST. Below, I give a general idea of how these are used in the translations.\n\n\n## Sound Imitation\n\n\nSound imitation is present in a few novels to imitate a conversational style. For example, in Munira's Bottle the main character gasps when a familiar song is suddenly played on the stereo: Example Thirty-two (ST, p. 115; TT, p. 98)\n\n<!-- formula-not-decoded -->\n\n## 'Allaaah… just imagine?'\n\nAllah, is a borrowed word, mainly meaning 'God', but the character uses it to evoke nostalgia and to reminisce over a past event. The translator tries to capture this by adding a triple 'aaa', which could imitate the character's sound intonation as she recalls the memories that had been awakened by the song.\n\nAnother example of imitating the sound intonation comes from Girls of Riyadh Example Thirty-three (ST, p. 49; TT, p. 43)\n\n:\n\n<!-- formula-not-decoded -->\n\n'Sooo, Lamees, what are we going to do with you? Isn't it enough, what you did last week, when you wouldn't tell me which girl it was who put the red ink on the teacher's chair in the class?' The 'o' at the end of the word 'so' is tripled to reflect the angry and threatening sound intonation of the school principal.\n\n\n## Emphasis and Emphatic Devices\n\n\nRepresentation of the conversational style of the dialogue is also occasionally achieved through non-orthographic features such as ellipses, exclamation marks, and dashes in most of the examined novels.\n\nAs for ellipsis, it is already in the ST and is reflected in the translation or removed from it and replaced. In some cases, it is used in STs to reflect pauses and incomplete sentences, such as in this example from The Open Door :\n\nExample Thirty-four (ST, p. 3; TT, p. 6)\n\n.ماما .. ماما\n\n'Mama… Mama.'\n\nHowever, sometimes the speech representation changes through the translation process: either the ellipsis is omitted, as is usually the case in Shumaisi , Cities of Salt, and Dongola , or it is changed to another emphatic device such as exclamation.\n\nThere is also a tendency in The Open Door to replace dots with a dash in the TT:\n\nExample Thirty-five (ST, p. 76; TT, p. 84)\n\n... والناس مالها ومالنا ياعصام؟ أنا مش فاهمه حاجه، مش فاهمه حاجه خالص و\n\n'People - what have they got to do with it, or with us? No, I don't understand anything, Isam, nothing at all, and -'\n\nOverall, the use of these non-orthographic features varies between novels and their translations. To some extent, these devices have been reduced in the translations. It is not clear what triggers the three options of keeping, adding, or removing emphatic devices, especially with ellipses. This might be attributable to stylistic preferences in the translation.\n\nTo sum up, the data analysis shows that translators did not use a target dialect to translate a source dialect  but  used  a  variety  of  procedures  to  deal  with  LDD  in  the  context.  As  previously demonstrated, the most common procedures found in almost all translations of the novels in the corpus include the use of marked form, standardisation, borrowing, substitution, and paraphrasing. Then comes the semi-frequent procedures that do not reach a high percentage in the novels and are found in only half of the novels, such as semi-literal translation, omission, addition, explication, and paratextual procedures. The data show that the same procedures were used in the translation of the novels regardless of the source dialect.\n\n## D iscussion\n\nThe  primary  question  of  this  project  was  to  identify  how  translators  deal  with  LDD  in  the translation  of  Saudi  and  Egyptian  novels.  The  descriptive  quantitative  and  qualitative  textual analysis indicates regularities of behaviour across the translators. Overall, the analysis of the data shows that the translators  for  Saudi  and  Egyptian  novels  did  not  follow  solely  the  previously suggested procedures to deal with LDD in the text which are using pseudo-dialect translation (Hatim  &amp;  Mason,  1990) parallel  dialect  translation (Sánchez,  1999b) dialect  compilation (Perteghella, 2012) or Standardisation Leppihalme (2000). In detail, they have opted for various procedures  rather  than  choosing  a  single  solution  to  deal  with  the  problem,  and  none  of  the translators rendered the source dialect into a target dialect. Interestingly, however, translators do not tend to standardise or erase the conversational elements of dialogue; on the contrary, they recognise the conversational aspect and try to adhere in general to that in their translations. In fact, their  procedure is one of compensation rather than a translation of the dialect.  Regarding the second question investigates if the translation procedures shift with changes in dialect? the data analysis  shows  that  fairly  similar  varieties  of  procedures  were  used  to  translate  the  different regional and social dialects in all the previous examples from the STs. Translators also seem to use the same procedures with dialects that co-exist in the same novel, and this shift is not always hinted  at  in  the  dialogue.  One  of  the  few  attempts  is  in Shumaisi where,  before  the  relevant sentences, the translator writes the name of the different dialect that is spoken by the Sudanese character.\n\nThe quantitative analysis shows that some procedures are more frequent than others in the translation of LDD. The most frequent categories, which are present in almost all the novels, are: using marked writing style, standardisation, substitution, borrowing, and paraphrasing. It seems that the translators in the corpus concentrate on reproducing the intention behind the use of dialect in the ST (Määttä, 2004). This is clear in the data through the translators' focus on retaining the different  layers  of  the  structure  of  the  novels  and,  in  particular,  on  producing  an  informal conversational style for the dialogue while to some extent preserving the formality, to some extent, of the narrative. At the same time, the translators keep the Arabic present in the TTs and make it clear that the text is a translation by borrowing Arabic words in the dialogue and the text in general.\n\nIn considering the changes that LDD went through in the translation, the question arises of whether or not  translators  have  the  intention  to  adapt  the  LDD  novels  to  certain  poetics.  The findings from the descriptive textual analysis suggest that the rewriting of LDD in the TTs is, to some extent, influenced by poetics and the universe of discourse of the TT (Lefevere, 1992b). The translators aim to produce mainly an informal conversational writing style to adhere to the general principle of the English literary system about writing informal dialogue in novels. Consequently, the translations present a reading experience that might to some extent adapt it to the TT literary productions. The LDD has changed in the translation process to become literary informal dialogue (LID).\n\nAnalysing the data within Toury's (1995) norm framework reveals that the regularities of behaviour  across  the  translators' work,  particularly in rewriting the LDD  into  informal conversational style (LID), indicates certain norms that these translators follow in relation to the translation  of  Saudi  and  Egyptian  novels.  It  seems  the  regularities  of  behaviour  have  been developed to adjust the novel to the TL's literary presentation, where it is acceptable to use a marked writing style in the dialogue of novels. The frequency of the marked writing style indicates that translators are situating LDD in the conversational sphere, so they draw on the informality of spoken elements of the dialect in the translation. However, the textual analysis is still limited and not enough to confirm if translators are following a norm. Thus, as suggested by Toury (1995) and Brownlie (2003), combining the descriptive analysis with interviews with all translators would help to examine if there is a translational norm in the case of translating LDD in Saudi and Egyptian novels. Hearing from the translators themselves will help to understand how the rewriting might be influenced by the role of patronage and what role ideology plays in the process.\n\nMoreover, the question arises of whether, if we look more deeply than at these external results and investigate the practice of the individual translator's style within these regularities of behaviour, an in-depth analysis of several works by the same translators can reveal variations and particularities related to individual practices? This question is especially relevant where there is, as  shown  in  the  previous  analysis,  an  indication  of  variation  in  the  application  of  certain procedures, such as in a translator's use of borrowing.\n\nA final and important limitation of this paper was related to the representativeness of the data. The selection of and the comparative data acquired by analysing the works of the translators have been used to provide an understanding of translation procedures in the translation of the work of Saudi and Egyptian novels. However, that does not guarantee representativeness, and the limited availability of the translations and the differences in the size of the corpora still means that there is a need for improvement. An element of subjectivity was inevitable in the layers of research, especially as relates to the classification of the categories. As a result, the findings of this research\n\nshould be treated as probabilistic and cannot be generalised. The detailed description of the mixed methods in the data analysis will hopefully open the door to further investigation and an alternative interpretation of the study of the translation for Literary Dialectal Dialogue (LDD).\n\n\n## Conclusion\n\n\nThis paper has discussed the procedures carried out by translators to deal with translating Literary Dialectal Dialogue (LDD) in the English translations of contemporary Saudi and Egyptian novels. It provided a quantitative and qualitative analysis of the data from the selected novels, with relevant examples. The paper ended by suggesting that due to the change in language communities, LDD has changed in translation to become Literary Informal Dialogue (LID). The data also show that in practice none of the translators transferred the source dialect into a target dialect. Interestingly, however, the translators do not tend to standardise or delete the conversational elements of the dialogue. On the contrary, they acknowledge the conversational aspect and generally try to retain it in their translations. Their approach is more of compensation than a translation of the dialect. In translating the different regional and social dialects, quite similar procedures were followed in all the selected STs.\n\nNote: * This article is based on the author's Ph.D. thesis (Almutairi, 2019) that was conducted in the Department of Translation at the University of Manchester.\n\n## About the Author:\n\nDr Eman Suraid Almutairi is a lecturer in translation studies at the University of Jeddah. She got her Ph.D. degree in translation and intercultural studies from the University of Manchester. Research interests include literary translation studies, translating dialects, descriptive translation studies, translation technology, and localisation.\n\nORCID ID: https://orcid.org/0000-0001-5768-2469\n\n## References\n\nAbu-Deeb, K (2000). The collapse of totalizing discourse and the rise of marginalized/minority discourse. In  K.  Abdel-Malak  &amp;  W.  Hallaq  (Eds.), Tradition,  modernity,  and  postmodernity  in  Arabic literature: Essays in honour of Professor Issa J. Boullata (pp. 335-366). Leiden: Brill. Almutairi, E. (2019). The Effects of Translators' Stylistic Choices on Translating Literary Dialectal Dialogue: Saudi and Egyptian Novels as a Case Study? (Unpublished Doctoral dissertation). University of Manchester, Manchester, the UK. Available at https://www.research.manchester.ac.uk/portal/en/theses/the-effects-of-translatorsa-stylistic- choices-on-translating-literary-dialectal-dialogue-saudi-and-egyptian-novels-as-a-casestudy(d99ec540-f967-419a-b62c-86d46940ec35).html\n\nAlsanea, R. (2007). Girls of Riyadh (R. Alsanea &amp; M. Booth, Trans.). London: Penguin UK.\n\nArrojo, R.  (1998). The revision of the traditional gap between theory and practice and the empowerment of translation in modern times. The Translator , 4 (1), 25-48. https://doi.org/10.1080/13556509.1998.10799005\n\nAzevedo,  M.  (1998).  Orality  in  translation:  Literary  dialect  from  English  into  Spanish  and  Catalan. Sintagma 10 , 27-43.\n\nBassnett, S. &amp; Lefevere, A. (1990). Translation, history and culture . London: Pinter.\n\nBerthele, R. (2000). Translating African-American vernacular English into German: The problem of 'Jim' in Mark Twain's Huckleberry Finn. Journal of Sociolinguistics , 4 (4), 588-614. https://doi.org/10.1111/1467-9481.00131\n\nBrownlie, S. (1999). Investigating norms. In J. Vandaele (Ed.), Translation and the (re)location of meaning: Selected  papers  of  the  CETRA  research  seminars  in  translation  studies  1994-1996 (pp.  7-21). Leuven: CETRA.\n\nBrownlie,  S.  (2003).  Investigating  explanations  of  translational  phenomena:  A  case  for  multiple causality. Target, 15 (1), 111-152. https://doi.org/10.1075/target.15.1.06bro\n\nCatford, J. (1965). A linguistic theory of translation . Oxford: Oxford University Press.\n\nDaoudi, A. (2011). Translating e-Arabic: Challenges and issues. In F. Federici (Ed.), Translating dialects and languages of minorities: Challenges and solutions (pp. 187-205). Oxford: Peter Lang.\n\nEven-Zohar, I. (1971). An introduction to a theory of literary translation , (Unpublished doctoral dissertation), Tel Aviv University, Tel Aviv.\n\nFawcett, P. D. (1997). Translation and language: Linguistic theories explained . Manchester: St. Jerome Publishing.\n\nFerguson, C. A. (1959). Diglossia. Word 15 , (2), 325-340.\n\nFine, E. (1983). In defense of literary dialect: A response to Dennis R. Preston. The Journal of American Folklore, 96 (381), 323-330.\n\nGenette,  G.  (1997). Paratexts:  Thresholds of interpretation (J.  Lewin,  Trans.).  Cambridge:  Cambridge University Press.\n\nHatim, B. &amp; Mason, I. (1990). Discourse and the translator . London: Longman.\n\nHermans, T. (1985). The manipulation of literature studies in literary translation . New York: St. Martin's Press.\n\nHermans, T. (1999). Translation in systems: Descriptive and system oriented approaches explained . Manchester: St. Jerome Publishing.\n\nHermans, T. (2014). Positioning translators: Voices, views and values in translation. Language and Literature, 23 (3), 285-301. https://doi.org/10.1177/0963947014536\n\nHoles, C. (2004). Modern Arabic: Structures, functions, and varieties . Washington: Georgetown University Press.\n\nIves, S. (1971). A theory of literary dialect. In J. V. Williamson &amp; V. M. Burke (Eds.), A various language: Perspectives on American dialects (pp. 145-177). New York: Holt, Rinehart &amp; Winston.\n\nIvir, V. (1987). Procedure and strategies for the translation of culture. In G. Toury (Ed.), Translation across cultures (pp. 35-46). New Delhi: Bahri Publications.\n\nJiménez, M. S. (2021). Linguistic Varieties in Homegoing: Translating the Other's Voice into Spanish.\n\nAlicante  Journal  of  English  Studies  Revista  Alicantina  de  Estudios  Ingleses,  36, 149-171. https://doi.org/10.14198/raei.2022.36.08\n\nLambert, J. and van Gorp, H. (1985). On describing translations. In T. Hermans (Ed.), The manipulation of literature: Studies in literary translation (pp.42-53). London: Croom Helm\n\nLeech, G. &amp; Short, M. (2007). Style in fiction: A linguistic introduction to English fictional prose (2nd ed.). Harlow: Pearson Education.\n\nLefevere, A. (1992a). Translating literature: Practice and theory in a comparative literature context . New York: Modern Language Association of America.\n\nLefevere, A. (1992b) Translation, rewriting and the manipulation of literary fame . London: pertRoutledge. Leppihalme, R. (2000). The two faces of standardization: On the translation of regionalisms in literary dialogue. The Translator , 6(2), 247-269.\n\nMäättä, S. K. (2004). Dialect and point of view: The ideology of translation in The Sound and the Fury in French. Target , 16 (2), 319-339. https://doi.org/10.1075/target.16.2.06maa\n\nMalmkjær,  K.  (2008).  Norms  and  nature  in  translation  studies.  In  G.  Anderman,  M.  Rogers  (Eds.), Incorporating  corpora:  The  linguist  and  the  translator (pp.  49-59).  Clevedon:  Multilingual Matters.\n\nNewmark, P. (1988). A textbook of translation\n\n. Hemel Hempstead: Prentice-Hall International.\n\nNord, C. (2002). Manipulation and loyalty in functional translation. Current Writing: Text and reception in Southern Africa , 14 (2), 32-44.\n\nPerteghella, M. (2012). Language and politics on stage: Strategies for translating dialect and slang with reference to Shaw's Pygmalion and Bond's Saved. Translation Review , 64 (1), 45-53. https://doi.org/10.1080/07374836.2002.10523826\n\nPym, A. (2011). Translation research terms: A tentative glossary for moments of perplexity and dispute. Translation Research Projects , 3 (1), 75-110.\n\nRosenbaum, G. (2001). Diglossia and translation: Egyptian literature in Hebrew and English. Bulletin of the Israeli Academic Centre in Cairo 24 , 8-17.\n\nSaldanha. G. &amp; O'Brien S. (2013). Research methodology in translation studies. Manchester: St. Jerome Publishing.\n\nSánchez, M. (1999a). The problems of literary translation: A study of the theory and practice of translation from English into Spanish . Oxford: Peter Lang.\n\nSánchez, M. (1999b). Translation as an (im) possible task: Dialect in literature. Babel , 45 (4),  301-310. https://doi.org/10.1075/babel.45.4.03san\n\nShmasnh, K. (2022). The Influence of the Translator's Cultural Background on Translating Arabic Literary Texts into English- Comparing the Translation of I Saw Ramallah and I was Born THERE; I was Born Here as A Case Study. A Journal of Humanities and Educational Research, 4 ,235-243.\n\nShuttleworth,  M.,  &amp;  Cowie,  M.  (1997). Dictionary  of  translation  studies . Manchester:  St.  Jerome Publishing.\n\nToury, G. (1980). In search of a translation theory . Tel Aviv: The Porter Institute for Poetics and Semiotics. Toury, G. (1985). A rationale for descriptive translation studies. In T. Hermans (Ed.), The manipulation of literature : Studies in literary translation (pp. 16-41). London: Croom Helm.\n\nToury, G. (1995). Descriptive translation studies  and beyond .  Amsterdam: John Benjamins Publishing Company.\n\nVinay, J., &amp; Darbelnet, J. (1958). Stylistique comparée du français et de l'anglais . Paris: Didier.\n\nVinay,  J.,  &amp;  Darbelnet,  J.  (1995). Comparative  stylistics  of  French  and  English:  A  methodology  for translation (J. C. Sager &amp; M.-J. Hamel, Trans.). Amsterdam: John Benjamins Publishing Company. Wekker, G. &amp; Wekker, H. (1991). Coming in from the cold: Linguistic and socio-cultural aspects of the (4), 221- translation of the black English vernacular literary texts into Surinamese Dutch. Babel, 37 239. https://doi.org/10.1075/babel.37.4.05wek",
         "The research aims to identify the procedures carried out by translators to deal with translating Literary Dialectal Dialogue (LDD) in the English translations of contemporary Saudi and Egyptian novels. The significance of this study is that it focuses on two Arabic dialects and examines what are the translation procedures if these procedures shift with changes in dialect. The study involves an analysis of random selections of LDD that were extracted from several Saudi and Egyptian novels. The study uses descriptive quantitative and qualitative analysis that focuses on mapping the procedures that were chosen to translate LDD in Arabic diglossic novels. The analysis first examines the construction and function of LDD in its source context and then studies how these procedures have managed to reconstruct the socio-cultural and socio-ideological function of LDD in the selected novels. This study finds evidence to suggest that due to the change in language communities, Literary Dialectal Dialogue (LDD) has changed in the translation to become Literary Informal Dialogue (LID). The data also reveals that in practice, none of the translators rendered the source dialect into a target dialect. Interestingly, however, translators do not tend to standardize or erase the conversational elements of dialogue. On the contrary, they recognize the conversational aspect and try to adhere in general to that in their translations. In fact, their procedure is one of compensation rather than a translation of the dialect. Fairly similar varieties of procedures were used to translate the different regional and social dialects in all the selected STs.",
         ""
        ],
        [
         "48",
         "48",
         "## Introduction\n\n\n29\n\nThe most recent IPCC Sixth Assessment was called 'code red for humanity' with the climate 30 crisis clearly accelerating (IPCC, 2021). Unprecedented political action is necessary to prevent 31 the destruction of earth's life support system that human life and civilisation relies on. The 32 forum at which global political action is negotiated, contested, agreed and scrutinised is the 33 climate change conference organised by UNFCCC, COP (Conference of the Parties), taking 34 place  annually  since  1995.  It  brings  together  delegations  from  countries  and  international 35 organisations to set targets on how to limit global warming. These yearly conferences are an 36 important  forum  where  normative  questions  about  climate  justice  interact  with  practical 37 debates around climate change solutions and international relations dynamics, defining the 38 space of possible solutions from the local to the global (Falkner 2019). Research on the annual 39 COPs has focused strongly on COP21 that brought about the breakthrough Paris Agreement 40 (e.g. Dimitrov 2016, Morgan 2016, Tobin et al. 2018). Hopke and Hestres (2018) for instance 41 noted that coordinated information campaigns on climate justice by climate stakeholders at 42\n\n- COP21 most likely contributed to the aspirational goal of limiting global warming to 1.5 ¡C 43\n\n- being  included  in  the  Paris  Agreement.  However,  since  the  landmark  Paris  Agreement, 44 essentially no progress has been made in reducing greenhouse gas (GHG) emissions. 45\n\n46\n\nHopes were high ahead of the COP26 in 2021 in Glasgow, postponed for a year due to the 47 COVID-19 pandemic, because for the first time since COP21, COP26 would see countries 48 disclosing  their  National  Determined  Contributions  (NDCs),  allowing  the  global  public  to 49 scrutinise governments on their climate change policies. Moreover, after the US election in 50 2020 with Joe Biden winning against the incumbent Donald Trump, the US returned to its 51 commitments under  the  Paris  Agreement.  And  the  world  has  changed  since  COP21  too. 52 People  across  the  world  are  displaying  an  increasing  awareness  of  the  climate  crisis. 53 Buchanan et al. (2022) for instance established a clear consensus among international public 54 for government action at COP26. In the end COP26 both disappointed (e.g. with respect to 55 financial support gap for adaptation in the Global South, Loss and Damage being blocked, 56 and  no  commitment  to  phasing  out  fossil  fuels)  and  gave  hope  (e.g.  with  respect  to 57 commitment  to  keeping  the  1.5¡C  alive,  accountability  and  scrutiny  as  countries  are  now 58 required to disclose their NDCs yearly, mentioning fossil fuels and the need to discard them 59 at all, etc.) (Moundford et al. 2021, Jacobs 2021, Owens 2022). Clearly, we are not yet on the 60 right  pathway,  but  equally,  we  see  some  positive  change,  even  if  not  fast  enough  yet 61 (IPCC2022, Jacobs 2021). 62\n\n63\n\n64\n\n65\n\n66\n\n67\n\n68\n\n69\n\n70\n\n71\n\n72\n\n73\n\n74\n\n75\n\n76\n\n77\n\n78\n\n79\n\n80\n\n81\n\n82\n\n83\n\n84\n\n85\n\n86\n\n87\n\n88\n\n89\n\n90\n\n91\n\n92\n\n93\n\n94\n\n95\n\nPolitical change and hence progress on political issues often follows normative change, i.e. the change in what is widely perceived as acceptable or desirable and what is perceived as inacceptable and reprehensible. New norms often emerge though initiatives by so called norm entrepreneurs.  Norm  entrepreneurs,  as  defined  by  Sunstein  (1996)  are  actors,  who  are strongly  interested  in  changing  a  norm  or  introducing  a  new  one,  because  they  perceive existing (old) norms to be inadequate and/or unjust. Ingebritsen (2002) points out that norm entrepreneurs can be individuals, states or other societal actors, such as social movements and  their  representatives  (Khagramet  al.  2002).  Activists  bring  new  ideas,  norms  and discourses into policy debates and hence change the terms and nature of these debates, but they also promote norm implementation through pressuring and monitoring (Keck and Sikkink 1998).\n\nA prominent norm entrepreneur in the context of climate change politics is Fridays for Future or youth climate strikers. Spaiser et al. (2022) analysed how Fridays for Future is challenging the normalisation of practices and thinking that prevent us from tackling the climate crisis, offering a new normative framework in response to the climate crisis with an emphasis on human rights and duty of care. Since 2018, the Fridays for Future movement has grown to include millions of school-aged children and University students around the world campaigning for increased climate action from the public and governments. Research on the movement and  youth  climate  activists  in  general  revealed  that  youth  stakeholders  and  their  political contributions are often underestimated or even dismissed due to common perceptions of youth not having acquired sufficiently knowledge and experience (Thew et al 2020, van Zabern and Tulloch  2021,  Evensen  2019).  This  ignores  the  fact  that  youth  climate  activists  perfectly understand where their expertise limitations are and hence were teaming up with scientists, who were keen to provide them with expertise and drafting up climate action plans (De Wever Van der Heydesn et al. 2020). In the past, youth stakeholders have also found that their climate justice claims with a focus on intergenerational justice have been at least partially dismissed by  other  stakeholders,  and  in  response,  some  groups  have  shifted  their  focus  from  their original intergenerational climate justice claims to solidarity claims about injustices experienced by other groups in the present (Thew et al 2020). With Fridays for Future the original intergenerational climate justice claims seems to have seen a revival (von Zabern and Tulloch 2021). The movement explicitly sees itself (i.e. youth, children) as an oppressed group\n\n(Bowman 2020),  feeling  'moral  injury'  (i.e.  betrayal,  abandonment)  because  of  the  sheer 96 disregard that societies and governments show for their (future) wellbeing (Hickman et al. 97 2021). As such, Fridays for Future was more successful to uphold both claims, 98 intergenerational  climate  justice  and  solidarity  with  present-day  climate  victims  (Bowman 99 2020, Marquardt 2020, Han &amp; Ahn 2020). After all, the movement consists also of young 100 activists from the Global South, where indeed climate change effects are already devastatingly 101 real  (Nakabuye et al. 2020). Despite common reservations against youth actors, research 102 suggests that young climate activists indeed are making an impact, whether by influencing 103 media's framing of climate change (von Zabern and Tulloch 2021, Marquardt 2020), driving 104 more  ambitious  climate  change  policies  (Marquardt  2020),  shifting  people's  attitudes 105 regarding  the  necessity  to  take  climate  action  (Sabherwal  et  al.  2021),  mobilising  older 106 generational for climate action (de Moor et al. 2020) or through climate litigation, filing suits 107 against national governments as they fail them and future generations (Moore et al. 2020). 108 Their  influence  on  international  climate  change  negotiations  and  policy  making  remains 109 however underexplored. 110\n\n111\n\nThe presence of activists at COPs has become commonplace and since 2018 includes youth 112 activists from the Fridays for Future. Although it should be stated that youth as stakeholders 113 have been represented at COPs through YOUNGO since 2009 (Thew et al. 2020). Greta 114 Thunberg was invited to give a speech at COP24 in Katowice, Poland in 2018 and at COP25 115 in Madrid, Spain in 2019. Other members of the movement have also been involved in COP24, 116 COP25 and to a lesser extent COP26. But what effect did these norm entrepreneurs have on 117 the COPs and climate change debates around them? Were they successful in shifting our 118 understanding of the climate crisis and how to respond to it. There is a lack in research that 119 attempts to tackle these admittedly difficult to answer questions. In this paper we assess to 120 what extent the Fridays for Future movement was able to influence the international climate 121 change politics discourse, introducing new or re-enforcing existing normative frames that have 122 the potential to shift international climate politics. Specifically, we will answer the following two 123 research  questions:  1)  To  what  extent  has  the  normative  discourse  of  Fridays  for  Future 124 permeated the global climate politics discourse around the annual UNFCCC conferences and 125 2) Who are the key actors driving the change around the annual UNFCCC conferences? With 126 the second question we want to investigate to what extent Fridays for Future was able to gain 127 supporters  outside  the  movement,  who  helped  the  movement  to  diffuse  its  normative 128 messages. 129\n\n130\n\n131\n\n132\n\n133\n\n134\n\n135\n\n136\n\n137\n\n138\n\n139\n\n140\n\n141\n\n142\n\n143\n\n144\n\n145\n\n146\n\n\n## International Norm Diffusion and the Role of Social Movements\n\n\nInternational norms, such as human rights set expectations with respect to what constitutes desirable  or  reprehensible  behaviour,  where  international  actors  can  expect  reward  or punishment when adhering to or violating an international norm. They can also set out which policies states, that claim to endorse a certain international norm, are expected to implement and they provide the basis for international criticism or even (economic) sanctions if states fail to adhere to certain international norms (Risse-Kappen et al. 1999).\n\nNorms can change, with new or revised norms contesting old norms. According to Finnemore and Sikkink (1998) new global norms that become widely accepted undergo three stages: (1)\n\nthe  norm  emerges,  at  this  stage  norm  entrepreneurs  are  the  central  actors,  (2)  the  norm reaches a tipping point, i.e. a critical number of states accept it, followed by norm cascade,\n\nwith more and more countries following suit, and (3) the norm is internalized, specified and institutionalised within legal documents and international agreements. As mentioned above,\n\nsocial movements can play a pivotal role as norm entrepreneurs in establishing global norms.\n\nThey can use a range of tactics in their efforts to promote a new norm, this includes, based 147 on Keck and Sikkink (1998): (1) information politics, (2) symbolic politics, (3) leverage politics 148 and (4) accountability politics. 149\n\n150 In terms of information politics, social movements, and certainly climate social movements, 151 rely  on  scientific  insights  as  they  generate  'politically  usable  information',  i.e.  scientific 152 information accessible to the public and spread it. Information politics is a quite essential tactic 153 for norm entrepreneurs, because for the norm to get established, the actors have to frame 154 available information in simple terms of right and wrong to persuade the public and political 155 decision makers that a 'given state of affairs is neither natural nor accidental, identify the 156 responsible party or parties, and propose credible solutions' (Keck and Sikkink 1998, p.19). 157 The message must be both credible and dramatic, e.g. by combining factual information with 158 testimonial information, i.e. human stories about the victims. Symbol politics uses symbols, 159 actions, and stories to make sense of the complex science and its evidence and predictions, 160 making an issue emotionally more tangible to the public. Furthermore, symbol politics may 161 also entail 'an appeal to existing norms to show an intrinsic fit between proposed policies 162 and/or actions and previously established norms' (Eilstrup-Sangiovanni and Bondaroff 2014, 163 p. 350). This link to established norms is indeed quite important for a new norm to take hold 164 because of the adjacency claims or path dependence: The better a norm fits in with existing 165 normative frameworks and the more analogies can be established by norm entrepreneurs, the 166 more powerful or persuasive the new norm becomes (Finnemore and Sikkink 1998). In terms 167 of  leverage  politics,  social  movements  seek  moral  leverage  over  more  powerful  actors. 168 According to Keck and Sikkink (1998) moral leverage involves the 'mobilization of shame, 169 where the behaviour of target actors is held up to the light of international scrutiny' (p.23). 170 Finally,  Keck  and  Sikkink(1998)  also  suggest  accountability  politics  as  a  typical  social 171 movement  tactic, i.e. when  social movements  hold  powerful  actors to their stated 172 commitments and principles, such as the Paris Agreement. 173\n\n174\n\nThe first stage of a normative change can be broken down in two substages (1) generating 175 attention  to  new  issues  and  setting  agendas  and  (2)  influence  discursive  positions  and 176 persuade (Keck and Sikkink 1998). However, how likely is the progression to stage two, when 177 the norm reaches a tipping point, i.e. a critical number of states accept it, followed by norm 178 cascade, with more and more countries following suit? Christakis and Fowler (2009) found 179 that new norms do not spread with the same dynamic as contagious diseases, the process is 180 more complex and requires reinforcement through multiple sources. But, new ideas and norms 181 that are more 'fit' than older ones can radiate quicker. This has been also suggested by Keck 182 and Sikkink (1998), who describe conditions that contribute to social movements' success in 183 terms of norms diffusion. First, there are certain issues and norm characteristics that make a 184 success more likely. The clearer and more specific the norm has been formulated, the longer 185 the norm has been around, the more often it has survived numerous challenges and the more 186 universal norms are (i.e. norms must transcend the specific cultural or political context), the 187 more likely they are to have expansive potential and be effective (Finnemore and Sikkink 188 1998). 'Issues that involve ideas about right and wrong are amenable to advocacy networks 189 because they arouse strong feelings, allow networks to recruit volunteers and activists, and 190 infuse meaning into these volunteer activities.' (ibid., p.26). Keck and Sikkink (1998) write 191 further that 'the real creativity of advocacy networks has been in finding intentionalist frames 192 within  which  to  address  some  elements  of  structural  problems'  (ibid.).  Social  movements 193 organize most effectively around (1) issues involving harm to vulnerable individuals, especially 194 when there is a short and clear causal chain (or story) assigning responsibility; and (2) issues 195 involving legal equality of opportunity.' (ibid.). This clearly speaks to the Moral Foundation 196 Theory (Graham et al. 2013) and its findings, which suggests that care/harm avoidance and 197 fairness  are  two  of  the  most  fundamental  and  universal  moral  foundations.  The  problem 198\n\n- however that social movements often face is that 'the causal chain needs to be sufficiently 199 short and clear to make the case convincing' (Keck and Sikkink 1998, p.27). 200\n\n201\n\n202\n\n203\n\n204\n\n205\n\n206\n\n207\n\n208\n\n209\n\n210\n\n211\n\n212\n\n213\n\n214\n\n215\n\n216\n\n217\n\n218\n\n219\n\n220\n\n221\n\n222\n\n223\n\n224\n\n225\n\n226\n\n227\n\n228\n\n229\n\n230\n\n231\n\n232\n\n233\n\n234\n\n235\n\n236\n\nBesides  issue  characteristic,  the  actors'  characteristics  can  also  be  decisive  for  social movements' success. Keck and Sikkink (1998) point out that 'networks operate best when\n\nthey are dense, with many actors, strong connections among groups in the networks, and reliable information flows' (p. 28). Generally, the more prominent the norm and/or the norm\n\nentrepreneur is, the more successful will the norm entrepreneur be in finding states to adopt and accept the new norm (Finnemore and Sikkink 1998). According to Green (2018) so called\n\nnorm champions are key for norm diffusion. Norm champions are trailblazers, willing to try out new ideas brought in by norm entrepreneurs when virtually no one else has done so. In that\n\nregard  they  are  quite  distinct  from  most  people,  who  look  to  their  peers  to  decide  which behaviour to choose (Cooney 2011). For norm entrepreneurs, it is important to persuade a\n\ncritical number of early adopters to make a change. Once this tipping point is reached the acceptance of the idea is likely to spread rapidly through the ripple effects of social networks.\n\nFor optimal ripple effects the ideal norm champions are connectors in a social network, so actors who have a large number of friends and acquaintances and ideally bridge different\n\ngroups of actors (Christakis and Fowler 2009). Research suggest that the s-shaped diffusion curve often takes off around the time that opinion leaders begin to adopt the new idea. This\n\nusually happens when between 3-16% of the actors have adopted the idea (Otto et al. 2020).\n\nIt is important that a diverse set of norm champions adopt the new norm, rather than norm champions  from  a  certain  group  only.  The  reinforcement  through  multiple  sources  in  the\n\nprocess  of  a  complex  contagion  works  best  if  those  multiple  sources  are  diverse.  When persuading  actors,  Keck  and  Sikkink  (1998)  also  point  out  that  target  actors  must  be\n\nvulnerable or at least sensitive to pressure. The more a state seeks to enhance their reputation or  esteem,  the  more  'insecure'  they  are  about  their  international  or  domestic  status  or\n\nreputation  in  situations  of  political  turmoil,  the  more  likely  they  are  to  embrace  new international  norms  (Finnemore  and  Sikkink  1998).  Keck  and  Sikkink  (1998)  write  that\n\n'countries that are most susceptible to network pressure are those that aspire to belong to a normative community of nations', here moral leverage can have a strong effect (p. 29). Norm\n\nacceptance and socialisation does not require all target actors to subscribe to a new norm.\n\nRisse et al. (1999) noted that even if actors might follow an instrumental rationale initially, they become  entrapped  in  their  rhetoric,  challenged  by  serious  arguments  of  international\n\nadvocacy networks, and do not have any option other than to accept the norm in an identity formation of member states and finally even adhere morally to the norm. Strategic motivation\n\nthus often sets into motion a process of identity transformation. According to that, 'norms initially adopted for instrumental reasons are later maintained for reasons of belief and identity'\n\n(Risse et al. 1999, p.12).\n\n237\n\nNormative change seldom proceeds without resistance, often embodied in norm 238 entrepreneurs' opponents or 'norm antipreneurs' (Bloomfield 2016), i.e. 'actors, who defend 239 the entrenched normative status quo against challengers' (p.321). The dynamic that evolves 240 between norm entrepreneurs and norm antipreneurs depends on the specific context. On the 241 institutional  context  regarding  to  what  extent  the  normative  status  quo  is  entrenched  or 242 institutionalised and on the temporal context regarding to what extent the push for normative 243 change  goes  hand  in  hand  with  major  power  shifts  or  crises  (Bloomfield  2016).  The 244 contestation of a new emerging norm can result in the failure of normative change (Acharya 245 2011, Bloomfield 2016). Ultimately, changing norms or policies is harder than maintaining the 246 status quo and the greater the proposed change the stronger the inertia (Bob, 2012), because, 247 as research suggests, people usually prefer the status quo and only when certain practices or 248 norms  fail  catastrophically  is  there  a  chance  for  change  (Legro,  2000).  Hence,  norm 249 antipreneurs  have  a  tactical  and  strategic  advantage  (Bloomfield,  2016).  According  to 250\n\nBloomfield (2016) norm antipreneurs can block normative change in two ways. Firstly, they 251 can  refute  claims  that  the  status  quo  produces  morally  problematic  outcomes.  Bloomfield 252 (2016) writes: 'The simplest way is to dismiss such claims as 'alarmist'.' (p. 323). Secondly, 253 even if the norm entrepreneurs succeed to convince the public that there is a moral problem 254 with the status quo, norm antipreneurs can attack the proposed new norm (Bloomfield 2016). 255 Again, the norm antipreneurs enjoy an advantage here, because changing the status quo 256 often  comes  at  considerable  costs,  new  norms  and  their  suggested  solutions  are  often 257 unproven and their viability uncertain, which makes it easy to dismiss them even if the status 258 quo norms fail catastrophically. Norm entrepreneurs are then attacked as idealistic, naive or 259 dangerously radical (ibid.). A new norm needs to build up some credibility, usually through 260 some socio-institutional  support,  before  in  becomes  viable  and  credible  and  hence  has  a 261 chance to prevail. Norm antipreneurs can prevent this by blocking efforts to reform institutions 262 or introduce policy changes (ibid.). However, with the climate emergency unfolding to a greater 263 extent and more dramatically than anticipated, there might be a window of opportunity in the 264 present for the climate change norm entrepreneurs. Finnemore and Sikkink (1998) point out 265 that the more unstable the international system gets through major disruptive events like global 266 recessions or wars, the more likely a search for and acceptance of new ideas and norms is. 267 An acceleration of the climate crisis can potentially contribute to the new norm gaining traction. 268\n\n269\n\n## Data and Methods 270\n\n271\n\n272\n\n273\n\n274\n\n275\n\n276\n\n277\n\n278\n\n279\n\n280\n\n281\n\n282\n\n283\n\n284\n\n285\n\n286\n\n287\n\n288\n\n289\n\n290\n\n291\n\nTo analyse the  two  research  questions  outlined  above,  we  use  a  large  dataset  of  tweets acquired via the Twitter Academic API v2. Specifically, we collected all Twitter data around the annual UNFCCC COP Conferences between 2014 and 2021 (note there was a gap year in 2020 due to the pandemic), gathering data over the two weeks duration of the conference, usually  either  in  November  or  December,  each  year.  We  moreover  collected  Twitter  data around all major, usually global Fridays for Future or youth climate strike protest events in 2018, 2019 and 2021 and then merged the datasets by year. Specifically, in year 2018 the data  was  almost  continuously  collected  throughout  November  and  first  half  of  December capturing a range of decentralised strikes. In year 2019 the data was collected around five global climate strikes: 15 March 2019, 24 May 2019, 20 September 2019, 27 September 2019 and 29 November 2019. In year 2021 the data was collected around three global climate strikes on 24 September 2021, 22 October 2021 and 5 November 2021. Data was captured for the strike day as well as the day before and the day after the strike. To identify relevant tweets,  we  collected  the  data  based  on  a  set  of  hashtags  for  each  year  (e.g.  #COP22), keyword and the official accounts (e.g. @COP22 and @UNFCCC). A full list of hashtags, keywords and account names can be found in the Supplementary Information. In total the data collection effort resulted a dataset of 17,890,106 tweets across ten data sets, seven COP datasets and three Fridays for Future datasets. The ten datasets vary quite significantly in size. A table that provides the full overview of the sizes of the datasets can be found in the Supplementary Information.\n\n292\n\nTwitter data is a well-known data source for social science research as Twitter provides a 293 popular  platform  for  direct,  public  communication,  used  by  individuals,  political  groups, 294 governments,  organisations,  businesses  etc.  (Ahmed  et  al.  2017).  Using  Twitter  data  to 295 understand international climate policy negotiations around the annual UNFCCC conferences 296 is not uncommon too. Hopke and Hestres (2018) used for instance Twitter data to understand 297 the different positions on the negotiations and agreements, looking at Twitter communication 298 by  media  outlets,  climate  stakeholders,  including  activists  and  fossil  fuel  industry  groups. 299 Similarly,  Twitter  is  a  valuable  data  source  for  studying  social  movements,  such  as  youth 300 climate activists (e.g. Boulianne et al. 2020, Spaiser et al. 2022). The main advantage of using 301\n\nTwitter data over media outlets is that the communication on Twitter is direct and unfiltered 302 and allows hence to capture a fuller range of voices and perspectives, including of media 303 outlets, while allowing to identify the dominant frames and themes in the public domain by 304 accounting for retweet and/or like counts. There are of course also issues with Twitter data. 305 Twitter data is for instance not suitable for identifying a representative distribution in public 306 attitudes, as Twitter users are not representative of a population. However, the goal of this 307 paper is not to establish a representative distribution of opinions in a population, rather to 308 capture the public debate around the annual UNFCCC conferences, in which various political 309 actors and stakeholders are involved and indeed we can assume that most of these actors 310 and stakeholders are represented on Twitter (Hopke and Hestres 2018). 311\n\n312\n\n313\n\n314\n\n315\n\n316\n\n317\n\n318\n\n319\n\n320\n\n321\n\n322\n\n323\n\n324\n\n325\n\n326\n\n327\n\nTo analyse the Twitter data and answer the two research questions, we used a range of methodological  approaches,  transformers-based  topic  modelling  and  discourse  similarity analysis for the first research question and social network analysis for the second research question. We will explain these methods in greater detail below. In terms of pre-processing the data for analysis, we extracted the tweets (along with tweet ID and retweet number) from the data and filtered that data for English language, this reduced the dataset to 12,406,965 tweets. The reason for this is that English is used predominantly in the international public debate on climate change, still, by filtering for English we may lose some non-English speaking voices in the debate. The second reason for the language filter is that multi-lingual natural language processing is still extremely complex and not to the same extent developed as for English. We furthermore removed all URLs from the tweets. Otherwise, the tweets were left as they are, as the transformers models, we used, require full sentence inputs rather than tokens.  For  topic  modelling  purposes,  we  also  removed  all  duplicate  tweets  by  removing retweets.  For  social  network  analysis,  we  extracted  the  user  ID,  username  and  retweet information from the overall dataset.\n\n328\n\n## Topic Modelling with Transformers-based models 329\n\n330\n\n331\n\n332\n\n333\n\n334\n\n335\n\n336\n\n337\n\n338\n\n339\n\n340\n\n341\n\n342\n\n343\n\n344\n\n345\n\n346\n\nTo  identify  topics  within  each  dataset  we  used  BERTopic,  a  transformers-based  topic modelling  algorithm  (Grootendorst  2022).  This  algorithm  combines  embedding  models, dimension reduction, and hierarchical clustering to create topic representations from data. Transformer models are machine learning, specifically deep learning models developed for natural language processing tasks. BERTopic uses specifically transformer models to extract sentence embedding vectors from text data. Embedding means that a sentence is taken as an input and a vector is created to capture the semantic information of the sentence. Within the BERTopic architecture, we used an adapted version of the MPNet (Masked and Permuted Pre-trained) embeddings (Song et al, 2020) and specifically the all-mpnet-base-v2 sentence embedding model. The adapted version developed by Hugging Face fine-tunes the MPNet using a self-supervising, contrasting learning objective that trains the model to learn features without  having  pre-assigned labels.  The embedding model maps the sentences to a 768dimensional  dense  vector  space  and  computes  the  cosine  similarity  from  each  possible sentence pair. It then applies cross-entropy loss by comparing the possible pairs with the true pairs to evaluate the accuracy of the model. This results in vector representations of sentences which allows to calculate the semantic similarity between documents, tweets in our context (Grootendorst 2022).\n\n347\n\nSecondly, the BERTopic architecture uses the Uniform Manifold Approximation and Projection 348 (UMAP)  dimension  reduction  algorithm,  which  reduces  the  dimensionality  of  the  MPNet 349 embeddings created earlier, while preserving the underlying structure (McInnes et al. 2018). 350\n\n351\n\nWe set the UMAP parameters to 15 nearest neighbours, 5 components, and used the default\n\n352\n\n0 minimum distance and cosine distance metrics. In order to aid reproducibility of the model,\n\nwe set the random state to 42. The output from this dimensionality reduction step is then fed 353 to the HDBSCAN (Hierarchical Density-Based Spatial Clustering of Applications with Noise) 354 clustering algorithm (Campello et al. 2013). This is a hierarchical clustering algorithm that uses 355 a  distance  metric  (e.g.  Euclidian)  to  calculate  the  core  distance  of  a  data  point  to  its  k-th 356 nearest neighbour. A large core distance value suggests few data points close together and 357 therefore a sparse area of data. Due to the UMAP dimensionality reduction at the previous 358 stage this clustering algorithm did not need to be further optimized for high-dimensional data. 359 The clustering algorithm further uses the mutual reachability distance, an indication of the 360 likelihood of a cluster, to spread points apart based on their density. The HDBSCAN model 361 parameters can be customised to limit or guide the number of extracted (topic) clusters. We 362 set the minimum cluster size parameter to d * 0.0017 where d is the number of tweets. This 363 parameter sets the boundary for how small the cluster can be, i.e. how many tweets it may 364 contain. Finally, we used a vectorizer model that included both bigrams and unigrams to aid 365 the interpretation of resulting topics and set the minimum document frequency parameter to 366 20 to ensure that a word appears in a minimum of 20 different tweets before being included in 367 the model. 368\n\n369\n\n370\n\n371\n\n372\n\n373\n\n374\n\n375\n\n376\n\n377\n\n378\n\n379\n\n380\n\n381\n\n382\n\n383\n\n384\n\n385\n\n386\n\n387\n\n388\n\n389\n\n390\n\n391\n\n392\n\nThe output of this multiple step topic modelling procedure includes hierarchically linked and nested  topic  clusters,  key  words  and  bigrams  that  define  those  topic  clusters,  a  set  of representative documents (tweets in our case) for each topic and estimated probabilities for each  tweet  to  belong  to  each  of  the  extracted  topics.  It  should  be  noted  that  BERTopic automatically  produces  a  -1-outlier  topic  cluster  that  consists  of  all  the  tweets  that  have extremely mixed probabilities and hence are difficult to assign to any single topic. This results typically  in  a  quite  large  outlier  topic,  which  is  difficult  to  interpret  and  hence  is  typically excluded  from  further  analysis  and  interpretation.  To  further  reduce  the  number  of  outlier tweets and hence to avoid losing potentially insightful data, we reassigned tweets to a specific topic, if they had at least a probability of 0.1 to belong to that topic. We also corrected the size of  topics  (number  of  tweets  assigned  to  them)  subsequently  by  adjusting  for  number  of retweets of each tweet in the topic.\n\nTopic modelling is an explorative knowledge discovery approach, hence determining how well a model performs is not trivial. BERTopic is an architecture that is set up to generate best-fit outputs  (Grootendorst  2022),  however  these  can  vary  depending  on  the  setting  of  the parameters discussed above. Our goal with the analysis was to extract interpretable topics, that  are  broad enough, to avoid a large number of extracted topics and at the same time differentiated enough so we can clearly identify normative topics within the topic space. This principle was guiding our approach when we experimented with different parameter settings and values before arriving at the ones reported here. All analysis were run on the University of Leeds High Performance Computing Nvidia GPU cluster. All Python code is available on GitHub (https://github.com/NicoleNisbett/BERTopic).\n\n393\n\nIn order to visualise the outcomes of the topic modelling we chose to represent the topic space 394 of  each  dataset  using  circular  packing  that  also  allows  for  hierarchic  organization,  i.e., 395 hierarchical  embedding of the extracted topics. We created the packed circle figures (see 396 Table 1, see also Supplementary Information) using Flourish (flourish.com). For that purpose, 397 we used the hierarchical arrangement of the topics (BERTopic dendrogram) revealed through 398 the topic modelling and the corrected topic sizes as input. Normative topics were highlighted 399 in  red.  When  deciding  which  topic  to  interpret  as  normative  we  were  using  the  Moral 400 Foundation Theory (Graham et al. 2013) and specifically the moral foundations that have been 401 empirically associated with the climate crisis, which are mainly care (no harm) and fairness 402 (Welsch 2020). We checked keywords and representative tweets of each topic and if a topic 403 contained  strong  notions  of  harm  (e.g.  fossil  fuels  as  doing  harm)  or  fairness  (e.g. 404\n\n405\n\n406\n\nintergenerational justice for future generations, human rights, justice for indigenous people etc.) then that topics would be classified as normative.\n\n407\n\n## Measuring Discourse Similarity 408\n\n409\n\n410\n\n411\n\n412\n\n413\n\n414\n\n415\n\n416\n\n417\n\nTo answer the first research question, it was important to understand which themes appeared in the climate change debate around the annual UNFCCC conferences, how they changed over time and whether the normative themes are referencing youth climate activists' normative frames.  But  we  wanted  also  to  quantify  the  extent  of  commonality  between  the  activists' arguments and UNFCCC conference debates to indirectly measure the influence the young climate activists had on shaping the agenda and frames. To measure the similarity of tweets content  between  COP  and  Friday  for  Futures  datasets,  we  used  the  Jensen-Shannon Distance  (JSD)  measure,  an  extension  of  the  Kullback-Leibler  divergence  (Kullback  and Leibler 1951), and the square root of the Jensen-Shannon divergence (Lin 1991), defined as:\n\n418\n\n419\n\n420\n\n421\n\n422\n\n423\n\n424\n\n425\n\n426\n\n427\n\n428\n\n429\n\n430\n\n431\n\n432\n\n433\n\n434\n\n435\n\n436\n\n437\n\n438\n\n439\n\n440\n\n441\n\n442\n\n443\n\nwhere m is the pointwise mean of arrays p and q and D is the Kullback-Leibler divergence.\n\nWe measured the similarities based on the normalised word frequency distributions in each dataset, calculating the JSD for each pair of datasets. JSD values closer to zero signifies the distributions are very similar while values closer to one suggest more distinct distributions. This measure of divergence or distance has been repeatedly demonstrated to be applicable to large textual data, for instance to estimate topic coherence between documents (Blair and Mulvenna 2020) or to measure to what extent climate scepticism arguments are taken up by mainstream media (Adam et al. 2020).\n\nFinally,  to  get  a  better  impression  of  what  similarity  means  more  qualitatively  we  used semantic networks to represent  the  normative  debate  around  COP26  and  the  Fridays  for Future  2021  discourse  to  identify  common  normative  frames.  The  semantic  networks  are based on bigrams, associations between two words based on the Student t-score, extracted from the tweets data and then visualised within Gephi. Nodes represent words and edges associations  between  words.  Betweenness  centrality  was  used  to  identify  key  words  and visually the attribute is represented through font size. Association scores were used as the weight attribute for the undirected edges. Modularity was used to detect theme clusters within the  semantic  network,  visually  represented  through  different  colours.  We  followed  the methodological approach of Spaiser et al. (2022) in their analysis of the normative framework of Fridays for Future based on Twitter data. We chose 2021 data for this more qualitative exploration as this was the last year of observation in our analysis and allowed us to see the most recent normative frame communalities.\n\n444\n\n## Social Network Analysis 445\n\nIn order to answer the second research question, we applied Social Network Analysis (SNA) 446 to our Twitter data and specifically to the data on (1) Twitter users posting the captured tweets, 447 which  we  can  now  attribute  to  the  extracted  topics  and  (2)  retweet  patterns,  i.e.,  who  is 448 retweeting whom regardless of their interaction with normative topics. SNA is a method used 449 to analyse and interpret how actors in a social network interact with each other. We specifically 450 built bipartite networks (Fouss et al. 2016) for each COP dataset, where the nodes could be 451 either Twitter users or normative topics and the directed edges would link users who retweeted 452\n\n453\n\n454\n\n455\n\n456\n\n457\n\n458\n\n459\n\n460\n\n461\n\n462\n\n463\n\n464\n\n465\n\n466\n\n467\n\n468\n\n469\n\n470\n\n471\n\n472\n\n473\n\n474\n\n475\n\n476\n\n477\n\n478\n\n479\n\n480\n\n481\n\n482\n\n483\n\n484\n\n485\n\neach other, or users and topics if the users posted or retweeted a tweet that was assigned to a normative topic. The retweet edges had a weight attribute that represented how often one user retweeted another.\n\nBefore creating the full bipartite network, a subgraph was derived from the overall retweet network (2), containing only user nodes with betweenness centrality measures in the top 99.9 th percentile.  We  had  two  reasons  for  sub-setting  the  retweet  networks:  1)  to  reduce  the dimensionality of the network for easier plotting, and 2) to produce a list of the most influential users  for  each  COP  based  on  the  highest  betweenness  centrality  scores.  Betweenness centrality is a popular and well-established measure for calculating the most central, influential nodes  in  a  network  (e.g.  Xu  et  al.  2014).  Nodes  that  cross  many  paths  will  have  a  high betweenness centrality.  In  the  context  of  our  data,  these  are  user  nodes  that  have  been retweeted by or retweeted many other users, they are the super-connectors and therefore very  influential  in  driving  debates.  This  retweet  subnetwork  was  then  combined  with  the bipartite network of users and topics in order to understand to what extent the overall most influential Twitter users (based on retweet patterns) were engaged in the normative debates around the COPs.\n\nWithin  the  combined  retweet  and  bipartite  network,  we  used  the  Page  Rank  measure  to identify the most important nodes, both in terms of topics and users, in the graph. Page Rank was originally developed by Google to measure which webpages were most important based on how many times they had been linked to other pages (Brin and Page 2018). Page Rank has been also used in social network analysis as a measure of influence (Heidemann et al. 2010). The topic nodes had the highest page rank value due to them having the highest indegree (highest number of accounts posting tweets assigned to the topic in our case), but there were also user nodes with high page ranks. These user nodes were the ones who were frequently retweeted by other users and hence were more central to the overall COP debates. To what extent these users were integrated within the normative bipartite network was indeed a  crucial  point  of  interest  in  this  analysis.  All  network  visualisations  (see  Table  2  and Supplementary Information) were made using Gephi, applying the Force Atlas 2 layout, and sized proportionally based on the Page Rank measure, calculated within Gephi. All Python code  for  building  the  networks  before  visualisation  within  Gephi  in  available  on  GitHub (https://github.com/NicoleNisbett/SNA).\n\n486\n\n## Results 487\n\n## Normative Themes COP20 - COP26 488\n\nTable  1  gives  an  overview  of  the  topic  constellations  across  the  seven  studied  UNFCCC 489 annual conferences, with a particular focus on explicitly normative topics that are highlighted 490 in red within the hierarchical, packed circle visualizations of the topics. 491\n\n492\n\nTable 1: COP20 - COP26 Topic Modelling Results Overview, Normative Topics listed with number of tweets 493\n\n<!-- image -->\n\n494\n\n495\n\n496\n\n497\n\n498\n\n499\n\n500\n\n501\n\n<!-- image -->\n\n<!-- image -->\n\n<!-- image -->\n\n<!-- image -->\n\n<!-- image -->\n\n<!-- image -->\n\nA general summary of the topic modelling results and the insights they provide with respect to our research question, will be given here (for more detailed description of the topics and their interrelations, see the Supplementary Information S1). Starting with COP20 in 2014 in Lima, our  analysis  suggests  that  normative  topics  did  feature  quite  prominently  in  COP20  but appeared  also  relatively  fragmented.  Particularly  the  public  pressure  and  protests,  led  by indigenous communities, were mounting high, demanding climate justice and a radical, rapid transition to a post-carbon world. Concerns for future generations, pushed in particularly by\n\n552\n\n## Assessing Friday for Future's influence 553\n\n554\n\n555\n\n556\n\n557\n\n558\n\n559\n\n560\n\n561\n\n562\n\n563\n\n564\n\n565\n\n566\n\n567\n\n568\n\n569\n\n570\n\n571\n\nWe have discussed how the normative themes have evolved between COP20 (2014) and COP26  (2021)  and  the  extracted  topics  suggest  that  the  youth  climate  activists  had  a remarkable influence on the overall discourse around the annual climate policy negotiations, influencing and boosting the normative considerations of these negotiations. Here we want to go a step further and attempt to quantify the discursive influence of the youth climate protest movement. Figure 1 shows the Jensen-Shannon Distance scores between the seven COPs and three annual Friday for Futures tweet datasets. We see that later COPs, starting with COP24 have a greater semantic similarity with the Fridays for Future discourse than earlier COPs, when Fridays for Future was not yet a phenomenon. And the semantic distances even decrease over time, e.g., COP24 (2018) and FFF2018 0.48, COP25 (2019) and FFF2019 0.47, COP26 (2021) and FFF2021 0.44  It seems, although, Fridays for Future was not as present at COP26 as at COP24 and COP25, its influence on the discourse lasted. This is also supported by the distance score between Fridays for Future 2019 discourse, the peak year of the movement and COP26 discourse, which is also 0.44. So, again, it seems although the movement  receded  somewhat  from  the  COP  as  an  event,  the  normative  frames  of  the movement still influenced the COP26 discourse. This suggests that Fridays for Future shifted the discourse with a lasting effect and that it established itself as an actor that can set the frames of how we think about climate change.\n\n572\n\n573\n\n574\n\n575\n\n576\n\n577\n\n578\n\n579\n\n580\n\n581\n\n582\n\n583 584\n\nFigure 1: Jensen-Shannon Distance score measuring semantic discourse similarity. Bigger (darker red) numbers indicate greater distance, smaller number (lighter red) greater similarity.\n\nWe can zoom into the specific discourses to further understand how the discourses compare. 585 For that purpose, we will look at the Fridays for Future 2021 and the COP26 (2021) discourse, 586 focusing on the normative topics for COP26 (red in Table 1). In Figure 2 and 3 both discourses 587 are shown as semantic networks.  When looking closer at the COP26 normative discourse 588 (Figure 2) we see that the anti-fossil fuel norm is quite strongly present with calls for phasing 589 out  fossil  fuels  (with  a  strong  focus  on  coal),  ending  subsidies  for  the  fossil  fuel  industry, 590\n\nAdditionally, among the earlier COPs before the ascent for the Fridays for Future movement, COP21 when the Paris Agreement was signed, has the greatest discourse similarity with the Fridays  for  Future  discourses.  This  suggests  that  the  discourse  that  resulted  in  the  Paris Agreement was quite distinct and that the normative frames that appear in the Fridays for Future discourse were also particularly pronounced at COP21. They were then again to some extent abandoned in the subsequent two years, and regained influence with the appearance of the youth climate activists in 2018.\n\n591\n\n592\n\n593\n\n594\n\n595\n\n596\n\n597\n\n598\n\n599\n\ncriticizing  their  lobbying  power,  accusing  fossil  fuel  companies  such  as  Exxon  Mobile  of pushing humanity to the brink (bottom pink, orange cluster). In the upper dark grey cluster, we see a norm emerging around preserving and protecting the planet that is linked to a duty of care  for  future  generations  and  young  people  and  children  alive  today,  a  theme  strongly advocated by Sir David Attenborough. Climate justice references appear in the blue cluster in the middle, a cluster that also references youth. The human right theme appears within the dark blue cluster above and features indigenous activists and other civil society actors pushing the  human  rights  agenda.  Stopping  deforestation  (green  cluster)  features  strongly  in  this normative discourse as well.\n\n<!-- image -->\n\n600 Figure 2: COP26 Semantic Network of Normative Topics. Nodes are words, with more central, frequent 601 words  appearing  larger,  and  edges  representing  collocations  of  words.  Colour  are  representing  fine602 grained topic clusters. 603\n\n604\n\n<!-- image -->\n\nFigure  3:  FFF2021  Semantic  Network.  Nodes  are  words,  with  more  central,  frequent  words  appearing larger, and edges representing collocations of words. Colour are representing fine-grained topic clusters.\n\n609\n\nWhile the Fridays for  Future  2021  discourse  features  themes  that  are  similar  to  the  ones 610 described above for COP26, e.g. human rights (turquois topic cluster, left bottom), protecting 611 forests (green cluster), climate justice (with purple cluster in the middle and red cluster top 612 right  including  #climatejustic,  #cllimatejusticenow  and  #climatecompensation),  saving  and 613 protecting the planet for the future (orange cluster, bottom), anti-fossil fuel norms (e.g. stop 614 fossil fuel, orange cluster), there are also dissimilarities. The Fridays for Future 2021 discourse 615 features much more grievances (e.g. #nomoreemptypromises, blue cluster), which we do not 616 see within the COP26 semantic network to this extent. It is also much more willing to formulate 617 system critique (e.g. #uprootthesystem, red topic cluster, right top) in response to the climate 618 crisis and discuss alternatives such as a green new  deal (#GNDE,  blue cluster, 619 #greennewdeal, red cluster). Listen to science (between the green and purple cluster, middle), 620 a  normative  demand,  the  movement  made  from  the  beginning,  is  also  missing  within  the 621 COP26 discourse. Overall, it appears Fridays for Future was successful in setting or boosting 622 normative themes around (1) duty of care for the planet and ultimately for our children and 623 future generations, linked to intergenerational justice, (2) human rights, i.e. responsibility to 624 protect the planet in order to protect humans and their rights (incl. right to life) around the world 625 and  (3)  anti-fossil  fuel  norms,  i.e.  necessity  to  abandon  fossil-fuel-based  practices  and 626 industries that endanger human life (see also Spaiser et al. (2022)). 627\n\n628\n\n## Actors of Change (SNA) 629\n\nThe focus of our second research question is on the actors, as we want to understand who is 630 driving normative discussions around the annual UNFCCC conferences and how influential 631 they are. Table 2 below provides an overview of the bipartite networks for each COP between 632 2014 and 2021 with a summary description. The nodes represent either normative topics 633 (green), regular users (purple) or influencers (orange). The edges are colored based on the 634 edge target, so green if it's a user-to-topic or influencer-to-topic edge, purple if it's user-to-user 635 edge, or influencer-to-user edge, and orange if it's a user-to-influencer edge or influencer-to636 influencer  edge,  where  the  influencers  are  users  in  the  99 th percentile  of  betweenness 637 centrality in the retweet network, irrespective of their engagement with the normative topics. 638 Across all COPs, while only a tiny proportion (around 1%) of users in the bipartite network 639 were also influencers, among the 50 top influencers almost all interacted at least once with a 640 normative topic (see Supplementary Information, Table S2). 641\n\n642\n\nTable 2: COP20 - COP26 Combined Bipartite Graphs Overview (Detailed Descriptions in Supplementary 643 Information) 644\n\n\n## COP20 (2014)\n\n\n<!-- image -->\n\nFossil Fuel Phaseout (FF Phaseout) had the greatest number of user interactions, strong overlap with the Protest topic, in terms of user interaction. Centrally integrated orange cluster. User nodes with highest page rank: LimaCOP20, CFigueres (Christiana Figueres, then UNFCCC president) and collinrees (environmental campaigner). 0.95% of the user nodes in the bipartite network were influencers. 38% of these influencers interacted with the FF Phaseout, 30% with Protest, 13% with Future Generations. Core influencers: johnlundin (Colombian Environmental Activist), NiliMajumder (Gender Equality Advocate), collinrees, jorgejhms (Peruvian Environmental Activist), ineeshadvs (Qatar-based climate advocate), SaleemulHuq (Director at ICCCAD, Senior Associate at IIED) and duycks (Senior Attorney, CIEL)\n\n\n## COP21 (2015)\n\n\n<!-- image -->\n\n<!-- image -->\n\n<!-- image -->\n\n<!-- image -->\n\n\n## COP24 (2018)\n\n\n<!-- image -->\n\nConsiderable overlap between most of the normative topics, with Future Generations and Fossil Fuel (FF) Problem being the largest. International Space Station (ISS) topic at the bottom right, more separated but with links through users to Future Generations, FF Problem, and Human Rights. Separate orange cluster with some links to Human Rights, Indigenous Communities, and ISS. User nodes with highest page rank: UNFCCC, COP21, UN. 1.44% of the bipartite user nodes were influencers, with the majority interacting with the Future Generations (28%), FF Problem (25%), and Indigenous Communities (23%) topics. Core influencers: NiliMajumder, IENearth (Indigenous Environmental Network), ineeshadvs, johnlundin, @DrSimEvans (journalist), 350 (global climate grassroots movement), and Climat21 (Citizen COP21 Coalition, France)\n\nDistinct clusters around normative topics, all interlinked. Indigenous Communities, Future Generations and FF Problem most popular. The YOUNGO Loss and Damage (L&amp;D) topic has a considerable overlap with the Future Generations in terms of interacting users. Centrally integrated orange cluster. User nodes with highest page rank: Connect4Climate (World Bank Trust Fund), UNFCCC, and UNEP. 1.92 % of user nodes in the bipartite network were influencers. The majority of these interacted with the FF Problem (27%), Future Generations, (24%) and Indigenous (20%) topics. Core Influencers: NiliMajumder, ineeshadvs, takvera (climate activist), PriceofOil (campaign), 350, estherclimate (climate campaigner), UNYouthEnvoy SIDS central normative topic, alongside FF Problem, Indigenous Communities, and Future Generations, all strongly interlinked. Mostly integrated orange cluster, with strong links to SIDS and some links with Future Generations. User nodes with highest page rank: PEspinosaC (Patricia Espinosa, then UNFCCC president), GlobalGoalsUN, and Momentum\\_UNFCCC. 0.85% of bipartite user nodes are influencers, with 56% of these interacting with the SIDS topic, and 22% with the FF Problem topic. Core Influencers: nolenen (feminist human-rights activist), HansLak (campaigner), collinrees, SaleemulHuq, COP23, BonnGlobal (Federal City of Bonn), FoEint (Friends of Earth International), takvera, ProfStrachan (researcher)\n\nAttenborough, Thunberg, and FF Problem largest topics, all strongly interlinked. Attenborough cluster somewhat distinct, but has especially many links to other topic clusters, showing strong resonance with users across all normative topics. Centrally integrated small orange cluster. User nodes with highest page rank: COP24, UN, UNFCCC, and PEspinosaC. 0.36% of the bipartite user nodes were influencers, interacting primarily with FF Problem (32%) and Thunberg (29%) topic, only 7% interacted with the Attenborough topic. Core Influencers: collinrees, EWestaway (Food Health SDG campaigner), SaleemulHuq, RalienBekkers (climate action advocate), GretaThunberg, ProfStrachan, takvera, natalieben (Green Party peer), ExtinctionR (Extinction Rebellion)\n\n645\n\n646\n\n647\n\n648\n\n649\n\n650\n\n651\n\n652\n\n653\n\n654\n\n655\n\n656\n\n657\n\n658\n\n659\n\n660\n\n661\n\n662\n\n663\n\n664\n\n665\n\n666\n\n667\n\n<!-- image -->\n\n\n## COP26 (2021)\n\n\n<!-- image -->\n\nThunberg's speech central node, sharing connections to almost all the smaller normative topics, showing strong resonance with users across all normative topics. Separate orange cluster with some links to FF Problem and UN General Secretary speech. Purple pockets indicate intensive interaction of regular users outside normative topics. User nodes with highest page rank: CMNUCC, COP25CL (COP25 Chile), mitecogob (Spanish ministry for ecological transition). 0.53% of bipartite user nodes were influencers, primarily interacting with FF Problem (27%), Future Generations (24%), and UN General Secretary speech, referencing youth activists (12%). Core Influencers: HansLak, parents4futureG, EllyanneCGithae (11-y. o. Africa's Climate Change Ambassador), collinrees, SaleemulHuq, ElmGrace (young climate justice advocate), vanessa\\_vash (Vanessa Nakate), GretaThunberb\n\nIndigenous Communities and Attenborough speech largest topic clusters. All normative topics strongly interlinked. Large separate orange cluster with strong links to Attenborough speech, Future Generations, Indigenous Communities and some links to SIDS. Purple pockets indicate intensive interaction of regular users outside normative topics. User nodes with highest page rank: Greta Thunberg, COP26\\_Coalition (climate justice coalition), and vanessa\\_vash (Vanessa Nakate, youth climate activist from Uganda). 1.02% of bipartite users were influencers, 57% interacting with the Indigenous and 19% with the SIDS topic. Core Influencers: Eco1stArt (ecological artist), UNBiodiversity, SaleemulHuq, Global Canopy (NGO against deforestation), collinrees, CANIntl (Climate Action Network International), GretaThunberg, vanessa\\_vash, LossandDamage (Loss and Damage Collaboration)\n\nNote: core influencers were involved repeatedly and in various normative debates (see Supplementary Information for details).\n\nThese seven combined retweet and bipartite networks across the seven COPs between 2014 and 2021 allow us to understand the changes over time in terms of how various actors have engaged  with  normative  themes.  In  the  earlier  COPs  we  see  actors  being  more  evenly distributed across various normative themes, while in the later COPs more central normative topics appear that attract large proportions of actors, for instance Indigenous Communities, David Attenborough Speech (with strong reference to duty of care for children) and SIDS in COP26. Quite notable is COP25, where the concentration of user interactions with the Greta Thunberg Speech theme is dominating the bipartite network.\n\nTo answer the question of who is driving the normative discourse, we need to pay attention to the influencers, who engage intensely with normative topics. Throughout all the COPs these are campaigners, activists, advocates, NGOs etc., some of whom, such as Saleemul Huq (Director  at  the  International  Centre  for  Climate  Change  and  Development  (ICCCAD)  in Bangladesh),  Collin  Rees  (Campaigner  at  Price  of  Oil),  have  been  a  normative  force throughout. These normative entrepreneurs receive support from some journalists (Thomas L.  Friedman,  Simon  Evans,  Megan  Rowling,  Adam  Vaughan),  researchers  and  research institutions (Michael E. Mann, Stockholm Environment Institute, Peter Strachan), UN bodies and officials (UN, UNFCCC, UNICEF) and even some industry sectors (e.g. @feeasso (Wind Energy), @InSunWeTrust (solar energy), Climate Bonds Initiative, KPMG, We Mean Business Coalition). Support from policy makers on the other hand has been rare and until recently\n\ncame usually from green parties, e.g. Elizabeth May (Green Party Canada), Christine Milne 668 (Green Party Australia), Denis Baupin (Green Party France), Natalie Bennett (Green Party 669 UK).  Youth  climate  activists  joined  the  diverse  group  of  norm  entrepreneurs  from  COP24 670 onwards and their influence has been growing ever since. So much so, that in the case of 671 COP25  they  (Greta  Thunberg,  Vanessa  Nakate)  along  with  other  climate  justice  groups 672 (COP26\\_Coalition) have become genuinely central discursive actors with page ranks scores 673 that surpass even official Twitter accounts that usually dominate. And at COP26 we have also 674 seen  a  few  more  policy  makers  (not  just  from  the  Green  Parties),  and  core  negotiators 675 adopting  and  diffusing  normative  frames,  such  as  Zac  Goldsmith  (UK  Minister  for  the 676 International  Environment  and  Climate),  Nicola  Sturgeon  (First  Minister  of  Scotland),  Alok 677 Sharma (UK COP26 President) or Nigel Toping (COP26 Champion). In fact, already at COP25 678 we begin to see some change, in terms of more official political bodies (e.g. EU Commission's 679 Directorate-General  for  Environment)  and  representatives  (e.g.  Gonzalo  Muñoz  Abogabir, 680 COP25 Champion) joining normative debates, often explicitly interacting with youth climate 681 activists'  themes.  They  are  not  driving  the  normative  debate,  but  they  are  very  important 682 multipliers and connectors. 683\n\n684\n\n## Discussion 685\n\n686\n\nWith respect to our first research question: To what extent has the normative discourse of 687 Fridays for Future permeated the global climate politics discourse around the annual UNFCCC 688 conferences?, we can answer that we clearly see evidence (topic modelling results, Jensen689 Shannon Distance scores, semantic network comparison) that the normative discourse of the 690 youth  climate  activists  permeated  the  global  climate  politics  discourse  around  the  annual 691 UNFCCC conferences. Their climate justice normative framework around duty of care for the 692 most vulnerable, which include our children, but also climate change victims in the Global 693 South, the responsibility  to  prevent  harming  them, has  resonated  strongly,  with  a  peak  at 694 COP25 and a more indirect, diffused continuation at COP26. They were also instrumental in 695 further strengthening anti-fossil fuel norms that are already present at COP20, linking them 696 explicitly to the duty of care norm, i.e. making clear that continuation of a fossil-fuel based 697 economy is incompatible with caring for children and other climate change victims. 698\n\n699\n\n700\n\n701\n\n702\n\n703\n\n704\n\n705\n\n706\n\n707\n\n708\n\n709\n\n710\n\n711\n\n712\n\n713\n\n714\n\n715\n\n716\n\n717\n\n718\n\nThe success of the youth climate activists can be attributed to them making use of a range of tactics, from  information  politics  and  symbol  politics,  where  they  linked  the  scientific information on climate change with their story as children and climate change victims, betrayed by world leaders, i.e. making use of leverage politics by mobilising shame as well as holding world  leaders  accountable  to  their  Paris  Agreement  commitments  (accountability  politics). Their  normative  framework  is  also  appealing  as  it  builds  on  existing,  well  established normative frames such as human rights and duty of care for children (outside climate change politics) (see also Spaiser et al. 2022). Over the course of the COPs since 2018 they were not only able to gather attention to their message and set agendas but also to influence discursive positions and persuade as other powerful actors were increasingly starting to reference their normative message. Of course, we need to be careful with causal claims, which are difficult to establish in this complex process of how humanity comes to terms with climate change. Also, it seems unlikely that a tipping point has been reached yet. Still, at more recent COPs some government bodies and representatives (and not just from SIDS countries and Green parties) are  starting  to  reference  the  youth  climate  activists'  and  other  normative  narratives. Governments will observe the shifting in the discursive positions (e.g. away from attempting to\n\naccommodate for\n\nfossil fuel\n\nindustry's interest\n\nas incompatible\n\nwith duty\n\nof care/responsibility to protect) and hence necessarily in the overtone window of policies they\n\nare increasingly expected to adopt by the public.\n\n719\n\n720\n\n721\n\n722\n\n723\n\n724\n\n725\n\n726\n\n727\n\n728\n\n729\n\n730\n\n731\n\n732\n\n733\n\n734\n\n735\n\n736\n\n737\n\n738\n\n739\n\n740\n\n741\n\n742\n\n743\n\n744\n\n745\n\n746\n\n747\n\n748\n\n749\n\n750\n\n751\n\n752\n\nOur results also show that the influence of the new normative frames is strongest, where multiple actors join forces and reinforce each other's message, e.g. youth activists, global south activists, SIDS representatives, indigenous communities, VIPs from media/culture (e.g. David Attenborough), faith leaders, politicians, astronauts. And this brings us to our second research question, who are the key actors driving the change around the annual UNFCCC conferences?  Youth  climate  activists  were  not  only  successful  in  establishing  normative alliances with various other climate justice campaigners and promoters, but they were also successful  in  gaining  support  from  influential  figures  and  organisations,  who  helped  the movement to diffuse its normative messages, such as David Attenborough, Antonio Guterres (UN Secretary General), Gonzalo Muñoz Abogabir (COP25 Champion), Alok Sharma (COP26 president),  various  NGOs  (e.g.  European  Climate  Foundation,  Ecologistas,  Power  Shift Africa).  Norm  champions  outside  of  the  movement  bring  increased  legitimacy  and  wider awareness of the norms of climate justice and duty of care that the youth movements try to progress. These influential norm champions can be key connectors diffusing new normative frames to key players in the global climate change politics arena.\n\nThere are limitations to what we can conclude from the data we have. Not only are causal inferences  not  possible  in  this  complex,  multiple  feedback  systems  and  with  explorative analysis of observational data, but Twitter data is also limited. The most influential actors and decision makers might not be as visible on this social media platform, as they may not engage at all (e.g. David Attenborough) or engage very minimally with the Platform (e.g negotiators). Negotiations are taking place often behind closed doors and negotiators are not allowed to tweet  about  negotiations,  hence  it  is  difficult  to  establish  what  influence  the  (normative) discourse has on the actual negotiations. Having interviewed a key member from the COP26 UK executive team however, it seems these normative frames have an influence, a quote from an interview highlights this: 'They [climate activists] have a big impact partly because they become the photo, (…) on the front page of the newspaper or Twitter.  And it's because they are more visual than lots of people sitting in a room. (…) And I think clever negotiators and officials use that. (…). Like Alok Sharma (…), he was an MP from Reading. He thought about climate change, cared about climate change, but wasn't a climate warrior or anything. And then the more you learn about it, the more it gets under your skin and you can't help yourself. (…) Engagement with indigenous communities and young people definitely make a difference. Made a difference in him.' But more research needs to happen here.\n\n753\n\n## Conclusion 754\n\n755\n\n756\n\n757\n\n758\n\n759\n\n760\n\n761\n\n762\n\n763\n\n764\n\n765\n\n766\n\n767\n\n768\n\n769\n\nSpaiser  et  al.  (2022)  argue  that  the  Friday  for  Future  normative  framework  has  a  great potential to drive forward wider social change, building on recent analyses that explore the possibilities for positive social tipping dynamics that could stabilize the Earth's Climate (Otto et al. 2020). Otto et al. (2020) identified six social systems, where positive social tipping can occur, one of them being the norms and values system. Otto et al. (2020) write that norms spread through social networks leading to changes in perceptions, expectations and decision making. Social feedback contributes to norms becoming self-reinforcing. A critical condition is reached 'if the majority of social and public opinion leaders recognise the ethical implications of fossil fuels and generate pressure in their peer groups to ostracize the use of products involving fossil fuel burning' (ibid., p. 2360). Based on previous research they estimate that a committed minority of roughly 25% would be sufficient to tip dominant social conventions and established behaviours (although an even smaller minority of 3-16% is required to initiate the new norm). Furthermore, once moral norms start to influence legislation further spreading of the new norm can be achieved.\n\n770\n\n771\n\n772\n\n773\n\n774\n\n775\n\n776\n\n777\n\n778\n\n779\n\n780\n\n781\n\n782\n\n783\n\n784\n\n785\n\n786\n\n787\n\n788\n\n789\n\n790\n\n791\n\n792\n\n793\n\n794\n\n795\n\n796\n\n797\n\n798\n\n799\n\n800\n\n801\n\n802\n\n803\n\nNorm entrepreneurs such as social movements and norm champions, which can be opinion leaders, state actors etc. have an important role to play in reaching the critical condition. At early stage the norm is likely to diffuse from norm champions to norm champions to early adopters, who share a common identity with the norm champions. Once a critical mass of actors have adopted a norm, a cascade will be triggered whereby most of the remaining actors will rapidly adopt the norm (Green 2018). Even countries, who strongly rely on fossil fuels for instance are likely to adopt the norm as the social costs for failing to adopt the norm will become unbearably high once only very few countries remain, who hold out. Civil society and social movements within the late adopter countries can further help to tip them toward norm adaptation (ibid.). However, for the successful tipping to occur in the first place, Otto et al. (2020) stress that substantial political effort is required, as well as persistent pressure from civil  society,  especially  the  young,  intellectually  and  social  justice-oriented  groups,  who initiated the normative change in the first place (Strimling et al. 2019). This is particularly true as there are financially and politically very powerful actors involved, who so far were quite successful  in  preventing  effective  measures  to  stabilize  the  Earth's  climate  and  they  are pushing back against the new emerging norm and the actors, who promote it. They are the 'norm antipreneurs' (Bloomfield 2016) that invest lots of efforts in preventing the normative change and hence the social tipping among others by deploying 'moral' counter-frames that attempt to justify their harmful practices (e.g. helping the world's energy poor) (Green 2018).\n\nOur  research  shows  that  normative  change  has  been  set  in  motion  by  the  youth  climate activists in collaboration with other activists such as indigenous communities, as the norm entrepreneurs and that they were able to persuade important norm champions, such as Sir David Attenborough. But our research also shows that governments have not yet been moved to subscribe to this normative framework. One reason for this may be strong entanglements between various governments and the fossil fuel industry, who clearly promote various climate action delay narratives (Mann 2021) and hence act as powerful norm antipreneurs. Indeed, when looking at the topic space for COP24 and COP25, we see that at the same time as youth climate  activists  were  given  central  stage  for  their  normative  appeal,  a  reappearance  and strengthening of the denial topic occurred. This suggests the youth climate activists have also provoked a pushback from norm antipreneurs (Falkenberg et al. 2021) and then there was the disruption  of  the  normative  change  dynamics  set  in  motion  because  of  the  COVID-19 pandemic, clearly visible in the change of topic space between COP25 and COP26.\n\n804\n\nFuture research should focus on understanding how tipping is delayed by norm antipreneurs 805 and how this can be averted. Indeed, as Nyborg et al. (2016) note, before a tipping occurs 806 'awareness  of  others'  non-adoption  tends  to  work  against  change'  (p.43).  Green  (2018) 807 believes  that  civil  society  will  be  crucial  here  too  to  undermine  opponents'  counter808 mobilisation, because activist groups have considerable discursive and symbolic power. In the 809 battle over ideas and legitimacy the morally based frames of climate activists have a clear 810 argumentative advantage (Strimling et al. 2019) and threaten to stigmatize and delegitimise 811 powerful players such as fossil fuel companies. If tipping in the social system of norms and 812 values succeeds then the normative change can amplify many other social tipping processes 813 (Otto et al. 2020), such as the tipping in financial markets, making investments in fossil fuels 814 morally untenable or even illegal. The exact mechanisms of these coupled tipping processes 815 should be a focus of future research. What is clear, however, is that the normative system is 816 quite a central social domain that has strong links to all other domains and can amplify the 817 tipping  processes  in  the  other  domains,  as  norms  define  which  behaviors,  policies  and 818 decisions are acceptable in the first place. 819\n\n820",
         "Youth  Climate  Activists  are  an  important  norm entrepreneur  as  humanity  is  increasingly awakening  to  the  realities  of  accelerating  climate  change.  They push  for  seeing  climate change not merely through cost-benefit analysis frames but through frames of multiple climate justices  and our  responsibility  to  protect  the  most  vulnerable,  including  our  own  children, against the unfolding climate crisis. But how successful have these activists been in shifting perspectives  in  the  context  of  international  climate  politics,  where  often  the  fundamental parameters are set for national climate politics? Here we computationally investigate to what extent the normative framework advanced by this movement is increasingly penetrating the international public  climate  debate,  changing  arguments, priorities, and  frames used  at international climate policy negotiations hosted by UNFCCC and we investigate the key actors pushing for normative change. We find that indeed the normative framework advanced by the movement has successfully penetrated the discourse around UNFCCC and that youth climate activists  were  able  gain  support  from  norm  champions  furthering  their  cause  and  further contributing  to  the  diffusion  of  their  normative  framework. We  also  find  that  their  normative framework is slowly starting to spread among government actors.",
         ""
        ],
        [
         "49",
         "49",
         "## Theoretical background\n\n\nMore than in other forms of work, the activities of experts are shaped by the shared values of the expert community of which they are a member (Bechky, 2011; Van Maanen &amp; Barley, 1984). Experts take on these values in a long process of socialization into such a community (Anteby, 2013; Becker et al., 1961). The close connection to the values of their community helps  experts  to  carry  out  their  work  conscientiously  and  consistently,  even  in  the  face  of external pressure or criticism. For example, in her study of a crime laboratory, Bechky (2020) shows how a group of experts-firearms examiners-mobilized their shared values in order to defend themselves against the political demand for a reform of their expert practices.\n\nFor  some  time  now,  there  has  also  been  research  investigating  the  extent  to  which shared values might not always be helpful but can also cause problems in the everyday work of experts (Augustine, 2021; Huising, 2015). A typical source of problems is when the values of experts come into conflict with the values and goals of important stakeholders such as clients or  superiors.  Previous  research  has  examined  these  conflicts  and  how  they  are  dealt  with, particularly in direct, personal interactions. For example, Chan and Hedden (2023) show that the core values of career counsellors in business schools often diverge from the values of the students who seek their advice. In order not to risk complaints to the school's management, experts try to anticipate value conflicts and situationally adapt their expert advice. Similarly, DiBenigno  (2020)  describes  conflicts  between  mental  health  experts  and  their  military superiors in the U.S. Army. In order for military superiors to accept the work of mental health experts,  the  experts  deliberately  signal  that  their  values  are  aligned  with  the  values  of  the military (e.g., by participating in strenuous exercises).\n\nExpert values also play an important role for the new phenomenon of algorithmic expert services.  Contrary to the image that many of these service providers convey to the outside world, algorithmic expert services do not completely take the human experts out of the loop. Instead, human expert work is shifted from direct interaction with clients seeking help to the back office of the algorithmic expert service. Here, the human experts work continuously but largely  invisibly  on  the  development  and  maintenance  of  the  computational  systems  that deliver  algorithmic  expert  advice  to  the  clients'  digital  devices  (Jaton,  2021;  Justesen  &amp; Plesner, 2024). Previous research on algorithmic expert services has shown how the values of back office experts have helped them accomplish their tasks. When problems occur, these are primarily 'normal, natural troubles' (Bittner &amp; Garfinkel, 1967, p. 187) that arise from the routines of everyday work and do not call the experts' core values into question. For example,\n\nSachs (2020) studied the work of art history experts in the back office of an algorithmic service that helps users to develop their taste in art. She describes how the experts use their shared values to classify artworks and artists. In particular, these shared values help the experts to understand  and  resolve  'breakdowns'  (2020,  p.  1693)  in  which  the  algorithmic  system produces what they consider to be incorrect expert advice.\n\nSo far, however, little is known about the extent to which the values of  back office experts can lead to more substantial conflicts with important stakeholders. One source of these conflicts,  which  is  specific  to  algorithmic  (in  contrast  to  human)  expert  services,  is  what Pfotenhauer and colleagues (2022, p. 4) describe as the 'scalability zeitgeist'. An insatiable 'appetite for scaling and monopoly', the authors argue, can be seen as the 'key ordering logic of  current  initiatives  in  innovation  and  public  policy'  (2022,  pp.  3-4).  According  to  this ordering logic the most important thing for the commercial success of a digital innovation is to gain  a  large  number  of  users  quickly.  The  viability  of  the  business  model  and  the  actual satisfaction of user needs become secondary to scaling. In the development of digital products and  services,  the  quest  for  scalability  means  that  development  is  never  complete,  but  that experiments are constantly being carried out to see which features and changes will keep more users  engaged  for  longer  (Marres  &amp;  Stark,  2020;  Rahman,  Weiss,  &amp;  Karunakaran,  2023). Seaver (2019) provides a particularly vivid description of the scalability zeitgeist in his study on  the  developers  of  algorithmic  services  for  recommending  music.  He  describes  how  the developers make it their goal to develop systems for 'getting people hooked' (2019, p. 3), although they are aware that the 'retention' of users is not synonymous with their 'satisfaction' (2019, p. 11; see also Pronzato, 2023).\n\nSince  the  experts  in  the  back  office  of  algorithmic  expert  services  have  no  direct interaction with clients, it is a great challenge for them to identify and adapt their advice to the needs of individual users (see Pakarinen &amp; Huising, 2023). In addition, many of the algorithmic expert services we see today are organized as profit-oriented companies. It therefore seems very likely that these companies are strongly influenced by scalability thinking. Back office experts  in  these  companies  are  thus  confronted  with  the  requirement  to  continuously experiment with the algorithmic expert advice in order to make it as captivating as possible. At the same time, the shared values of the back office experts provide them with rigid constraints on the kind of advice they can give with a clear conscience. To better understand this state of affairs, this study examines how human experts in the back office of an algorithmic expert service  deal  with  tensions  between  their  expert  values  and  the  scalability  imperative  often associated with digital innovation.\n\n\n## Methods\n\n\n\n## Agricultural extension as expert service\n\n\nAgricultural extension-broadly understood as the transfer of knowledge and technology from agricultural science to agricultural practitioners-is a centuries-old form of expert service. As such, it plays a central role in improving productivity and, more recently, other dimensions of agricultural systems (e.g., sustainability) by supporting farmers with expert advice. From the mid-19th century to the end of the 20th century, agricultural extension agents worked almost exclusively for the state. They usually had a high level of academic training (e.g., in agronomy, biology or chemistry), and enjoyed high social prestige. Contemporary sociological studies also describe how extension agents mobilize the materiality of farms to convince farmers of certain  products  or  procedures  (Henke,  2008;  Le  Velly  &amp;  Goulet,  2015),  for  example,  by measuring nitrate levels in the soil to persuade farmers to use less fertilizer. These credentials and abilities helped, and still help, human extension agents to establish expert authority over farmers  and  induce  behavioral  changes.  With  this  in  mind,  historians  and  anthropologists studying agricultural extension attribute the emergence of contemporary productivist agriculture in large part to the ongoing modernization efforts of extension agents (Jas, 2005; Scott, 1998).\n\nHowever, this state-funded model of agricultural extension was inevitably associated with high costs for the respective governments. As a result, state agricultural extension services have come under increasing criticism for failing to reach  all farmers in need of  advice. In response to such criticisms, as of the early 1990s the field of agricultural extension started to become privatized  (Labarthe  &amp;  Laurent,  2013)-a  trend  that  also  took  hold  in  developing countries (Feder, Birner, &amp; Anderson, 2011). By generating new incentives for innovation, the partial privatization of the agricultural extension sector provided an important breeding ground for the emergence of mobile (and eventually algorithmic) extension services such as the one at the center of this study.\n\nIn the mid-2000s, companies began to develop agricultural extension services based on classic cell phones-a development that can be viewed as the first wave of mobile agricultural extension  services.  These  companies  set  out  to  leverage  the  increasing  penetration  of  cell phones  in  rural  areas  to  create  new  markets  for  the  sale  of  information  services.  These companies  oftentimes  motivated  their  business  activities  with  a  critical  assessment  of traditional  extension  services:  As  they  put  it,  most  in-person  agricultural  expert  advice\n\n(especially in poor countries) was of low quality (e.g., 'biased', 'unscientific', 'outdated') or simply nonexistent. In view of this situation, they went on to argue, mobile advisory services would permit the delivery of science-based expert advice to a wide audience in a cost-efficient way.  In  contrast  to  the  lofty  promises  of  these  companies,  both  development  scholars (Baumüller, 2017) and anthropologists (Stone, 2011) documented that these companies often had difficulties providing effective extension services. Reasons for this were, for example, that farmers did not see the advice of these companies as expert advice, that farmers did not want to pay for the offered services or that the companies were unable to properly monitor the effect of their services at a distance.\n\nWith the proliferation of smartphones in ever more rural areas around the world, the market for mobile agricultural extension services gained new momentum. As an example, in a 2019 Science article, economists Fabregas, Kremer, and Schillbach pointed out that '[m]obile technologies, particularly smartphones, have the potential to bring sophisticated science-based agricultural advice to smallholder farmers to improve productivity' (2019, p. 1). To explain this enthusiasm: The key difference between cell phone-based and smartphone-based extension services is that the latter typically deploy algorithms to transform data that is collected with the help of the smartphone into expert advice. This novelty of smartphone-based mobile extension is reflected in a semantic shift that often accompanies these algorithmic expert services: Mobile extension services for cell phones were mainly portrayed as new means of delivering the advice of human experts to their clients. The providers of mobile extension services for smartphones, however, frequently promote their algorithms as experts in their own right-a typical hallmark of what we refer to as algorithmic expert services.\n\n\n## An algorithmic expert service for agricultural extension: The case of PHYTØ\n\n\nThe algorithmic expert service at the center of this article is the smartphone app PHYTØ which is developed by the German startup FLORA. The app's expert service consists of diagnosing plant damages based on digital images of symptoms and providing advice on treatment and prevention (see Heimstädt, 2023a). At the time of writing PHYTØ covers 500 different plant damages on 30 different  crops and has been downloaded about 15  million times. The vast majority  of  PHYTØ  clients  are  located  in  India,  where  conditions  for  the  provision  of smartphone-based  agricultural  extension  are  particularly  favorable  (see  Heimstädt,  2023b): well-developed mobile internet, high smartphone coverage in rural areas, relatively inexpensive  mobile  data,  many  smallholder  farmers  (potential  clients),  and  strong  political\n\nsupport for digital agriculture. Given this regional focus, FLORA is headquartered in Germany and additionally operates two regional offices in India.\n\nAs is typical for algorithmic expert services, FLORA portrays PHYTØ as a replacement for human experts, as this can be seen as one of the unique selling points of these services. This is very clear in public accounts by or about the startup, where the app is variously described as 'digital plant expert', 'mobile crop doctor', 'digital expert in your pocket', 'crop doctor app' or  'pocket  agronomist'.  However,  also  typical  of  algorithmic  expert  services,  on  closer examination, it becomes clear that FLORA does not completely take human experts out of the loop. Instead, the work of these experts is shifted to the back office and delivered to clients via a digital interface.\n\n\n## Data collection and analysis\n\n\nTo investigate this problem, we mobilize data from the first author's doctoral dissertation in which he reconstructed the development of FLORA from the startup's foundation in 2014 to the year 2022 (Heimstädt, 2022). Ethnographic data collection took place between 2018 and 2022. In order to reconstruct the development of the startup, this ethnographic data collection involved three different data sources. One important data source was observational data from the startup's offices in Germany and in India, as well as from accompanying the startup's staff during various field trips. Another data source was interviews with the startup's staff and users of the app. A third data source was archival data (e.g., business plans, pitch decks, onboarding documents, and press articles) which, in addition to retrospective interviews, were particularly important for reconstructing the development of the startup before 2018.\n\nFor this study, we analyzed the parts of this larger data set which provide information about the work of the so-called 'plant team', a group of back office experts made up of staff with academic backgrounds in fields providing  them with plant expertise, such as biology, agronomy or geography. The overall task of the plant team is to prepare the plant-related expert advice that PHYTØ displays to its users, and to find the best way to display this advice to the app's clients after a successful algorithmic diagnosis.\n\nOur analytical process consisted of three phases. In the first phase, we openly coded the data with the broad intention to understand how the members of the plant team prepare the expert advice to be provided to farmers by the app. From this, we learned that over the lifespan of the startup, the plant team experimented with very different approaches to providing expert advice.  We  understood  that  the  team  sometimes  discontinued  advisory  features  of  the  app\n\nand-more often-added new or reconfigured existing ones. In the second phase, we looked more closely at the way the plant team explained and motivated these changes.  During this phase, we learned that for the members of the plant team, the approach to providing expert advice is closely linked to one of their core values, namely reducing the environmental damage caused by agricultural pesticide use. At the same time, their approach to providing advice is also shaped by their regular exposure to management demands for better scalability of advice. In the third phase, we divided our data into three 'temporal brackets' (Langley, 1999) in order to  better  understand  the  'trial  of  strength'  (Latour,  1987,  p.  78)  between  expert  value  and scalability thinking, and how the outcome of this trial materialized in the app's algorithmic expert advice at different points in time. As a result, we found that each temporal bracket is characterized  by  a  different  interpretation  of  the  plant  team's  core  value,  and  a  resulting materialization of that interpretation in how the app represents its algorithmically delivered advice. Specifically, in the first bracket, the app's representation of advice revolves around 'home remedies', in the second around 'personalized advice', and in the third around 'the right pesticides'. To better understand, compare, and contrast these brackets, we used a set of guiding questions: What characterized the representation of expert advice provided by the plant team in each bracket? How does the representation of expert advice in each bracket express the core value of the plant team? How does the representation of expert advice in each bracket respond to management's demand for scalability? At the end of this phase, we were able to reconstruct how exactly the expert advice of the app changed over time, and how the tension between expert values and scalability has shaped this change process.\n\n\n## Findings\n\n\n\n## Replacing pesticides through home remedies\n\n\nDuring my earlier fieldwork visits to the FLORA offices, I occasionally picked up the term 'home remedies' in the plant team's conversations. 1  As I could not quite grasp the meaning of this term, one day I took the team's lead plant pathologist aside and asked him to clarify. He explained  to  me,  that  since  the  beginning  of  the  app  home  remedies  constituted  a  key component of the expert advice that the plant team prepared and deployed in the app. Loosely rooted in discourses around organic farming, his team used the term home remedies to refer to do-it-yourself mixtures of non-chemical ingredients that they assumed clients would have at\n\nhome or could easily obtain, such as horsetail broth or soap solution. This was nothing unusual, I  was further explained, even the Food and Agriculture Organization of the United Nations (FAO) would recommend home remedies in regions where agricultural inputs were difficult to obtain. In technical terms, to promote home remedies, FLORA designed the app so that after a successful diagnosis, clients would be directed to an encyclopedia entry prepared by the plant team.  This  encyclopedia  entry,  created  by  copying  and  slightly  editing  parts  of  text  from scientific literature, was intended to provide users with all the information they needed about the treatment of the diagnosed disease.\n\nIn developing this way of representing advice, the plant team was guided by a shared expert value: PHYTØ's advice should reduce the environmental damage caused by agricultural pesticide use. In the view of the plant team, their recommendations for home remedies were a promising  way  of  putting  this  value  into  practice,  as  they  believed  that  these  treatment suggestions would discourage farmers from using chemical pesticides. In an interview for a gardening blog from that time, one of the co-founders of FLORA summarized this idea as follows: 'By publicizing ecological alternatives to chemical plant protection products via the app, everyone can contribute to a more environmentally friendly approach to plant diseases'. A TV report from 2015 featuring PHYTØ gives a more concrete impression of how the plant team  initially  envisioned  these  ecological  alternatives:  The  report  features  three  amateur gardeners  who  are  jointly  testing  PHYTØ  in  a  small  kitchen  garden.  Accompanied  by  the camera,  the  three  gardeners  discover  that  one  of  their  zucchini  plants  is  infested  with  an unknown pest. With the help of information provided by PHYTØ, they arrive at the diagnosis that  the  zucchini  is  infested  by  spider  mites.  Once  this  diagnosis  is  established,  one  of  the gardeners goes on to read out the 'biological advice' that the app recommends as a treatment, namely that they should apply 'garlic tea'. Subsequently, the voice of the narrator of the report steps in to clarify the advantages of this treatment: 'Most of what you need can be found in every  household.  In  no  time  at  all,  Sina  [the  gardener]  has  a  remedy  ready  to  chase  the troublemakers away from the zucchini. Very important, without chemicals!'\n\nHowever, putting their core value of reducing pesticide use into practice was not the only concern shaping the work of the plant team at the time. Back then, the founders of FLORA received a grant from the German government for scientific spin-offs, which provided them with  both  financial  support  and  coaching  sessions  for  future  entrepreneurs.  Through  this coaching, the FLORA team learned that in order to attract funding for the further development of the app, they needed to demonstrate to potential investors that their innovation was valuable. They also learnt that, as PHYTØ was still in its early stages, it was not yet expected that they\n\nwould be able to present a profitable business model for this purpose. Instead, they were made aware  that  metrics  such  as  user  numbers  and  'user  retention'  were  important  sources  of information for potential investors at this stage, in order to assess the future value of the app. This expectation was also passed on to the plant team, who were optimistic that their advice on home remedies would be able to meet it. In particular, the plant team believed that potential clients would see a cost advantage in home remedies over chemical pesticides-as they would have to pay little or nothing for their ingredients-which in turn would turn many of them into regular PHYTØ users. As one member of the plant team put it: 'These things work perfectly at almost no cost. And that's the important thing'.\n\nYet, despite this strong initial focus of PHYTØ on home remedies, the plant team did not completely exclude chemical pesticides from the app's advice. More specifically, the plant team decided against completely excluding chemical pesticides from the app's expert advice, as they feared that the app's advice might otherwise put off users who were very accustomed to  using  these  substances.  Instead,  they  presented  the  provision  of  advice  on  chemical pesticides as a means of attracting as many clients as possible in order to gradually guide them towards the use of home remedies. A vivid example of this reasoning is the following quote in which the head of the plant team explains what consequences could be expected if they did not provide content on chemical pesticides:\n\nWe're losing the opportunity to pull people who swear by chemical treatment or who do it because that's the way they have always done it, onto 'the right side,' in quotation marks.\n\nAs this quote illustrates, the decision to include chemical pesticides in the app's advice must also be interpreted as a response to management's demand to the plant team to fill the app with expert advice that would help to scale up PHYTØ's user base. The quote highlights that at this stage the plant team saw chemical pesticides as being as fundamentally at odds with their expert value of reducing environmental damage caused by agricultural pesticide use. However, they justified the recommendation of these substances as a necessary intermediate step in realizing their expert value by convincing clients of home remedies-an ambiguous configuration of expert advice the plant team could live with.\n\nHowever, much to the disappointment of the FLORA management, and contrary to the expectations of the plant team, farmers were not very receptive to PHYTØ's home remedybased advice. This was evident, among other things, in a metric that FLORA's experts referred to as 'user retention', which measures the amount of time users spend scrolling and clicking through the app. As this metric demonstrated, despite the plant team's best efforts to create\n\nscientifically sound encyclopedia entries on home remedies and other treatments, users did not really  engage  with  the  app,  that  is,  they  did  not  read  its  expert  advice.  One  of  PHYTØ's developers, who worked intensively on the app's representation of expert advice, summarized the realization at the time as follows:\n\nWe cannot be like Wikipedia, like we have been doing so far, like: 'Here you go this is the information, read it and make up your mind after you read it.' We need to be more actionable.\n\nHence, the fact that farmers did not read PHYTØ's expert advice represented a challenge in the plant team's thinking about the provision of expert advice in at least two ways. Firstly, farmers' lack of interest in PHYTØ's expert advice meant that the app did not induce the hopedfor  behavioral  changes and thus failed to realize the plant team's expert value of reducing environmental damage caused by agricultural pesticides. Secondly, the unsatisfactory use of PHYTØ  jeopardized  the  financial  basis  for  the  continued  existence  of  the  app,  as  it compromised FLORA's anticipated ability to raise funds to develop the app further. As a result of this educationally and financially dissatisfying use of PHYTØ, the plant team eventually began to conceive of a different, 'more actionable' way of representing advice in the app.\n\n\n## Reducing pesticides through personalized advice\n\n\nA few months after the disappointment over the home remedies, I had the opportunity to sit in on a meeting in which members of the plant team outlined their progress in developing the new way of representing advice in PHYTØ. The core of this new way of representing advice, as the presenters  made  clear,  should  be  'personalized'  recommendations  for  improved  farming practices. The redesign of PHYTØ was therefore meant as an expansion of the advice given to users following a successful diagnosis, in that it included not only treatment recommendations, but also recommendations for agricultural practices to be carried out throughout the growing cycle. Examples of advice on such practices include advice on how to best select seeds, water one's crops or plough one's field in order to minimize the use of pesticides. Technically, the provision of this way of representing advice was to be achieved by redesigning the app so that it would request additional data from clients (e.g., climate zone, cultivated crops, sowing date) in order to subsequently provide them with recommendations tailored to this data. As described in an onboarding document for new employees, this advice should no longer be presented to clients in the form of lengthy encyclopedia-like entries, but in the form of short, illustrated texts called 'events'. Furthermore, the document specifies that '[i]n a cropping cycle from about 3 to 4 months' clients should be provided with '30 to 40 events for each crop'. So rather than\n\nproviding clients with all the expert advice on their chosen crops at once, the plant team sought to improve the user retention of the app by delivering the advice in small chunks throughout the growing season.\n\nAlthough this second way of representing PHYTØ's advice was very different from the plant team's representation of expert advice in the first phase, they still felt that it was in line with  their  core  expert  value  of  reducing  the  environmental  damage  caused  by  agricultural pesticide use. In justifying how PHYTØ's reconfigured representation of advice would help to realize this value, the plant team regularly drew a link between their advisory efforts and current debates on  'precision agriculture'. This means that during this phase, in line with broader precision agriculture discourses, the plant team  regularly emphasized  that the app's personalized advice should help ensure that clients only apply fertilizers and pesticides 'where they are needed, and when they are needed' (Bongiovanni &amp; Loewenberg-DeBoer, 2004, p. 359). Hence, in contrast to the home remedy phase, the focus of the plant team in this phase was no longer on preventing users from using chemical pesticides by showing them alternatives to  these  substances,  but  on  making  their  pesticide  use  more  efficient.  The  plant  team  thus distanced  itself from  the  relatively  strong  opposition  to chemical  pesticides  that  had characterized the first phase; whereas in the first phase chemical pesticides were seen as an undesirable intermediate step to bind clients to home remedies, in the second phase they were seen as a legitimate treatment, provided they were used in moderate doses.\n\nIn order to achieve this, the plant team planned that the advice of PHYTØ should be displayed to clients at an ideal moment in the growing cycle (e.g., an event dealing with weed control,  at  a  time  when  it  is  advisable  from  an  agronomic  point  of  view  to  engage  in  this practice).  For  this,  the  app  was  redesigned  to  collect  two  additional  types  of  data  from  its clients.  For  one,  data  about  the  sowing  or  planting  date  of  their  crops.  For  another,  it  was designed in such a way that it could deduce the climate zone in which users operated from their geolocations. Next, using the sowing or planting date provided by a given client and average climate zone-specific growth rates for the crops selected by that client, the feature was designed to calculate the approximate growth stage (e.g., seedling, tillering, stem extension) that the client's crop should be in at a given point in time after the provided sowing or planting date. As a hypothetical example, it might be recorded in the app that it is advisable to perform weed control on corn in the stem extension stage. Accordingly, the app would send users events related  to  chemical  or  biological  weed  control  as  soon  as  it  has  concluded  via  the  method specified above that the corn plants of the corresponding client should now be in the stem extension stage.\n\nIn addition to reducing the negative environmental impact of their clients' practices, the plant team envisioned that their increased efforts to personalize PHYTØ's advice would also increase  their  clients'  productivity.  Specifically,  they  assumed  that  PHYTØ's  personalized advice would optimize their clients' pesticide use so that the same or even a higher yield could be achieved with fewer pesticides. As with the home remedies before, they assumed that this would lead to increased earnings and cost savings on the part of clients, which would entice farmers to use the app and thus contribute to its scaling.\n\nEven  though  the  plant  team  put  a  lot  of  work  into  the  development  of  PHYTØ's personalized advice, the advice did not perform as expected. To the continued disappointment of FLORA's management, as with the home remedies before, user numbers and user retention remained low. This prompted the FLORA team to send a crew consisting of members of the plant team and several UX researchers to India-the country where most PHYTØ users were located-to find out in face-to-face interactions with farmers why users did not engage with the app. As one of the UX researchers summarized in an interview, they realized on the trip that with their personalized advice, instead of increasing PHYTØ's user retention, they were 'losing the user'. One important reason for this, which they identified on the trip, was that the intended  personalization  of  PHYTØ's  advice  did  not  work  as  expected.  More  specifically, FLORA found that it was more difficult than originally anticipated to determine the growth stage of their clients' crops, as well as other environmental factors, at a distance, that is, via a digital interface. In the following quote, a long-standing member of the plant team sums up the increased complexity brought about by FLORA's aim to provide its clients with personalized advice:\n\nWhen you deal with a disease, it's a one-factor thing. You take a picture, you have a disease, you apply your treatment [...]. The [new representation of advice] is a multi-factor [problem]. You have the soil, you have the watering, you have the nutrients, you have, you know, a lot of management things.\n\nThis increased complexity resulted in allegedly personalized advice being displayed to clients at inappropriate times in the growing cycle, causing them to lose interest in the app. As a result, the developers saw the expert status they claimed for the app in jeopardy. This was a problem for the plant team, as it prevented them from realizing their expert value, but more importantly for FLORA's current and potential investors, as it reduced the future value of the application. In view of this twofold problem, the plant team eventually decided to stop working on advice in the form of personalized recommendations for agricultural practices  and to focus on the\n\ndevelopment of a new advisory feature in which concise pesticide recommendations should play a much more important role.\n\n\n## Ranking the right pesticides\n\n\nDuring my visit to one of the FLORA offices in India, a group of FLORA employees from Germany happened to be travelling to the same office. To my surprise, one of the reasons for their visit was that they wanted to conduct interviews with the owners of small pesticide shops in  the  vicinity  of  the  FLORA  office.  However,  as  I  was  busy  at  the  time  collecting  data regarding FLORA's interaction with farmers, I did not pay much attention to these interviews. It was only a few weeks later, during another visit to the German FLORA office, that I found out that the interviews with the pesticide dealers were intended to examine the feasibility of a possible business model for PHYTØ. This business model envisaged turning PHYTØ into a platform  for  brokering  pesticide  sales  between  farmers,  pesticide  dealers  and  pesticide manufacturers-a business model that went hand in hand with a new representation of advice that the plant team prepared in the back office of the startup. This new representation of advice was intended to guide clients to choose 'the right pesticides' among the many different ones available on the market. To this end, PHYTØ was redesigned so that, following a successful diagnosis, it would provide clients with lists of both chemical and (where available) biological pesticides. In the next step, clients were asked to select the pesticide that best suited their needs from these lists. Hence, in this phase, the plant team moved away from the more prescriptive advice  in  the  form  of  recommendations  for  home  remedies  or  allegedly  personalized recommendations for agricultural practices that had characterized the previous phases and took a less prescriptive approach by offering clients a range of biological and chemical pesticides from which to choose.\n\nDespite  this  much  greater  endorsement  of  chemical  pesticides  compared  to  earlier phases, the plant team continued to believe that their work on the app would help to put into practice their core value of reducing environmental damage caused by agricultural pesticide use. To substantiate this claim, the plant team began to adopt a particular framing of Indian farmers. This framing consisted of portraying the pesticide use of their actual and potential clients as fundamentally flawed. The classic examples they gave to illustrate this flawed nature were that farmers would usually mix many different pesticides irresponsibly, would use poor quality pesticides (e.g., adulterated pesticides) or simply use the wrong pesticides. The plant team therefore argued that if they were able to dissuade farmers from these flawed practices,\n\nthey  would  already  be  making  a  contribution  to  reducing  the  environmental  impact  of agriculture.  An  illustrative  example  of  this  way  of  thinking  is  the  following  quote  from  a member of the plant team:\n\nIndian farmers don't need us to make wrong decisions, they are making wrong decisions the whole time. We are here to improve a chaotic situation. So, like, if you are in the chaos, there are not many things that you can do wrong.\n\nIt  was against the background of this framing that the plant team viewed its expert task of identifying  the  right  pesticides  for  a  given  plant  disease.  As  was  regularly  emphasized  in interviews with members of the plant team, identifying the right pesticides was a multi-step process. It began with a review of country-specific regulatory documents to gain an overview of the products registered in India. However, given the large number of pesticides registered in India, a second step taken by the plant team to further narrow down the list of pesticides to be recommended  by  PHYTØ  was  to  subject  this  initial  selection  to  additional  regulatory frameworks from countries, regions or organizations whose approach to pesticides the startup considered to be more stringent. In other words, the plant team saw their expert work as using PHYTØ's advice to enforce external pesticide-related regulatory frameworks in India. Finally, as a third step in compiling PHYTØ's pesticide lists, the FLORA team asked local expertsfor example, agricultural extension workers or professors-to further narrow down the lists of pesticides that the startup had compiled. In this process, the experts were given a fairly free hand, meaning that FLORA did not have a highly formalized process according to which the experts were to select the pesticides to be recommended by the app. Rather, they were asked to  use  their  professional  experience  to  determine  which  pesticides  would  work  well  in  the countries or regions for which they were responsible.\n\nThis selection process often resulted in the plant team considering not one, but several pesticides as recommendable for treating a particular plant disease. However, the problem with this  approach  of  recommending  several  pesticides  was  that  the  experts  of  the  plant  team considered some of the listed pesticides to be more recommendable than others (e.g., because they were less toxic). With this in mind, the plant team began to rank the pesticide lists that PHYTØ displayed to clients, so that pesticides they considered more recommendable were displayed higher up and pesticides they considered less recommendable were displayed lower down. In other words, they were trying to nudge their clients to use the pesticides they thought were most appropriate, without excluding pesticides they thought were less than ideal but still 'right' for the job. The strategy of presenting the app's pesticide recommendations in the form\n\nof  rankings  must  therefore  also  be  seen  as  a  strategy  through  which  the  plant  team  subtly expressed its core value. A vivid example of this is the following quote, in which the head of the plant team expresses his team's strong support for biopesticides, while at the same time expressing his concern 'not to exclude anyone' by not recommending chemical pesticides:\n\nWe said: Hey, we always try to present the biological ones a little more prominently, that is, to put them in the first place, for example, and still show the whole range of treatment options, from preventive to biological to chemical, so as not to exclude anyone.\n\nApart from the realization of their expert values, the fact that the plant team issued ranked lists of  pesticides  rather  than  individual,  unambiguous  pesticide  recommendations  must  also  be interpreted as a direct response to the imperative of scalability with which the plant team was confronted.  PHYTØ's  new  platform  business  model  envisioned  that  after  a  successful diagnosis, clients would be referred to pesticide dealers near their farms, who would then sell the pesticides that clients had chosen from the app's lists to those clients. This transaction was to be free for farmers and pesticide retailers and monetized through commissions that FLORA planned to collect on the additional pesticide sales generated by the app's recommendations for  agrochemical  companies.  In  this  business  model,  the  lists  created  by  the  plant  team represented a means of scaling up PHYTØ's user base in two respects. On the one hand, the lists  should help to  increase the number of PHYTØ users, as they no longer recommended home  remedies  or  personalized  advice  regarding  agricultural  practices,  which  were  far removed from the everyday practices of farmers in India, but pesticides that were already an integral part of their everyday practices. On the other hand, the lists were intended to help scale up PHYTØ's user numbers by not privileging one pesticide manufacturer but offering many manufacturers a platform to sell their products, thus turning the app into a single gateway to all sorts of pesticides.\n\nThis  third  way  of  representing  PHYTØ's  expert  advice  ultimately  proved  to  be successful in the eyes of the plant team and FLORA's management. An initial sign of success was a substantial increase in the number of PHYTØ users and pesticide sales brokered through the  app.  Even  greater  proof  of  this  success,  in  the  eyes  of  FLORA's  management  and  the broader startup world, was the fact that the startup was acquired by the major distributor of agrochemicals  and  fertilizers  AGRO-TRADE  [a  pseudonym]  in  2023.  In  a  press  release following  the  acquisition,  AGRO-TRADE's  Head  of  Corporate  Development  explicitly pointed  out  that  PHYTØ  bridges  the  gap  between  scalability  and  positive  environmental impact.\n\nWe are proud to partner with PHYTØ, which already serves nearly six million farmers in India. With  AGRO-TRADE's global network,  we  will  grow PHYTØ's  presence  to  support  more farmers.  At  the  same  time,  AGRO-TRADE expands its agricultural technology capabilities digital  technology  to  reduce  resource  use  in  agriculture  and  especially  the  misuse  of  crop protection products\n\nAs this press release shows, the plant team's latest interpretation of their core value perfectly matched the agrochemical distributors' interpretation of how agricultural pesticide use should be transformed. So, it is fair to say that the app's way of representing expert advice has changed drastically since its early days, when it used to recommend garlic tea and other home remedies to give farmers an alternative to the agrochemical industry. Curiously, however, the core value of  the  plant  team's  experts-reducing  the  negative  environmental  impact  of  agricultural pesticide use-has remained the same.\n\n\n## Discussion and future research\n\n\nThe  objective  of  this  study  was  to  analyze  how  human  experts  in  the  back  office  of  an algorithmic expert service deal with tensions between their expert values and the imperative of scaling. We explored this question through a case study of the agricultural algorithmic expert service PHYTØ. We found that the experts developing PHYTØ operated in a constant state of tension between their core value of reducing the environmental damage caused by the use of pesticides in agriculture and the demands of the startup's management to develop advice that is appealing to the greatest number of users-demands rooted in investor-induced scalability thinking. Our findings show that the experts navigated this tension by repeatedly embracing their core value (i.e., emphasizing their intention to reduce environmental damage caused by agricultural pesticide use), while simultaneously changing their interpretation of this core value and  its  subsequent  translation  into  corresponding  representations  of  advice  in  the  app's interface.  The  result  of  these  cycles  of  embracing  and  reinterpreting  was  to  find  a  way  of providing algorithmically mediated expert advice that would reconcile the plant team's core value  and  management's  demand  for  scalability.  In  more  detail,  our  results  identify  three phases. In each of these phases, the back office experts tested a different way of representing their algorithmic expert service in vivo , by exposing it to real users. In the first two phases, the representations of advice (one centered on 'home remedies' and one on 'personalized advice') resulting from the interpretation and reinterpretation of the plant team's core value failed these tests,  leading  the  experts  to  reconsider.  It  was  only  in  the  third  phase  that  the  plant  team's\n\nreinterpretation of their core value-now  centered  on  brokering  sales of 'the right pesticides'-led to a representation of PHYTØ's advice that satisfied management's demands for scalability. In summary, then, FLORA's experts navigated the tension between their expert value and their management's scalability thinking by performing what might be referred to as moral  acrobatics,  maintaining  outward  adherence  to  their  core  value  while  bending  the interpretation of that value to justify their companies' efforts.\n\nAs such, our study contributes to the debate on how shared values shape the work of experts  in  and  around  organizations  (Bechky,  2011;  Van  Maanen  &amp;  Barley,  1984),  and  in particular to the question how experts can handle value conflicts with key stakeholders (Chan &amp; Hedden, 2023; DiBenigno, 2020). In one sense, the problem faced by  the plant  team is similar  to  the  problems  faced  by  the  experts  studied  by  Chan  and  Hedden  (2023)  and DiBenigno (2020), in that in all cases the expert communities analyzed are confronted with powerful clients who (in part) seem not to share their core values. However, it is also quite different because, to use the terminology proposed by Chan and Hedden (2023), FLORA's experts must 'discern' their clients' values through a digital interface, without face-to-face interaction,  and  can  only  'modulate'  their  value  enactments  through  adaptations  of  that interface.\n\nGoing even further, the question arises as to whether it is even appropriate to speak of manifest value conflicts in the case of FLORA. This is due to the fact that most of what the plant team discerns as the values of their clients is mediated by metrics and does not result from situated interactions with these clients. Based on the information they have, the plant team cannot be sure that the reason why certain farmers have stopped using PHYTØ or never used it in the first place is because of value conflicts. However, the plant team's reinterpretations of their core value suggest that experts working from the back office may easily interpret metric results  such  as  low  user  retention  as  value  conflicts  and  adjust  their  services  accordingly. Furthermore, the case of PHYTØ shows that experts who develop and maintain algorithmic expert services from the back office have great difficulty in taking into account the values of individual  clients.  Rather  than  precisely  discerning  the  values  of  individual  clients  and modulating  their  services  accordingly,  it  shows  that  the  experts  in  the  back  offices  of algorithmic expert services can only respond to anticipated value conflicts by making quite generalized changes to their representations of advice in the interface of their digital service. In short, the ability of experts who develop algorithmic expert services to discern their clients' values currently seems very limited, and their mechanisms for modulating their values, and\n\nthus their  services,  based  on  this  limited  knowledge  of  their  clients'  values  currently  seem rather crude.\n\nThe alleged conflict of values between experts and users is not the only conflict of values that has shaped the development of PHYTØ. Even more influential, perhaps, was the conflict between the plant team's core value and the values of another powerful stakeholder group, FLORA's management and, by extension, FLORA's investors, which manifested itself in the scalability imperative under which the plant team was constantly operating. Our analysis of the case of FLORA thus provides an insightful contribution to the discussion of whether expert advice can be scaled using algorithmic technologies. An important contribution to this debate comes from Pakarinen and Huising (2023), who argue that algorithmic technologies cannot scale expert advice because human experts will always be needed to adapt the outputs of  algorithms  to  the  situated  needs  of  clients-a  problem  they  refer  to  as  the  'translation challenge' (2023, p. 15). Our findings shed a slightly different light on the debate by showing that the use of algorithmic technologies can actually help to make expert advice available to a wider audience. There is no denying that, in just a few years, the developers of FLORA have succeeded in providing 'almost six million farmers' with a particular kind of expert advice, namely advice on 'the right pesticides'.\n\nHowever, and more in line with Pakarinen and Huising's (2023) argument, our findings also suggest that this act of making expert advice available to a wider audience simultaneously affects the quality of the expert advice offered. More specifically, it seems that the proliferation of algorithmic expert services such as PHYTØ are contributing to what we call a massification of expert advice. This means, on the one hand, that a hitherto underserved mass of clients is provided  with  advice  that  can  still  be  considered  expert  advice,  for  example  because  it  is factually correct or because it conforms to the conventions of certain expert groups (e.g., inhouse  chemists  in  the  agricultural  industry).  On  the  other  hand,  compared  to  advice  from human experts, this expert advice is very likely to be less adapted to the situational needs of individual clients and thus of lower quality. Moreover, in  line with this neglect of clients' situated needs, the massification of expert advice also means that it may seem increasingly rational to providers of such advice to recommend products and procedures that do not require much recognition of situated needs. In the case of FLORA, this was clearly demonstrated by the gradual approximation of PHYTØ's representation of advice to the standardized products and  associated  procedures  of  the  agrochemical  industry,  that  is,  by  the  intertwinement  of PHYTØ  with  the  'thinking  infrastructures'  (Kornberger  et  al.,  2019)  of  global  pesticide markets (e.g., toxicity standards).\n\nGiven that algorithmic expert services are often targeted at populations that would not otherwise have access to expert advice, for example because they cannot afford it or because it is  not  available in their region of  the world (see Fabregas et al., 2019), it is likely that the proliferation of these services will lead to a client-side stratification of expert advice in society (see Abbott, 1988). This stratification consists of wealthy clients or clients born in a certain region of the world, benefiting from the situated and ideally more independent advice of human experts, while the rest of the world's population (assuming they have access to digital devices) receives the probably correct but certainly less situated and often less independent advice of algorithmic expert services. This stratification can occur both within a country or region of the global North and between countries of the global North and the global South, thus perpetuating or reinforcing historical patterns of inequality. Overall, this insight casts serious doubt on the claim made by many proponents of algorithmic expert services that these technologies can 'democratize' the provision of expert advice.\n\nOur  investigation  of  an  algorithmic  expert  service  offers  many  avenues  for  future research, three of which shall be highlighted here as particularly promising. Firstly, it seems important to analyze algorithmic expert services not only in their development, but also in their use. This line of work could address questions such as: How do clients integrate algorithmic expert services into their everyday work or private life? What practical problems arise in the process? What unintended forms of use arise? Secondly, it seems fruitful to analyze algorithmic expert services in other areas of society in order to identify similarities and differences to their use in agriculture. Possible areas of interest include dating advice, financial advice or medical advice.  Thirdly,  it  seems  crucial  to  understand  the  relationship  between  the  providers  of algorithmic expert services and the established experts challenged by them. Will the emergence of algorithmic expert services lead to a further differentiation or transformation of the work of human experts? Are new forms of collaboration emerging? These are just some of the questions that should help us to better understand how algorithmic expert services will contribute to the transformation of expert work in and around organizations.\n\n",
         "In many areas of life, people who search for expert advice can now obtain it through algorithmic expert services. With these services, expert advice is generated by an algorithmic system and provided over a digital interface. Human experts disappear from direct interaction with clients, but instead orchestrate the algorithmic generation of expert advice from the back office of these services. Algorithmic expert services are often associated with the hope of making expert advice available to a large number of clients in a profitable way. However, this expectation is challenged by research on the role of shared expert values in and around organizations. In this study, we therefore explore how human experts in the back office of algorithmic expert services deal with tensions between their expert values and the imperative of scaling. Empirically, we draw on ethnographic material from a startup developing an algorithmic expert service for agriculture. We find that the human experts in the back office experience tension between their core value (i.e., reducing the environmental damages caused by pesticides) and managerial demands to maximize the app’s user retention. The experts navigate this tension by constantly experimenting with new representations of advice in the app’s interface, a process in which they repeatedly embrace their core value while simultaneously reinterpreting it, until they eventually find a way of representing advice that accommodates both their core value and the monopolistic tendencies of digital capitalism. Our study thus contributes to debates about whether expert advice can be scaled up by organizations using algorithmic means, and the role of values therein.",
         ""
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 1000
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>## FROM SOVEREIGNTY TO EXTRATERRITORIAL CONSCI...</td>\n",
       "      <td>In this article, Victor Fan argues that analys...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>## 1. Introduction\\n\\n\\nAn Electronic Health R...</td>\n",
       "      <td>Problem definition: Physicians spend more than...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>## Introduction\\n\\n\\nTranslation  plays  an  i...</td>\n",
       "      <td>Literary translation is one of the most challe...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>## 1 Problem Setup\\n\\n\\nRecent political scien...</td>\n",
       "      <td>There is a long-running debate on evaluating f...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>## INTRODUCTION\\n\\n\\nThis  article  investigat...</td>\n",
       "      <td>Recently, ‘bimajyo’ (美魔女) came into focus in J...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>## Methods\\n\\n\\n\\n## Sample\\n\\n\\nOur data come...</td>\n",
       "      <td>Demand for democratic accountability in polici...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>## Introduction\\n\\n\\nCanada is a high-income c...</td>\n",
       "      <td>Canada’s employment standards laws and mandato...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>## Introduction\\n\\n\\nCultural studies has ofte...</td>\n",
       "      <td>Cultural studies has often favoured a Foucauld...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>## 1. Introduction\\n\\n\\nTwentieth century plan...</td>\n",
       "      <td>Vehicular air pollution has created an ongoing...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>## 1. Introduction\\n\\n\\nLongleaf pine ( Pinus ...</td>\n",
       "      <td>For the last several decades, a substantial am...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     paper_id                                               text  \\\n",
       "0           0  ## FROM SOVEREIGNTY TO EXTRATERRITORIAL CONSCI...   \n",
       "1           1  ## 1. Introduction\\n\\n\\nAn Electronic Health R...   \n",
       "2           2  ## Introduction\\n\\n\\nTranslation  plays  an  i...   \n",
       "3           3  ## 1 Problem Setup\\n\\n\\nRecent political scien...   \n",
       "4           4  ## INTRODUCTION\\n\\n\\nThis  article  investigat...   \n",
       "..        ...                                                ...   \n",
       "995       995  ## Methods\\n\\n\\n\\n## Sample\\n\\n\\nOur data come...   \n",
       "996       996  ## Introduction\\n\\n\\nCanada is a high-income c...   \n",
       "997       997  ## Introduction\\n\\n\\nCultural studies has ofte...   \n",
       "998       998  ## 1. Introduction\\n\\n\\nTwentieth century plan...   \n",
       "999       999  ## 1. Introduction\\n\\n\\nLongleaf pine ( Pinus ...   \n",
       "\n",
       "                                               summary clean_text  \n",
       "0    In this article, Victor Fan argues that analys...             \n",
       "1    Problem definition: Physicians spend more than...             \n",
       "2    Literary translation is one of the most challe...             \n",
       "3    There is a long-running debate on evaluating f...             \n",
       "4    Recently, ‘bimajyo’ (美魔女) came into focus in J...             \n",
       "..                                                 ...        ...  \n",
       "995  Demand for democratic accountability in polici...             \n",
       "996  Canada’s employment standards laws and mandato...             \n",
       "997  Cultural studies has often favoured a Foucauld...             \n",
       "998  Vehicular air pollution has created an ongoing...             \n",
       "999  For the last several decades, a substantial am...             \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f349cc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m summarizer \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msummarization\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfacebook/bart-large-cnn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m summaries \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\30109302\\AppData\\Local\\anaconda3\\envs\\my-env\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:942\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    941\u001b[0m     model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[1;32m--> 942\u001b[0m     framework, model \u001b[38;5;241m=\u001b[39m \u001b[43minfer_framework_load_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43madapter_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43madapter_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    949\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    950\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    952\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m    953\u001b[0m hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_commit_hash\n",
      "File \u001b[1;32mc:\\Users\\30109302\\AppData\\Local\\anaconda3\\envs\\my-env\\Lib\\site-packages\\transformers\\pipelines\\base.py:243\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03mSelect framework (TensorFlow or PyTorch) to use from the `model` passed. Returns a tuple (framework, model).\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;124;03m    `Tuple`: A tuple framework, model.\u001b[39;00m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tf_available() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_available():\n\u001b[1;32m--> 243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one of TensorFlow 2.0 or PyTorch should be installed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    245\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo install PyTorch, read the instructions at https://pytorch.org/.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    247\u001b[0m     )\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    249\u001b[0m     model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_pipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m task\n",
      "\u001b[1;31mRuntimeError\u001b[0m: At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/."
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "summaries = []\n",
    "for text in df['text']:\n",
    "    result = summarizer(text, max_length=150, min_length=40, do_sample=False)\n",
    "    summaries.append(result[0]['summary_text'])\n",
    "\n",
    "df['generated_summary'] = summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdf1e34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0+cpu\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7de08e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
